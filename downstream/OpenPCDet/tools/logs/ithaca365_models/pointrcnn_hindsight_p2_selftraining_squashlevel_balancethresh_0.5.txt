+ NGPUS=4
+ PY_ARGS='--cfg_file cfgs/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5.yaml --ckpt ../output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/ckpt/checkpoint_epoch_4.pth --ckpt_save_interval 1 --wandb_project pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5 --set DATA_CONFIG.DATA_PATH ../data/ithaca365_pl_hindsight_p2_balancethresh_0.5'
+ true
+ PORT=50753
++ nc -z 127.0.0.1 50753
++ echo 1
+ status=1
+ '[' 1 '!=' 0 ']'
+ break
+ echo 50753
50753
+ python -m torch.distributed.launch --nproc_per_node=4 --rdzv_endpoint=localhost:50753 train.py --launcher pytorch --cfg_file cfgs/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5.yaml --ckpt ../output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/ckpt/checkpoint_epoch_4.pth --ckpt_save_interval 1 --wandb_project pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5 --set DATA_CONFIG.DATA_PATH ../data/ithaca365_pl_hindsight_p2_balancethresh_0.5
/home/tz98/anaconda3/envs/continual-da/lib/python3.8/site-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : train.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 4
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : localhost:50753
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_ow3_ex2j/none_nsmwek5b
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/home/tz98/anaconda3/envs/continual-da/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=localhost
  master_port=50753
  group_rank=0
  group_world_size=1
  local_ranks=[0, 1, 2, 3]
  role_ranks=[0, 1, 2, 3]
  global_ranks=[0, 1, 2, 3]
  role_world_sizes=[4, 4, 4, 4]
  global_world_sizes=[4, 4, 4, 4]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_ow3_ex2j/none_nsmwek5b/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_ow3_ex2j/none_nsmwek5b/attempt_0/1/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_ow3_ex2j/none_nsmwek5b/attempt_0/2/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_ow3_ex2j/none_nsmwek5b/attempt_0/3/error.json
2023-03-03 09:37:40,318   INFO  **********************Start logging**********************
2023-03-03 09:37:40,318   INFO  CUDA_VISIBLE_DEVICES=0,1,2,3
2023-03-03 09:37:40,318   INFO  total_batch_size: 8
2023-03-03 09:37:40,318   INFO  cfg_file         cfgs/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5.yaml
2023-03-03 09:37:40,318   INFO  batch_size       2
2023-03-03 09:37:40,318   INFO  epochs           10
2023-03-03 09:37:40,318   INFO  workers          4
2023-03-03 09:37:40,318   INFO  extra_tag        default
2023-03-03 09:37:40,318   INFO  ckpt             ../output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/ckpt/checkpoint_epoch_4.pth
2023-03-03 09:37:40,318   INFO  pretrained_model None
2023-03-03 09:37:40,319   INFO  launcher         pytorch
2023-03-03 09:37:40,319   INFO  tcp_port         18888
2023-03-03 09:37:40,319   INFO  sync_bn          False
2023-03-03 09:37:40,319   INFO  fix_random_seed  False
2023-03-03 09:37:40,319   INFO  ckpt_save_interval 1
2023-03-03 09:37:40,319   INFO  local_rank       0
2023-03-03 09:37:40,319   INFO  max_ckpt_save_num 30
2023-03-03 09:37:40,319   INFO  merge_all_iters_to_one_epoch False
2023-03-03 09:37:40,320   INFO  set_cfgs         ['DATA_CONFIG.DATA_PATH', '../data/ithaca365_pl_hindsight_p2_balancethresh_0.5']
2023-03-03 09:37:40,320   INFO  empty_cache_every -1
2023-03-03 09:37:40,320   INFO  max_waiting_mins 0
2023-03-03 09:37:40,320   INFO  start_epoch      0
2023-03-03 09:37:40,320   INFO  num_epochs_to_eval 0
2023-03-03 09:37:40,320   INFO  save_to_file     False
2023-03-03 09:37:40,320   INFO  wandb_project    pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5
2023-03-03 09:37:40,320   INFO  wandb_group      None
2023-03-03 09:37:40,320   INFO  hq_path          None
2023-03-03 09:37:40,320   INFO  cfg.ROOT_DIR: /home/tz98/projects/continual-DA/downstream/OpenPCDet
2023-03-03 09:37:40,320   INFO  cfg.LOCAL_RANK: 0
2023-03-03 09:37:40,320   INFO  cfg.CLASS_NAMES: ['car', 'pedestrian']
2023-03-03 09:37:40,320   INFO  
cfg.DATA_CONFIG = edict()
2023-03-03 09:37:40,320   INFO  cfg.DATA_CONFIG.DATASET: Ithaca365Dataset
2023-03-03 09:37:40,320   INFO  cfg.DATA_CONFIG.DATA_PATH: ../data/ithaca365_pl_hindsight_p2_balancethresh_0.5
2023-03-03 09:37:40,320   INFO  cfg.DATA_CONFIG.VERSION: v1.1
2023-03-03 09:37:40,321   INFO  cfg.DATA_CONFIG.MAX_SWEEPS: 1
2023-03-03 09:37:40,321   INFO  cfg.DATA_CONFIG.PRED_VELOCITY: False
2023-03-03 09:37:40,321   INFO  cfg.DATA_CONFIG.SET_NAN_VELOCITY_TO_ZEROS: True
2023-03-03 09:37:40,321   INFO  cfg.DATA_CONFIG.FILTER_MIN_POINTS_IN_GT: 1
2023-03-03 09:37:40,321   INFO  cfg.DATA_CONFIG.FOV_POINTS_ONLY: True
2023-03-03 09:37:40,321   INFO  cfg.DATA_CONFIG.CONSTANT_REFLEX: 100.0
2023-03-03 09:37:40,321   INFO  
cfg.DATA_CONFIG.DATA_SPLIT = edict()
2023-03-03 09:37:40,321   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train
2023-03-03 09:37:40,321   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val
2023-03-03 09:37:40,321   INFO  
cfg.DATA_CONFIG.INFO_PATH = edict()
2023-03-03 09:37:40,321   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['ithaca365_infos_1sweeps_train.pkl']
2023-03-03 09:37:40,321   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['ithaca365_infos_1sweeps_val.pkl']
2023-03-03 09:37:40,321   INFO  
cfg.DATA_CONFIG.LOAD_HISTORY = edict()
2023-03-03 09:37:40,322   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.LIMIT_NUM: 5
2023-03-03 09:37:40,322   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.VOXEL_SIZE: -1
2023-03-03 09:37:40,322   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.FORWARD_ONLY: True
2023-03-03 09:37:40,322   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.CACHE_ROOT: /scratch/hindsight_travis_cache/
2023-03-03 09:37:40,322   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.HISTORY_AUG: True
2023-03-03 09:37:40,322   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.DATA_PATH: ../data/ithaca365/v1.1/best_pos_history
2023-03-03 09:37:40,322   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [0, -40, -3, 90.4, 40, 1]
2023-03-03 09:37:40,322   INFO  cfg.DATA_CONFIG.BALANCED_RESAMPLING: False
2023-03-03 09:37:40,322   INFO  
cfg.DATA_CONFIG.DATA_AUGMENTOR = edict()
2023-03-03 09:37:40,322   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']
2023-03-03 09:37:40,322   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'DB_INFO_PATH': ['ithaca365_dbinfos_1sweeps_withvelo.pkl'], 'PREPARE': {'filter_by_min_points': ['car:5', 'truck:5', 'bus:5', 'pedestrian:5', 'bicyclist:5']}, 'SAMPLE_GROUPS': ['car:5', 'truck:5', 'bus:5', 'pedestrian:10', 'bicyclist:5'], 'NUM_POINT_FEATURES': 5, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': True}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.3925, 0.3925]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}, {'NAME': 'point_quantize', 'VOXEL_SIZE': 0.3}]
2023-03-03 09:37:40,322   INFO  
cfg.DATA_CONFIG.POINT_FEATURE_ENCODING = edict()
2023-03-03 09:37:40,322   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding
2023-03-03 09:37:40,322   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity']
2023-03-03 09:37:40,322   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity', 'timestamp']
2023-03-03 09:37:40,323   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'sample_points', 'NUM_POINTS': {'train': 16384, 'test': 16384}}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': False}}]
2023-03-03 09:37:40,323   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: cfgs/dataset_configs/ithaca365_dataset_hindsight.yaml
2023-03-03 09:37:40,323   INFO  cfg.DATA_CONFIG.GET_ITEM_LIST: ['points', 'p2_score', 'history_scans']
2023-03-03 09:37:40,323   INFO  cfg.DATA_CONFIG.LOAD_P2_SCORE: /home/kzl6/datasets/ithaca365/p2_score_fw70_5m_20hist
2023-03-03 09:37:40,323   INFO  
cfg.MODEL = edict()
2023-03-03 09:37:40,323   INFO  cfg.MODEL.NAME: PointRCNN
2023-03-03 09:37:40,323   INFO  
cfg.MODEL.HISTORY_QUERY = edict()
2023-03-03 09:37:40,323   INFO  cfg.MODEL.HISTORY_QUERY.NAME: SparseResUQueryNet
2023-03-03 09:37:40,323   INFO  cfg.MODEL.HISTORY_QUERY.history_backbone: Res16UNet14E
2023-03-03 09:37:40,323   INFO  
cfg.MODEL.HISTORY_QUERY.history_backbone_config = edict()
2023-03-03 09:37:40,323   INFO  cfg.MODEL.HISTORY_QUERY.history_backbone_config.bn_momentum: 0.05
2023-03-03 09:37:40,323   INFO  cfg.MODEL.HISTORY_QUERY.history_backbone_config.conv1_kernel_size: 3
2023-03-03 09:37:40,323   INFO  cfg.MODEL.HISTORY_QUERY.history_backbone_config.final_feature_size: 64
2023-03-03 09:37:40,323   INFO  cfg.MODEL.HISTORY_QUERY.simple_conv_kernel_size: 5
2023-03-03 09:37:40,323   INFO  cfg.MODEL.HISTORY_QUERY.extra_conv: False
2023-03-03 09:37:40,323   INFO  cfg.MODEL.HISTORY_QUERY.mode: update_point_features
2023-03-03 09:37:40,324   INFO  
cfg.MODEL.HISTORY_QUERY.P2_LOSS_CONFIG = edict()
2023-03-03 09:37:40,324   INFO  cfg.MODEL.HISTORY_QUERY.P2_LOSS_CONFIG.LOSS_FN: l1
2023-03-03 09:37:40,324   INFO  cfg.MODEL.HISTORY_QUERY.P2_LOSS_CONFIG.BALANCE_THRESHOLD: 0.5
2023-03-03 09:37:40,324   INFO  
cfg.MODEL.BACKBONE_3D = edict()
2023-03-03 09:37:40,324   INFO  cfg.MODEL.BACKBONE_3D.NAME: PointNet2MSG
2023-03-03 09:37:40,324   INFO  
cfg.MODEL.BACKBONE_3D.SA_CONFIG = edict()
2023-03-03 09:37:40,324   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.NPOINTS: [4096, 1024, 256, 64]
2023-03-03 09:37:40,324   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.RADIUS: [[0.1, 0.5], [0.5, 1.0], [1.0, 2.0], [2.0, 4.0]]
2023-03-03 09:37:40,324   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.NSAMPLE: [[16, 32], [16, 32], [16, 32], [16, 32]]
2023-03-03 09:37:40,324   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.MLPS: [[[16, 16, 32], [32, 32, 64]], [[64, 64, 128], [64, 96, 128]], [[128, 196, 256], [128, 196, 256]], [[256, 256, 512], [256, 384, 512]]]
2023-03-03 09:37:40,324   INFO  cfg.MODEL.BACKBONE_3D.FP_MLPS: [[128, 128], [256, 256], [512, 512], [512, 512]]
2023-03-03 09:37:40,324   INFO  
cfg.MODEL.POINT_HEAD = edict()
2023-03-03 09:37:40,324   INFO  cfg.MODEL.POINT_HEAD.NAME: PointHeadBox
2023-03-03 09:37:40,324   INFO  cfg.MODEL.POINT_HEAD.CLS_FC: [256, 256]
2023-03-03 09:37:40,324   INFO  cfg.MODEL.POINT_HEAD.REG_FC: [256, 256]
2023-03-03 09:37:40,324   INFO  cfg.MODEL.POINT_HEAD.CLASS_AGNOSTIC: False
2023-03-03 09:37:40,325   INFO  cfg.MODEL.POINT_HEAD.USE_POINT_FEATURES_BEFORE_FUSION: False
2023-03-03 09:37:40,325   INFO  
cfg.MODEL.POINT_HEAD.TARGET_CONFIG = edict()
2023-03-03 09:37:40,325   INFO  cfg.MODEL.POINT_HEAD.TARGET_CONFIG.GT_EXTRA_WIDTH: [0.2, 0.2, 0.2]
2023-03-03 09:37:40,325   INFO  cfg.MODEL.POINT_HEAD.TARGET_CONFIG.BOX_CODER: PointResidualCoder
2023-03-03 09:37:40,325   INFO  
cfg.MODEL.POINT_HEAD.TARGET_CONFIG.BOX_CODER_CONFIG = edict()
2023-03-03 09:37:40,325   INFO  cfg.MODEL.POINT_HEAD.TARGET_CONFIG.BOX_CODER_CONFIG.use_mean_size: True
2023-03-03 09:37:40,325   INFO  cfg.MODEL.POINT_HEAD.TARGET_CONFIG.BOX_CODER_CONFIG.mean_size: [[3.9, 1.6, 1.56], [0.8, 0.6, 1.73], [1.76, 0.6, 1.73]]
2023-03-03 09:37:40,325   INFO  
cfg.MODEL.POINT_HEAD.LOSS_CONFIG = edict()
2023-03-03 09:37:40,325   INFO  cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_REG: WeightedSmoothL1Loss
2023-03-03 09:37:40,325   INFO  
cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_WEIGHTS = edict()
2023-03-03 09:37:40,325   INFO  cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.point_cls_weight: 1.0
2023-03-03 09:37:40,325   INFO  cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.point_box_weight: 1.0
2023-03-03 09:37:40,325   INFO  cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
2023-03-03 09:37:40,325   INFO  
cfg.MODEL.ROI_HEAD = edict()
2023-03-03 09:37:40,325   INFO  cfg.MODEL.ROI_HEAD.NAME: PointRCNNHead
2023-03-03 09:37:40,325   INFO  cfg.MODEL.ROI_HEAD.CLASS_AGNOSTIC: True
2023-03-03 09:37:40,326   INFO  
cfg.MODEL.ROI_HEAD.ROI_POINT_POOL = edict()
2023-03-03 09:37:40,326   INFO  cfg.MODEL.ROI_HEAD.ROI_POINT_POOL.POOL_EXTRA_WIDTH: [0.0, 0.0, 0.0]
2023-03-03 09:37:40,326   INFO  cfg.MODEL.ROI_HEAD.ROI_POINT_POOL.NUM_SAMPLED_POINTS: 512
2023-03-03 09:37:40,326   INFO  cfg.MODEL.ROI_HEAD.ROI_POINT_POOL.DEPTH_NORMALIZER: 70.0
2023-03-03 09:37:40,326   INFO  cfg.MODEL.ROI_HEAD.XYZ_UP_LAYER: [128, 128]
2023-03-03 09:37:40,326   INFO  cfg.MODEL.ROI_HEAD.CLS_FC: [256, 256]
2023-03-03 09:37:40,326   INFO  cfg.MODEL.ROI_HEAD.REG_FC: [256, 256]
2023-03-03 09:37:40,326   INFO  cfg.MODEL.ROI_HEAD.DP_RATIO: 0.0
2023-03-03 09:37:40,326   INFO  cfg.MODEL.ROI_HEAD.USE_BN: False
2023-03-03 09:37:40,326   INFO  
cfg.MODEL.ROI_HEAD.SA_CONFIG = edict()
2023-03-03 09:37:40,326   INFO  cfg.MODEL.ROI_HEAD.SA_CONFIG.NPOINTS: [128, 32, -1]
2023-03-03 09:37:40,326   INFO  cfg.MODEL.ROI_HEAD.SA_CONFIG.RADIUS: [0.2, 0.4, 100]
2023-03-03 09:37:40,326   INFO  cfg.MODEL.ROI_HEAD.SA_CONFIG.NSAMPLE: [16, 16, 16]
2023-03-03 09:37:40,326   INFO  cfg.MODEL.ROI_HEAD.SA_CONFIG.MLPS: [[128, 128, 128], [128, 128, 256], [256, 256, 512]]
2023-03-03 09:37:40,326   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG = edict()
2023-03-03 09:37:40,326   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN = edict()
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_TYPE: nms_gpu
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.MULTI_CLASSES_NMS: False
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_PRE_MAXSIZE: 9000
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_POST_MAXSIZE: 512
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_THRESH: 0.8
2023-03-03 09:37:40,327   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST = edict()
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_TYPE: nms_gpu
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.MULTI_CLASSES_NMS: False
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_PRE_MAXSIZE: 9000
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_POST_MAXSIZE: 100
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_THRESH: 0.85
2023-03-03 09:37:40,327   INFO  
cfg.MODEL.ROI_HEAD.TARGET_CONFIG = edict()
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.BOX_CODER: ResidualCoder
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.ROI_PER_IMAGE: 128
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.FG_RATIO: 0.5
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.SAMPLE_ROI_BY_EACH_CLASS: True
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_SCORE_TYPE: cls
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_FG_THRESH: 0.6
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_BG_THRESH: 0.45
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_BG_THRESH_LO: 0.1
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.HARD_BG_RATIO: 0.8
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.REG_FG_THRESH: 0.55
2023-03-03 09:37:40,327   INFO  
cfg.MODEL.ROI_HEAD.LOSS_CONFIG = edict()
2023-03-03 09:37:40,327   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.CLS_LOSS: BinaryCrossEntropy
2023-03-03 09:37:40,328   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.REG_LOSS: smooth-l1
2023-03-03 09:37:40,328   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.CORNER_LOSS_REGULARIZATION: True
2023-03-03 09:37:40,328   INFO  
cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS = edict()
2023-03-03 09:37:40,328   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_cls_weight: 1.0
2023-03-03 09:37:40,328   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_reg_weight: 1.0
2023-03-03 09:37:40,328   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_corner_weight: 1.0
2023-03-03 09:37:40,328   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
2023-03-03 09:37:40,328   INFO  
cfg.MODEL.POST_PROCESSING = edict()
2023-03-03 09:37:40,328   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
2023-03-03 09:37:40,328   INFO  cfg.MODEL.POST_PROCESSING.SCORE_THRESH: 0.1
2023-03-03 09:37:40,328   INFO  cfg.MODEL.POST_PROCESSING.OUTPUT_RAW_SCORE: False
2023-03-03 09:37:40,328   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: ithaca365
2023-03-03 09:37:40,328   INFO  
cfg.MODEL.POST_PROCESSING.NMS_CONFIG = edict()
2023-03-03 09:37:40,328   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.MULTI_CLASSES_NMS: False
2023-03-03 09:37:40,328   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: nms_gpu
2023-03-03 09:37:40,328   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: 0.1
2023-03-03 09:37:40,328   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: 4096
2023-03-03 09:37:40,328   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: 500
2023-03-03 09:37:40,328   INFO  
cfg.OPTIMIZATION = edict()
2023-03-03 09:37:40,328   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 2
2023-03-03 09:37:40,328   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 10
2023-03-03 09:37:40,328   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle
2023-03-03 09:37:40,328   INFO  cfg.OPTIMIZATION.LR: 0.01
2023-03-03 09:37:40,328   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01
2023-03-03 09:37:40,328   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9
2023-03-03 09:37:40,328   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]
2023-03-03 09:37:40,328   INFO  cfg.OPTIMIZATION.PCT_START: 0.4
2023-03-03 09:37:40,328   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10
2023-03-03 09:37:40,328   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]
2023-03-03 09:37:40,328   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1
2023-03-03 09:37:40,328   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07
2023-03-03 09:37:40,328   INFO  cfg.OPTIMIZATION.LR_WARMUP: False
2023-03-03 09:37:40,328   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1
2023-03-03 09:37:40,328   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 10
2023-03-03 09:37:40,328   INFO  cfg.TAG: pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5
2023-03-03 09:37:40,328   INFO  cfg.EXP_GROUP_PATH: ithaca365_models
wandb: Currently logged in as: travis10. Use `wandb login --relogin` to force relogin
==> Checkpoint trained from version: pcdet+0.3.0+0000000
==> Checkpoint trained from version: pcdet+0.3.0+0000000
==> Checkpoint trained from version: pcdet+0.3.0+0000000
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/tz98/projects/continual-DA/downstream/OpenPCDet/tools/wandb/run-20230303_093741-2apw9v7a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ithaca365_models_pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5_default
wandb: ⭐️ View project at https://wandb.ai/travis10/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5
wandb: 🚀 View run at https://wandb.ai/travis10/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/runs/2apw9v7a
wandb: WARNING Found log directory outside of given root_logdir, dropping given root_logdir for event file in /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/tensorboard
2023-03-03 09:37:47,275   INFO  Database filter by min points car: 7572 => 7080
2023-03-03 09:37:47,277   INFO  Database filter by min points pedestrian: 5278 => 4766
2023-03-03 09:37:47,278   INFO  Loading Ithaca365 dataset
2023-03-03 09:37:47,346   INFO  Total samples for Ithaca365 dataset: 4445
2023-03-03 09:37:49,993   INFO  ==> Loading parameters from checkpoint ../output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/ckpt/checkpoint_epoch_4.pth to CPU
2023-03-03 09:37:50,116   INFO  ==> Loading optimizer parameters from checkpoint ../output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/ckpt/checkpoint_epoch_4.pth to CPU
==> Checkpoint trained from version: pcdet+0.3.0+0000000
2023-03-03 09:37:50,194   INFO  ==> Done
2023-03-03 09:37:50,458   INFO  DistributedDataParallel(
  (module): PointRCNN(
    (history_query): SparseResUQueryNet(
      (history_backbone): Res16UNet14E(
        (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
        (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block1): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
          )
        )
        (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block2): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block3): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block4): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
          )
        )
        (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block5): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block6): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block7): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block8): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (relu): MinkowskiReLU()
        (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
      )
      (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
      (p2_backbone): Sequential(
        (0): Linear(in_features=68, out_features=32, bias=True)
        (1): ReLU()
        (2): Linear(in_features=32, out_features=1, bias=True)
      )
      (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (vfe): None
    (backbone_3d): PointNet2MSG(
      (SA_modules): ModuleList(
        (0): PointnetSAModuleMSG(
          (groupers): ModuleList(
            (0): QueryAndGroup()
            (1): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
            (1): Sequential(
              (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (1): PointnetSAModuleMSG(
          (groupers): ModuleList(
            (0): QueryAndGroup()
            (1): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
            (1): Sequential(
              (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (2): PointnetSAModuleMSG(
          (groupers): ModuleList(
            (0): QueryAndGroup()
            (1): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
            (1): Sequential(
              (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (3): PointnetSAModuleMSG(
          (groupers): ModuleList(
            (0): QueryAndGroup()
            (1): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
            (1): Sequential(
              (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
      )
      (FP_modules): ModuleList(
        (0): PointnetFPModule(
          (mlp): Sequential(
            (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
          )
        )
        (1): PointnetFPModule(
          (mlp): Sequential(
            (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
          )
        )
        (2): PointnetFPModule(
          (mlp): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
          )
        )
        (3): PointnetFPModule(
          (mlp): Sequential(
            (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
          )
        )
      )
    )
    (map_to_bev_module): None
    (pfe): None
    (backbone_2d): None
    (dense_head): None
    (point_head): PointHeadBox(
      (cls_loss_func): SigmoidFocalClassificationLoss()
      (reg_loss_func): WeightedSmoothL1Loss()
      (cls_layers): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=256, out_features=256, bias=False)
        (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU()
        (6): Linear(in_features=256, out_features=2, bias=True)
      )
      (box_layers): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=256, out_features=256, bias=False)
        (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU()
        (6): Linear(in_features=256, out_features=8, bias=True)
      )
    )
    (roi_head): PointRCNNHead(
      (proposal_target_layer): ProposalTargetLayer()
      (reg_loss_func): WeightedSmoothL1Loss()
      (SA_modules): ModuleList(
        (0): PointnetSAModule(
          (groupers): ModuleList(
            (0): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (1): PointnetSAModule(
          (groupers): ModuleList(
            (0): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (2): PointnetSAModule(
          (groupers): ModuleList(
            (0): GroupAll()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
      )
      (xyz_up_layer): Sequential(
        (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
        (1): ReLU()
        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        (3): ReLU()
      )
      (merge_down_layer): Sequential(
        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
        (1): ReLU()
      )
      (cls_layers): Sequential(
        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.0, inplace=False)
        (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
      )
      (reg_layers): Sequential(
        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.0, inplace=False)
        (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
      )
      (roipoint_pool3d_layer): RoIPointPool3d()
    )
  )
)
2023-03-03 09:37:50,465   INFO  **********************Start training ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5(default)**********************
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
wandb: Network error (ReadTimeout), entering retry loop.
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
2023-03-03 11:46:55,732   INFO  **********************End training ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5(default)**********************



2023-03-03 11:46:55,734   INFO  **********************Start evaluation ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5(default)**********************
2023-03-03 11:46:55,735   INFO  Loading Ithaca365 dataset
2023-03-03 11:46:55,792   INFO  Total samples for Ithaca365 dataset: 1644
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING Found log directory outside of given root_logdir, dropping given root_logdir for event file in /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/eval/eval_with_train/tensorboard_val
2023-03-03 11:46:55,799   INFO  ==> Loading parameters from checkpoint /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/ckpt/checkpoint_epoch_8.pth to CPU
2023-03-03 11:46:56,105   INFO  ==> Checkpoint trained from version: pcdet+0.3.0+0000000
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
2023-03-03 11:46:57,383   INFO  ==> Done (loaded 502/502)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
2023-03-03 11:46:57,392   INFO  *************** EPOCH 8 EVALUATION *****************
eval:   0%|                                                                                       | 0/206 [00:00<?, ?it/s]PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
eval:   0%|                                                                | 0/206 [00:08<?, ?it/s, recall_0.3=(2, 2) / 5]eval:   0%|▎                                                       | 1/206 [00:08<28:53,  8.46s/it, recall_0.3=(2, 2) / 5]eval:   0%|▎                                                    | 1/206 [00:09<28:53,  8.46s/it, recall_0.3=(12, 12) / 23]eval:   1%|▌                                                    | 2/206 [00:09<14:04,  4.14s/it, recall_0.3=(12, 12) / 23]eval:   1%|▌                                                    | 2/206 [00:10<14:04,  4.14s/it, recall_0.3=(16, 16) / 30]eval:   1%|▊                                                    | 3/206 [00:10<09:12,  2.72s/it, recall_0.3=(16, 16) / 30]eval:   1%|▊                                                    | 3/206 [00:11<09:12,  2.72s/it, recall_0.3=(20, 20) / 36]eval:   2%|█                                                    | 4/206 [00:11<06:51,  2.04s/it, recall_0.3=(20, 20) / 36]eval:   2%|█                                                    | 4/206 [00:13<06:51,  2.04s/it, recall_0.3=(25, 25) / 43]eval:   2%|█▎                                                   | 5/206 [00:13<06:16,  1.87s/it, recall_0.3=(25, 25) / 43]eval:   2%|█▎                                                   | 5/206 [00:14<06:16,  1.87s/it, recall_0.3=(28, 28) / 48]eval:   3%|█▌                                                   | 6/206 [00:14<05:17,  1.59s/it, recall_0.3=(28, 28) / 48]eval:   3%|█▌                                                   | 6/206 [00:15<05:17,  1.59s/it, recall_0.3=(31, 31) / 53]eval:   3%|█▊                                                   | 7/206 [00:15<04:43,  1.42s/it, recall_0.3=(31, 31) / 53]eval:   3%|█▊                                                   | 7/206 [00:16<04:43,  1.42s/it, recall_0.3=(31, 31) / 56]eval:   4%|██                                                   | 8/206 [00:16<04:36,  1.39s/it, recall_0.3=(31, 31) / 56]eval:   4%|██                                                   | 8/206 [00:17<04:36,  1.39s/it, recall_0.3=(31, 31) / 56]eval:   4%|██▎                                                  | 9/206 [00:17<04:11,  1.27s/it, recall_0.3=(31, 31) / 56]eval:   4%|██▎                                                  | 9/206 [00:18<04:11,  1.27s/it, recall_0.3=(31, 31) / 56]eval:   5%|██▌                                                 | 10/206 [00:18<03:57,  1.21s/it, recall_0.3=(31, 31) / 56]eval:   5%|██▌                                                 | 10/206 [00:19<03:57,  1.21s/it, recall_0.3=(31, 31) / 58]eval:   5%|██▊                                                 | 11/206 [00:19<03:50,  1.18s/it, recall_0.3=(31, 31) / 58]eval:   5%|██▊                                                 | 11/206 [00:20<03:50,  1.18s/it, recall_0.3=(31, 31) / 61]eval:   6%|███                                                 | 12/206 [00:20<03:47,  1.17s/it, recall_0.3=(31, 31) / 61]eval:   6%|███                                                 | 12/206 [00:22<03:47,  1.17s/it, recall_0.3=(34, 33) / 67]eval:   6%|███▎                                                | 13/206 [00:22<03:39,  1.14s/it, recall_0.3=(34, 33) / 67]eval:   6%|███▎                                                | 13/206 [00:22<03:39,  1.14s/it, recall_0.3=(36, 35) / 72]eval:   7%|███▌                                                | 14/206 [00:22<03:28,  1.08s/it, recall_0.3=(36, 35) / 72]eval:   7%|███▌                                                | 14/206 [00:24<03:28,  1.08s/it, recall_0.3=(37, 36) / 75]eval:   7%|███▊                                                | 15/206 [00:24<03:44,  1.18s/it, recall_0.3=(37, 36) / 75]eval:   7%|███▊                                                | 15/206 [00:25<03:44,  1.18s/it, recall_0.3=(39, 38) / 77]eval:   8%|████                                                | 16/206 [00:25<03:39,  1.16s/it, recall_0.3=(39, 38) / 77]eval:   8%|████                                                | 16/206 [00:28<03:39,  1.16s/it, recall_0.3=(39, 38) / 80]eval:   8%|████▎                                               | 17/206 [00:28<05:20,  1.70s/it, recall_0.3=(39, 38) / 80]eval:   8%|████▎                                               | 17/206 [00:29<05:20,  1.70s/it, recall_0.3=(40, 39) / 83]eval:   9%|████▌                                               | 18/206 [00:29<04:46,  1.53s/it, recall_0.3=(40, 39) / 83]eval:   9%|████▌                                               | 18/206 [00:30<04:46,  1.53s/it, recall_0.3=(41, 40) / 85]eval:   9%|████▊                                               | 19/206 [00:30<04:13,  1.36s/it, recall_0.3=(41, 40) / 85]eval:   9%|████▊                                               | 19/206 [00:31<04:13,  1.36s/it, recall_0.3=(42, 41) / 87]eval:  10%|█████                                               | 20/206 [00:31<03:57,  1.28s/it, recall_0.3=(42, 41) / 87]eval:  10%|█████                                               | 20/206 [00:34<03:57,  1.28s/it, recall_0.3=(46, 45) / 92]eval:  10%|█████▎                                              | 21/206 [00:34<05:16,  1.71s/it, recall_0.3=(46, 45) / 92]eval:  10%|█████▏                                             | 21/206 [00:34<05:16,  1.71s/it, recall_0.3=(49, 48) / 103]eval:  11%|█████▍                                             | 22/206 [00:34<04:13,  1.38s/it, recall_0.3=(49, 48) / 103]eval:  11%|█████▍                                             | 22/206 [00:35<04:13,  1.38s/it, recall_0.3=(59, 58) / 125]eval:  11%|█████▋                                             | 23/206 [00:35<03:16,  1.07s/it, recall_0.3=(59, 58) / 125]eval:  11%|█████▋                                             | 23/206 [00:36<03:16,  1.07s/it, recall_0.3=(66, 65) / 133]eval:  12%|█████▉                                             | 24/206 [00:36<03:04,  1.01s/it, recall_0.3=(66, 65) / 133]eval:  12%|█████▉                                             | 24/206 [00:39<03:04,  1.01s/it, recall_0.3=(76, 75) / 145]eval:  12%|██████▏                                            | 25/206 [00:39<04:47,  1.59s/it, recall_0.3=(76, 75) / 145]eval:  12%|██████▏                                            | 25/206 [00:39<04:47,  1.59s/it, recall_0.3=(80, 79) / 153]eval:  13%|██████▍                                            | 26/206 [00:40<04:08,  1.38s/it, recall_0.3=(80, 79) / 153]eval:  13%|██████▍                                            | 26/206 [00:40<04:08,  1.38s/it, recall_0.3=(83, 82) / 156]eval:  13%|██████▋                                            | 27/206 [00:40<03:34,  1.20s/it, recall_0.3=(83, 82) / 156]eval:  13%|██████▋                                            | 27/206 [00:41<03:34,  1.20s/it, recall_0.3=(87, 86) / 163]eval:  14%|██████▉                                            | 28/206 [00:41<03:18,  1.12s/it, recall_0.3=(87, 86) / 163]eval:  14%|██████▉                                            | 28/206 [00:47<03:18,  1.12s/it, recall_0.3=(94, 93) / 171]eval:  14%|███████▏                                           | 29/206 [00:47<07:09,  2.43s/it, recall_0.3=(94, 93) / 171]eval:  14%|███████▏                                           | 29/206 [00:48<07:09,  2.43s/it, recall_0.3=(97, 96) / 174]eval:  15%|███████▍                                           | 30/206 [00:48<05:53,  2.01s/it, recall_0.3=(97, 96) / 174]eval:  15%|███████▍                                           | 30/206 [00:48<05:53,  2.01s/it, recall_0.3=(99, 98) / 177]eval:  15%|███████▋                                           | 31/206 [00:48<04:34,  1.57s/it, recall_0.3=(99, 98) / 177]eval:  15%|███████▋                                           | 31/206 [00:49<04:34,  1.57s/it, recall_0.3=(99, 98) / 179]eval:  16%|███████▉                                           | 32/206 [00:49<03:55,  1.35s/it, recall_0.3=(99, 98) / 179]eval:  16%|███████▌                                         | 32/206 [00:50<03:55,  1.35s/it, recall_0.3=(102, 101) / 182]eval:  16%|███████▊                                         | 33/206 [00:50<03:37,  1.26s/it, recall_0.3=(102, 101) / 182]eval:  16%|███████▊                                         | 33/206 [00:51<03:37,  1.26s/it, recall_0.3=(103, 102) / 184]eval:  17%|████████                                         | 34/206 [00:51<03:26,  1.20s/it, recall_0.3=(103, 102) / 184]eval:  17%|████████                                         | 34/206 [00:52<03:26,  1.20s/it, recall_0.3=(103, 102) / 184]eval:  17%|████████▎                                        | 35/206 [00:52<03:26,  1.21s/it, recall_0.3=(103, 102) / 184]eval:  17%|████████▎                                        | 35/206 [00:53<03:26,  1.21s/it, recall_0.3=(106, 105) / 189]eval:  17%|████████▌                                        | 36/206 [00:53<03:15,  1.15s/it, recall_0.3=(106, 105) / 189]eval:  17%|████████▌                                        | 36/206 [00:56<03:15,  1.15s/it, recall_0.3=(106, 105) / 189]eval:  18%|████████▊                                        | 37/206 [00:56<04:09,  1.47s/it, recall_0.3=(106, 105) / 189]eval:  18%|████████▊                                        | 37/206 [00:57<04:09,  1.47s/it, recall_0.3=(106, 105) / 189]eval:  18%|█████████                                        | 38/206 [00:57<03:46,  1.35s/it, recall_0.3=(106, 105) / 189]eval:  18%|█████████                                        | 38/206 [00:58<03:46,  1.35s/it, recall_0.3=(106, 105) / 189]eval:  19%|█████████▎                                       | 39/206 [00:58<03:25,  1.23s/it, recall_0.3=(106, 105) / 189]eval:  19%|█████████▎                                       | 39/206 [00:59<03:25,  1.23s/it, recall_0.3=(106, 105) / 189]eval:  19%|█████████▌                                       | 40/206 [00:59<03:12,  1.16s/it, recall_0.3=(106, 105) / 189]eval:  19%|█████████▌                                       | 40/206 [01:01<03:12,  1.16s/it, recall_0.3=(107, 106) / 193]eval:  20%|█████████▊                                       | 41/206 [01:01<03:54,  1.42s/it, recall_0.3=(107, 106) / 193]eval:  20%|█████████▊                                       | 41/206 [01:02<03:54,  1.42s/it, recall_0.3=(109, 108) / 197]eval:  20%|█████████▉                                       | 42/206 [01:02<03:38,  1.33s/it, recall_0.3=(109, 108) / 197]eval:  20%|█████████▉                                       | 42/206 [01:03<03:38,  1.33s/it, recall_0.3=(120, 119) / 220]eval:  21%|██████████▏                                      | 43/206 [01:03<03:29,  1.29s/it, recall_0.3=(120, 119) / 220]eval:  21%|██████████▏                                      | 43/206 [01:04<03:29,  1.29s/it, recall_0.3=(131, 130) / 236]eval:  21%|██████████▍                                      | 44/206 [01:04<03:21,  1.24s/it, recall_0.3=(131, 130) / 236]eval:  21%|██████████▍                                      | 44/206 [01:06<03:21,  1.24s/it, recall_0.3=(143, 142) / 255]eval:  22%|██████████▋                                      | 45/206 [01:06<03:56,  1.47s/it, recall_0.3=(143, 142) / 255]eval:  22%|██████████▋                                      | 45/206 [01:07<03:56,  1.47s/it, recall_0.3=(147, 146) / 263]eval:  22%|██████████▉                                      | 46/206 [01:07<03:07,  1.17s/it, recall_0.3=(147, 146) / 263]eval:  22%|██████████▉                                      | 46/206 [01:07<03:07,  1.17s/it, recall_0.3=(153, 152) / 274]eval:  23%|███████████▏                                     | 47/206 [01:07<02:36,  1.02it/s, recall_0.3=(153, 152) / 274]eval:  23%|███████████▏                                     | 47/206 [01:08<02:36,  1.02it/s, recall_0.3=(158, 158) / 284]eval:  23%|███████████▍                                     | 48/206 [01:08<02:27,  1.07it/s, recall_0.3=(158, 158) / 284]eval:  23%|███████████▍                                     | 48/206 [01:14<02:27,  1.07it/s, recall_0.3=(163, 163) / 290]eval:  24%|███████████▋                                     | 49/206 [01:14<06:28,  2.47s/it, recall_0.3=(163, 163) / 290]eval:  24%|███████████▋                                     | 49/206 [01:15<06:28,  2.47s/it, recall_0.3=(164, 164) / 292]eval:  24%|███████████▉                                     | 50/206 [01:15<05:01,  1.93s/it, recall_0.3=(164, 164) / 292]eval:  24%|███████████▉                                     | 50/206 [01:16<05:01,  1.93s/it, recall_0.3=(166, 166) / 296]eval:  25%|████████████▏                                    | 51/206 [01:16<04:16,  1.66s/it, recall_0.3=(166, 166) / 296]eval:  25%|████████████▏                                    | 51/206 [01:17<04:16,  1.66s/it, recall_0.3=(168, 168) / 300]eval:  25%|████████████▎                                    | 52/206 [01:17<03:38,  1.42s/it, recall_0.3=(168, 168) / 300]eval:  25%|████████████▎                                    | 52/206 [01:17<03:38,  1.42s/it, recall_0.3=(173, 173) / 308]eval:  26%|████████████▌                                    | 53/206 [01:18<03:13,  1.26s/it, recall_0.3=(173, 173) / 308]eval:  26%|████████████▌                                    | 53/206 [01:18<03:13,  1.26s/it, recall_0.3=(176, 176) / 314]eval:  26%|████████████▊                                    | 54/206 [01:18<02:49,  1.12s/it, recall_0.3=(176, 176) / 314]eval:  26%|████████████▊                                    | 54/206 [01:19<02:49,  1.12s/it, recall_0.3=(177, 177) / 317]eval:  27%|█████████████                                    | 55/206 [01:19<02:40,  1.06s/it, recall_0.3=(177, 177) / 317]eval:  27%|█████████████                                    | 55/206 [01:20<02:40,  1.06s/it, recall_0.3=(185, 185) / 331]eval:  27%|█████████████▎                                   | 56/206 [01:20<02:42,  1.09s/it, recall_0.3=(185, 185) / 331]eval:  27%|█████████████▎                                   | 56/206 [01:22<02:42,  1.09s/it, recall_0.3=(186, 186) / 335]eval:  28%|█████████████▌                                   | 57/206 [01:22<03:22,  1.36s/it, recall_0.3=(186, 186) / 335]eval:  28%|█████████████▌                                   | 57/206 [01:23<03:22,  1.36s/it, recall_0.3=(186, 186) / 337]eval:  28%|█████████████▊                                   | 58/206 [01:23<03:08,  1.27s/it, recall_0.3=(186, 186) / 337]eval:  28%|█████████████▊                                   | 58/206 [01:24<03:08,  1.27s/it, recall_0.3=(190, 190) / 349]eval:  29%|██████████████                                   | 59/206 [01:24<02:57,  1.21s/it, recall_0.3=(190, 190) / 349]eval:  29%|██████████████                                   | 59/206 [01:25<02:57,  1.21s/it, recall_0.3=(199, 199) / 362]eval:  29%|██████████████▎                                  | 60/206 [01:25<02:46,  1.14s/it, recall_0.3=(199, 199) / 362]eval:  29%|██████████████▎                                  | 60/206 [01:28<02:46,  1.14s/it, recall_0.3=(210, 210) / 374]eval:  30%|██████████████▌                                  | 61/206 [01:28<04:06,  1.70s/it, recall_0.3=(210, 210) / 374]eval:  30%|██████████████▌                                  | 61/206 [01:29<04:06,  1.70s/it, recall_0.3=(221, 220) / 391]eval:  30%|██████████████▋                                  | 62/206 [01:29<03:27,  1.44s/it, recall_0.3=(221, 220) / 391]eval:  30%|██████████████▋                                  | 62/206 [01:30<03:27,  1.44s/it, recall_0.3=(229, 228) / 408]eval:  31%|██████████████▉                                  | 63/206 [01:30<03:12,  1.35s/it, recall_0.3=(229, 228) / 408]eval:  31%|██████████████▉                                  | 63/206 [01:31<03:12,  1.35s/it, recall_0.3=(236, 235) / 422]eval:  31%|███████████████▏                                 | 64/206 [01:31<02:53,  1.22s/it, recall_0.3=(236, 235) / 422]eval:  31%|███████████████▏                                 | 64/206 [01:35<02:53,  1.22s/it, recall_0.3=(249, 248) / 438]eval:  32%|███████████████▍                                 | 65/206 [01:35<04:20,  1.85s/it, recall_0.3=(249, 248) / 438]eval:  32%|███████████████▍                                 | 65/206 [01:36<04:20,  1.85s/it, recall_0.3=(258, 257) / 450]eval:  32%|███████████████▋                                 | 66/206 [01:36<03:36,  1.55s/it, recall_0.3=(258, 257) / 450]eval:  32%|███████████████▋                                 | 66/206 [01:36<03:36,  1.55s/it, recall_0.3=(265, 264) / 464]eval:  33%|███████████████▉                                 | 67/206 [01:36<03:00,  1.30s/it, recall_0.3=(265, 264) / 464]eval:  33%|███████████████▉                                 | 67/206 [01:37<03:00,  1.30s/it, recall_0.3=(268, 267) / 468]eval:  33%|████████████████▏                                | 68/206 [01:37<02:24,  1.04s/it, recall_0.3=(268, 267) / 468]eval:  33%|████████████████▏                                | 68/206 [01:40<02:24,  1.04s/it, recall_0.3=(270, 269) / 471]eval:  33%|████████████████▍                                | 69/206 [01:40<03:46,  1.65s/it, recall_0.3=(270, 269) / 471]eval:  33%|████████████████▍                                | 69/206 [01:41<03:46,  1.65s/it, recall_0.3=(271, 270) / 473]eval:  34%|████████████████▋                                | 70/206 [01:41<03:16,  1.44s/it, recall_0.3=(271, 270) / 473]eval:  34%|████████████████▋                                | 70/206 [01:42<03:16,  1.44s/it, recall_0.3=(272, 271) / 476]eval:  34%|████████████████▉                                | 71/206 [01:42<02:50,  1.27s/it, recall_0.3=(272, 271) / 476]eval:  34%|████████████████▉                                | 71/206 [01:42<02:50,  1.27s/it, recall_0.3=(273, 272) / 479]eval:  35%|█████████████████▏                               | 72/206 [01:42<02:34,  1.15s/it, recall_0.3=(273, 272) / 479]eval:  35%|█████████████████▏                               | 72/206 [01:43<02:34,  1.15s/it, recall_0.3=(273, 272) / 479]eval:  35%|█████████████████▎                               | 73/206 [01:43<02:27,  1.11s/it, recall_0.3=(273, 272) / 479]eval:  35%|█████████████████▎                               | 73/206 [01:44<02:27,  1.11s/it, recall_0.3=(273, 272) / 481]eval:  36%|█████████████████▌                               | 74/206 [01:44<02:14,  1.02s/it, recall_0.3=(273, 272) / 481]eval:  36%|█████████████████▌                               | 74/206 [01:45<02:14,  1.02s/it, recall_0.3=(274, 273) / 484]eval:  36%|█████████████████▊                               | 75/206 [01:45<02:09,  1.01it/s, recall_0.3=(274, 273) / 484]eval:  36%|█████████████████▊                               | 75/206 [01:46<02:09,  1.01it/s, recall_0.3=(276, 275) / 488]eval:  37%|██████████████████                               | 76/206 [01:46<02:03,  1.05it/s, recall_0.3=(276, 275) / 488]eval:  37%|██████████████████                               | 76/206 [01:47<02:03,  1.05it/s, recall_0.3=(277, 276) / 492]eval:  37%|██████████████████▎                              | 77/206 [01:47<02:09,  1.01s/it, recall_0.3=(277, 276) / 492]eval:  37%|██████████████████▎                              | 77/206 [01:48<02:09,  1.01s/it, recall_0.3=(278, 277) / 494]eval:  38%|██████████████████▌                              | 78/206 [01:48<02:11,  1.03s/it, recall_0.3=(278, 277) / 494]eval:  38%|██████████████████▌                              | 78/206 [01:49<02:11,  1.03s/it, recall_0.3=(284, 283) / 504]eval:  38%|██████████████████▊                              | 79/206 [01:49<02:16,  1.07s/it, recall_0.3=(284, 283) / 504]eval:  38%|██████████████████▊                              | 79/206 [01:51<02:16,  1.07s/it, recall_0.3=(288, 287) / 510]eval:  39%|███████████████████                              | 80/206 [01:51<02:22,  1.13s/it, recall_0.3=(288, 287) / 510]eval:  39%|███████████████████                              | 80/206 [01:52<02:22,  1.13s/it, recall_0.3=(292, 291) / 516]eval:  39%|███████████████████▎                             | 81/206 [01:52<02:28,  1.19s/it, recall_0.3=(292, 291) / 516]eval:  39%|███████████████████▎                             | 81/206 [01:53<02:28,  1.19s/it, recall_0.3=(297, 296) / 523]eval:  40%|███████████████████▌                             | 82/206 [01:53<02:21,  1.14s/it, recall_0.3=(297, 296) / 523]eval:  40%|███████████████████▌                             | 82/206 [01:54<02:21,  1.14s/it, recall_0.3=(303, 302) / 529]eval:  40%|███████████████████▋                             | 83/206 [01:54<02:19,  1.13s/it, recall_0.3=(303, 302) / 529]eval:  40%|███████████████████▋                             | 83/206 [01:55<02:19,  1.13s/it, recall_0.3=(314, 313) / 553]eval:  41%|███████████████████▉                             | 84/206 [01:55<02:11,  1.08s/it, recall_0.3=(314, 313) / 553]eval:  41%|███████████████████▉                             | 84/206 [02:00<02:11,  1.08s/it, recall_0.3=(326, 326) / 572]eval:  41%|████████████████████▏                            | 85/206 [02:00<04:13,  2.09s/it, recall_0.3=(326, 326) / 572]eval:  41%|████████████████████▏                            | 85/206 [02:01<04:13,  2.09s/it, recall_0.3=(337, 337) / 589]eval:  42%|████████████████████▍                            | 86/206 [02:01<03:34,  1.79s/it, recall_0.3=(337, 337) / 589]eval:  42%|████████████████████▍                            | 86/206 [02:02<03:34,  1.79s/it, recall_0.3=(344, 344) / 601]eval:  42%|████████████████████▋                            | 87/206 [02:02<03:06,  1.57s/it, recall_0.3=(344, 344) / 601]eval:  42%|████████████████████▋                            | 87/206 [02:03<03:06,  1.57s/it, recall_0.3=(353, 353) / 616]eval:  43%|████████████████████▉                            | 88/206 [02:03<02:47,  1.42s/it, recall_0.3=(353, 353) / 616]eval:  43%|████████████████████▉                            | 88/206 [02:06<02:47,  1.42s/it, recall_0.3=(358, 358) / 625]eval:  43%|█████████████████████▏                           | 89/206 [02:06<03:44,  1.92s/it, recall_0.3=(358, 358) / 625]eval:  43%|█████████████████████▏                           | 89/206 [02:07<03:44,  1.92s/it, recall_0.3=(361, 361) / 632]eval:  44%|█████████████████████▍                           | 90/206 [02:07<03:06,  1.61s/it, recall_0.3=(361, 361) / 632]eval:  44%|█████████████████████▍                           | 90/206 [02:07<03:06,  1.61s/it, recall_0.3=(364, 364) / 636]eval:  44%|█████████████████████▋                           | 91/206 [02:07<02:33,  1.33s/it, recall_0.3=(364, 364) / 636]eval:  44%|█████████████████████▋                           | 91/206 [02:08<02:33,  1.33s/it, recall_0.3=(365, 365) / 638]eval:  45%|█████████████████████▉                           | 92/206 [02:08<02:17,  1.21s/it, recall_0.3=(365, 365) / 638]eval:  45%|█████████████████████▉                           | 92/206 [02:10<02:17,  1.21s/it, recall_0.3=(367, 367) / 641]eval:  45%|██████████████████████                           | 93/206 [02:10<02:41,  1.43s/it, recall_0.3=(367, 367) / 641]eval:  45%|██████████████████████                           | 93/206 [02:11<02:41,  1.43s/it, recall_0.3=(370, 370) / 644]eval:  46%|██████████████████████▎                          | 94/206 [02:11<02:23,  1.28s/it, recall_0.3=(370, 370) / 644]eval:  46%|██████████████████████▎                          | 94/206 [02:12<02:23,  1.28s/it, recall_0.3=(373, 373) / 647]eval:  46%|██████████████████████▌                          | 95/206 [02:12<02:05,  1.13s/it, recall_0.3=(373, 373) / 647]eval:  46%|██████████████████████▌                          | 95/206 [02:13<02:05,  1.13s/it, recall_0.3=(376, 376) / 655]eval:  47%|██████████████████████▊                          | 96/206 [02:13<01:59,  1.09s/it, recall_0.3=(376, 376) / 655]eval:  47%|██████████████████████▊                          | 96/206 [02:14<01:59,  1.09s/it, recall_0.3=(380, 380) / 659]eval:  47%|███████████████████████                          | 97/206 [02:14<02:04,  1.14s/it, recall_0.3=(380, 380) / 659]eval:  47%|███████████████████████                          | 97/206 [02:15<02:04,  1.14s/it, recall_0.3=(381, 381) / 661]eval:  48%|███████████████████████▎                         | 98/206 [02:15<02:05,  1.16s/it, recall_0.3=(381, 381) / 661]eval:  48%|███████████████████████▎                         | 98/206 [02:16<02:05,  1.16s/it, recall_0.3=(386, 386) / 667]eval:  48%|███████████████████████▌                         | 99/206 [02:16<01:58,  1.11s/it, recall_0.3=(386, 386) / 667]eval:  48%|███████████████████████▌                         | 99/206 [02:17<01:58,  1.11s/it, recall_0.3=(387, 387) / 670]eval:  49%|███████████████████████▎                        | 100/206 [02:17<01:51,  1.05s/it, recall_0.3=(387, 387) / 670]eval:  49%|███████████████████████▎                        | 100/206 [02:19<01:51,  1.05s/it, recall_0.3=(389, 389) / 673]eval:  49%|███████████████████████▌                        | 101/206 [02:19<02:02,  1.17s/it, recall_0.3=(389, 389) / 673]eval:  49%|███████████████████████▌                        | 101/206 [02:20<02:02,  1.17s/it, recall_0.3=(392, 392) / 681]eval:  50%|███████████████████████▊                        | 102/206 [02:20<01:57,  1.13s/it, recall_0.3=(392, 392) / 681]eval:  50%|███████████████████████▊                        | 102/206 [02:21<01:57,  1.13s/it, recall_0.3=(405, 405) / 700]eval:  50%|████████████████████████                        | 103/206 [02:21<01:54,  1.11s/it, recall_0.3=(405, 405) / 700]eval:  50%|████████████████████████                        | 103/206 [02:22<01:54,  1.11s/it, recall_0.3=(414, 414) / 717]eval:  50%|████████████████████████▏                       | 104/206 [02:22<01:54,  1.12s/it, recall_0.3=(414, 414) / 717]eval:  50%|████████████████████████▏                       | 104/206 [02:25<01:54,  1.12s/it, recall_0.3=(427, 427) / 743]eval:  51%|████████████████████████▍                       | 105/206 [02:25<02:33,  1.52s/it, recall_0.3=(427, 427) / 743]eval:  51%|████████████████████████▍                       | 105/206 [02:26<02:33,  1.52s/it, recall_0.3=(430, 430) / 752]eval:  51%|████████████████████████▋                       | 106/206 [02:26<02:23,  1.43s/it, recall_0.3=(430, 430) / 752]eval:  51%|████████████████████████▋                       | 106/206 [02:27<02:23,  1.43s/it, recall_0.3=(437, 437) / 763]eval:  52%|████████████████████████▉                       | 107/206 [02:27<02:03,  1.25s/it, recall_0.3=(437, 437) / 763]eval:  52%|████████████████████████▉                       | 107/206 [02:28<02:03,  1.25s/it, recall_0.3=(443, 442) / 772]eval:  52%|█████████████████████████▏                      | 108/206 [02:28<02:01,  1.24s/it, recall_0.3=(443, 442) / 772]eval:  52%|█████████████████████████▏                      | 108/206 [02:32<02:01,  1.24s/it, recall_0.3=(450, 449) / 781]eval:  53%|█████████████████████████▍                      | 109/206 [02:32<03:29,  2.16s/it, recall_0.3=(450, 449) / 781]eval:  53%|█████████████████████████▍                      | 109/206 [02:33<03:29,  2.16s/it, recall_0.3=(452, 451) / 784]eval:  53%|█████████████████████████▋                      | 110/206 [02:33<02:48,  1.76s/it, recall_0.3=(452, 451) / 784]eval:  53%|█████████████████████████▋                      | 110/206 [02:34<02:48,  1.76s/it, recall_0.3=(454, 453) / 790]eval:  54%|█████████████████████████▊                      | 111/206 [02:34<02:17,  1.44s/it, recall_0.3=(454, 453) / 790]eval:  54%|█████████████████████████▊                      | 111/206 [02:34<02:17,  1.44s/it, recall_0.3=(454, 453) / 795]eval:  54%|██████████████████████████                      | 112/206 [02:34<01:55,  1.23s/it, recall_0.3=(454, 453) / 795]eval:  54%|██████████████████████████                      | 112/206 [02:35<01:55,  1.23s/it, recall_0.3=(455, 454) / 800]eval:  55%|██████████████████████████▎                     | 113/206 [02:35<01:44,  1.13s/it, recall_0.3=(455, 454) / 800]eval:  55%|██████████████████████████▎                     | 113/206 [02:36<01:44,  1.13s/it, recall_0.3=(456, 455) / 805]eval:  55%|██████████████████████████▌                     | 114/206 [02:36<01:31,  1.00it/s, recall_0.3=(456, 455) / 805]eval:  55%|██████████████████████████▌                     | 114/206 [02:37<01:31,  1.00it/s, recall_0.3=(458, 457) / 812]eval:  56%|██████████████████████████▊                     | 115/206 [02:37<01:26,  1.06it/s, recall_0.3=(458, 457) / 812]eval:  56%|██████████████████████████▊                     | 115/206 [02:38<01:26,  1.06it/s, recall_0.3=(460, 459) / 816]eval:  56%|███████████████████████████                     | 116/206 [02:38<01:21,  1.10it/s, recall_0.3=(460, 459) / 816]eval:  56%|███████████████████████████                     | 116/206 [02:39<01:21,  1.10it/s, recall_0.3=(465, 464) / 821]eval:  57%|███████████████████████████▎                    | 117/206 [02:39<01:22,  1.08it/s, recall_0.3=(465, 464) / 821]eval:  57%|███████████████████████████▎                    | 117/206 [02:39<01:22,  1.08it/s, recall_0.3=(466, 465) / 824]eval:  57%|███████████████████████████▍                    | 118/206 [02:39<01:12,  1.21it/s, recall_0.3=(466, 465) / 824]eval:  57%|███████████████████████████▍                    | 118/206 [02:40<01:12,  1.21it/s, recall_0.3=(469, 468) / 828]eval:  58%|███████████████████████████▋                    | 119/206 [02:40<01:08,  1.27it/s, recall_0.3=(469, 468) / 828]eval:  58%|███████████████████████████▋                    | 119/206 [02:41<01:08,  1.27it/s, recall_0.3=(478, 477) / 840]eval:  58%|███████████████████████████▉                    | 120/206 [02:41<01:05,  1.32it/s, recall_0.3=(478, 477) / 840]eval:  58%|███████████████████████████▉                    | 120/206 [02:47<01:05,  1.32it/s, recall_0.3=(490, 489) / 852]eval:  59%|████████████████████████████▏                   | 121/206 [02:47<03:24,  2.41s/it, recall_0.3=(490, 489) / 852]eval:  59%|████████████████████████████▏                   | 121/206 [02:48<03:24,  2.41s/it, recall_0.3=(500, 499) / 867]eval:  59%|████████████████████████████▍                   | 122/206 [02:48<02:47,  1.99s/it, recall_0.3=(500, 499) / 867]eval:  59%|████████████████████████████▍                   | 122/206 [02:49<02:47,  1.99s/it, recall_0.3=(515, 513) / 900]eval:  60%|████████████████████████████▋                   | 123/206 [02:49<02:26,  1.77s/it, recall_0.3=(515, 513) / 900]eval:  60%|████████████████████████████▋                   | 123/206 [02:50<02:26,  1.77s/it, recall_0.3=(525, 523) / 923]eval:  60%|████████████████████████████▉                   | 124/206 [02:50<02:05,  1.53s/it, recall_0.3=(525, 523) / 923]eval:  60%|████████████████████████████▉                   | 124/206 [02:53<02:05,  1.53s/it, recall_0.3=(533, 530) / 943]eval:  61%|█████████████████████████████▏                  | 125/206 [02:53<02:46,  2.06s/it, recall_0.3=(533, 530) / 943]eval:  61%|█████████████████████████████▏                  | 125/206 [02:55<02:46,  2.06s/it, recall_0.3=(534, 531) / 947]eval:  61%|█████████████████████████████▎                  | 126/206 [02:55<02:25,  1.81s/it, recall_0.3=(534, 531) / 947]eval:  61%|█████████████████████████████▎                  | 126/206 [02:56<02:25,  1.81s/it, recall_0.3=(539, 536) / 954]eval:  62%|█████████████████████████████▌                  | 127/206 [02:56<02:07,  1.62s/it, recall_0.3=(539, 536) / 954]eval:  62%|█████████████████████████████▌                  | 127/206 [02:57<02:07,  1.62s/it, recall_0.3=(543, 540) / 962]eval:  62%|█████████████████████████████▊                  | 128/206 [02:57<01:55,  1.49s/it, recall_0.3=(543, 540) / 962]eval:  62%|█████████████████████████████▊                  | 128/206 [03:01<01:55,  1.49s/it, recall_0.3=(546, 543) / 970]eval:  63%|██████████████████████████████                  | 129/206 [03:01<02:47,  2.18s/it, recall_0.3=(546, 543) / 970]eval:  63%|██████████████████████████████                  | 129/206 [03:02<02:47,  2.18s/it, recall_0.3=(548, 545) / 976]eval:  63%|██████████████████████████████▎                 | 130/206 [03:02<02:21,  1.86s/it, recall_0.3=(548, 545) / 976]eval:  63%|██████████████████████████████▎                 | 130/206 [03:03<02:21,  1.86s/it, recall_0.3=(549, 546) / 978]eval:  64%|██████████████████████████████▌                 | 131/206 [03:03<02:03,  1.65s/it, recall_0.3=(549, 546) / 978]eval:  64%|██████████████████████████████▌                 | 131/206 [03:04<02:03,  1.65s/it, recall_0.3=(549, 546) / 980]eval:  64%|██████████████████████████████▊                 | 132/206 [03:04<01:51,  1.50s/it, recall_0.3=(549, 546) / 980]eval:  64%|██████████████████████████████▊                 | 132/206 [03:06<01:51,  1.50s/it, recall_0.3=(550, 547) / 984]eval:  65%|██████████████████████████████▉                 | 133/206 [03:06<01:56,  1.60s/it, recall_0.3=(550, 547) / 984]eval:  65%|██████████████████████████████▉                 | 133/206 [03:07<01:56,  1.60s/it, recall_0.3=(550, 547) / 987]eval:  65%|███████████████████████████████▏                | 134/206 [03:07<01:43,  1.44s/it, recall_0.3=(550, 547) / 987]eval:  65%|███████████████████████████████▏                | 134/206 [03:08<01:43,  1.44s/it, recall_0.3=(553, 550) / 997]eval:  66%|███████████████████████████████▍                | 135/206 [03:08<01:29,  1.26s/it, recall_0.3=(553, 550) / 997]eval:  66%|███████████████████████████████▍                | 135/206 [03:09<01:29,  1.26s/it, recall_0.3=(553, 550) / 999]eval:  66%|███████████████████████████████▋                | 136/206 [03:09<01:18,  1.12s/it, recall_0.3=(553, 550) / 999]eval:  66%|███████████████████████████████                | 136/206 [03:09<01:18,  1.12s/it, recall_0.3=(555, 553) / 1004]eval:  67%|███████████████████████████████▎               | 137/206 [03:09<01:10,  1.02s/it, recall_0.3=(555, 553) / 1004]eval:  67%|███████████████████████████████▎               | 137/206 [03:10<01:10,  1.02s/it, recall_0.3=(555, 553) / 1009]eval:  67%|███████████████████████████████▍               | 138/206 [03:10<00:58,  1.16it/s, recall_0.3=(555, 553) / 1009]eval:  67%|███████████████████████████████▍               | 138/206 [03:11<00:58,  1.16it/s, recall_0.3=(557, 555) / 1015]eval:  67%|███████████████████████████████▋               | 139/206 [03:11<00:53,  1.25it/s, recall_0.3=(557, 555) / 1015]eval:  67%|███████████████████████████████▋               | 139/206 [03:14<00:53,  1.25it/s, recall_0.3=(563, 561) / 1026]eval:  68%|███████████████████████████████▉               | 140/206 [03:14<01:47,  1.64s/it, recall_0.3=(563, 561) / 1026]eval:  68%|███████████████████████████████▉               | 140/206 [03:18<01:47,  1.64s/it, recall_0.3=(571, 569) / 1040]eval:  68%|████████████████████████████████▏              | 141/206 [03:18<02:28,  2.28s/it, recall_0.3=(571, 569) / 1040]eval:  68%|████████████████████████████████▏              | 141/206 [03:19<02:28,  2.28s/it, recall_0.3=(581, 579) / 1053]eval:  69%|████████████████████████████████▍              | 142/206 [03:19<02:01,  1.91s/it, recall_0.3=(581, 579) / 1053]eval:  69%|████████████████████████████████▍              | 142/206 [03:20<02:01,  1.91s/it, recall_0.3=(600, 598) / 1076]eval:  69%|████████████████████████████████▋              | 143/206 [03:20<01:41,  1.62s/it, recall_0.3=(600, 598) / 1076]eval:  69%|████████████████████████████████▋              | 143/206 [03:21<01:41,  1.62s/it, recall_0.3=(610, 608) / 1093]eval:  70%|████████████████████████████████▊              | 144/206 [03:21<01:24,  1.36s/it, recall_0.3=(610, 608) / 1093]eval:  70%|████████████████████████████████▊              | 144/206 [03:23<01:24,  1.36s/it, recall_0.3=(618, 617) / 1104]eval:  70%|█████████████████████████████████              | 145/206 [03:23<01:46,  1.74s/it, recall_0.3=(618, 617) / 1104]eval:  70%|█████████████████████████████████              | 145/206 [03:24<01:46,  1.74s/it, recall_0.3=(624, 623) / 1121]eval:  71%|█████████████████████████████████▎             | 146/206 [03:24<01:30,  1.50s/it, recall_0.3=(624, 623) / 1121]eval:  71%|█████████████████████████████████▎             | 146/206 [03:25<01:30,  1.50s/it, recall_0.3=(625, 624) / 1123]eval:  71%|█████████████████████████████████▌             | 147/206 [03:25<01:22,  1.41s/it, recall_0.3=(625, 624) / 1123]eval:  71%|█████████████████████████████████▌             | 147/206 [03:27<01:22,  1.41s/it, recall_0.3=(628, 627) / 1131]eval:  72%|█████████████████████████████████▊             | 148/206 [03:27<01:27,  1.51s/it, recall_0.3=(628, 627) / 1131]eval:  72%|█████████████████████████████████▊             | 148/206 [03:31<01:27,  1.51s/it, recall_0.3=(630, 629) / 1134]eval:  72%|█████████████████████████████████▉             | 149/206 [03:31<01:58,  2.08s/it, recall_0.3=(630, 629) / 1134]eval:  72%|█████████████████████████████████▉             | 149/206 [03:32<01:58,  2.08s/it, recall_0.3=(632, 631) / 1137]eval:  73%|██████████████████████████████████▏            | 150/206 [03:32<01:36,  1.73s/it, recall_0.3=(632, 631) / 1137]eval:  73%|██████████████████████████████████▏            | 150/206 [03:32<01:36,  1.73s/it, recall_0.3=(634, 633) / 1142]eval:  73%|██████████████████████████████████▍            | 151/206 [03:32<01:17,  1.41s/it, recall_0.3=(634, 633) / 1142]eval:  73%|██████████████████████████████████▍            | 151/206 [03:33<01:17,  1.41s/it, recall_0.3=(635, 634) / 1145]eval:  74%|██████████████████████████████████▋            | 152/206 [03:33<01:06,  1.23s/it, recall_0.3=(635, 634) / 1145]eval:  74%|██████████████████████████████████▋            | 152/206 [03:34<01:06,  1.23s/it, recall_0.3=(638, 637) / 1150]eval:  74%|██████████████████████████████████▉            | 153/206 [03:34<00:59,  1.13s/it, recall_0.3=(638, 637) / 1150]eval:  74%|██████████████████████████████████▉            | 153/206 [03:35<00:59,  1.13s/it, recall_0.3=(640, 639) / 1154]eval:  75%|███████████████████████████████████▏           | 154/206 [03:35<00:52,  1.00s/it, recall_0.3=(640, 639) / 1154]eval:  75%|███████████████████████████████████▏           | 154/206 [03:35<00:52,  1.00s/it, recall_0.3=(642, 641) / 1157]eval:  75%|███████████████████████████████████▎           | 155/206 [03:35<00:48,  1.05it/s, recall_0.3=(642, 641) / 1157]eval:  75%|███████████████████████████████████▎           | 155/206 [03:36<00:48,  1.05it/s, recall_0.3=(644, 643) / 1162]eval:  76%|███████████████████████████████████▌           | 156/206 [03:36<00:45,  1.10it/s, recall_0.3=(644, 643) / 1162]eval:  76%|███████████████████████████████████▌           | 156/206 [03:39<00:45,  1.10it/s, recall_0.3=(646, 645) / 1166]eval:  76%|███████████████████████████████████▊           | 157/206 [03:39<01:14,  1.51s/it, recall_0.3=(646, 645) / 1166]eval:  76%|███████████████████████████████████▊           | 157/206 [03:40<01:14,  1.51s/it, recall_0.3=(647, 646) / 1168]eval:  77%|████████████████████████████████████           | 158/206 [03:40<01:01,  1.29s/it, recall_0.3=(647, 646) / 1168]eval:  77%|████████████████████████████████████           | 158/206 [03:41<01:01,  1.29s/it, recall_0.3=(647, 646) / 1168]eval:  77%|████████████████████████████████████▎          | 159/206 [03:41<00:56,  1.21s/it, recall_0.3=(647, 646) / 1168]eval:  77%|████████████████████████████████████▎          | 159/206 [03:42<00:56,  1.21s/it, recall_0.3=(649, 648) / 1172]eval:  78%|████████████████████████████████████▌          | 160/206 [03:42<00:56,  1.23s/it, recall_0.3=(649, 648) / 1172]eval:  78%|████████████████████████████████████▌          | 160/206 [03:44<00:56,  1.23s/it, recall_0.3=(653, 652) / 1177]eval:  78%|████████████████████████████████████▋          | 161/206 [03:44<00:55,  1.24s/it, recall_0.3=(653, 652) / 1177]eval:  78%|████████████████████████████████████▋          | 161/206 [03:44<00:55,  1.24s/it, recall_0.3=(661, 660) / 1189]eval:  79%|████████████████████████████████████▉          | 162/206 [03:44<00:49,  1.13s/it, recall_0.3=(661, 660) / 1189]eval:  79%|████████████████████████████████████▉          | 162/206 [03:45<00:49,  1.13s/it, recall_0.3=(674, 673) / 1206]eval:  79%|█████████████████████████████████████▏         | 163/206 [03:45<00:47,  1.12s/it, recall_0.3=(674, 673) / 1206]eval:  79%|█████████████████████████████████████▏         | 163/206 [03:47<00:47,  1.12s/it, recall_0.3=(683, 684) / 1222]eval:  80%|█████████████████████████████████████▍         | 164/206 [03:47<00:47,  1.14s/it, recall_0.3=(683, 684) / 1222]eval:  80%|█████████████████████████████████████▍         | 164/206 [03:49<00:47,  1.14s/it, recall_0.3=(690, 691) / 1233]eval:  80%|█████████████████████████████████████▋         | 165/206 [03:49<01:04,  1.57s/it, recall_0.3=(690, 691) / 1233]eval:  80%|█████████████████████████████████████▋         | 165/206 [03:50<01:04,  1.57s/it, recall_0.3=(698, 699) / 1253]eval:  81%|█████████████████████████████████████▊         | 166/206 [03:50<00:53,  1.33s/it, recall_0.3=(698, 699) / 1253]eval:  81%|█████████████████████████████████████▊         | 166/206 [03:51<00:53,  1.33s/it, recall_0.3=(704, 706) / 1268]eval:  81%|██████████████████████████████████████         | 167/206 [03:51<00:47,  1.21s/it, recall_0.3=(704, 706) / 1268]eval:  81%|██████████████████████████████████████         | 167/206 [03:52<00:47,  1.21s/it, recall_0.3=(709, 711) / 1280]eval:  82%|██████████████████████████████████████▎        | 168/206 [03:52<00:45,  1.19s/it, recall_0.3=(709, 711) / 1280]eval:  82%|██████████████████████████████████████▎        | 168/206 [03:57<00:45,  1.19s/it, recall_0.3=(711, 713) / 1290]eval:  82%|██████████████████████████████████████▌        | 169/206 [03:57<01:22,  2.23s/it, recall_0.3=(711, 713) / 1290]eval:  82%|██████████████████████████████████████▌        | 169/206 [03:58<01:22,  2.23s/it, recall_0.3=(713, 715) / 1298]eval:  83%|██████████████████████████████████████▊        | 170/206 [03:58<01:07,  1.89s/it, recall_0.3=(713, 715) / 1298]eval:  83%|██████████████████████████████████████▊        | 170/206 [03:59<01:07,  1.89s/it, recall_0.3=(720, 722) / 1310]eval:  83%|███████████████████████████████████████        | 171/206 [03:59<00:59,  1.69s/it, recall_0.3=(720, 722) / 1310]eval:  83%|███████████████████████████████████████        | 171/206 [04:00<00:59,  1.69s/it, recall_0.3=(722, 724) / 1315]eval:  83%|███████████████████████████████████████▏       | 172/206 [04:00<00:53,  1.58s/it, recall_0.3=(722, 724) / 1315]eval:  83%|███████████████████████████████████████▏       | 172/206 [04:01<00:53,  1.58s/it, recall_0.3=(724, 726) / 1319]eval:  84%|███████████████████████████████████████▍       | 173/206 [04:01<00:45,  1.37s/it, recall_0.3=(724, 726) / 1319]eval:  84%|███████████████████████████████████████▍       | 173/206 [04:02<00:45,  1.37s/it, recall_0.3=(727, 729) / 1323]eval:  84%|███████████████████████████████████████▋       | 174/206 [04:02<00:40,  1.26s/it, recall_0.3=(727, 729) / 1323]eval:  84%|███████████████████████████████████████▋       | 174/206 [04:03<00:40,  1.26s/it, recall_0.3=(727, 729) / 1328]eval:  85%|███████████████████████████████████████▉       | 175/206 [04:03<00:35,  1.13s/it, recall_0.3=(727, 729) / 1328]eval:  85%|███████████████████████████████████████▉       | 175/206 [04:04<00:35,  1.13s/it, recall_0.3=(728, 730) / 1333]eval:  85%|████████████████████████████████████████▏      | 176/206 [04:04<00:30,  1.03s/it, recall_0.3=(728, 730) / 1333]eval:  85%|████████████████████████████████████████▏      | 176/206 [04:05<00:30,  1.03s/it, recall_0.3=(728, 730) / 1335]eval:  86%|████████████████████████████████████████▍      | 177/206 [04:05<00:30,  1.06s/it, recall_0.3=(728, 730) / 1335]eval:  86%|████████████████████████████████████████▍      | 177/206 [04:06<00:30,  1.06s/it, recall_0.3=(728, 730) / 1339]eval:  86%|████████████████████████████████████████▌      | 178/206 [04:06<00:28,  1.02s/it, recall_0.3=(728, 730) / 1339]eval:  86%|████████████████████████████████████████▌      | 178/206 [04:07<00:28,  1.02s/it, recall_0.3=(728, 730) / 1341]eval:  87%|████████████████████████████████████████▊      | 179/206 [04:07<00:26,  1.02it/s, recall_0.3=(728, 730) / 1341]eval:  87%|████████████████████████████████████████▊      | 179/206 [04:08<00:26,  1.02it/s, recall_0.3=(731, 734) / 1346]eval:  87%|█████████████████████████████████████████      | 180/206 [04:08<00:25,  1.01it/s, recall_0.3=(731, 734) / 1346]eval:  87%|█████████████████████████████████████████      | 180/206 [04:13<00:25,  1.01it/s, recall_0.3=(731, 734) / 1346]eval:  88%|█████████████████████████████████████████▎     | 181/206 [04:13<00:55,  2.21s/it, recall_0.3=(731, 734) / 1346]eval:  88%|█████████████████████████████████████████▎     | 181/206 [04:14<00:55,  2.21s/it, recall_0.3=(733, 736) / 1354]eval:  88%|█████████████████████████████████████████▌     | 182/206 [04:14<00:44,  1.84s/it, recall_0.3=(733, 736) / 1354]eval:  88%|█████████████████████████████████████████▌     | 182/206 [04:15<00:44,  1.84s/it, recall_0.3=(735, 738) / 1361]eval:  89%|█████████████████████████████████████████▊     | 183/206 [04:15<00:35,  1.54s/it, recall_0.3=(735, 738) / 1361]eval:  89%|█████████████████████████████████████████▊     | 183/206 [04:16<00:35,  1.54s/it, recall_0.3=(737, 740) / 1386]eval:  89%|█████████████████████████████████████████▉     | 184/206 [04:16<00:30,  1.38s/it, recall_0.3=(737, 740) / 1386]eval:  89%|█████████████████████████████████████████▉     | 184/206 [04:20<00:30,  1.38s/it, recall_0.3=(746, 749) / 1401]eval:  90%|██████████████████████████████████████████▏    | 185/206 [04:20<00:45,  2.15s/it, recall_0.3=(746, 749) / 1401]eval:  90%|██████████████████████████████████████████▏    | 185/206 [04:21<00:45,  2.15s/it, recall_0.3=(756, 759) / 1415]eval:  90%|██████████████████████████████████████████▍    | 186/206 [04:21<00:35,  1.77s/it, recall_0.3=(756, 759) / 1415]eval:  90%|██████████████████████████████████████████▍    | 186/206 [04:21<00:35,  1.77s/it, recall_0.3=(763, 766) / 1427]eval:  91%|██████████████████████████████████████████▋    | 187/206 [04:22<00:28,  1.53s/it, recall_0.3=(763, 766) / 1427]eval:  91%|██████████████████████████████████████████▋    | 187/206 [04:23<00:28,  1.53s/it, recall_0.3=(764, 767) / 1436]eval:  91%|██████████████████████████████████████████▉    | 188/206 [04:23<00:26,  1.45s/it, recall_0.3=(764, 767) / 1436]eval:  91%|██████████████████████████████████████████▉    | 188/206 [04:25<00:26,  1.45s/it, recall_0.3=(766, 769) / 1440]eval:  92%|███████████████████████████████████████████    | 189/206 [04:25<00:29,  1.72s/it, recall_0.3=(766, 769) / 1440]eval:  92%|███████████████████████████████████████████    | 189/206 [04:26<00:29,  1.72s/it, recall_0.3=(769, 772) / 1446]eval:  92%|███████████████████████████████████████████▎   | 190/206 [04:26<00:23,  1.50s/it, recall_0.3=(769, 772) / 1446]eval:  92%|███████████████████████████████████████████▎   | 190/206 [04:27<00:23,  1.50s/it, recall_0.3=(771, 774) / 1450]eval:  93%|███████████████████████████████████████████▌   | 191/206 [04:27<00:20,  1.40s/it, recall_0.3=(771, 774) / 1450]eval:  93%|███████████████████████████████████████████▌   | 191/206 [04:28<00:20,  1.40s/it, recall_0.3=(772, 775) / 1452]eval:  93%|███████████████████████████████████████████▊   | 192/206 [04:28<00:17,  1.26s/it, recall_0.3=(772, 775) / 1452]eval:  93%|███████████████████████████████████████████▊   | 192/206 [04:29<00:17,  1.26s/it, recall_0.3=(773, 776) / 1455]eval:  94%|████████████████████████████████████████████   | 193/206 [04:29<00:15,  1.20s/it, recall_0.3=(773, 776) / 1455]eval:  94%|████████████████████████████████████████████   | 193/206 [04:30<00:15,  1.20s/it, recall_0.3=(773, 776) / 1455]eval:  94%|████████████████████████████████████████████▎  | 194/206 [04:30<00:13,  1.13s/it, recall_0.3=(773, 776) / 1455]eval:  94%|████████████████████████████████████████████▎  | 194/206 [04:31<00:13,  1.13s/it, recall_0.3=(773, 776) / 1455]eval:  95%|████████████████████████████████████████████▍  | 195/206 [04:31<00:11,  1.09s/it, recall_0.3=(773, 776) / 1455]eval:  95%|████████████████████████████████████████████▍  | 195/206 [04:32<00:11,  1.09s/it, recall_0.3=(773, 776) / 1455]eval:  95%|████████████████████████████████████████████▋  | 196/206 [04:32<00:10,  1.04s/it, recall_0.3=(773, 776) / 1455]eval:  95%|████████████████████████████████████████████▋  | 196/206 [04:33<00:10,  1.04s/it, recall_0.3=(773, 776) / 1455]eval:  96%|████████████████████████████████████████████▉  | 197/206 [04:33<00:09,  1.03s/it, recall_0.3=(773, 776) / 1455]eval:  96%|████████████████████████████████████████████▉  | 197/206 [04:34<00:09,  1.03s/it, recall_0.3=(775, 778) / 1458]eval:  96%|█████████████████████████████████████████████▏ | 198/206 [04:34<00:07,  1.01it/s, recall_0.3=(775, 778) / 1458]eval:  96%|█████████████████████████████████████████████▏ | 198/206 [04:35<00:07,  1.01it/s, recall_0.3=(778, 781) / 1463]eval:  97%|█████████████████████████████████████████████▍ | 199/206 [04:35<00:07,  1.02s/it, recall_0.3=(778, 781) / 1463]eval:  97%|█████████████████████████████████████████████▍ | 199/206 [04:36<00:07,  1.02s/it, recall_0.3=(778, 781) / 1465]eval:  97%|█████████████████████████████████████████████▋ | 200/206 [04:36<00:06,  1.03s/it, recall_0.3=(778, 781) / 1465]eval:  97%|█████████████████████████████████████████████▋ | 200/206 [04:39<00:06,  1.03s/it, recall_0.3=(778, 781) / 1465]eval:  98%|█████████████████████████████████████████████▊ | 201/206 [04:39<00:07,  1.59s/it, recall_0.3=(778, 781) / 1465]eval:  98%|█████████████████████████████████████████████▊ | 201/206 [04:40<00:07,  1.59s/it, recall_0.3=(779, 782) / 1468]eval:  98%|██████████████████████████████████████████████ | 202/206 [04:40<00:05,  1.33s/it, recall_0.3=(779, 782) / 1468]eval:  98%|██████████████████████████████████████████████ | 202/206 [04:41<00:05,  1.33s/it, recall_0.3=(782, 785) / 1471]eval:  99%|██████████████████████████████████████████████▎| 203/206 [04:41<00:03,  1.15s/it, recall_0.3=(782, 785) / 1471]eval:  99%|██████████████████████████████████████████████▎| 203/206 [04:41<00:03,  1.15s/it, recall_0.3=(784, 787) / 1474]eval:  99%|██████████████████████████████████████████████▌| 204/206 [04:41<00:01,  1.08it/s, recall_0.3=(784, 787) / 1474]eval:  99%|██████████████████████████████████████████████▌| 204/206 [04:41<00:01,  1.08it/s, recall_0.3=(785, 788) / 1477]eval: 100%|██████████████████████████████████████████████▊| 205/206 [04:41<00:00,  1.32it/s, recall_0.3=(785, 788) / 1477]eval: 100%|██████████████████████████████████████████████▊| 205/206 [04:42<00:00,  1.32it/s, recall_0.3=(785, 788) / 1478]eval: 100%|███████████████████████████████████████████████| 206/206 [04:42<00:00,  1.60it/s, recall_0.3=(785, 788) / 1478]eval: 100%|███████████████████████████████████████████████| 206/206 [04:42<00:00,  1.37s/it, recall_0.3=(785, 788) / 1478]
2023-03-03 11:51:44,297   INFO  *************** Performance of EPOCH 8 *****************
2023-03-03 11:51:44,298   INFO  Generate label finished(sec_per_example: 0.1745 second).
2023-03-03 11:51:44,298   INFO  recall_roi_0.3: 0.527807
2023-03-03 11:51:44,299   INFO  recall_rcnn_0.3: 0.530995
2023-03-03 11:51:44,299   INFO  recall_roi_0.5: 0.402586
2023-03-03 11:51:44,300   INFO  recall_rcnn_0.5: 0.427736
2023-03-03 11:51:44,300   INFO  recall_roi_0.7: 0.188452
2023-03-03 11:51:44,300   INFO  recall_rcnn_0.7: 0.232200
2023-03-03 11:51:44,301   INFO  Average predicted number of objects(1644 samples): 6.788
======
Loading Ithaca365 tables for version v1.1...
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
6 category,
1 attribute,
4 visibility,
25839 instance,
3 sensor,
3 calibrated_sensor,
760811 ego_pose,
40 log,
40 scene,
6576 sample,
2282433 sample_data,
25839 sample_annotation,
1 map,
2579 location,
Done loading in 52.660 seconds.
======
Reverse indexing ...
Done reverse indexing in 5.8 seconds.
======
2023-03-03 11:52:44,935   INFO  The predictions of NuScenes have been saved to /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/eval/eval_with_train/epoch_8/val/final_result/data/results_nusc.json
Initializing nuScenes detection evaluation
Loaded results from /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/eval/eval_with_train/epoch_8/val/final_result/data/results_nusc.json. Found detections for 1644 samples.
Loading annotations for val split from nuScenes version: v1.1
  0%|                                                                                            | 0/1644 [00:00<?, ?it/s] 40%|████████████████████████████████▎                                               | 664/1644 [00:00<00:00, 6628.79it/s] 81%|███████████████████████████████████████████████████████████████▊               | 1327/1644 [00:00<00:00, 5897.08it/s]100%|███████████████████████████████████████████████████████████████████████████████| 1644/1644 [00:00<00:00, 6286.64it/s]
Loaded ground truth annotations for 1644 samples.
Filtering predictions
Detection range: (0, 30)
=> Original number of boxes: 11160
=> After distance based filtering: 3023
=> After LIDAR and RADAR points based filtering: 3023
Detection range: (30, 50)
=> Original number of boxes: 11160
=> After distance based filtering: 3994
=> After LIDAR and RADAR points based filtering: 3994
Detection range: (50, 80)
=> Original number of boxes: 11160
=> After distance based filtering: 3642
=> After LIDAR and RADAR points based filtering: 3642
Detection range: (0, 80)
=> Original number of boxes: 11160
=> After distance based filtering: 10659
=> After LIDAR and RADAR points based filtering: 10659
Filtering ground truth annotations
Detection range: (0, 30)
=> Original number of boxes: 6018
=> After distance based filtering: 1648
=> After LIDAR and RADAR points based filtering: 1648
Detection range: (30, 50)
=> Original number of boxes: 6018
=> After distance based filtering: 1660
=> After LIDAR and RADAR points based filtering: 1660
Detection range: (50, 80)
=> Original number of boxes: 6018
=> After distance based filtering: 1493
=> After LIDAR and RADAR points based filtering: 1493
Detection range: (0, 80)
=> Original number of boxes: 6018
=> After distance based filtering: 4801
=> After LIDAR and RADAR points based filtering: 4801
Accumulating metric data...
Calculating metrics...
Saving metrics to: /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/eval/eval_with_train/epoch_8/val/final_result/data
mAP: 0.1380
mATE: 0.7259
mASE: 0.7544
mAOE: 1.0036
NDS: 0.1556
Eval time: 2.8s

Per-class results:
Object Class	Det. Range	AP	ATE	ASE	AOE
car         	(0, 30)   	0.603	0.232	0.148	1.041
car         	(30, 50)  	0.361	0.254	0.168	0.813
car         	(50, 80)  	0.159	0.383	0.191	0.872
car         	(0, 80)   	0.390	0.261	0.160	0.935
truck       	(0, 30)   	0.000	1.000	1.000	1.000
truck       	(30, 50)  	0.000	1.000	1.000	1.000
truck       	(50, 80)  	0.000	1.000	1.000	1.000
truck       	(0, 80)   	0.000	1.000	1.000	1.000
bus         	(0, 30)   	0.000	1.000	1.000	1.000
bus         	(30, 50)  	0.000	1.000	1.000	1.000
bus         	(50, 80)  	0.000	1.000	1.000	1.000
bus         	(0, 80)   	0.000	1.000	1.000	1.000
pedestrian  	(0, 30)   	0.554	0.075	0.332	0.831
pedestrian  	(30, 50)  	0.440	0.101	0.392	1.238
pedestrian  	(50, 80)  	0.211	0.141	0.405	1.381
pedestrian  	(0, 80)   	0.438	0.094	0.367	1.087
motorcyclist	(0, 30)   	0.000	1.000	1.000	1.000
motorcyclist	(30, 50)  	0.000	1.000	1.000	1.000
motorcyclist	(50, 80)  	0.000	1.000	1.000	1.000
motorcyclist	(0, 80)   	0.000	1.000	1.000	1.000
bicyclist   	(0, 30)   	0.000	1.000	1.000	1.000
bicyclist   	(30, 50)  	0.000	1.000	1.000	1.000
bicyclist   	(50, 80)  	0.000	1.000	1.000	1.000
bicyclist   	(0, 80)   	0.000	1.000	1.000	1.000
2023-03-03 11:52:53,122   INFO  ----------------Nuscene detection_by_range results-----------------
***car
range (0, 30) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.23, 0.15, 1.04 | 53.38, 59.13, 63.78, 64.73 | mean AP: 0.6025329784554043
range (30, 50) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.25, 0.17, 0.81 | 29.90, 34.94, 38.92, 40.62 | mean AP: 0.3609644419413994
range (50, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.38, 0.19, 0.87 | 9.56, 13.96, 19.64, 20.30 | mean AP: 0.15864244347767636
range (0, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.26, 0.16, 0.93 | 32.01, 37.66, 42.50, 43.87 | mean AP: 0.3901062434234258
***pedestrian
range (0, 30) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.07, 0.33, 0.83 | 55.04, 55.04, 55.45, 56.06 | mean AP: 0.5539660042643051
range (30, 50) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.10, 0.39, 1.24 | 43.16, 43.29, 43.52, 45.86 | mean AP: 0.43957715517930585
range (50, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.14, 0.40, 1.38 | 20.84, 20.97, 20.97, 21.80 | mean AP: 0.21147216409988995
range (0, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.09, 0.37, 1.09 | 43.22, 43.36, 43.56, 45.09 | mean AP: 0.43809578190941834
--------------average performance-------------
trans_err:	 0.7259
scale_err:	 0.7544
orient_err:	 1.0036
mAP:	 0.1380
NDS:	 0.1556
--------------table log summary-------------
***car
match 1.0m:	(0, 30), (30, 50), (50, 80), (0, 80)
59.13, 34.94, 13.96, 37.66
***pedestrian
match 1.0m:	(0, 30), (30, 50), (50, 80), (0, 80)
55.04, 43.29, 20.97, 43.36

2023-03-03 11:52:53,123   INFO  Result is save to /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/eval/eval_with_train/epoch_8/val
2023-03-03 11:52:53,123   INFO  ****************Evaluation done.*****************
2023-03-03 11:52:53,133   INFO  Epoch 8 has been evaluated
2023-03-03 11:52:53,136   INFO  ==> Loading parameters from checkpoint /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/ckpt/checkpoint_epoch_9.pth to CPU
2023-03-03 11:52:53,240   INFO  ==> Checkpoint trained from version: pcdet+0.3.0+0000000
2023-03-03 11:52:54,340   INFO  ==> Done (loaded 502/502)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
2023-03-03 11:52:54,351   INFO  *************** EPOCH 9 EVALUATION *****************
eval:   0%|                                                                                       | 0/206 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
eval:   0%|                                                                | 0/206 [00:09<?, ?it/s, recall_0.3=(2, 2) / 5]eval:   0%|▎                                                       | 1/206 [00:09<33:03,  9.68s/it, recall_0.3=(2, 2) / 5]eval:   0%|▎                                                    | 1/206 [00:10<33:03,  9.68s/it, recall_0.3=(15, 15) / 23]eval:   1%|▌                                                    | 2/206 [00:10<15:40,  4.61s/it, recall_0.3=(15, 15) / 23]eval:   1%|▌                                                    | 2/206 [00:11<15:40,  4.61s/it, recall_0.3=(20, 20) / 30]eval:   1%|▊                                                    | 3/206 [00:11<10:17,  3.04s/it, recall_0.3=(20, 20) / 30]eval:   1%|▊                                                    | 3/206 [00:12<10:17,  3.04s/it, recall_0.3=(24, 24) / 36]eval:   2%|█                                                    | 4/206 [00:12<07:34,  2.25s/it, recall_0.3=(24, 24) / 36]eval:   2%|█                                                    | 4/206 [00:16<07:34,  2.25s/it, recall_0.3=(30, 30) / 43]eval:   2%|█▎                                                   | 5/206 [00:16<09:34,  2.86s/it, recall_0.3=(30, 30) / 43]eval:   2%|█▎                                                   | 5/206 [00:18<09:34,  2.86s/it, recall_0.3=(33, 33) / 48]eval:   3%|█▌                                                   | 6/206 [00:18<07:51,  2.36s/it, recall_0.3=(33, 33) / 48]eval:   3%|█▌                                                   | 6/206 [00:19<07:51,  2.36s/it, recall_0.3=(37, 37) / 53]eval:   3%|█▊                                                   | 7/206 [00:19<06:24,  1.93s/it, recall_0.3=(37, 37) / 53]eval:   3%|█▊                                                   | 7/206 [00:20<06:24,  1.93s/it, recall_0.3=(38, 38) / 56]eval:   4%|██                                                   | 8/206 [00:20<05:39,  1.72s/it, recall_0.3=(38, 38) / 56]eval:   4%|██                                                   | 8/206 [00:21<05:39,  1.72s/it, recall_0.3=(38, 38) / 56]eval:   4%|██▎                                                  | 9/206 [00:21<04:48,  1.46s/it, recall_0.3=(38, 38) / 56]eval:   4%|██▎                                                  | 9/206 [00:22<04:48,  1.46s/it, recall_0.3=(38, 38) / 56]eval:   5%|██▌                                                 | 10/206 [00:22<04:23,  1.35s/it, recall_0.3=(38, 38) / 56]eval:   5%|██▌                                                 | 10/206 [00:23<04:23,  1.35s/it, recall_0.3=(38, 38) / 58]eval:   5%|██▊                                                 | 11/206 [00:23<04:15,  1.31s/it, recall_0.3=(38, 38) / 58]eval:   5%|██▊                                                 | 11/206 [00:24<04:15,  1.31s/it, recall_0.3=(38, 38) / 61]eval:   6%|███                                                 | 12/206 [00:24<03:54,  1.21s/it, recall_0.3=(38, 38) / 61]eval:   6%|███                                                 | 12/206 [00:26<03:54,  1.21s/it, recall_0.3=(41, 41) / 67]eval:   6%|███▎                                                | 13/206 [00:26<04:22,  1.36s/it, recall_0.3=(41, 41) / 67]eval:   6%|███▎                                                | 13/206 [00:27<04:22,  1.36s/it, recall_0.3=(44, 44) / 72]eval:   7%|███▌                                                | 14/206 [00:27<04:05,  1.28s/it, recall_0.3=(44, 44) / 72]eval:   7%|███▌                                                | 14/206 [00:28<04:05,  1.28s/it, recall_0.3=(46, 46) / 75]eval:   7%|███▊                                                | 15/206 [00:28<04:01,  1.26s/it, recall_0.3=(46, 46) / 75]eval:   7%|███▊                                                | 15/206 [00:29<04:01,  1.26s/it, recall_0.3=(48, 48) / 77]eval:   8%|████                                                | 16/206 [00:29<03:46,  1.19s/it, recall_0.3=(48, 48) / 77]eval:   8%|████                                                | 16/206 [00:33<03:46,  1.19s/it, recall_0.3=(48, 48) / 80]eval:   8%|████▎                                               | 17/206 [00:33<06:33,  2.08s/it, recall_0.3=(48, 48) / 80]eval:   8%|████▎                                               | 17/206 [00:34<06:33,  2.08s/it, recall_0.3=(50, 50) / 83]eval:   9%|████▌                                               | 18/206 [00:34<05:30,  1.76s/it, recall_0.3=(50, 50) / 83]eval:   9%|████▌                                               | 18/206 [00:36<05:30,  1.76s/it, recall_0.3=(51, 51) / 85]eval:   9%|████▊                                               | 19/206 [00:36<04:49,  1.55s/it, recall_0.3=(51, 51) / 85]eval:   9%|████▊                                               | 19/206 [00:36<04:49,  1.55s/it, recall_0.3=(52, 52) / 87]eval:  10%|█████                                               | 20/206 [00:36<04:07,  1.33s/it, recall_0.3=(52, 52) / 87]eval:  10%|█████                                               | 20/206 [00:40<04:07,  1.33s/it, recall_0.3=(56, 56) / 92]eval:  10%|█████▎                                              | 21/206 [00:40<06:09,  2.00s/it, recall_0.3=(56, 56) / 92]eval:  10%|█████▏                                             | 21/206 [00:41<06:09,  2.00s/it, recall_0.3=(61, 61) / 103]eval:  11%|█████▍                                             | 22/206 [00:41<05:26,  1.77s/it, recall_0.3=(61, 61) / 103]eval:  11%|█████▍                                             | 22/206 [00:42<05:26,  1.77s/it, recall_0.3=(72, 72) / 125]eval:  11%|█████▋                                             | 23/206 [00:42<04:55,  1.61s/it, recall_0.3=(72, 72) / 125]eval:  11%|█████▋                                             | 23/206 [00:44<04:55,  1.61s/it, recall_0.3=(79, 79) / 133]eval:  12%|█████▉                                             | 24/206 [00:44<04:27,  1.47s/it, recall_0.3=(79, 79) / 133]eval:  12%|█████▉                                             | 24/206 [00:45<04:27,  1.47s/it, recall_0.3=(89, 89) / 145]eval:  12%|██████▏                                            | 25/206 [00:45<04:45,  1.58s/it, recall_0.3=(89, 89) / 145]eval:  12%|██████▏                                            | 25/206 [00:46<04:45,  1.58s/it, recall_0.3=(92, 92) / 153]eval:  13%|██████▍                                            | 26/206 [00:46<04:13,  1.41s/it, recall_0.3=(92, 92) / 153]eval:  13%|██████▍                                            | 26/206 [00:47<04:13,  1.41s/it, recall_0.3=(95, 95) / 156]eval:  13%|██████▋                                            | 27/206 [00:47<03:47,  1.27s/it, recall_0.3=(95, 95) / 156]eval:  13%|██████▍                                          | 27/206 [00:48<03:47,  1.27s/it, recall_0.3=(101, 101) / 163]eval:  14%|██████▋                                          | 28/206 [00:48<03:37,  1.22s/it, recall_0.3=(101, 101) / 163]eval:  14%|██████▋                                          | 28/206 [00:52<03:37,  1.22s/it, recall_0.3=(108, 108) / 171]eval:  14%|██████▉                                          | 29/206 [00:52<05:21,  1.82s/it, recall_0.3=(108, 108) / 171]eval:  14%|██████▉                                          | 29/206 [00:53<05:21,  1.82s/it, recall_0.3=(111, 111) / 174]eval:  15%|███████▏                                         | 30/206 [00:53<04:36,  1.57s/it, recall_0.3=(111, 111) / 174]eval:  15%|███████▏                                         | 30/206 [00:54<04:36,  1.57s/it, recall_0.3=(113, 113) / 177]eval:  15%|███████▎                                         | 31/206 [00:54<04:08,  1.42s/it, recall_0.3=(113, 113) / 177]eval:  15%|███████▎                                         | 31/206 [00:55<04:08,  1.42s/it, recall_0.3=(113, 113) / 179]eval:  16%|███████▌                                         | 32/206 [00:55<03:50,  1.32s/it, recall_0.3=(113, 113) / 179]eval:  16%|███████▌                                         | 32/206 [00:56<03:50,  1.32s/it, recall_0.3=(116, 116) / 182]eval:  16%|███████▊                                         | 33/206 [00:56<03:35,  1.25s/it, recall_0.3=(116, 116) / 182]eval:  16%|███████▊                                         | 33/206 [00:57<03:35,  1.25s/it, recall_0.3=(117, 117) / 184]eval:  17%|████████                                         | 34/206 [00:57<03:33,  1.24s/it, recall_0.3=(117, 117) / 184]eval:  17%|████████                                         | 34/206 [00:58<03:33,  1.24s/it, recall_0.3=(117, 117) / 184]eval:  17%|████████▎                                        | 35/206 [00:58<03:27,  1.21s/it, recall_0.3=(117, 117) / 184]eval:  17%|████████▎                                        | 35/206 [00:59<03:27,  1.21s/it, recall_0.3=(120, 120) / 189]eval:  17%|████████▌                                        | 36/206 [00:59<03:24,  1.20s/it, recall_0.3=(120, 120) / 189]eval:  17%|████████▌                                        | 36/206 [01:01<03:24,  1.20s/it, recall_0.3=(120, 120) / 189]eval:  18%|████████▊                                        | 37/206 [01:01<03:54,  1.39s/it, recall_0.3=(120, 120) / 189]eval:  18%|████████▊                                        | 37/206 [01:03<03:54,  1.39s/it, recall_0.3=(120, 120) / 189]eval:  18%|█████████                                        | 38/206 [01:03<04:01,  1.44s/it, recall_0.3=(120, 120) / 189]eval:  18%|█████████                                        | 38/206 [01:04<04:01,  1.44s/it, recall_0.3=(120, 120) / 189]eval:  19%|█████████▎                                       | 39/206 [01:04<03:46,  1.35s/it, recall_0.3=(120, 120) / 189]eval:  19%|█████████▎                                       | 39/206 [01:05<03:46,  1.35s/it, recall_0.3=(120, 120) / 189]eval:  19%|█████████▌                                       | 40/206 [01:05<03:31,  1.27s/it, recall_0.3=(120, 120) / 189]eval:  19%|█████████▌                                       | 40/206 [01:07<03:31,  1.27s/it, recall_0.3=(121, 121) / 193]eval:  20%|█████████▊                                       | 41/206 [01:07<04:18,  1.57s/it, recall_0.3=(121, 121) / 193]eval:  20%|█████████▊                                       | 41/206 [01:09<04:18,  1.57s/it, recall_0.3=(124, 124) / 197]eval:  20%|█████████▉                                       | 42/206 [01:09<04:06,  1.50s/it, recall_0.3=(124, 124) / 197]eval:  20%|█████████▉                                       | 42/206 [01:10<04:06,  1.50s/it, recall_0.3=(132, 133) / 220]eval:  21%|██████████▏                                      | 43/206 [01:10<03:44,  1.38s/it, recall_0.3=(132, 133) / 220]eval:  21%|██████████▏                                      | 43/206 [01:10<03:44,  1.38s/it, recall_0.3=(143, 144) / 236]eval:  21%|██████████▍                                      | 44/206 [01:10<03:10,  1.17s/it, recall_0.3=(143, 144) / 236]eval:  21%|██████████▍                                      | 44/206 [01:13<03:10,  1.17s/it, recall_0.3=(156, 157) / 255]eval:  22%|██████████▋                                      | 45/206 [01:13<04:27,  1.66s/it, recall_0.3=(156, 157) / 255]eval:  22%|██████████▋                                      | 45/206 [01:15<04:27,  1.66s/it, recall_0.3=(161, 162) / 263]eval:  22%|██████████▉                                      | 46/206 [01:15<04:09,  1.56s/it, recall_0.3=(161, 162) / 263]eval:  22%|██████████▉                                      | 46/206 [01:16<04:09,  1.56s/it, recall_0.3=(168, 169) / 274]eval:  23%|███████████▏                                     | 47/206 [01:16<03:51,  1.45s/it, recall_0.3=(168, 169) / 274]eval:  23%|███████████▏                                     | 47/206 [01:17<03:51,  1.45s/it, recall_0.3=(174, 175) / 284]eval:  23%|███████████▍                                     | 48/206 [01:17<04:00,  1.52s/it, recall_0.3=(174, 175) / 284]eval:  23%|███████████▍                                     | 48/206 [01:21<04:00,  1.52s/it, recall_0.3=(179, 180) / 290]eval:  24%|███████████▋                                     | 49/206 [01:21<05:11,  1.98s/it, recall_0.3=(179, 180) / 290]eval:  24%|███████████▋                                     | 49/206 [01:21<05:11,  1.98s/it, recall_0.3=(180, 181) / 292]eval:  24%|███████████▉                                     | 50/206 [01:21<04:16,  1.65s/it, recall_0.3=(180, 181) / 292]eval:  24%|███████████▉                                     | 50/206 [01:22<04:16,  1.65s/it, recall_0.3=(182, 183) / 296]eval:  25%|████████████▏                                    | 51/206 [01:22<03:50,  1.49s/it, recall_0.3=(182, 183) / 296]eval:  25%|████████████▏                                    | 51/206 [01:23<03:50,  1.49s/it, recall_0.3=(184, 185) / 300]eval:  25%|████████████▎                                    | 52/206 [01:23<03:25,  1.33s/it, recall_0.3=(184, 185) / 300]eval:  25%|████████████▎                                    | 52/206 [01:25<03:25,  1.33s/it, recall_0.3=(189, 190) / 308]eval:  26%|████████████▌                                    | 53/206 [01:25<03:17,  1.29s/it, recall_0.3=(189, 190) / 308]eval:  26%|████████████▌                                    | 53/206 [01:26<03:17,  1.29s/it, recall_0.3=(192, 193) / 314]eval:  26%|████████████▊                                    | 54/206 [01:26<02:59,  1.18s/it, recall_0.3=(192, 193) / 314]eval:  26%|████████████▊                                    | 54/206 [01:27<02:59,  1.18s/it, recall_0.3=(193, 194) / 317]eval:  27%|█████████████                                    | 55/206 [01:27<02:58,  1.18s/it, recall_0.3=(193, 194) / 317]eval:  27%|█████████████                                    | 55/206 [01:28<02:58,  1.18s/it, recall_0.3=(201, 202) / 331]eval:  27%|█████████████▎                                   | 56/206 [01:28<02:56,  1.17s/it, recall_0.3=(201, 202) / 331]eval:  27%|█████████████▎                                   | 56/206 [01:30<02:56,  1.17s/it, recall_0.3=(202, 203) / 335]eval:  28%|█████████████▌                                   | 57/206 [01:30<03:28,  1.40s/it, recall_0.3=(202, 203) / 335]eval:  28%|█████████████▌                                   | 57/206 [01:31<03:28,  1.40s/it, recall_0.3=(202, 203) / 337]eval:  28%|█████████████▊                                   | 58/206 [01:31<03:13,  1.31s/it, recall_0.3=(202, 203) / 337]eval:  28%|█████████████▊                                   | 58/206 [01:32<03:13,  1.31s/it, recall_0.3=(209, 210) / 349]eval:  29%|██████████████                                   | 59/206 [01:32<03:01,  1.24s/it, recall_0.3=(209, 210) / 349]eval:  29%|██████████████                                   | 59/206 [01:33<03:01,  1.24s/it, recall_0.3=(219, 220) / 362]eval:  29%|██████████████▎                                  | 60/206 [01:33<02:55,  1.20s/it, recall_0.3=(219, 220) / 362]eval:  29%|██████████████▎                                  | 60/206 [01:37<02:55,  1.20s/it, recall_0.3=(230, 232) / 374]eval:  30%|██████████████▌                                  | 61/206 [01:37<04:43,  1.95s/it, recall_0.3=(230, 232) / 374]eval:  30%|██████████████▌                                  | 61/206 [01:38<04:43,  1.95s/it, recall_0.3=(241, 242) / 391]eval:  30%|██████████████▋                                  | 62/206 [01:38<03:56,  1.64s/it, recall_0.3=(241, 242) / 391]eval:  30%|██████████████▋                                  | 62/206 [01:39<03:56,  1.64s/it, recall_0.3=(251, 254) / 408]eval:  31%|██████████████▉                                  | 63/206 [01:39<03:35,  1.51s/it, recall_0.3=(251, 254) / 408]eval:  31%|██████████████▉                                  | 63/206 [01:40<03:35,  1.51s/it, recall_0.3=(259, 262) / 422]eval:  31%|███████████████▏                                 | 64/206 [01:40<03:22,  1.43s/it, recall_0.3=(259, 262) / 422]eval:  31%|███████████████▏                                 | 64/206 [01:43<03:22,  1.43s/it, recall_0.3=(272, 275) / 438]eval:  32%|███████████████▍                                 | 65/206 [01:43<04:06,  1.75s/it, recall_0.3=(272, 275) / 438]eval:  32%|███████████████▍                                 | 65/206 [01:44<04:06,  1.75s/it, recall_0.3=(280, 282) / 450]eval:  32%|███████████████▋                                 | 66/206 [01:44<03:35,  1.54s/it, recall_0.3=(280, 282) / 450]eval:  32%|███████████████▋                                 | 66/206 [01:45<03:35,  1.54s/it, recall_0.3=(287, 289) / 464]eval:  33%|███████████████▉                                 | 67/206 [01:45<03:23,  1.47s/it, recall_0.3=(287, 289) / 464]eval:  33%|███████████████▉                                 | 67/206 [01:46<03:23,  1.47s/it, recall_0.3=(290, 292) / 468]eval:  33%|████████████████▏                                | 68/206 [01:46<03:05,  1.35s/it, recall_0.3=(290, 292) / 468]eval:  33%|████████████████▏                                | 68/206 [01:51<03:05,  1.35s/it, recall_0.3=(292, 294) / 471]eval:  33%|████████████████▍                                | 69/206 [01:51<05:13,  2.29s/it, recall_0.3=(292, 294) / 471]eval:  33%|████████████████▍                                | 69/206 [01:52<05:13,  2.29s/it, recall_0.3=(293, 295) / 473]eval:  34%|████████████████▋                                | 70/206 [01:52<04:20,  1.91s/it, recall_0.3=(293, 295) / 473]eval:  34%|████████████████▋                                | 70/206 [01:53<04:20,  1.91s/it, recall_0.3=(294, 296) / 476]eval:  34%|████████████████▉                                | 71/206 [01:53<03:46,  1.68s/it, recall_0.3=(294, 296) / 476]eval:  34%|████████████████▉                                | 71/206 [01:54<03:46,  1.68s/it, recall_0.3=(295, 297) / 479]eval:  35%|█████████████████▏                               | 72/206 [01:54<03:22,  1.51s/it, recall_0.3=(295, 297) / 479]eval:  35%|█████████████████▏                               | 72/206 [01:55<03:22,  1.51s/it, recall_0.3=(295, 297) / 479]eval:  35%|█████████████████▎                               | 73/206 [01:55<03:13,  1.45s/it, recall_0.3=(295, 297) / 479]eval:  35%|█████████████████▎                               | 73/206 [01:56<03:13,  1.45s/it, recall_0.3=(295, 297) / 481]eval:  36%|█████████████████▌                               | 74/206 [01:56<02:53,  1.32s/it, recall_0.3=(295, 297) / 481]eval:  36%|█████████████████▌                               | 74/206 [01:57<02:53,  1.32s/it, recall_0.3=(296, 298) / 484]eval:  36%|█████████████████▊                               | 75/206 [01:57<02:36,  1.20s/it, recall_0.3=(296, 298) / 484]eval:  36%|█████████████████▊                               | 75/206 [01:58<02:36,  1.20s/it, recall_0.3=(298, 300) / 488]eval:  37%|██████████████████                               | 76/206 [01:58<02:27,  1.13s/it, recall_0.3=(298, 300) / 488]eval:  37%|██████████████████                               | 76/206 [02:00<02:27,  1.13s/it, recall_0.3=(299, 301) / 492]eval:  37%|██████████████████▎                              | 77/206 [02:00<02:49,  1.32s/it, recall_0.3=(299, 301) / 492]eval:  37%|██████████████████▎                              | 77/206 [02:01<02:49,  1.32s/it, recall_0.3=(300, 302) / 494]eval:  38%|██████████████████▌                              | 78/206 [02:01<02:40,  1.25s/it, recall_0.3=(300, 302) / 494]eval:  38%|██████████████████▌                              | 78/206 [02:02<02:40,  1.25s/it, recall_0.3=(306, 307) / 504]eval:  38%|██████████████████▊                              | 79/206 [02:02<02:26,  1.16s/it, recall_0.3=(306, 307) / 504]eval:  38%|██████████████████▊                              | 79/206 [02:03<02:26,  1.16s/it, recall_0.3=(310, 311) / 510]eval:  39%|███████████████████                              | 80/206 [02:03<02:19,  1.10s/it, recall_0.3=(310, 311) / 510]eval:  39%|███████████████████                              | 80/206 [02:06<02:19,  1.10s/it, recall_0.3=(315, 316) / 516]eval:  39%|███████████████████▎                             | 81/206 [02:06<03:19,  1.59s/it, recall_0.3=(315, 316) / 516]eval:  39%|███████████████████▎                             | 81/206 [02:07<03:19,  1.59s/it, recall_0.3=(321, 322) / 523]eval:  40%|███████████████████▌                             | 82/206 [02:07<02:57,  1.43s/it, recall_0.3=(321, 322) / 523]eval:  40%|███████████████████▌                             | 82/206 [02:08<02:57,  1.43s/it, recall_0.3=(327, 328) / 529]eval:  40%|███████████████████▋                             | 83/206 [02:08<02:48,  1.37s/it, recall_0.3=(327, 328) / 529]eval:  40%|███████████████████▋                             | 83/206 [02:09<02:48,  1.37s/it, recall_0.3=(337, 338) / 553]eval:  41%|███████████████████▉                             | 84/206 [02:09<02:32,  1.25s/it, recall_0.3=(337, 338) / 553]eval:  41%|███████████████████▉                             | 84/206 [02:15<02:32,  1.25s/it, recall_0.3=(348, 349) / 572]eval:  41%|████████████████████▏                            | 85/206 [02:15<05:23,  2.68s/it, recall_0.3=(348, 349) / 572]eval:  41%|████████████████████▏                            | 85/206 [02:16<05:23,  2.68s/it, recall_0.3=(359, 360) / 589]eval:  42%|████████████████████▍                            | 86/206 [02:16<04:24,  2.21s/it, recall_0.3=(359, 360) / 589]eval:  42%|████████████████████▍                            | 86/206 [02:17<04:24,  2.21s/it, recall_0.3=(364, 365) / 601]eval:  42%|████████████████████▋                            | 87/206 [02:17<03:42,  1.87s/it, recall_0.3=(364, 365) / 601]eval:  42%|████████████████████▋                            | 87/206 [02:18<03:42,  1.87s/it, recall_0.3=(370, 371) / 616]eval:  43%|████████████████████▉                            | 88/206 [02:18<03:18,  1.68s/it, recall_0.3=(370, 371) / 616]eval:  43%|████████████████████▉                            | 88/206 [02:23<03:18,  1.68s/it, recall_0.3=(377, 378) / 625]eval:  43%|█████████████████████▏                           | 89/206 [02:23<04:48,  2.46s/it, recall_0.3=(377, 378) / 625]eval:  43%|█████████████████████▏                           | 89/206 [02:24<04:48,  2.46s/it, recall_0.3=(380, 381) / 632]eval:  44%|█████████████████████▍                           | 90/206 [02:24<04:01,  2.08s/it, recall_0.3=(380, 381) / 632]eval:  44%|█████████████████████▍                           | 90/206 [02:25<04:01,  2.08s/it, recall_0.3=(383, 384) / 636]eval:  44%|█████████████████████▋                           | 91/206 [02:25<03:22,  1.76s/it, recall_0.3=(383, 384) / 636]eval:  44%|█████████████████████▋                           | 91/206 [02:26<03:22,  1.76s/it, recall_0.3=(384, 385) / 638]eval:  45%|█████████████████████▉                           | 92/206 [02:26<02:53,  1.52s/it, recall_0.3=(384, 385) / 638]eval:  45%|█████████████████████▉                           | 92/206 [02:27<02:53,  1.52s/it, recall_0.3=(385, 386) / 641]eval:  45%|██████████████████████                           | 93/206 [02:27<02:35,  1.37s/it, recall_0.3=(385, 386) / 641]eval:  45%|██████████████████████                           | 93/206 [02:28<02:35,  1.37s/it, recall_0.3=(388, 389) / 644]eval:  46%|██████████████████████▎                          | 94/206 [02:28<02:17,  1.23s/it, recall_0.3=(388, 389) / 644]eval:  46%|██████████████████████▎                          | 94/206 [02:29<02:17,  1.23s/it, recall_0.3=(391, 392) / 647]eval:  46%|██████████████████████▌                          | 95/206 [02:29<02:10,  1.17s/it, recall_0.3=(391, 392) / 647]eval:  46%|██████████████████████▌                          | 95/206 [02:30<02:10,  1.17s/it, recall_0.3=(395, 396) / 655]eval:  47%|██████████████████████▊                          | 96/206 [02:30<02:04,  1.14s/it, recall_0.3=(395, 396) / 655]eval:  47%|██████████████████████▊                          | 96/206 [02:32<02:04,  1.14s/it, recall_0.3=(399, 400) / 659]eval:  47%|███████████████████████                          | 97/206 [02:32<02:31,  1.39s/it, recall_0.3=(399, 400) / 659]eval:  47%|███████████████████████                          | 97/206 [02:33<02:31,  1.39s/it, recall_0.3=(400, 401) / 661]eval:  48%|███████████████████████▎                         | 98/206 [02:33<02:21,  1.31s/it, recall_0.3=(400, 401) / 661]eval:  48%|███████████████████████▎                         | 98/206 [02:34<02:21,  1.31s/it, recall_0.3=(405, 406) / 667]eval:  48%|███████████████████████▌                         | 99/206 [02:34<02:08,  1.20s/it, recall_0.3=(405, 406) / 667]eval:  48%|███████████████████████▌                         | 99/206 [02:35<02:08,  1.20s/it, recall_0.3=(406, 407) / 670]eval:  49%|███████████████████████▎                        | 100/206 [02:35<02:02,  1.15s/it, recall_0.3=(406, 407) / 670]eval:  49%|███████████████████████▎                        | 100/206 [02:38<02:02,  1.15s/it, recall_0.3=(408, 409) / 673]eval:  49%|███████████████████████▌                        | 101/206 [02:38<02:57,  1.69s/it, recall_0.3=(408, 409) / 673]eval:  49%|███████████████████████▌                        | 101/206 [02:39<02:57,  1.69s/it, recall_0.3=(412, 413) / 681]eval:  50%|███████████████████████▊                        | 102/206 [02:39<02:40,  1.54s/it, recall_0.3=(412, 413) / 681]eval:  50%|███████████████████████▊                        | 102/206 [02:40<02:40,  1.54s/it, recall_0.3=(422, 423) / 700]eval:  50%|████████████████████████                        | 103/206 [02:40<02:22,  1.38s/it, recall_0.3=(422, 423) / 700]eval:  50%|████████████████████████                        | 103/206 [02:41<02:22,  1.38s/it, recall_0.3=(433, 434) / 717]eval:  50%|████████████████████████▏                       | 104/206 [02:41<02:17,  1.34s/it, recall_0.3=(433, 434) / 717]eval:  50%|████████████████████████▏                       | 104/206 [02:45<02:17,  1.34s/it, recall_0.3=(450, 451) / 743]eval:  51%|████████████████████████▍                       | 105/206 [02:45<03:27,  2.06s/it, recall_0.3=(450, 451) / 743]eval:  51%|████████████████████████▍                       | 105/206 [02:46<03:27,  2.06s/it, recall_0.3=(454, 455) / 752]eval:  51%|████████████████████████▋                       | 106/206 [02:46<02:55,  1.76s/it, recall_0.3=(454, 455) / 752]eval:  51%|████████████████████████▋                       | 106/206 [02:47<02:55,  1.76s/it, recall_0.3=(462, 463) / 763]eval:  52%|████████████████████████▉                       | 107/206 [02:47<02:41,  1.63s/it, recall_0.3=(462, 463) / 763]eval:  52%|████████████████████████▉                       | 107/206 [02:49<02:41,  1.63s/it, recall_0.3=(467, 468) / 772]eval:  52%|█████████████████████████▏                      | 108/206 [02:49<02:33,  1.56s/it, recall_0.3=(467, 468) / 772]eval:  52%|█████████████████████████▏                      | 108/206 [02:52<02:33,  1.56s/it, recall_0.3=(474, 475) / 781]eval:  53%|█████████████████████████▍                      | 109/206 [02:52<03:13,  1.99s/it, recall_0.3=(474, 475) / 781]eval:  53%|█████████████████████████▍                      | 109/206 [02:53<03:13,  1.99s/it, recall_0.3=(476, 477) / 784]eval:  53%|█████████████████████████▋                      | 110/206 [02:53<02:40,  1.67s/it, recall_0.3=(476, 477) / 784]eval:  53%|█████████████████████████▋                      | 110/206 [02:54<02:40,  1.67s/it, recall_0.3=(480, 481) / 790]eval:  54%|█████████████████████████▊                      | 111/206 [02:54<02:26,  1.54s/it, recall_0.3=(480, 481) / 790]eval:  54%|█████████████████████████▊                      | 111/206 [02:55<02:26,  1.54s/it, recall_0.3=(480, 481) / 795]eval:  54%|██████████████████████████                      | 112/206 [02:55<02:11,  1.40s/it, recall_0.3=(480, 481) / 795]eval:  54%|██████████████████████████                      | 112/206 [02:56<02:11,  1.40s/it, recall_0.3=(481, 482) / 800]eval:  55%|██████████████████████████▎                     | 113/206 [02:56<02:03,  1.32s/it, recall_0.3=(481, 482) / 800]eval:  55%|██████████████████████████▎                     | 113/206 [02:57<02:03,  1.32s/it, recall_0.3=(482, 483) / 805]eval:  55%|██████████████████████████▌                     | 114/206 [02:57<01:48,  1.18s/it, recall_0.3=(482, 483) / 805]eval:  55%|██████████████████████████▌                     | 114/206 [02:58<01:48,  1.18s/it, recall_0.3=(485, 486) / 812]eval:  56%|██████████████████████████▊                     | 115/206 [02:58<01:42,  1.12s/it, recall_0.3=(485, 486) / 812]eval:  56%|██████████████████████████▊                     | 115/206 [02:59<01:42,  1.12s/it, recall_0.3=(487, 488) / 816]eval:  56%|███████████████████████████                     | 116/206 [02:59<01:46,  1.18s/it, recall_0.3=(487, 488) / 816]eval:  56%|███████████████████████████                     | 116/206 [03:01<01:46,  1.18s/it, recall_0.3=(492, 493) / 821]eval:  57%|███████████████████████████▎                    | 117/206 [03:01<01:50,  1.24s/it, recall_0.3=(492, 493) / 821]eval:  57%|███████████████████████████▎                    | 117/206 [03:02<01:50,  1.24s/it, recall_0.3=(493, 494) / 824]eval:  57%|███████████████████████████▍                    | 118/206 [03:02<01:53,  1.29s/it, recall_0.3=(493, 494) / 824]eval:  57%|███████████████████████████▍                    | 118/206 [03:03<01:53,  1.29s/it, recall_0.3=(496, 497) / 828]eval:  58%|███████████████████████████▋                    | 119/206 [03:03<01:51,  1.29s/it, recall_0.3=(496, 497) / 828]eval:  58%|███████████████████████████▋                    | 119/206 [03:05<01:51,  1.29s/it, recall_0.3=(506, 507) / 840]eval:  58%|███████████████████████████▉                    | 120/206 [03:05<01:49,  1.27s/it, recall_0.3=(506, 507) / 840]eval:  58%|███████████████████████████▉                    | 120/206 [03:06<01:49,  1.27s/it, recall_0.3=(518, 519) / 852]eval:  59%|████████████████████████████▏                   | 121/206 [03:06<01:47,  1.27s/it, recall_0.3=(518, 519) / 852]eval:  59%|████████████████████████████▏                   | 121/206 [03:07<01:47,  1.27s/it, recall_0.3=(528, 529) / 867]eval:  59%|████████████████████████████▍                   | 122/206 [03:07<01:49,  1.31s/it, recall_0.3=(528, 529) / 867]eval:  59%|████████████████████████████▍                   | 122/206 [03:08<01:49,  1.31s/it, recall_0.3=(546, 548) / 900]eval:  60%|████████████████████████████▋                   | 123/206 [03:08<01:46,  1.28s/it, recall_0.3=(546, 548) / 900]eval:  60%|████████████████████████████▋                   | 123/206 [03:09<01:46,  1.28s/it, recall_0.3=(557, 560) / 923]eval:  60%|████████████████████████████▉                   | 124/206 [03:09<01:34,  1.15s/it, recall_0.3=(557, 560) / 923]eval:  60%|████████████████████████████▉                   | 124/206 [03:11<01:34,  1.15s/it, recall_0.3=(568, 570) / 943]eval:  61%|█████████████████████████████▏                  | 125/206 [03:11<01:58,  1.46s/it, recall_0.3=(568, 570) / 943]eval:  61%|█████████████████████████████▏                  | 125/206 [03:13<01:58,  1.46s/it, recall_0.3=(569, 571) / 947]eval:  61%|█████████████████████████████▎                  | 126/206 [03:13<02:03,  1.54s/it, recall_0.3=(569, 571) / 947]eval:  61%|█████████████████████████████▎                  | 126/206 [03:14<02:03,  1.54s/it, recall_0.3=(574, 576) / 954]eval:  62%|█████████████████████████████▌                  | 127/206 [03:14<01:50,  1.40s/it, recall_0.3=(574, 576) / 954]eval:  62%|█████████████████████████████▌                  | 127/206 [03:16<01:50,  1.40s/it, recall_0.3=(578, 580) / 962]eval:  62%|█████████████████████████████▊                  | 128/206 [03:16<01:47,  1.38s/it, recall_0.3=(578, 580) / 962]eval:  62%|█████████████████████████████▊                  | 128/206 [03:19<01:47,  1.38s/it, recall_0.3=(582, 584) / 970]eval:  63%|██████████████████████████████                  | 129/206 [03:19<02:38,  2.05s/it, recall_0.3=(582, 584) / 970]eval:  63%|██████████████████████████████                  | 129/206 [03:20<02:38,  2.05s/it, recall_0.3=(584, 586) / 976]eval:  63%|██████████████████████████████▎                 | 130/206 [03:20<02:14,  1.77s/it, recall_0.3=(584, 586) / 976]eval:  63%|██████████████████████████████▎                 | 130/206 [03:21<02:14,  1.77s/it, recall_0.3=(585, 587) / 978]eval:  64%|██████████████████████████████▌                 | 131/206 [03:21<01:54,  1.53s/it, recall_0.3=(585, 587) / 978]eval:  64%|██████████████████████████████▌                 | 131/206 [03:22<01:54,  1.53s/it, recall_0.3=(585, 587) / 980]eval:  64%|██████████████████████████████▊                 | 132/206 [03:22<01:39,  1.35s/it, recall_0.3=(585, 587) / 980]eval:  64%|██████████████████████████████▊                 | 132/206 [03:24<01:39,  1.35s/it, recall_0.3=(586, 588) / 984]eval:  65%|██████████████████████████████▉                 | 133/206 [03:24<01:37,  1.33s/it, recall_0.3=(586, 588) / 984]eval:  65%|██████████████████████████████▉                 | 133/206 [03:24<01:37,  1.33s/it, recall_0.3=(586, 588) / 987]eval:  65%|███████████████████████████████▏                | 134/206 [03:25<01:28,  1.22s/it, recall_0.3=(586, 588) / 987]eval:  65%|███████████████████████████████▏                | 134/206 [03:26<01:28,  1.22s/it, recall_0.3=(589, 591) / 997]eval:  66%|███████████████████████████████▍                | 135/206 [03:26<01:22,  1.16s/it, recall_0.3=(589, 591) / 997]eval:  66%|███████████████████████████████▍                | 135/206 [03:27<01:22,  1.16s/it, recall_0.3=(589, 591) / 999]eval:  66%|███████████████████████████████▋                | 136/206 [03:27<01:24,  1.21s/it, recall_0.3=(589, 591) / 999]eval:  66%|███████████████████████████████                | 136/206 [03:28<01:24,  1.21s/it, recall_0.3=(591, 593) / 1004]eval:  67%|███████████████████████████████▎               | 137/206 [03:28<01:21,  1.18s/it, recall_0.3=(591, 593) / 1004]eval:  67%|███████████████████████████████▎               | 137/206 [03:29<01:21,  1.18s/it, recall_0.3=(591, 593) / 1009]eval:  67%|███████████████████████████████▍               | 138/206 [03:29<01:23,  1.23s/it, recall_0.3=(591, 593) / 1009]eval:  67%|███████████████████████████████▍               | 138/206 [03:31<01:23,  1.23s/it, recall_0.3=(593, 595) / 1015]eval:  67%|███████████████████████████████▋               | 139/206 [03:31<01:26,  1.29s/it, recall_0.3=(593, 595) / 1015]eval:  67%|███████████████████████████████▋               | 139/206 [03:32<01:26,  1.29s/it, recall_0.3=(600, 602) / 1026]eval:  68%|███████████████████████████████▉               | 140/206 [03:32<01:20,  1.23s/it, recall_0.3=(600, 602) / 1026]eval:  68%|███████████████████████████████▉               | 140/206 [03:34<01:20,  1.23s/it, recall_0.3=(608, 610) / 1040]eval:  68%|████████████████████████████████▏              | 141/206 [03:34<01:46,  1.64s/it, recall_0.3=(608, 610) / 1040]eval:  68%|████████████████████████████████▏              | 141/206 [03:36<01:46,  1.64s/it, recall_0.3=(617, 620) / 1053]eval:  69%|████████████████████████████████▍              | 142/206 [03:36<01:41,  1.58s/it, recall_0.3=(617, 620) / 1053]eval:  69%|████████████████████████████████▍              | 142/206 [03:37<01:41,  1.58s/it, recall_0.3=(635, 638) / 1076]eval:  69%|████████████████████████████████▋              | 143/206 [03:37<01:32,  1.47s/it, recall_0.3=(635, 638) / 1076]eval:  69%|████████████████████████████████▋              | 143/206 [03:38<01:32,  1.47s/it, recall_0.3=(645, 648) / 1093]eval:  70%|████████████████████████████████▊              | 144/206 [03:38<01:23,  1.35s/it, recall_0.3=(645, 648) / 1093]eval:  70%|████████████████████████████████▊              | 144/206 [03:40<01:23,  1.35s/it, recall_0.3=(653, 656) / 1104]eval:  70%|█████████████████████████████████              | 145/206 [03:40<01:40,  1.65s/it, recall_0.3=(653, 656) / 1104]eval:  70%|█████████████████████████████████              | 145/206 [03:41<01:40,  1.65s/it, recall_0.3=(659, 661) / 1121]eval:  71%|█████████████████████████████████▎             | 146/206 [03:41<01:27,  1.45s/it, recall_0.3=(659, 661) / 1121]eval:  71%|█████████████████████████████████▎             | 146/206 [03:43<01:27,  1.45s/it, recall_0.3=(660, 662) / 1123]eval:  71%|█████████████████████████████████▌             | 147/206 [03:43<01:24,  1.44s/it, recall_0.3=(660, 662) / 1123]eval:  71%|█████████████████████████████████▌             | 147/206 [03:44<01:24,  1.44s/it, recall_0.3=(662, 664) / 1131]eval:  72%|█████████████████████████████████▊             | 148/206 [03:44<01:22,  1.42s/it, recall_0.3=(662, 664) / 1131]eval:  72%|█████████████████████████████████▊             | 148/206 [03:48<01:22,  1.42s/it, recall_0.3=(664, 665) / 1134]eval:  72%|█████████████████████████████████▉             | 149/206 [03:48<01:57,  2.06s/it, recall_0.3=(664, 665) / 1134]eval:  72%|█████████████████████████████████▉             | 149/206 [03:49<01:57,  2.06s/it, recall_0.3=(667, 668) / 1137]eval:  73%|██████████████████████████████████▏            | 150/206 [03:49<01:38,  1.76s/it, recall_0.3=(667, 668) / 1137]eval:  73%|██████████████████████████████████▏            | 150/206 [03:50<01:38,  1.76s/it, recall_0.3=(670, 671) / 1142]eval:  73%|██████████████████████████████████▍            | 151/206 [03:50<01:23,  1.52s/it, recall_0.3=(670, 671) / 1142]eval:  73%|██████████████████████████████████▍            | 151/206 [03:51<01:23,  1.52s/it, recall_0.3=(671, 672) / 1145]eval:  74%|██████████████████████████████████▋            | 152/206 [03:51<01:11,  1.33s/it, recall_0.3=(671, 672) / 1145]eval:  74%|██████████████████████████████████▋            | 152/206 [03:52<01:11,  1.33s/it, recall_0.3=(674, 675) / 1150]eval:  74%|██████████████████████████████████▉            | 153/206 [03:52<01:03,  1.20s/it, recall_0.3=(674, 675) / 1150]eval:  74%|██████████████████████████████████▉            | 153/206 [03:52<01:03,  1.20s/it, recall_0.3=(676, 677) / 1154]eval:  75%|███████████████████████████████████▏           | 154/206 [03:53<00:57,  1.11s/it, recall_0.3=(676, 677) / 1154]eval:  75%|███████████████████████████████████▏           | 154/206 [03:53<00:57,  1.11s/it, recall_0.3=(678, 679) / 1157]eval:  75%|███████████████████████████████████▎           | 155/206 [03:53<00:49,  1.02it/s, recall_0.3=(678, 679) / 1157]eval:  75%|███████████████████████████████████▎           | 155/206 [03:54<00:49,  1.02it/s, recall_0.3=(680, 681) / 1162]eval:  76%|███████████████████████████████████▌           | 156/206 [03:54<00:48,  1.02it/s, recall_0.3=(680, 681) / 1162]eval:  76%|███████████████████████████████████▌           | 156/206 [03:55<00:48,  1.02it/s, recall_0.3=(682, 683) / 1166]eval:  76%|███████████████████████████████████▊           | 157/206 [03:55<00:49,  1.01s/it, recall_0.3=(682, 683) / 1166]eval:  76%|███████████████████████████████████▊           | 157/206 [03:56<00:49,  1.01s/it, recall_0.3=(683, 684) / 1168]eval:  77%|████████████████████████████████████           | 158/206 [03:56<00:51,  1.08s/it, recall_0.3=(683, 684) / 1168]eval:  77%|████████████████████████████████████           | 158/206 [03:58<00:51,  1.08s/it, recall_0.3=(683, 684) / 1168]eval:  77%|████████████████████████████████████▎          | 159/206 [03:58<00:51,  1.10s/it, recall_0.3=(683, 684) / 1168]eval:  77%|████████████████████████████████████▎          | 159/206 [03:59<00:51,  1.10s/it, recall_0.3=(686, 686) / 1172]eval:  78%|████████████████████████████████████▌          | 160/206 [03:59<00:51,  1.11s/it, recall_0.3=(686, 686) / 1172]eval:  78%|████████████████████████████████████▌          | 160/206 [04:00<00:51,  1.11s/it, recall_0.3=(689, 689) / 1177]eval:  78%|████████████████████████████████████▋          | 161/206 [04:00<00:50,  1.13s/it, recall_0.3=(689, 689) / 1177]eval:  78%|████████████████████████████████████▋          | 161/206 [04:01<00:50,  1.13s/it, recall_0.3=(698, 698) / 1189]eval:  79%|████████████████████████████████████▉          | 162/206 [04:01<00:46,  1.06s/it, recall_0.3=(698, 698) / 1189]eval:  79%|████████████████████████████████████▉          | 162/206 [04:03<00:46,  1.06s/it, recall_0.3=(710, 710) / 1206]eval:  79%|█████████████████████████████████████▏         | 163/206 [04:03<01:00,  1.40s/it, recall_0.3=(710, 710) / 1206]eval:  79%|█████████████████████████████████████▏         | 163/206 [04:04<01:00,  1.40s/it, recall_0.3=(720, 720) / 1222]eval:  80%|█████████████████████████████████████▍         | 164/206 [04:04<00:54,  1.29s/it, recall_0.3=(720, 720) / 1222]eval:  80%|█████████████████████████████████████▍         | 164/206 [04:06<00:54,  1.29s/it, recall_0.3=(726, 726) / 1233]eval:  80%|█████████████████████████████████████▋         | 165/206 [04:06<01:01,  1.49s/it, recall_0.3=(726, 726) / 1233]eval:  80%|█████████████████████████████████████▋         | 165/206 [04:07<01:01,  1.49s/it, recall_0.3=(734, 734) / 1253]eval:  81%|█████████████████████████████████████▊         | 166/206 [04:07<00:54,  1.37s/it, recall_0.3=(734, 734) / 1253]eval:  81%|█████████████████████████████████████▊         | 166/206 [04:09<00:54,  1.37s/it, recall_0.3=(741, 741) / 1268]eval:  81%|██████████████████████████████████████         | 167/206 [04:09<01:02,  1.60s/it, recall_0.3=(741, 741) / 1268]eval:  81%|██████████████████████████████████████         | 167/206 [04:10<01:02,  1.60s/it, recall_0.3=(747, 747) / 1280]eval:  82%|██████████████████████████████████████▎        | 168/206 [04:10<00:53,  1.42s/it, recall_0.3=(747, 747) / 1280]eval:  82%|██████████████████████████████████████▎        | 168/206 [04:13<00:53,  1.42s/it, recall_0.3=(750, 750) / 1290]eval:  82%|██████████████████████████████████████▌        | 169/206 [04:13<01:08,  1.86s/it, recall_0.3=(750, 750) / 1290]eval:  82%|██████████████████████████████████████▌        | 169/206 [04:14<01:08,  1.86s/it, recall_0.3=(752, 752) / 1298]eval:  83%|██████████████████████████████████████▊        | 170/206 [04:14<00:59,  1.67s/it, recall_0.3=(752, 752) / 1298]eval:  83%|██████████████████████████████████████▊        | 170/206 [04:16<00:59,  1.67s/it, recall_0.3=(759, 759) / 1310]eval:  83%|███████████████████████████████████████        | 171/206 [04:16<00:56,  1.60s/it, recall_0.3=(759, 759) / 1310]eval:  83%|███████████████████████████████████████        | 171/206 [04:17<00:56,  1.60s/it, recall_0.3=(761, 761) / 1315]eval:  83%|███████████████████████████████████████▏       | 172/206 [04:17<00:48,  1.43s/it, recall_0.3=(761, 761) / 1315]eval:  83%|███████████████████████████████████████▏       | 172/206 [04:18<00:48,  1.43s/it, recall_0.3=(763, 763) / 1319]eval:  84%|███████████████████████████████████████▍       | 173/206 [04:18<00:43,  1.32s/it, recall_0.3=(763, 763) / 1319]eval:  84%|███████████████████████████████████████▍       | 173/206 [04:19<00:43,  1.32s/it, recall_0.3=(766, 766) / 1323]eval:  84%|███████████████████████████████████████▋       | 174/206 [04:19<00:42,  1.32s/it, recall_0.3=(766, 766) / 1323]eval:  84%|███████████████████████████████████████▋       | 174/206 [04:20<00:42,  1.32s/it, recall_0.3=(768, 768) / 1328]eval:  85%|███████████████████████████████████████▉       | 175/206 [04:20<00:39,  1.27s/it, recall_0.3=(768, 768) / 1328]eval:  85%|███████████████████████████████████████▉       | 175/206 [04:21<00:39,  1.27s/it, recall_0.3=(769, 769) / 1333]eval:  85%|████████████████████████████████████████▏      | 176/206 [04:21<00:36,  1.21s/it, recall_0.3=(769, 769) / 1333]eval:  85%|████████████████████████████████████████▏      | 176/206 [04:23<00:36,  1.21s/it, recall_0.3=(770, 770) / 1335]eval:  86%|████████████████████████████████████████▍      | 177/206 [04:23<00:34,  1.17s/it, recall_0.3=(770, 770) / 1335]eval:  86%|████████████████████████████████████████▍      | 177/206 [04:24<00:34,  1.17s/it, recall_0.3=(770, 770) / 1339]eval:  86%|████████████████████████████████████████▌      | 178/206 [04:24<00:32,  1.18s/it, recall_0.3=(770, 770) / 1339]eval:  86%|████████████████████████████████████████▌      | 178/206 [04:25<00:32,  1.18s/it, recall_0.3=(770, 770) / 1341]eval:  87%|████████████████████████████████████████▊      | 179/206 [04:25<00:32,  1.21s/it, recall_0.3=(770, 770) / 1341]eval:  87%|████████████████████████████████████████▊      | 179/206 [04:26<00:32,  1.21s/it, recall_0.3=(773, 773) / 1346]eval:  87%|█████████████████████████████████████████      | 180/206 [04:26<00:28,  1.09s/it, recall_0.3=(773, 773) / 1346]eval:  87%|█████████████████████████████████████████      | 180/206 [04:28<00:28,  1.09s/it, recall_0.3=(773, 773) / 1346]eval:  88%|█████████████████████████████████████████▎     | 181/206 [04:28<00:32,  1.31s/it, recall_0.3=(773, 773) / 1346]eval:  88%|█████████████████████████████████████████▎     | 181/206 [04:29<00:32,  1.31s/it, recall_0.3=(775, 775) / 1354]eval:  88%|█████████████████████████████████████████▌     | 182/206 [04:29<00:28,  1.20s/it, recall_0.3=(775, 775) / 1354]eval:  88%|█████████████████████████████████████████▌     | 182/206 [04:29<00:28,  1.20s/it, recall_0.3=(779, 779) / 1361]eval:  89%|█████████████████████████████████████████▊     | 183/206 [04:29<00:25,  1.11s/it, recall_0.3=(779, 779) / 1361]eval:  89%|█████████████████████████████████████████▊     | 183/206 [04:31<00:25,  1.11s/it, recall_0.3=(782, 782) / 1386]eval:  89%|█████████████████████████████████████████▉     | 184/206 [04:31<00:24,  1.11s/it, recall_0.3=(782, 782) / 1386]eval:  89%|█████████████████████████████████████████▉     | 184/206 [04:31<00:24,  1.11s/it, recall_0.3=(791, 791) / 1401]eval:  90%|██████████████████████████████████████████▏    | 185/206 [04:31<00:21,  1.02s/it, recall_0.3=(791, 791) / 1401]eval:  90%|██████████████████████████████████████████▏    | 185/206 [04:33<00:21,  1.02s/it, recall_0.3=(802, 802) / 1415]eval:  90%|██████████████████████████████████████████▍    | 186/206 [04:33<00:22,  1.11s/it, recall_0.3=(802, 802) / 1415]eval:  90%|██████████████████████████████████████████▍    | 186/206 [04:34<00:22,  1.11s/it, recall_0.3=(808, 808) / 1427]eval:  91%|██████████████████████████████████████████▋    | 187/206 [04:34<00:19,  1.04s/it, recall_0.3=(808, 808) / 1427]eval:  91%|██████████████████████████████████████████▋    | 187/206 [04:35<00:19,  1.04s/it, recall_0.3=(809, 809) / 1436]eval:  91%|██████████████████████████████████████████▉    | 188/206 [04:35<00:18,  1.02s/it, recall_0.3=(809, 809) / 1436]eval:  91%|██████████████████████████████████████████▉    | 188/206 [04:36<00:18,  1.02s/it, recall_0.3=(812, 812) / 1440]eval:  92%|███████████████████████████████████████████    | 189/206 [04:36<00:17,  1.03s/it, recall_0.3=(812, 812) / 1440]eval:  92%|███████████████████████████████████████████    | 189/206 [04:37<00:17,  1.03s/it, recall_0.3=(815, 815) / 1446]eval:  92%|███████████████████████████████████████████▎   | 190/206 [04:37<00:16,  1.04s/it, recall_0.3=(815, 815) / 1446]eval:  92%|███████████████████████████████████████████▎   | 190/206 [04:38<00:16,  1.04s/it, recall_0.3=(817, 817) / 1450]eval:  93%|███████████████████████████████████████████▌   | 191/206 [04:38<00:15,  1.01s/it, recall_0.3=(817, 817) / 1450]eval:  93%|███████████████████████████████████████████▌   | 191/206 [04:38<00:15,  1.01s/it, recall_0.3=(817, 817) / 1452]eval:  93%|███████████████████████████████████████████▊   | 192/206 [04:38<00:13,  1.03it/s, recall_0.3=(817, 817) / 1452]eval:  93%|███████████████████████████████████████████▊   | 192/206 [04:39<00:13,  1.03it/s, recall_0.3=(817, 818) / 1455]eval:  94%|████████████████████████████████████████████   | 193/206 [04:39<00:11,  1.09it/s, recall_0.3=(817, 818) / 1455]eval:  94%|████████████████████████████████████████████   | 193/206 [04:40<00:11,  1.09it/s, recall_0.3=(817, 818) / 1455]eval:  94%|████████████████████████████████████████████▎  | 194/206 [04:40<00:09,  1.20it/s, recall_0.3=(817, 818) / 1455]eval:  94%|████████████████████████████████████████████▎  | 194/206 [04:41<00:09,  1.20it/s, recall_0.3=(817, 818) / 1455]eval:  95%|████████████████████████████████████████████▍  | 195/206 [04:41<00:08,  1.31it/s, recall_0.3=(817, 818) / 1455]eval:  95%|████████████████████████████████████████████▍  | 195/206 [04:41<00:08,  1.31it/s, recall_0.3=(817, 818) / 1455]eval:  95%|████████████████████████████████████████████▋  | 196/206 [04:41<00:07,  1.39it/s, recall_0.3=(817, 818) / 1455]eval:  95%|████████████████████████████████████████████▋  | 196/206 [04:42<00:07,  1.39it/s, recall_0.3=(817, 818) / 1455]eval:  96%|████████████████████████████████████████████▉  | 197/206 [04:42<00:06,  1.46it/s, recall_0.3=(817, 818) / 1455]eval:  96%|████████████████████████████████████████████▉  | 197/206 [04:42<00:06,  1.46it/s, recall_0.3=(819, 820) / 1458]eval:  96%|█████████████████████████████████████████████▏ | 198/206 [04:42<00:05,  1.44it/s, recall_0.3=(819, 820) / 1458]eval:  96%|█████████████████████████████████████████████▏ | 198/206 [04:43<00:05,  1.44it/s, recall_0.3=(823, 824) / 1463]eval:  97%|█████████████████████████████████████████████▍ | 199/206 [04:43<00:04,  1.44it/s, recall_0.3=(823, 824) / 1463]eval:  97%|█████████████████████████████████████████████▍ | 199/206 [04:44<00:04,  1.44it/s, recall_0.3=(823, 824) / 1465]eval:  97%|█████████████████████████████████████████████▋ | 200/206 [04:44<00:03,  1.57it/s, recall_0.3=(823, 824) / 1465]eval:  97%|█████████████████████████████████████████████▋ | 200/206 [04:44<00:03,  1.57it/s, recall_0.3=(823, 824) / 1465]eval:  98%|█████████████████████████████████████████████▊ | 201/206 [04:44<00:03,  1.64it/s, recall_0.3=(823, 824) / 1465]eval:  98%|█████████████████████████████████████████████▊ | 201/206 [04:45<00:03,  1.64it/s, recall_0.3=(824, 825) / 1468]eval:  98%|██████████████████████████████████████████████ | 202/206 [04:45<00:02,  1.79it/s, recall_0.3=(824, 825) / 1468]eval:  98%|██████████████████████████████████████████████ | 202/206 [04:45<00:02,  1.79it/s, recall_0.3=(827, 828) / 1471]eval:  99%|██████████████████████████████████████████████▎| 203/206 [04:45<00:01,  1.96it/s, recall_0.3=(827, 828) / 1471]eval:  99%|██████████████████████████████████████████████▎| 203/206 [04:45<00:01,  1.96it/s, recall_0.3=(829, 830) / 1474]eval:  99%|██████████████████████████████████████████████▌| 204/206 [04:45<00:00,  2.10it/s, recall_0.3=(829, 830) / 1474]eval:  99%|██████████████████████████████████████████████▌| 204/206 [04:46<00:00,  2.10it/s, recall_0.3=(830, 831) / 1477]eval: 100%|██████████████████████████████████████████████▊| 205/206 [04:46<00:00,  2.26it/s, recall_0.3=(830, 831) / 1477]eval: 100%|██████████████████████████████████████████████▊| 205/206 [04:46<00:00,  2.26it/s, recall_0.3=(830, 831) / 1478]eval: 100%|███████████████████████████████████████████████| 206/206 [04:46<00:00,  2.59it/s, recall_0.3=(830, 831) / 1478]eval: 100%|███████████████████████████████████████████████| 206/206 [04:47<00:00,  1.39s/it, recall_0.3=(830, 831) / 1478]
2023-03-03 11:57:41,523   INFO  *************** Performance of EPOCH 9 *****************
2023-03-03 11:57:41,525   INFO  Generate label finished(sec_per_example: 0.1747 second).
2023-03-03 11:57:41,525   INFO  recall_roi_0.3: 0.555437
2023-03-03 11:57:41,526   INFO  recall_rcnn_0.3: 0.558094
2023-03-03 11:57:41,527   INFO  recall_roi_0.5: 0.423663
2023-03-03 11:57:41,527   INFO  recall_rcnn_0.5: 0.437832
2023-03-03 11:57:41,528   INFO  recall_roi_0.7: 0.193057
2023-03-03 11:57:41,529   INFO  recall_rcnn_0.7: 0.221573
2023-03-03 11:57:41,530   INFO  Average predicted number of objects(1644 samples): 6.397
======
Loading Ithaca365 tables for version v1.1...
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
6 category,
1 attribute,
4 visibility,
25839 instance,
3 sensor,
3 calibrated_sensor,
760811 ego_pose,
40 log,
40 scene,
6576 sample,
2282433 sample_data,
25839 sample_annotation,
1 map,
2579 location,
Done loading in 34.112 seconds.
======
Reverse indexing ...
Done reverse indexing in 5.6 seconds.
======
2023-03-03 11:58:23,189   INFO  The predictions of NuScenes have been saved to /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/eval/eval_with_train/epoch_9/val/final_result/data/results_nusc.json
Initializing nuScenes detection evaluation
Loaded results from /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/eval/eval_with_train/epoch_9/val/final_result/data/results_nusc.json. Found detections for 1644 samples.
Loading annotations for val split from nuScenes version: v1.1
  0%|                                                                                            | 0/1644 [00:00<?, ?it/s] 40%|████████████████████████████████▎                                               | 664/1644 [00:00<00:00, 6631.67it/s] 81%|███████████████████████████████████████████████████████████████▊               | 1328/1644 [00:00<00:00, 5978.93it/s]100%|███████████████████████████████████████████████████████████████████████████████| 1644/1644 [00:00<00:00, 6389.91it/s]
Loaded ground truth annotations for 1644 samples.
Filtering predictions
Detection range: (0, 30)
=> Original number of boxes: 10516
=> After distance based filtering: 2711
=> After LIDAR and RADAR points based filtering: 2711
Detection range: (30, 50)
=> Original number of boxes: 10516
=> After distance based filtering: 3848
=> After LIDAR and RADAR points based filtering: 3848
Detection range: (50, 80)
=> Original number of boxes: 10516
=> After distance based filtering: 3407
=> After LIDAR and RADAR points based filtering: 3407
Detection range: (0, 80)
=> Original number of boxes: 10516
=> After distance based filtering: 9966
=> After LIDAR and RADAR points based filtering: 9966
Filtering ground truth annotations
Detection range: (0, 30)
=> Original number of boxes: 6018
=> After distance based filtering: 1648
=> After LIDAR and RADAR points based filtering: 1648
Detection range: (30, 50)
=> Original number of boxes: 6018
=> After distance based filtering: 1660
=> After LIDAR and RADAR points based filtering: 1660
Detection range: (50, 80)
=> Original number of boxes: 6018
=> After distance based filtering: 1493
=> After LIDAR and RADAR points based filtering: 1493
Detection range: (0, 80)
=> Original number of boxes: 6018
=> After distance based filtering: 4801
=> After LIDAR and RADAR points based filtering: 4801
Accumulating metric data...
Calculating metrics...
Saving metrics to: /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/eval/eval_with_train/epoch_9/val/final_result/data
mAP: 0.1479
mATE: 0.7226
mASE: 0.7608
mAOE: 0.9769
NDS: 0.1639
Eval time: 2.7s

Per-class results:
Object Class	Det. Range	AP	ATE	ASE	AOE
car         	(0, 30)   	0.593	0.217	0.162	0.827
car         	(30, 50)  	0.391	0.241	0.197	0.755
car         	(50, 80)  	0.206	0.327	0.225	0.832
car         	(0, 80)   	0.415	0.242	0.182	0.822
truck       	(0, 30)   	0.000	1.000	1.000	1.000
truck       	(30, 50)  	0.000	1.000	1.000	1.000
truck       	(50, 80)  	0.000	1.000	1.000	1.000
truck       	(0, 80)   	0.000	1.000	1.000	1.000
bus         	(0, 30)   	0.000	1.000	1.000	1.000
bus         	(30, 50)  	0.000	1.000	1.000	1.000
bus         	(50, 80)  	0.000	1.000	1.000	1.000
bus         	(0, 80)   	0.000	1.000	1.000	1.000
pedestrian  	(0, 30)   	0.592	0.075	0.352	0.802
pedestrian  	(30, 50)  	0.482	0.099	0.404	1.102
pedestrian  	(50, 80)  	0.221	0.132	0.422	1.544
pedestrian  	(0, 80)   	0.472	0.093	0.383	1.039
motorcyclist	(0, 30)   	0.000	1.000	1.000	1.000
motorcyclist	(30, 50)  	0.000	1.000	1.000	1.000
motorcyclist	(50, 80)  	0.000	1.000	1.000	1.000
motorcyclist	(0, 80)   	0.000	1.000	1.000	1.000
bicyclist   	(0, 30)   	0.000	1.000	1.000	1.000
bicyclist   	(30, 50)  	0.000	1.000	1.000	1.000
bicyclist   	(50, 80)  	0.000	1.000	1.000	1.000
bicyclist   	(0, 80)   	0.000	1.000	1.000	1.000
2023-03-03 11:58:28,400   INFO  ----------------Nuscene detection_by_range results-----------------
***car
range (0, 30) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.22, 0.16, 0.83 | 52.99, 58.45, 62.20, 63.74 | mean AP: 0.5934350851474396
range (30, 50) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.24, 0.20, 0.75 | 32.73, 38.59, 41.57, 43.33 | mean AP: 0.39056291692847306
range (50, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.33, 0.22, 0.83 | 14.14, 19.93, 23.56, 24.60 | mean AP: 0.20555562149128942
range (0, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.24, 0.18, 0.82 | 35.05, 40.70, 44.57, 45.71 | mean AP: 0.41505952293200643
***pedestrian
range (0, 30) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.07, 0.35, 0.80 | 58.88, 58.88, 59.06, 59.87 | mean AP: 0.5917144624176599
range (30, 50) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.10, 0.40, 1.10 | 47.21, 47.21, 47.38, 50.96 | mean AP: 0.4818843447885187
range (50, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.13, 0.42, 1.54 | 21.82, 21.84, 21.84, 22.74 | mean AP: 0.22060527413972336
range (0, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.09, 0.38, 1.04 | 46.62, 46.62, 46.81, 48.84 | mean AP: 0.4722031380367202
--------------average performance-------------
trans_err:	 0.7226
scale_err:	 0.7608
orient_err:	 0.9769
mAP:	 0.1479
NDS:	 0.1639
--------------table log summary-------------
***car
match 1.0m:	(0, 30), (30, 50), (50, 80), (0, 80)
58.45, 38.59, 19.93, 40.70
***pedestrian
match 1.0m:	(0, 30), (30, 50), (50, 80), (0, 80)
58.88, 47.21, 21.84, 46.62

2023-03-03 11:58:28,401   INFO  Result is save to /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/eval/eval_with_train/epoch_9/val
2023-03-03 11:58:28,401   INFO  ****************Evaluation done.*****************
2023-03-03 11:58:28,411   INFO  Epoch 9 has been evaluated
2023-03-03 11:58:28,413   INFO  ==> Loading parameters from checkpoint /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/ckpt/checkpoint_epoch_10.pth to CPU
2023-03-03 11:58:28,508   INFO  ==> Checkpoint trained from version: pcdet+0.3.0+0000000
2023-03-03 11:58:29,638   INFO  ==> Done (loaded 502/502)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
2023-03-03 11:58:29,649   INFO  *************** EPOCH 10 EVALUATION *****************
eval:   0%|                                                                                       | 0/206 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
eval:   0%|                                                                | 0/206 [00:09<?, ?it/s, recall_0.3=(2, 2) / 5]eval:   0%|▎                                                       | 1/206 [00:09<32:41,  9.57s/it, recall_0.3=(2, 2) / 5]eval:   0%|▎                                                    | 1/206 [00:10<32:41,  9.57s/it, recall_0.3=(13, 13) / 23]eval:   1%|▌                                                    | 2/206 [00:10<15:41,  4.61s/it, recall_0.3=(13, 13) / 23]eval:   1%|▌                                                    | 2/206 [00:11<15:41,  4.61s/it, recall_0.3=(18, 18) / 30]eval:   1%|▊                                                    | 3/206 [00:11<09:53,  2.93s/it, recall_0.3=(18, 18) / 30]eval:   1%|▊                                                    | 3/206 [00:12<09:53,  2.93s/it, recall_0.3=(21, 21) / 36]eval:   2%|█                                                    | 4/206 [00:12<07:34,  2.25s/it, recall_0.3=(21, 21) / 36]eval:   2%|█                                                    | 4/206 [00:14<07:34,  2.25s/it, recall_0.3=(27, 27) / 43]eval:   2%|█▎                                                   | 5/206 [00:14<06:21,  1.90s/it, recall_0.3=(27, 27) / 43]eval:   2%|█▎                                                   | 5/206 [00:15<06:21,  1.90s/it, recall_0.3=(30, 30) / 48]eval:   3%|█▌                                                   | 6/206 [00:15<05:46,  1.73s/it, recall_0.3=(30, 30) / 48]eval:   3%|█▌                                                   | 6/206 [00:16<05:46,  1.73s/it, recall_0.3=(33, 33) / 53]eval:   3%|█▊                                                   | 7/206 [00:16<04:52,  1.47s/it, recall_0.3=(33, 33) / 53]eval:   3%|█▊                                                   | 7/206 [00:17<04:52,  1.47s/it, recall_0.3=(34, 34) / 56]eval:   4%|██                                                   | 8/206 [00:17<04:29,  1.36s/it, recall_0.3=(34, 34) / 56]eval:   4%|██                                                   | 8/206 [00:18<04:29,  1.36s/it, recall_0.3=(34, 34) / 56]eval:   4%|██▎                                                  | 9/206 [00:18<04:02,  1.23s/it, recall_0.3=(34, 34) / 56]eval:   4%|██▎                                                  | 9/206 [00:19<04:02,  1.23s/it, recall_0.3=(34, 34) / 56]eval:   5%|██▌                                                 | 10/206 [00:19<03:41,  1.13s/it, recall_0.3=(34, 34) / 56]eval:   5%|██▌                                                 | 10/206 [00:20<03:41,  1.13s/it, recall_0.3=(34, 34) / 58]eval:   5%|██▊                                                 | 11/206 [00:20<03:23,  1.04s/it, recall_0.3=(34, 34) / 58]eval:   5%|██▊                                                 | 11/206 [00:21<03:23,  1.04s/it, recall_0.3=(34, 34) / 61]eval:   6%|███                                                 | 12/206 [00:21<03:35,  1.11s/it, recall_0.3=(34, 34) / 61]eval:   6%|███                                                 | 12/206 [00:22<03:35,  1.11s/it, recall_0.3=(37, 37) / 67]eval:   6%|███▎                                                | 13/206 [00:22<03:39,  1.14s/it, recall_0.3=(37, 37) / 67]eval:   6%|███▎                                                | 13/206 [00:23<03:39,  1.14s/it, recall_0.3=(39, 39) / 72]eval:   7%|███▌                                                | 14/206 [00:23<03:32,  1.11s/it, recall_0.3=(39, 39) / 72]eval:   7%|███▌                                                | 14/206 [00:24<03:32,  1.11s/it, recall_0.3=(40, 40) / 75]eval:   7%|███▊                                                | 15/206 [00:24<03:33,  1.12s/it, recall_0.3=(40, 40) / 75]eval:   7%|███▊                                                | 15/206 [00:26<03:33,  1.12s/it, recall_0.3=(42, 42) / 77]eval:   8%|████                                                | 16/206 [00:26<03:40,  1.16s/it, recall_0.3=(42, 42) / 77]eval:   8%|████                                                | 16/206 [00:27<03:40,  1.16s/it, recall_0.3=(42, 42) / 80]eval:   8%|████▎                                               | 17/206 [00:27<03:59,  1.27s/it, recall_0.3=(42, 42) / 80]eval:   8%|████▎                                               | 17/206 [00:29<03:59,  1.27s/it, recall_0.3=(43, 43) / 83]eval:   9%|████▌                                               | 18/206 [00:29<04:03,  1.29s/it, recall_0.3=(43, 43) / 83]eval:   9%|████▌                                               | 18/206 [00:30<04:03,  1.29s/it, recall_0.3=(44, 44) / 85]eval:   9%|████▊                                               | 19/206 [00:30<04:03,  1.30s/it, recall_0.3=(44, 44) / 85]eval:   9%|████▊                                               | 19/206 [00:31<04:03,  1.30s/it, recall_0.3=(45, 45) / 87]eval:  10%|█████                                               | 20/206 [00:31<04:04,  1.32s/it, recall_0.3=(45, 45) / 87]eval:  10%|█████                                               | 20/206 [00:33<04:04,  1.32s/it, recall_0.3=(49, 49) / 92]eval:  10%|█████▎                                              | 21/206 [00:33<04:06,  1.33s/it, recall_0.3=(49, 49) / 92]eval:  10%|█████▏                                             | 21/206 [00:34<04:06,  1.33s/it, recall_0.3=(55, 55) / 103]eval:  11%|█████▍                                             | 22/206 [00:34<03:59,  1.30s/it, recall_0.3=(55, 55) / 103]eval:  11%|█████▍                                             | 22/206 [00:35<03:59,  1.30s/it, recall_0.3=(65, 65) / 125]eval:  11%|█████▋                                             | 23/206 [00:35<03:42,  1.21s/it, recall_0.3=(65, 65) / 125]eval:  11%|█████▋                                             | 23/206 [00:36<03:42,  1.21s/it, recall_0.3=(72, 72) / 133]eval:  12%|█████▉                                             | 24/206 [00:36<03:27,  1.14s/it, recall_0.3=(72, 72) / 133]eval:  12%|█████▉                                             | 24/206 [00:39<03:27,  1.14s/it, recall_0.3=(82, 82) / 145]eval:  12%|██████▏                                            | 25/206 [00:39<05:03,  1.68s/it, recall_0.3=(82, 82) / 145]eval:  12%|██████▏                                            | 25/206 [00:40<05:03,  1.68s/it, recall_0.3=(85, 85) / 153]eval:  13%|██████▍                                            | 26/206 [00:40<04:41,  1.56s/it, recall_0.3=(85, 85) / 153]eval:  13%|██████▍                                            | 26/206 [00:41<04:41,  1.56s/it, recall_0.3=(88, 88) / 156]eval:  13%|██████▋                                            | 27/206 [00:41<04:08,  1.39s/it, recall_0.3=(88, 88) / 156]eval:  13%|██████▋                                            | 27/206 [00:42<04:08,  1.39s/it, recall_0.3=(94, 94) / 163]eval:  14%|██████▉                                            | 28/206 [00:42<03:43,  1.26s/it, recall_0.3=(94, 94) / 163]eval:  14%|██████▋                                          | 28/206 [00:46<03:43,  1.26s/it, recall_0.3=(100, 100) / 171]eval:  14%|██████▉                                          | 29/206 [00:46<05:54,  2.00s/it, recall_0.3=(100, 100) / 171]eval:  14%|██████▉                                          | 29/206 [00:47<05:54,  2.00s/it, recall_0.3=(103, 103) / 174]eval:  15%|███████▏                                         | 30/206 [00:47<04:53,  1.67s/it, recall_0.3=(103, 103) / 174]eval:  15%|███████▏                                         | 30/206 [00:48<04:53,  1.67s/it, recall_0.3=(105, 105) / 177]eval:  15%|███████▎                                         | 31/206 [00:48<04:23,  1.51s/it, recall_0.3=(105, 105) / 177]eval:  15%|███████▎                                         | 31/206 [00:49<04:23,  1.51s/it, recall_0.3=(105, 105) / 179]eval:  16%|███████▌                                         | 32/206 [00:49<04:08,  1.43s/it, recall_0.3=(105, 105) / 179]eval:  16%|███████▌                                         | 32/206 [00:50<04:08,  1.43s/it, recall_0.3=(108, 108) / 182]eval:  16%|███████▊                                         | 33/206 [00:50<03:42,  1.29s/it, recall_0.3=(108, 108) / 182]eval:  16%|███████▊                                         | 33/206 [00:51<03:42,  1.29s/it, recall_0.3=(109, 109) / 184]eval:  17%|████████                                         | 34/206 [00:51<03:14,  1.13s/it, recall_0.3=(109, 109) / 184]eval:  17%|████████                                         | 34/206 [00:52<03:14,  1.13s/it, recall_0.3=(109, 109) / 184]eval:  17%|████████▎                                        | 35/206 [00:52<03:06,  1.09s/it, recall_0.3=(109, 109) / 184]eval:  17%|████████▎                                        | 35/206 [00:53<03:06,  1.09s/it, recall_0.3=(112, 112) / 189]eval:  17%|████████▌                                        | 36/206 [00:53<03:17,  1.16s/it, recall_0.3=(112, 112) / 189]eval:  17%|████████▌                                        | 36/206 [00:57<03:17,  1.16s/it, recall_0.3=(112, 112) / 189]eval:  18%|████████▊                                        | 37/206 [00:57<05:40,  2.01s/it, recall_0.3=(112, 112) / 189]eval:  18%|████████▊                                        | 37/206 [00:58<05:40,  2.01s/it, recall_0.3=(112, 112) / 189]eval:  18%|█████████                                        | 38/206 [00:58<04:56,  1.76s/it, recall_0.3=(112, 112) / 189]eval:  18%|█████████                                        | 38/206 [00:59<04:56,  1.76s/it, recall_0.3=(112, 112) / 189]eval:  19%|█████████▎                                       | 39/206 [00:59<04:13,  1.52s/it, recall_0.3=(112, 112) / 189]eval:  19%|█████████▎                                       | 39/206 [01:00<04:13,  1.52s/it, recall_0.3=(112, 112) / 189]eval:  19%|█████████▌                                       | 40/206 [01:00<03:50,  1.39s/it, recall_0.3=(112, 112) / 189]eval:  19%|█████████▌                                       | 40/206 [01:02<03:50,  1.39s/it, recall_0.3=(113, 113) / 193]eval:  20%|█████████▊                                       | 41/206 [01:02<04:29,  1.64s/it, recall_0.3=(113, 113) / 193]eval:  20%|█████████▊                                       | 41/206 [01:04<04:29,  1.64s/it, recall_0.3=(115, 115) / 197]eval:  20%|█████████▉                                       | 42/206 [01:04<04:13,  1.55s/it, recall_0.3=(115, 115) / 197]eval:  20%|█████████▉                                       | 42/206 [01:05<04:13,  1.55s/it, recall_0.3=(124, 124) / 220]eval:  21%|██████████▏                                      | 43/206 [01:05<03:46,  1.39s/it, recall_0.3=(124, 124) / 220]eval:  21%|██████████▏                                      | 43/206 [01:06<03:46,  1.39s/it, recall_0.3=(136, 135) / 236]eval:  21%|██████████▍                                      | 44/206 [01:06<03:27,  1.28s/it, recall_0.3=(136, 135) / 236]eval:  21%|██████████▍                                      | 44/206 [01:10<03:27,  1.28s/it, recall_0.3=(148, 147) / 255]eval:  22%|██████████▋                                      | 45/206 [01:10<05:25,  2.02s/it, recall_0.3=(148, 147) / 255]eval:  22%|██████████▋                                      | 45/206 [01:11<05:25,  2.02s/it, recall_0.3=(153, 152) / 263]eval:  22%|██████████▉                                      | 46/206 [01:11<04:34,  1.71s/it, recall_0.3=(153, 152) / 263]eval:  22%|██████████▉                                      | 46/206 [01:12<04:34,  1.71s/it, recall_0.3=(159, 158) / 274]eval:  23%|███████████▏                                     | 47/206 [01:12<04:06,  1.55s/it, recall_0.3=(159, 158) / 274]eval:  23%|███████████▏                                     | 47/206 [01:13<04:06,  1.55s/it, recall_0.3=(165, 163) / 284]eval:  23%|███████████▍                                     | 48/206 [01:13<03:41,  1.40s/it, recall_0.3=(165, 163) / 284]eval:  23%|███████████▍                                     | 48/206 [01:16<03:41,  1.40s/it, recall_0.3=(170, 168) / 290]eval:  24%|███████████▋                                     | 49/206 [01:16<04:49,  1.84s/it, recall_0.3=(170, 168) / 290]eval:  24%|███████████▋                                     | 49/206 [01:17<04:49,  1.84s/it, recall_0.3=(171, 169) / 292]eval:  24%|███████████▉                                     | 50/206 [01:17<04:04,  1.57s/it, recall_0.3=(171, 169) / 292]eval:  24%|███████████▉                                     | 50/206 [01:18<04:04,  1.57s/it, recall_0.3=(173, 171) / 296]eval:  25%|████████████▏                                    | 51/206 [01:18<03:35,  1.39s/it, recall_0.3=(173, 171) / 296]eval:  25%|████████████▏                                    | 51/206 [01:19<03:35,  1.39s/it, recall_0.3=(175, 173) / 300]eval:  25%|████████████▎                                    | 52/206 [01:19<03:25,  1.33s/it, recall_0.3=(175, 173) / 300]eval:  25%|████████████▎                                    | 52/206 [01:20<03:25,  1.33s/it, recall_0.3=(180, 178) / 308]eval:  26%|████████████▌                                    | 53/206 [01:20<03:29,  1.37s/it, recall_0.3=(180, 178) / 308]eval:  26%|████████████▌                                    | 53/206 [01:21<03:29,  1.37s/it, recall_0.3=(183, 181) / 314]eval:  26%|████████████▊                                    | 54/206 [01:21<03:13,  1.27s/it, recall_0.3=(183, 181) / 314]eval:  26%|████████████▊                                    | 54/206 [01:22<03:13,  1.27s/it, recall_0.3=(184, 182) / 317]eval:  27%|█████████████                                    | 55/206 [01:22<03:08,  1.25s/it, recall_0.3=(184, 182) / 317]eval:  27%|█████████████                                    | 55/206 [01:24<03:08,  1.25s/it, recall_0.3=(192, 190) / 331]eval:  27%|█████████████▎                                   | 56/206 [01:24<03:06,  1.25s/it, recall_0.3=(192, 190) / 331]eval:  27%|█████████████▎                                   | 56/206 [01:26<03:06,  1.25s/it, recall_0.3=(193, 191) / 335]eval:  28%|█████████████▌                                   | 57/206 [01:26<03:35,  1.45s/it, recall_0.3=(193, 191) / 335]eval:  28%|█████████████▌                                   | 57/206 [01:27<03:35,  1.45s/it, recall_0.3=(193, 191) / 337]eval:  28%|█████████████▊                                   | 58/206 [01:27<03:18,  1.34s/it, recall_0.3=(193, 191) / 337]eval:  28%|█████████████▊                                   | 58/206 [01:28<03:18,  1.34s/it, recall_0.3=(199, 197) / 349]eval:  29%|██████████████                                   | 59/206 [01:28<03:06,  1.27s/it, recall_0.3=(199, 197) / 349]eval:  29%|██████████████                                   | 59/206 [01:29<03:06,  1.27s/it, recall_0.3=(211, 209) / 362]eval:  29%|██████████████▎                                  | 60/206 [01:29<03:02,  1.25s/it, recall_0.3=(211, 209) / 362]eval:  29%|██████████████▎                                  | 60/206 [01:33<03:02,  1.25s/it, recall_0.3=(222, 220) / 374]eval:  30%|██████████████▌                                  | 61/206 [01:33<04:42,  1.95s/it, recall_0.3=(222, 220) / 374]eval:  30%|██████████████▌                                  | 61/206 [01:34<04:42,  1.95s/it, recall_0.3=(231, 229) / 391]eval:  30%|██████████████▋                                  | 62/206 [01:34<04:01,  1.67s/it, recall_0.3=(231, 229) / 391]eval:  30%|██████████████▋                                  | 62/206 [01:35<04:01,  1.67s/it, recall_0.3=(241, 240) / 408]eval:  31%|██████████████▉                                  | 63/206 [01:35<03:29,  1.46s/it, recall_0.3=(241, 240) / 408]eval:  31%|██████████████▉                                  | 63/206 [01:36<03:29,  1.46s/it, recall_0.3=(249, 248) / 422]eval:  31%|███████████████▏                                 | 64/206 [01:36<03:09,  1.34s/it, recall_0.3=(249, 248) / 422]eval:  31%|███████████████▏                                 | 64/206 [01:38<03:09,  1.34s/it, recall_0.3=(261, 260) / 438]eval:  32%|███████████████▍                                 | 65/206 [01:38<04:01,  1.72s/it, recall_0.3=(261, 260) / 438]eval:  32%|███████████████▍                                 | 65/206 [01:39<04:01,  1.72s/it, recall_0.3=(269, 268) / 450]eval:  32%|███████████████▋                                 | 66/206 [01:39<03:26,  1.47s/it, recall_0.3=(269, 268) / 450]eval:  32%|███████████████▋                                 | 66/206 [01:40<03:26,  1.47s/it, recall_0.3=(276, 275) / 464]eval:  33%|███████████████▉                                 | 67/206 [01:40<03:08,  1.36s/it, recall_0.3=(276, 275) / 464]eval:  33%|███████████████▉                                 | 67/206 [01:41<03:08,  1.36s/it, recall_0.3=(279, 278) / 468]eval:  33%|████████████████▏                                | 68/206 [01:41<02:48,  1.22s/it, recall_0.3=(279, 278) / 468]eval:  33%|████████████████▏                                | 68/206 [01:43<02:48,  1.22s/it, recall_0.3=(281, 280) / 471]eval:  33%|████████████████▍                                | 69/206 [01:43<03:21,  1.47s/it, recall_0.3=(281, 280) / 471]eval:  33%|████████████████▍                                | 69/206 [01:44<03:21,  1.47s/it, recall_0.3=(282, 281) / 473]eval:  34%|████████████████▋                                | 70/206 [01:44<02:58,  1.31s/it, recall_0.3=(282, 281) / 473]eval:  34%|████████████████▋                                | 70/206 [01:45<02:58,  1.31s/it, recall_0.3=(284, 283) / 476]eval:  34%|████████████████▉                                | 71/206 [01:45<02:39,  1.18s/it, recall_0.3=(284, 283) / 476]eval:  34%|████████████████▉                                | 71/206 [01:46<02:39,  1.18s/it, recall_0.3=(285, 284) / 479]eval:  35%|█████████████████▏                               | 72/206 [01:46<02:33,  1.15s/it, recall_0.3=(285, 284) / 479]eval:  35%|█████████████████▏                               | 72/206 [01:47<02:33,  1.15s/it, recall_0.3=(285, 284) / 479]eval:  35%|█████████████████▎                               | 73/206 [01:47<02:22,  1.07s/it, recall_0.3=(285, 284) / 479]eval:  35%|█████████████████▎                               | 73/206 [01:48<02:22,  1.07s/it, recall_0.3=(285, 284) / 481]eval:  36%|█████████████████▌                               | 74/206 [01:48<02:05,  1.05it/s, recall_0.3=(285, 284) / 481]eval:  36%|█████████████████▌                               | 74/206 [01:48<02:05,  1.05it/s, recall_0.3=(286, 285) / 484]eval:  36%|█████████████████▊                               | 75/206 [01:48<01:51,  1.18it/s, recall_0.3=(286, 285) / 484]eval:  36%|█████████████████▊                               | 75/206 [01:49<01:51,  1.18it/s, recall_0.3=(288, 287) / 488]eval:  37%|██████████████████                               | 76/206 [01:49<01:56,  1.12it/s, recall_0.3=(288, 287) / 488]eval:  37%|██████████████████                               | 76/206 [01:51<01:56,  1.12it/s, recall_0.3=(289, 288) / 492]eval:  37%|██████████████████▎                              | 77/206 [01:51<02:28,  1.15s/it, recall_0.3=(289, 288) / 492]eval:  37%|██████████████████▎                              | 77/206 [01:52<02:28,  1.15s/it, recall_0.3=(290, 289) / 494]eval:  38%|██████████████████▌                              | 78/206 [01:52<02:24,  1.13s/it, recall_0.3=(290, 289) / 494]eval:  38%|██████████████████▌                              | 78/206 [01:53<02:24,  1.13s/it, recall_0.3=(296, 295) / 504]eval:  38%|██████████████████▊                              | 79/206 [01:53<02:22,  1.12s/it, recall_0.3=(296, 295) / 504]eval:  38%|██████████████████▊                              | 79/206 [01:54<02:22,  1.12s/it, recall_0.3=(300, 299) / 510]eval:  39%|███████████████████                              | 80/206 [01:54<02:15,  1.07s/it, recall_0.3=(300, 299) / 510]eval:  39%|███████████████████                              | 80/206 [01:55<02:15,  1.07s/it, recall_0.3=(304, 303) / 516]eval:  39%|███████████████████▎                             | 81/206 [01:55<02:14,  1.07s/it, recall_0.3=(304, 303) / 516]eval:  39%|███████████████████▎                             | 81/206 [01:57<02:14,  1.07s/it, recall_0.3=(311, 310) / 523]eval:  40%|███████████████████▌                             | 82/206 [01:57<02:23,  1.16s/it, recall_0.3=(311, 310) / 523]eval:  40%|███████████████████▌                             | 82/206 [01:58<02:23,  1.16s/it, recall_0.3=(317, 316) / 529]eval:  40%|███████████████████▋                             | 83/206 [01:58<02:28,  1.21s/it, recall_0.3=(317, 316) / 529]eval:  40%|███████████████████▋                             | 83/206 [01:59<02:28,  1.21s/it, recall_0.3=(328, 327) / 553]eval:  41%|███████████████████▉                             | 84/206 [01:59<02:11,  1.08s/it, recall_0.3=(328, 327) / 553]eval:  41%|███████████████████▉                             | 84/206 [02:00<02:11,  1.08s/it, recall_0.3=(339, 338) / 572]eval:  41%|████████████████████▏                            | 85/206 [02:00<02:16,  1.13s/it, recall_0.3=(339, 338) / 572]eval:  41%|████████████████████▏                            | 85/206 [02:03<02:16,  1.13s/it, recall_0.3=(349, 348) / 589]eval:  42%|████████████████████▍                            | 86/206 [02:03<03:27,  1.73s/it, recall_0.3=(349, 348) / 589]eval:  42%|████████████████████▍                            | 86/206 [02:04<03:27,  1.73s/it, recall_0.3=(356, 355) / 601]eval:  42%|████████████████████▋                            | 87/206 [02:04<03:12,  1.62s/it, recall_0.3=(356, 355) / 601]eval:  42%|████████████████████▋                            | 87/206 [02:06<03:12,  1.62s/it, recall_0.3=(363, 361) / 616]eval:  43%|████████████████████▉                            | 88/206 [02:06<02:54,  1.48s/it, recall_0.3=(363, 361) / 616]eval:  43%|████████████████████▉                            | 88/206 [02:07<02:54,  1.48s/it, recall_0.3=(368, 366) / 625]eval:  43%|█████████████████████▏                           | 89/206 [02:07<02:42,  1.38s/it, recall_0.3=(368, 366) / 625]eval:  43%|█████████████████████▏                           | 89/206 [02:10<02:42,  1.38s/it, recall_0.3=(371, 369) / 632]eval:  44%|█████████████████████▍                           | 90/206 [02:10<03:35,  1.86s/it, recall_0.3=(371, 369) / 632]eval:  44%|█████████████████████▍                           | 90/206 [02:11<03:35,  1.86s/it, recall_0.3=(374, 372) / 636]eval:  44%|█████████████████████▋                           | 91/206 [02:11<03:09,  1.65s/it, recall_0.3=(374, 372) / 636]eval:  44%|█████████████████████▋                           | 91/206 [02:12<03:09,  1.65s/it, recall_0.3=(375, 373) / 638]eval:  45%|█████████████████████▉                           | 92/206 [02:12<02:45,  1.45s/it, recall_0.3=(375, 373) / 638]eval:  45%|█████████████████████▉                           | 92/206 [02:13<02:45,  1.45s/it, recall_0.3=(377, 375) / 641]eval:  45%|██████████████████████                           | 93/206 [02:13<02:32,  1.35s/it, recall_0.3=(377, 375) / 641]eval:  45%|██████████████████████                           | 93/206 [02:14<02:32,  1.35s/it, recall_0.3=(380, 378) / 644]eval:  46%|██████████████████████▎                          | 94/206 [02:14<02:18,  1.24s/it, recall_0.3=(380, 378) / 644]eval:  46%|██████████████████████▎                          | 94/206 [02:15<02:18,  1.24s/it, recall_0.3=(383, 381) / 647]eval:  46%|██████████████████████▌                          | 95/206 [02:15<02:07,  1.15s/it, recall_0.3=(383, 381) / 647]eval:  46%|██████████████████████▌                          | 95/206 [02:16<02:07,  1.15s/it, recall_0.3=(386, 384) / 655]eval:  47%|██████████████████████▊                          | 96/206 [02:16<01:55,  1.05s/it, recall_0.3=(386, 384) / 655]eval:  47%|██████████████████████▊                          | 96/206 [02:17<01:55,  1.05s/it, recall_0.3=(390, 388) / 659]eval:  47%|███████████████████████                          | 97/206 [02:17<01:49,  1.01s/it, recall_0.3=(390, 388) / 659]eval:  47%|███████████████████████                          | 97/206 [02:19<01:49,  1.01s/it, recall_0.3=(391, 389) / 661]eval:  48%|███████████████████████▎                         | 98/206 [02:19<02:25,  1.35s/it, recall_0.3=(391, 389) / 661]eval:  48%|███████████████████████▎                         | 98/206 [02:20<02:25,  1.35s/it, recall_0.3=(396, 394) / 667]eval:  48%|███████████████████████▌                         | 99/206 [02:20<02:19,  1.30s/it, recall_0.3=(396, 394) / 667]eval:  48%|███████████████████████▌                         | 99/206 [02:21<02:19,  1.30s/it, recall_0.3=(397, 395) / 670]eval:  49%|███████████████████████▎                        | 100/206 [02:21<02:14,  1.27s/it, recall_0.3=(397, 395) / 670]eval:  49%|███████████████████████▎                        | 100/206 [02:23<02:14,  1.27s/it, recall_0.3=(399, 397) / 673]eval:  49%|███████████████████████▌                        | 101/206 [02:23<02:17,  1.31s/it, recall_0.3=(399, 397) / 673]eval:  49%|███████████████████████▌                        | 101/206 [02:25<02:17,  1.31s/it, recall_0.3=(403, 401) / 681]eval:  50%|███████████████████████▊                        | 102/206 [02:25<02:47,  1.61s/it, recall_0.3=(403, 401) / 681]eval:  50%|███████████████████████▊                        | 102/206 [02:26<02:47,  1.61s/it, recall_0.3=(415, 413) / 700]eval:  50%|████████████████████████                        | 103/206 [02:26<02:30,  1.46s/it, recall_0.3=(415, 413) / 700]eval:  50%|████████████████████████                        | 103/206 [02:27<02:30,  1.46s/it, recall_0.3=(427, 424) / 717]eval:  50%|████████████████████████▏                       | 104/206 [02:27<02:25,  1.42s/it, recall_0.3=(427, 424) / 717]eval:  50%|████████████████████████▏                       | 104/206 [02:28<02:25,  1.42s/it, recall_0.3=(441, 438) / 743]eval:  51%|████████████████████████▍                       | 105/206 [02:28<02:12,  1.31s/it, recall_0.3=(441, 438) / 743]eval:  51%|████████████████████████▍                       | 105/206 [02:32<02:12,  1.31s/it, recall_0.3=(446, 443) / 752]eval:  51%|████████████████████████▋                       | 106/206 [02:32<03:14,  1.94s/it, recall_0.3=(446, 443) / 752]eval:  51%|████████████████████████▋                       | 106/206 [02:33<03:14,  1.94s/it, recall_0.3=(453, 450) / 763]eval:  52%|████████████████████████▉                       | 107/206 [02:33<02:51,  1.73s/it, recall_0.3=(453, 450) / 763]eval:  52%|████████████████████████▉                       | 107/206 [02:34<02:51,  1.73s/it, recall_0.3=(460, 457) / 772]eval:  52%|█████████████████████████▏                      | 108/206 [02:34<02:35,  1.59s/it, recall_0.3=(460, 457) / 772]eval:  52%|█████████████████████████▏                      | 108/206 [02:35<02:35,  1.59s/it, recall_0.3=(467, 464) / 781]eval:  53%|█████████████████████████▍                      | 109/206 [02:35<02:21,  1.45s/it, recall_0.3=(467, 464) / 781]eval:  53%|█████████████████████████▍                      | 109/206 [02:37<02:21,  1.45s/it, recall_0.3=(469, 466) / 784]eval:  53%|█████████████████████████▋                      | 110/206 [02:37<02:14,  1.40s/it, recall_0.3=(469, 466) / 784]eval:  53%|█████████████████████████▋                      | 110/206 [02:38<02:14,  1.40s/it, recall_0.3=(472, 469) / 790]eval:  54%|█████████████████████████▊                      | 111/206 [02:38<02:06,  1.33s/it, recall_0.3=(472, 469) / 790]eval:  54%|█████████████████████████▊                      | 111/206 [02:39<02:06,  1.33s/it, recall_0.3=(472, 469) / 795]eval:  54%|██████████████████████████                      | 112/206 [02:39<01:59,  1.27s/it, recall_0.3=(472, 469) / 795]eval:  54%|██████████████████████████                      | 112/206 [02:40<01:59,  1.27s/it, recall_0.3=(473, 470) / 800]eval:  55%|██████████████████████████▎                     | 113/206 [02:40<01:56,  1.25s/it, recall_0.3=(473, 470) / 800]eval:  55%|██████████████████████████▎                     | 113/206 [02:41<01:56,  1.25s/it, recall_0.3=(474, 471) / 805]eval:  55%|██████████████████████████▌                     | 114/206 [02:41<01:42,  1.11s/it, recall_0.3=(474, 471) / 805]eval:  55%|██████████████████████████▌                     | 114/206 [02:42<01:42,  1.11s/it, recall_0.3=(476, 473) / 812]eval:  56%|██████████████████████████▊                     | 115/206 [02:42<01:33,  1.02s/it, recall_0.3=(476, 473) / 812]eval:  56%|██████████████████████████▊                     | 115/206 [02:42<01:33,  1.02s/it, recall_0.3=(477, 474) / 816]eval:  56%|███████████████████████████                     | 116/206 [02:42<01:21,  1.10it/s, recall_0.3=(477, 474) / 816]eval:  56%|███████████████████████████                     | 116/206 [02:43<01:21,  1.10it/s, recall_0.3=(482, 479) / 821]eval:  57%|███████████████████████████▎                    | 117/206 [02:43<01:23,  1.07it/s, recall_0.3=(482, 479) / 821]eval:  57%|███████████████████████████▎                    | 117/206 [02:48<01:23,  1.07it/s, recall_0.3=(483, 480) / 824]eval:  57%|███████████████████████████▍                    | 118/206 [02:48<03:03,  2.09s/it, recall_0.3=(483, 480) / 824]eval:  57%|███████████████████████████▍                    | 118/206 [02:49<03:03,  2.09s/it, recall_0.3=(486, 483) / 828]eval:  58%|███████████████████████████▋                    | 119/206 [02:49<02:36,  1.80s/it, recall_0.3=(486, 483) / 828]eval:  58%|███████████████████████████▋                    | 119/206 [02:51<02:36,  1.80s/it, recall_0.3=(495, 492) / 840]eval:  58%|███████████████████████████▉                    | 120/206 [02:51<02:24,  1.68s/it, recall_0.3=(495, 492) / 840]eval:  58%|███████████████████████████▉                    | 120/206 [02:52<02:24,  1.68s/it, recall_0.3=(506, 503) / 852]eval:  59%|████████████████████████████▏                   | 121/206 [02:52<02:14,  1.59s/it, recall_0.3=(506, 503) / 852]eval:  59%|████████████████████████████▏                   | 121/206 [02:54<02:14,  1.59s/it, recall_0.3=(516, 513) / 867]eval:  59%|████████████████████████████▍                   | 122/206 [02:54<02:12,  1.58s/it, recall_0.3=(516, 513) / 867]eval:  59%|████████████████████████████▍                   | 122/206 [02:55<02:12,  1.58s/it, recall_0.3=(533, 529) / 900]eval:  60%|████████████████████████████▋                   | 123/206 [02:55<01:56,  1.41s/it, recall_0.3=(533, 529) / 900]eval:  60%|████████████████████████████▋                   | 123/206 [02:56<01:56,  1.41s/it, recall_0.3=(545, 541) / 923]eval:  60%|████████████████████████████▉                   | 124/206 [02:56<01:41,  1.24s/it, recall_0.3=(545, 541) / 923]eval:  60%|████████████████████████████▉                   | 124/206 [02:57<01:41,  1.24s/it, recall_0.3=(555, 551) / 943]eval:  61%|█████████████████████████████▏                  | 125/206 [02:57<01:40,  1.24s/it, recall_0.3=(555, 551) / 943]eval:  61%|█████████████████████████████▏                  | 125/206 [03:02<01:40,  1.24s/it, recall_0.3=(556, 552) / 947]eval:  61%|█████████████████████████████▎                  | 126/206 [03:02<03:03,  2.29s/it, recall_0.3=(556, 552) / 947]eval:  61%|█████████████████████████████▎                  | 126/206 [03:02<03:03,  2.29s/it, recall_0.3=(561, 557) / 954]eval:  62%|█████████████████████████████▌                  | 127/206 [03:02<02:28,  1.88s/it, recall_0.3=(561, 557) / 954]eval:  62%|█████████████████████████████▌                  | 127/206 [03:03<02:28,  1.88s/it, recall_0.3=(565, 561) / 962]eval:  62%|█████████████████████████████▊                  | 128/206 [03:03<02:01,  1.56s/it, recall_0.3=(565, 561) / 962]eval:  62%|█████████████████████████████▊                  | 128/206 [03:04<02:01,  1.56s/it, recall_0.3=(569, 565) / 970]eval:  63%|██████████████████████████████                  | 129/206 [03:04<01:46,  1.39s/it, recall_0.3=(569, 565) / 970]eval:  63%|██████████████████████████████                  | 129/206 [03:08<01:46,  1.39s/it, recall_0.3=(571, 567) / 976]eval:  63%|██████████████████████████████▎                 | 130/206 [03:08<02:48,  2.22s/it, recall_0.3=(571, 567) / 976]eval:  63%|██████████████████████████████▎                 | 130/206 [03:09<02:48,  2.22s/it, recall_0.3=(572, 568) / 978]eval:  64%|██████████████████████████████▌                 | 131/206 [03:09<02:18,  1.85s/it, recall_0.3=(572, 568) / 978]eval:  64%|██████████████████████████████▌                 | 131/206 [03:10<02:18,  1.85s/it, recall_0.3=(572, 568) / 980]eval:  64%|██████████████████████████████▊                 | 132/206 [03:10<02:00,  1.62s/it, recall_0.3=(572, 568) / 980]eval:  64%|██████████████████████████████▊                 | 132/206 [03:12<02:00,  1.62s/it, recall_0.3=(573, 569) / 984]eval:  65%|██████████████████████████████▉                 | 133/206 [03:12<01:51,  1.52s/it, recall_0.3=(573, 569) / 984]eval:  65%|██████████████████████████████▉                 | 133/206 [03:13<01:51,  1.52s/it, recall_0.3=(573, 569) / 987]eval:  65%|███████████████████████████████▏                | 134/206 [03:13<01:41,  1.41s/it, recall_0.3=(573, 569) / 987]eval:  65%|███████████████████████████████▏                | 134/206 [03:14<01:41,  1.41s/it, recall_0.3=(576, 572) / 997]eval:  66%|███████████████████████████████▍                | 135/206 [03:14<01:35,  1.34s/it, recall_0.3=(576, 572) / 997]eval:  66%|███████████████████████████████▍                | 135/206 [03:15<01:35,  1.34s/it, recall_0.3=(576, 572) / 999]eval:  66%|███████████████████████████████▋                | 136/206 [03:15<01:30,  1.29s/it, recall_0.3=(576, 572) / 999]eval:  66%|███████████████████████████████                | 136/206 [03:16<01:30,  1.29s/it, recall_0.3=(578, 574) / 1004]eval:  67%|███████████████████████████████▎               | 137/206 [03:16<01:22,  1.19s/it, recall_0.3=(578, 574) / 1004]eval:  67%|███████████████████████████████▎               | 137/206 [03:18<01:22,  1.19s/it, recall_0.3=(578, 574) / 1009]eval:  67%|███████████████████████████████▍               | 138/206 [03:18<01:41,  1.49s/it, recall_0.3=(578, 574) / 1009]eval:  67%|███████████████████████████████▍               | 138/206 [03:20<01:41,  1.49s/it, recall_0.3=(580, 576) / 1015]eval:  67%|███████████████████████████████▋               | 139/206 [03:20<01:34,  1.41s/it, recall_0.3=(580, 576) / 1015]eval:  67%|███████████████████████████████▋               | 139/206 [03:21<01:34,  1.41s/it, recall_0.3=(587, 582) / 1026]eval:  68%|███████████████████████████████▉               | 140/206 [03:21<01:25,  1.30s/it, recall_0.3=(587, 582) / 1026]eval:  68%|███████████████████████████████▉               | 140/206 [03:22<01:25,  1.30s/it, recall_0.3=(595, 589) / 1040]eval:  68%|████████████████████████████████▏              | 141/206 [03:22<01:28,  1.36s/it, recall_0.3=(595, 589) / 1040]eval:  68%|████████████████████████████████▏              | 141/206 [03:24<01:28,  1.36s/it, recall_0.3=(603, 598) / 1053]eval:  69%|████████████████████████████████▍              | 142/206 [03:24<01:39,  1.56s/it, recall_0.3=(603, 598) / 1053]eval:  69%|████████████████████████████████▍              | 142/206 [03:25<01:39,  1.56s/it, recall_0.3=(622, 617) / 1076]eval:  69%|████████████████████████████████▋              | 143/206 [03:25<01:26,  1.37s/it, recall_0.3=(622, 617) / 1076]eval:  69%|████████████████████████████████▋              | 143/206 [03:26<01:26,  1.37s/it, recall_0.3=(633, 628) / 1093]eval:  70%|████████████████████████████████▊              | 144/206 [03:26<01:22,  1.33s/it, recall_0.3=(633, 628) / 1093]eval:  70%|████████████████████████████████▊              | 144/206 [03:27<01:22,  1.33s/it, recall_0.3=(640, 635) / 1104]eval:  70%|█████████████████████████████████              | 145/206 [03:27<01:17,  1.26s/it, recall_0.3=(640, 635) / 1104]eval:  70%|█████████████████████████████████              | 145/206 [03:29<01:17,  1.26s/it, recall_0.3=(646, 641) / 1121]eval:  71%|█████████████████████████████████▎             | 146/206 [03:29<01:12,  1.20s/it, recall_0.3=(646, 641) / 1121]eval:  71%|█████████████████████████████████▎             | 146/206 [03:30<01:12,  1.20s/it, recall_0.3=(647, 642) / 1123]eval:  71%|█████████████████████████████████▌             | 147/206 [03:30<01:12,  1.23s/it, recall_0.3=(647, 642) / 1123]eval:  71%|█████████████████████████████████▌             | 147/206 [03:31<01:12,  1.23s/it, recall_0.3=(650, 645) / 1131]eval:  72%|█████████████████████████████████▊             | 148/206 [03:31<01:08,  1.19s/it, recall_0.3=(650, 645) / 1131]eval:  72%|█████████████████████████████████▊             | 148/206 [03:32<01:08,  1.19s/it, recall_0.3=(652, 646) / 1134]eval:  72%|█████████████████████████████████▉             | 149/206 [03:32<01:08,  1.20s/it, recall_0.3=(652, 646) / 1134]eval:  72%|█████████████████████████████████▉             | 149/206 [03:33<01:08,  1.20s/it, recall_0.3=(655, 649) / 1137]eval:  73%|██████████████████████████████████▏            | 150/206 [03:33<01:04,  1.16s/it, recall_0.3=(655, 649) / 1137]eval:  73%|██████████████████████████████████▏            | 150/206 [03:34<01:04,  1.16s/it, recall_0.3=(658, 652) / 1142]eval:  73%|██████████████████████████████████▍            | 151/206 [03:34<00:59,  1.07s/it, recall_0.3=(658, 652) / 1142]eval:  73%|██████████████████████████████████▍            | 151/206 [03:35<00:59,  1.07s/it, recall_0.3=(659, 653) / 1145]eval:  74%|██████████████████████████████████▋            | 152/206 [03:35<00:57,  1.06s/it, recall_0.3=(659, 653) / 1145]eval:  74%|██████████████████████████████████▋            | 152/206 [03:36<00:57,  1.06s/it, recall_0.3=(661, 655) / 1150]eval:  74%|██████████████████████████████████▉            | 153/206 [03:36<00:54,  1.03s/it, recall_0.3=(661, 655) / 1150]eval:  74%|██████████████████████████████████▉            | 153/206 [03:37<00:54,  1.03s/it, recall_0.3=(663, 657) / 1154]eval:  75%|███████████████████████████████████▏           | 154/206 [03:37<00:51,  1.01it/s, recall_0.3=(663, 657) / 1154]eval:  75%|███████████████████████████████████▏           | 154/206 [03:38<00:51,  1.01it/s, recall_0.3=(665, 659) / 1157]eval:  75%|███████████████████████████████████▎           | 155/206 [03:38<00:47,  1.08it/s, recall_0.3=(665, 659) / 1157]eval:  75%|███████████████████████████████████▎           | 155/206 [03:39<00:47,  1.08it/s, recall_0.3=(667, 661) / 1162]eval:  76%|███████████████████████████████████▌           | 156/206 [03:39<00:45,  1.10it/s, recall_0.3=(667, 661) / 1162]eval:  76%|███████████████████████████████████▌           | 156/206 [03:40<00:45,  1.10it/s, recall_0.3=(670, 664) / 1166]eval:  76%|███████████████████████████████████▊           | 157/206 [03:40<00:48,  1.00it/s, recall_0.3=(670, 664) / 1166]eval:  76%|███████████████████████████████████▊           | 157/206 [03:41<00:48,  1.00it/s, recall_0.3=(671, 665) / 1168]eval:  77%|████████████████████████████████████           | 158/206 [03:41<00:49,  1.04s/it, recall_0.3=(671, 665) / 1168]eval:  77%|████████████████████████████████████           | 158/206 [03:42<00:49,  1.04s/it, recall_0.3=(671, 665) / 1168]eval:  77%|████████████████████████████████████▎          | 159/206 [03:42<00:53,  1.14s/it, recall_0.3=(671, 665) / 1168]eval:  77%|████████████████████████████████████▎          | 159/206 [03:44<00:53,  1.14s/it, recall_0.3=(673, 668) / 1172]eval:  78%|████████████████████████████████████▌          | 160/206 [03:44<00:56,  1.23s/it, recall_0.3=(673, 668) / 1172]eval:  78%|████████████████████████████████████▌          | 160/206 [03:45<00:56,  1.23s/it, recall_0.3=(677, 672) / 1177]eval:  78%|████████████████████████████████████▋          | 161/206 [03:45<00:54,  1.20s/it, recall_0.3=(677, 672) / 1177]eval:  78%|████████████████████████████████████▋          | 161/206 [03:46<00:54,  1.20s/it, recall_0.3=(686, 681) / 1189]eval:  79%|████████████████████████████████████▉          | 162/206 [03:46<00:51,  1.18s/it, recall_0.3=(686, 681) / 1189]eval:  79%|████████████████████████████████████▉          | 162/206 [03:47<00:51,  1.18s/it, recall_0.3=(698, 693) / 1206]eval:  79%|█████████████████████████████████████▏         | 163/206 [03:47<00:48,  1.12s/it, recall_0.3=(698, 693) / 1206]eval:  79%|█████████████████████████████████████▏         | 163/206 [03:48<00:48,  1.12s/it, recall_0.3=(708, 704) / 1222]eval:  80%|█████████████████████████████████████▍         | 164/206 [03:48<00:44,  1.06s/it, recall_0.3=(708, 704) / 1222]eval:  80%|█████████████████████████████████████▍         | 164/206 [03:49<00:44,  1.06s/it, recall_0.3=(715, 711) / 1233]eval:  80%|█████████████████████████████████████▋         | 165/206 [03:49<00:42,  1.05s/it, recall_0.3=(715, 711) / 1233]eval:  80%|█████████████████████████████████████▋         | 165/206 [03:51<00:42,  1.05s/it, recall_0.3=(723, 719) / 1253]eval:  81%|█████████████████████████████████████▊         | 166/206 [03:51<00:53,  1.35s/it, recall_0.3=(723, 719) / 1253]eval:  81%|█████████████████████████████████████▊         | 166/206 [03:53<00:53,  1.35s/it, recall_0.3=(730, 726) / 1268]eval:  81%|██████████████████████████████████████         | 167/206 [03:53<01:03,  1.63s/it, recall_0.3=(730, 726) / 1268]eval:  81%|██████████████████████████████████████         | 167/206 [03:54<01:03,  1.63s/it, recall_0.3=(736, 732) / 1280]eval:  82%|██████████████████████████████████████▎        | 168/206 [03:54<00:54,  1.43s/it, recall_0.3=(736, 732) / 1280]eval:  82%|██████████████████████████████████████▎        | 168/206 [03:55<00:54,  1.43s/it, recall_0.3=(739, 735) / 1290]eval:  82%|██████████████████████████████████████▌        | 169/206 [03:55<00:49,  1.33s/it, recall_0.3=(739, 735) / 1290]eval:  82%|██████████████████████████████████████▌        | 169/206 [03:57<00:49,  1.33s/it, recall_0.3=(741, 737) / 1298]eval:  83%|██████████████████████████████████████▊        | 170/206 [03:57<00:46,  1.28s/it, recall_0.3=(741, 737) / 1298]eval:  83%|██████████████████████████████████████▊        | 170/206 [03:59<00:46,  1.28s/it, recall_0.3=(748, 744) / 1310]eval:  83%|███████████████████████████████████████        | 171/206 [03:59<00:56,  1.61s/it, recall_0.3=(748, 744) / 1310]eval:  83%|███████████████████████████████████████        | 171/206 [04:00<00:56,  1.61s/it, recall_0.3=(750, 746) / 1315]eval:  83%|███████████████████████████████████████▏       | 172/206 [04:00<00:48,  1.44s/it, recall_0.3=(750, 746) / 1315]eval:  83%|███████████████████████████████████████▏       | 172/206 [04:01<00:48,  1.44s/it, recall_0.3=(752, 748) / 1319]eval:  84%|███████████████████████████████████████▍       | 173/206 [04:01<00:42,  1.28s/it, recall_0.3=(752, 748) / 1319]eval:  84%|███████████████████████████████████████▍       | 173/206 [04:02<00:42,  1.28s/it, recall_0.3=(755, 751) / 1323]eval:  84%|███████████████████████████████████████▋       | 174/206 [04:02<00:36,  1.14s/it, recall_0.3=(755, 751) / 1323]eval:  84%|███████████████████████████████████████▋       | 174/206 [04:02<00:36,  1.14s/it, recall_0.3=(756, 752) / 1328]eval:  85%|███████████████████████████████████████▉       | 175/206 [04:02<00:31,  1.01s/it, recall_0.3=(756, 752) / 1328]eval:  85%|███████████████████████████████████████▉       | 175/206 [04:03<00:31,  1.01s/it, recall_0.3=(757, 753) / 1333]eval:  85%|████████████████████████████████████████▏      | 176/206 [04:03<00:30,  1.02s/it, recall_0.3=(757, 753) / 1333]eval:  85%|████████████████████████████████████████▏      | 176/206 [04:04<00:30,  1.02s/it, recall_0.3=(758, 754) / 1335]eval:  86%|████████████████████████████████████████▍      | 177/206 [04:04<00:29,  1.03s/it, recall_0.3=(758, 754) / 1335]eval:  86%|████████████████████████████████████████▍      | 177/206 [04:05<00:29,  1.03s/it, recall_0.3=(758, 754) / 1339]eval:  86%|████████████████████████████████████████▌      | 178/206 [04:05<00:27,  1.03it/s, recall_0.3=(758, 754) / 1339]eval:  86%|████████████████████████████████████████▌      | 178/206 [04:08<00:27,  1.03it/s, recall_0.3=(758, 754) / 1341]eval:  87%|████████████████████████████████████████▊      | 179/206 [04:08<00:36,  1.35s/it, recall_0.3=(758, 754) / 1341]eval:  87%|████████████████████████████████████████▊      | 179/206 [04:09<00:36,  1.35s/it, recall_0.3=(761, 757) / 1346]eval:  87%|█████████████████████████████████████████      | 180/206 [04:09<00:34,  1.31s/it, recall_0.3=(761, 757) / 1346]eval:  87%|█████████████████████████████████████████      | 180/206 [04:10<00:34,  1.31s/it, recall_0.3=(761, 757) / 1346]eval:  88%|█████████████████████████████████████████▎     | 181/206 [04:10<00:32,  1.30s/it, recall_0.3=(761, 757) / 1346]eval:  88%|█████████████████████████████████████████▎     | 181/206 [04:11<00:32,  1.30s/it, recall_0.3=(763, 759) / 1354]eval:  88%|█████████████████████████████████████████▌     | 182/206 [04:11<00:32,  1.33s/it, recall_0.3=(763, 759) / 1354]eval:  88%|█████████████████████████████████████████▌     | 182/206 [04:13<00:32,  1.33s/it, recall_0.3=(767, 763) / 1361]eval:  89%|█████████████████████████████████████████▊     | 183/206 [04:13<00:29,  1.30s/it, recall_0.3=(767, 763) / 1361]eval:  89%|█████████████████████████████████████████▊     | 183/206 [04:14<00:29,  1.30s/it, recall_0.3=(770, 766) / 1386]eval:  89%|█████████████████████████████████████████▉     | 184/206 [04:14<00:27,  1.24s/it, recall_0.3=(770, 766) / 1386]eval:  89%|█████████████████████████████████████████▉     | 184/206 [04:15<00:27,  1.24s/it, recall_0.3=(779, 775) / 1401]eval:  90%|██████████████████████████████████████████▏    | 185/206 [04:15<00:23,  1.13s/it, recall_0.3=(779, 775) / 1401]eval:  90%|██████████████████████████████████████████▏    | 185/206 [04:15<00:23,  1.13s/it, recall_0.3=(788, 785) / 1415]eval:  90%|██████████████████████████████████████████▍    | 186/206 [04:15<00:20,  1.04s/it, recall_0.3=(788, 785) / 1415]eval:  90%|██████████████████████████████████████████▍    | 186/206 [04:16<00:20,  1.04s/it, recall_0.3=(796, 793) / 1427]eval:  91%|██████████████████████████████████████████▋    | 187/206 [04:16<00:19,  1.03s/it, recall_0.3=(796, 793) / 1427]eval:  91%|██████████████████████████████████████████▋    | 187/206 [04:17<00:19,  1.03s/it, recall_0.3=(797, 794) / 1436]eval:  91%|██████████████████████████████████████████▉    | 188/206 [04:17<00:18,  1.01s/it, recall_0.3=(797, 794) / 1436]eval:  91%|██████████████████████████████████████████▉    | 188/206 [04:20<00:18,  1.01s/it, recall_0.3=(799, 796) / 1440]eval:  92%|███████████████████████████████████████████    | 189/206 [04:20<00:25,  1.52s/it, recall_0.3=(799, 796) / 1440]eval:  92%|███████████████████████████████████████████    | 189/206 [04:22<00:25,  1.52s/it, recall_0.3=(801, 798) / 1446]eval:  92%|███████████████████████████████████████████▎   | 190/206 [04:22<00:23,  1.47s/it, recall_0.3=(801, 798) / 1446]eval:  92%|███████████████████████████████████████████▎   | 190/206 [04:23<00:23,  1.47s/it, recall_0.3=(803, 800) / 1450]eval:  93%|███████████████████████████████████████████▌   | 191/206 [04:23<00:20,  1.37s/it, recall_0.3=(803, 800) / 1450]eval:  93%|███████████████████████████████████████████▌   | 191/206 [04:24<00:20,  1.37s/it, recall_0.3=(804, 801) / 1452]eval:  93%|███████████████████████████████████████████▊   | 192/206 [04:24<00:18,  1.34s/it, recall_0.3=(804, 801) / 1452]eval:  93%|███████████████████████████████████████████▊   | 192/206 [04:25<00:18,  1.34s/it, recall_0.3=(805, 801) / 1455]eval:  94%|████████████████████████████████████████████   | 193/206 [04:25<00:16,  1.26s/it, recall_0.3=(805, 801) / 1455]eval:  94%|████████████████████████████████████████████   | 193/206 [04:26<00:16,  1.26s/it, recall_0.3=(805, 801) / 1455]eval:  94%|████████████████████████████████████████████▎  | 194/206 [04:26<00:14,  1.18s/it, recall_0.3=(805, 801) / 1455]eval:  94%|████████████████████████████████████████████▎  | 194/206 [04:27<00:14,  1.18s/it, recall_0.3=(805, 801) / 1455]eval:  95%|████████████████████████████████████████████▍  | 195/206 [04:27<00:12,  1.12s/it, recall_0.3=(805, 801) / 1455]eval:  95%|████████████████████████████████████████████▍  | 195/206 [04:28<00:12,  1.12s/it, recall_0.3=(805, 801) / 1455]eval:  95%|████████████████████████████████████████████▋  | 196/206 [04:28<00:10,  1.07s/it, recall_0.3=(805, 801) / 1455]eval:  95%|████████████████████████████████████████████▋  | 196/206 [04:29<00:10,  1.07s/it, recall_0.3=(805, 801) / 1455]eval:  96%|████████████████████████████████████████████▉  | 197/206 [04:29<00:09,  1.04s/it, recall_0.3=(805, 801) / 1455]eval:  96%|████████████████████████████████████████████▉  | 197/206 [04:30<00:09,  1.04s/it, recall_0.3=(807, 803) / 1458]eval:  96%|█████████████████████████████████████████████▏ | 198/206 [04:30<00:08,  1.03s/it, recall_0.3=(807, 803) / 1458]eval:  96%|█████████████████████████████████████████████▏ | 198/206 [04:31<00:08,  1.03s/it, recall_0.3=(811, 807) / 1463]eval:  97%|█████████████████████████████████████████████▍ | 199/206 [04:31<00:07,  1.09s/it, recall_0.3=(811, 807) / 1463]eval:  97%|█████████████████████████████████████████████▍ | 199/206 [04:32<00:07,  1.09s/it, recall_0.3=(811, 807) / 1465]eval:  97%|█████████████████████████████████████████████▋ | 200/206 [04:32<00:06,  1.12s/it, recall_0.3=(811, 807) / 1465]eval:  97%|█████████████████████████████████████████████▋ | 200/206 [04:33<00:06,  1.12s/it, recall_0.3=(811, 807) / 1465]eval:  98%|█████████████████████████████████████████████▊ | 201/206 [04:33<00:05,  1.11s/it, recall_0.3=(811, 807) / 1465]eval:  98%|█████████████████████████████████████████████▊ | 201/206 [04:34<00:05,  1.11s/it, recall_0.3=(813, 809) / 1468]eval:  98%|██████████████████████████████████████████████ | 202/206 [04:34<00:04,  1.05s/it, recall_0.3=(813, 809) / 1468]eval:  98%|██████████████████████████████████████████████ | 202/206 [04:35<00:04,  1.05s/it, recall_0.3=(816, 812) / 1471]eval:  99%|██████████████████████████████████████████████▎| 203/206 [04:35<00:02,  1.08it/s, recall_0.3=(816, 812) / 1471]eval:  99%|██████████████████████████████████████████████▎| 203/206 [04:36<00:02,  1.08it/s, recall_0.3=(818, 814) / 1474]eval:  99%|██████████████████████████████████████████████▌| 204/206 [04:36<00:01,  1.21it/s, recall_0.3=(818, 814) / 1474]eval:  99%|██████████████████████████████████████████████▌| 204/206 [04:36<00:01,  1.21it/s, recall_0.3=(819, 815) / 1477]eval: 100%|██████████████████████████████████████████████▊| 205/206 [04:36<00:00,  1.41it/s, recall_0.3=(819, 815) / 1477]eval: 100%|██████████████████████████████████████████████▊| 205/206 [04:36<00:00,  1.41it/s, recall_0.3=(819, 815) / 1478]eval: 100%|███████████████████████████████████████████████| 206/206 [04:36<00:00,  1.74it/s, recall_0.3=(819, 815) / 1478]eval: 100%|███████████████████████████████████████████████| 206/206 [04:37<00:00,  1.35s/it, recall_0.3=(819, 815) / 1478]
2023-03-03 12:03:08,332   INFO  *************** Performance of EPOCH 10 *****************
2023-03-03 12:03:08,333   INFO  Generate label finished(sec_per_example: 0.1695 second).
2023-03-03 12:03:08,333   INFO  recall_roi_0.3: 0.555615
2023-03-03 12:03:08,333   INFO  recall_rcnn_0.3: 0.557563
2023-03-03 12:03:08,333   INFO  recall_roi_0.5: 0.422954
2023-03-03 12:03:08,333   INFO  recall_rcnn_0.5: 0.444917
2023-03-03 12:03:08,334   INFO  recall_roi_0.7: 0.190932
2023-03-03 12:03:08,334   INFO  recall_rcnn_0.7: 0.228657
2023-03-03 12:03:08,334   INFO  Average predicted number of objects(1644 samples): 6.095
======
Loading Ithaca365 tables for version v1.1...
6 category,
1 attribute,
4 visibility,
25839 instance,
3 sensor,
3 calibrated_sensor,
760811 ego_pose,
40 log,
40 scene,
6576 sample,
2282433 sample_data,
25839 sample_annotation,
1 map,
2579 location,
Done loading in 35.266 seconds.
======
Reverse indexing ...
Done reverse indexing in 5.8 seconds.
======
2023-03-03 12:03:51,536   INFO  The predictions of NuScenes have been saved to /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/eval/eval_with_train/epoch_10/val/final_result/data/results_nusc.json
Initializing nuScenes detection evaluation
Loaded results from /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/eval/eval_with_train/epoch_10/val/final_result/data/results_nusc.json. Found detections for 1644 samples.
Loading annotations for val split from nuScenes version: v1.1
  0%|                                                                                            | 0/1644 [00:00<?, ?it/s] 41%|████████████████████████████████▌                                               | 668/1644 [00:00<00:00, 6674.50it/s] 81%|████████████████████████████████████████████████████████████████▏              | 1336/1644 [00:00<00:00, 6105.50it/s]100%|███████████████████████████████████████████████████████████████████████████████| 1644/1644 [00:00<00:00, 6521.96it/s]
Loaded ground truth annotations for 1644 samples.
Filtering predictions
Detection range: (0, 30)
=> Original number of boxes: 10021
=> After distance based filtering: 2689
=> After LIDAR and RADAR points based filtering: 2689
Detection range: (30, 50)
=> Original number of boxes: 10021
=> After distance based filtering: 3555
=> After LIDAR and RADAR points based filtering: 3555
Detection range: (50, 80)
=> Original number of boxes: 10021
=> After distance based filtering: 3245
=> After LIDAR and RADAR points based filtering: 3245
Detection range: (0, 80)
=> Original number of boxes: 10021
=> After distance based filtering: 9489
=> After LIDAR and RADAR points based filtering: 9489
Filtering ground truth annotations
Detection range: (0, 30)
=> Original number of boxes: 6018
=> After distance based filtering: 1648
=> After LIDAR and RADAR points based filtering: 1648
Detection range: (30, 50)
=> Original number of boxes: 6018
=> After distance based filtering: 1660
=> After LIDAR and RADAR points based filtering: 1660
Detection range: (50, 80)
=> Original number of boxes: 6018
=> After distance based filtering: 1493
=> After LIDAR and RADAR points based filtering: 1493
Detection range: (0, 80)
=> Original number of boxes: 6018
=> After distance based filtering: 4801
=> After LIDAR and RADAR points based filtering: 4801
Accumulating metric data...
Calculating metrics...
Saving metrics to: /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/eval/eval_with_train/epoch_10/val/final_result/data
mAP: 0.1501
mATE: 0.7229
mASE: 0.7576
mAOE: 0.9807
NDS: 0.1649
Eval time: 2.7s

Per-class results:
Object Class	Det. Range	AP	ATE	ASE	AOE
car         	(0, 30)   	0.595	0.210	0.157	0.768
car         	(30, 50)  	0.398	0.245	0.177	0.679
car         	(50, 80)  	0.224	0.320	0.194	0.779
car         	(0, 80)   	0.423	0.241	0.168	0.762
truck       	(0, 30)   	0.000	1.000	1.000	1.000
truck       	(30, 50)  	0.000	1.000	1.000	1.000
truck       	(50, 80)  	0.000	1.000	1.000	1.000
truck       	(0, 80)   	0.000	1.000	1.000	1.000
bus         	(0, 30)   	0.000	1.000	1.000	1.000
bus         	(30, 50)  	0.000	1.000	1.000	1.000
bus         	(50, 80)  	0.000	1.000	1.000	1.000
bus         	(0, 80)   	0.000	1.000	1.000	1.000
pedestrian  	(0, 30)   	0.591	0.077	0.348	0.846
pedestrian  	(30, 50)  	0.485	0.102	0.399	1.260
pedestrian  	(50, 80)  	0.230	0.145	0.414	1.649
pedestrian  	(0, 80)   	0.478	0.097	0.378	1.123
motorcyclist	(0, 30)   	0.000	1.000	1.000	1.000
motorcyclist	(30, 50)  	0.000	1.000	1.000	1.000
motorcyclist	(50, 80)  	0.000	1.000	1.000	1.000
motorcyclist	(0, 80)   	0.000	1.000	1.000	1.000
bicyclist   	(0, 30)   	0.000	1.000	1.000	1.000
bicyclist   	(30, 50)  	0.000	1.000	1.000	1.000
bicyclist   	(50, 80)  	0.000	1.000	1.000	1.000
bicyclist   	(0, 80)   	0.000	1.000	1.000	1.000
2023-03-03 12:03:59,142   INFO  ----------------Nuscene detection_by_range results-----------------
***car
range (0, 30) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.21, 0.16, 0.77 | 52.74, 58.73, 62.36, 64.12 | mean AP: 0.5948709356583722
range (30, 50) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.24, 0.18, 0.68 | 34.01, 38.73, 42.37, 44.21 | mean AP: 0.3982851847355362
range (50, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.32, 0.19, 0.78 | 15.58, 21.88, 25.53, 26.44 | mean AP: 0.22358313181548414
range (0, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.24, 0.17, 0.76 | 35.53, 41.38, 45.54, 46.74 | mean AP: 0.4229879252480859
***pedestrian
range (0, 30) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.08, 0.35, 0.85 | 58.63, 58.81, 59.07, 59.83 | mean AP: 0.5908282052451361
range (30, 50) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.10, 0.40, 1.26 | 47.62, 47.62, 47.86, 50.87 | mean AP: 0.484952527775351
range (50, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.14, 0.41, 1.65 | 22.78, 22.78, 22.78, 23.58 | mean AP: 0.22976714178307672
range (0, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.10, 0.38, 1.12 | 47.17, 47.22, 47.48, 49.29 | mean AP: 0.47790403352522504
--------------average performance-------------
trans_err:	 0.7229
scale_err:	 0.7576
orient_err:	 0.9807
mAP:	 0.1501
NDS:	 0.1649
--------------table log summary-------------
***car
match 1.0m:	(0, 30), (30, 50), (50, 80), (0, 80)
58.73, 38.73, 21.88, 41.38
***pedestrian
match 1.0m:	(0, 30), (30, 50), (50, 80), (0, 80)
58.81, 47.62, 22.78, 47.22

2023-03-03 12:03:59,143   INFO  Result is save to /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/eval/eval_with_train/epoch_10/val
2023-03-03 12:03:59,144   INFO  ****************Evaluation done.*****************
2023-03-03 12:03:59,154   INFO  Epoch 10 has been evaluated
Wait 30 seconds for next check (progress: 0.0 / 0 minutes): /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/default/ckpt 2023-03-03 12:04:29,187   INFO  **********************End evaluation ithaca365_models/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5(default)**********************
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:             eval/eval_with_train/tensorboard_val/NDS ▁▇█
wandb:     eval/eval_with_train/tensorboard_val/global_step ▁▅█
wandb:             eval/eval_with_train/tensorboard_val/mAP ▁▇█
wandb:      eval/eval_with_train/tensorboard_val/orient_err █▁▂
wandb: eval/eval_with_train/tensorboard_val/recall/rcnn_0.3 ▁██
wandb: eval/eval_with_train/tensorboard_val/recall/rcnn_0.5 ▁▅█
wandb: eval/eval_with_train/tensorboard_val/recall/rcnn_0.7 █▁▆
wandb:  eval/eval_with_train/tensorboard_val/recall/roi_0.3 ▁██
wandb:  eval/eval_with_train/tensorboard_val/recall/roi_0.5 ▁██
wandb:  eval/eval_with_train/tensorboard_val/recall/roi_0.7 ▁█▅
wandb:       eval/eval_with_train/tensorboard_val/scale_err ▁█▅
wandb:       eval/eval_with_train/tensorboard_val/trans_err █▁▂
wandb:                                          global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:                              meta_data/learning_rate ███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:                               train/higher_part_loss ▂▄▁▂▁▁▅▂▃▃▄▁▃▁▂▂▅▄▂▃▂▁▄▂█▁▄▂▆█▄▂▂▂▃▁▄▃▂▂
wandb:                                train/imbalanced_loss ▃▆█▁▁▃▂▁▂▂▃▁▂▁▂▁▃▂▁▂▂▂▇▁▄▂▅▆▅▅▁▃▁▂▆▃▆▄▂▁
wandb:                                           train/loss ▅█▅▆▅▅▅▆▅▇▄▅▆▄▃▄▃▆▆▇▅▅▂▆▆▄▃▅▃▁▁▅▅▃▃▃▄▅▂▄
wandb:                                train/lower_part_loss ▅▅▅▅▅█▄▆▆▆▄▃▂▄▅▂▃▅▄▆█▂▄▆▄▃▄▇▅▄▁▄▄▆▅▅▄▄▅▁
wandb:                                        train/p2_loss ▅▅▅▅▄█▄▆▆▆▄▂▂▄▅▂▃▅▄▆█▂▅▆▅▃▄▇▅▅▁▄▄▆▅▅▄▄▄▁
wandb:                                 train/point_loss_box ▄█▅▇▅▄▅▅▄▅▄▅▆▄▃▄▃▆▆▅▄▆▂▅▆▅▃▄▂▁▂▆▅▂▂▃▄▆▃▅
wandb:                                 train/point_loss_cls ▂▃▂▃▂▂▂▂▃▃▃▂▃▂▂▁▁▃▃▄▄▁▁▃█▂▁▃▂▁▁▂▂▂▃▁▂▂▂▅
wandb:                       train/point_loss_cls_margin_p2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                  train/point_pos_num ▃▄▇▂▁▂▁▁▂▁▂▂▁▂▂▂▃▁▁▁▂▆█▁▁▃▇▅▄▅▅▃▁▂▆▃▃▄▂▁
wandb:                               train/point_total_loss ▂▃▂▃▂▂▂▂▃▃▃▂▃▂▂▁▁▃▃▄▄▁▁▃█▂▁▃▂▁▁▂▂▂▃▁▂▂▂▅
wandb:                                      train/rcnn_loss ▄▆▃▃▃▄▅█▅▆▂▅▆▃▄▄▄▅▆▇▁▅▁▄▃▃▂▄▃▁▂▂▄▃▄▃▃▃▂▃
wandb:                                  train/rcnn_loss_cls ▄▅▂▄▄▃▅▆▄▅▂▃▃▃▄▄▄▅▃█▂▂▁▃▄▂▂▆▃▁▃▂▅▄▃▄▅▃▃▃
wandb:                               train/rcnn_loss_corner ▄▄▄▂▂▃▆█▆▄▂▅▆▂▆▃▄▄██▁▇▃▇▂▄▅▄▄▁▂▃▃▂▄▄▁▄▁▁
wandb:                                  train/rcnn_loss_reg ▄▆▄▃▂▄▃█▅▇▃▇▇▃▃▄▄▅█▄▂▇▁▄▂▄▂▂▃▂▁▃▂▃▄▂▁▂▁▃
wandb: 
wandb: Run summary:
wandb:             eval/eval_with_train/tensorboard_val/NDS 0.16486
wandb:     eval/eval_with_train/tensorboard_val/global_step 10
wandb:             eval/eval_with_train/tensorboard_val/mAP 0.15015
wandb:      eval/eval_with_train/tensorboard_val/orient_err 0.98074
wandb: eval/eval_with_train/tensorboard_val/recall/rcnn_0.3 0.55756
wandb: eval/eval_with_train/tensorboard_val/recall/rcnn_0.5 0.44492
wandb: eval/eval_with_train/tensorboard_val/recall/rcnn_0.7 0.22866
wandb:  eval/eval_with_train/tensorboard_val/recall/roi_0.3 0.55561
wandb:  eval/eval_with_train/tensorboard_val/recall/roi_0.5 0.42295
wandb:  eval/eval_with_train/tensorboard_val/recall/roi_0.7 0.19093
wandb:       eval/eval_with_train/tensorboard_val/scale_err 0.75763
wandb:       eval/eval_with_train/tensorboard_val/trans_err 0.72291
wandb:                                          global_step 5560
wandb:                              meta_data/learning_rate 0.0
wandb:                               train/higher_part_loss 0.02737
wandb:                                train/imbalanced_loss 0.19
wandb:                                           train/loss 1.63109
wandb:                                train/lower_part_loss 0.30463
wandb:                                        train/p2_loss 0.332
wandb:                                 train/point_loss_box 0.67111
wandb:                                 train/point_loss_cls 0.11217
wandb:                       train/point_loss_cls_margin_p2 0.0
wandb:                                  train/point_pos_num 7833.0
wandb:                               train/point_total_loss 0.11217
wandb:                                      train/rcnn_loss 0.51582
wandb:                                  train/rcnn_loss_cls 0.19832
wandb:                               train/rcnn_loss_corner 0.04741
wandb:                                  train/rcnn_loss_reg 0.2701
wandb: 
wandb: Synced ithaca365_models_pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5_default: https://wandb.ai/travis10/pointrcnn_hindsight_p2_selftraining_squashlevel_balancethresh_0.5/runs/2apw9v7a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)
wandb: Find logs at: ./wandb/run-20230303_093741-2apw9v7a/logs
INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.
INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish
/home/tz98/anaconda3/envs/continual-da/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:70: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.0011589527130126953 seconds
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 0, "group_rank": 0, "worker_id": "2634291", "role": "default", "hostname": "nikola-compute-16.cs.cornell.edu", "state": "SUCCEEDED", "total_run_time": 8832, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [0], \"role_rank\": [0], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 1, "group_rank": 0, "worker_id": "2634292", "role": "default", "hostname": "nikola-compute-16.cs.cornell.edu", "state": "SUCCEEDED", "total_run_time": 8832, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [1], \"role_rank\": [1], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 2, "group_rank": 0, "worker_id": "2634293", "role": "default", "hostname": "nikola-compute-16.cs.cornell.edu", "state": "SUCCEEDED", "total_run_time": 8832, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [2], \"role_rank\": [2], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 3, "group_rank": 0, "worker_id": "2634294", "role": "default", "hostname": "nikola-compute-16.cs.cornell.edu", "state": "SUCCEEDED", "total_run_time": 8832, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [3], \"role_rank\": [3], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "AGENT", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": null, "group_rank": 0, "worker_id": null, "role": "default", "hostname": "nikola-compute-16.cs.cornell.edu", "state": "SUCCEEDED", "total_run_time": 8832, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\"}", "agent_restarts": 0}}
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
