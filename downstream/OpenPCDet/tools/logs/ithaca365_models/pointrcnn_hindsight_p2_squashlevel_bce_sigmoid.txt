+ NGPUS=4
+ PY_ARGS='--cfg_file cfgs/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid.yaml --wandb_project pointrcnn_hindsight_p2_squashlevel_bce_sigmoid'
+ true
+ PORT=32559
++ nc -z 127.0.0.1 32559
++ echo 1
+ status=1
+ '[' 1 '!=' 0 ']'
+ break
+ echo 32559
32559
+ python -m torch.distributed.launch --nproc_per_node=4 --rdzv_endpoint=localhost:32559 train.py --launcher pytorch --cfg_file cfgs/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid.yaml --wandb_project pointrcnn_hindsight_p2_squashlevel_bce_sigmoid
/home/tz98/anaconda3/envs/continual-da/lib/python3.8/site-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : train.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 4
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : localhost:32559
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_ivinprbp/none_7qxpu58j
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/home/tz98/anaconda3/envs/continual-da/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=localhost
  master_port=32559
  group_rank=0
  group_world_size=1
  local_ranks=[0, 1, 2, 3]
  role_ranks=[0, 1, 2, 3]
  global_ranks=[0, 1, 2, 3]
  role_world_sizes=[4, 4, 4, 4]
  global_world_sizes=[4, 4, 4, 4]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_ivinprbp/none_7qxpu58j/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_ivinprbp/none_7qxpu58j/attempt_0/1/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_ivinprbp/none_7qxpu58j/attempt_0/2/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_ivinprbp/none_7qxpu58j/attempt_0/3/error.json
2023-03-02 23:25:02,011   INFO  **********************Start logging**********************
2023-03-02 23:25:02,012   INFO  CUDA_VISIBLE_DEVICES=0,1,2,3
2023-03-02 23:25:02,012   INFO  total_batch_size: 8
2023-03-02 23:25:02,013   INFO  cfg_file         cfgs/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid.yaml
2023-03-02 23:25:02,013   INFO  batch_size       2
2023-03-02 23:25:02,013   INFO  epochs           60
2023-03-02 23:25:02,013   INFO  workers          4
2023-03-02 23:25:02,013   INFO  extra_tag        default
2023-03-02 23:25:02,013   INFO  ckpt             None
2023-03-02 23:25:02,013   INFO  pretrained_model None
2023-03-02 23:25:02,013   INFO  launcher         pytorch
2023-03-02 23:25:02,013   INFO  tcp_port         18888
2023-03-02 23:25:02,013   INFO  sync_bn          False
2023-03-02 23:25:02,013   INFO  fix_random_seed  False
2023-03-02 23:25:02,013   INFO  ckpt_save_interval 10
2023-03-02 23:25:02,014   INFO  local_rank       0
2023-03-02 23:25:02,014   INFO  max_ckpt_save_num 30
2023-03-02 23:25:02,014   INFO  merge_all_iters_to_one_epoch False
2023-03-02 23:25:02,014   INFO  set_cfgs         None
2023-03-02 23:25:02,014   INFO  empty_cache_every -1
2023-03-02 23:25:02,014   INFO  max_waiting_mins 0
2023-03-02 23:25:02,014   INFO  start_epoch      0
2023-03-02 23:25:02,014   INFO  num_epochs_to_eval 0
2023-03-02 23:25:02,014   INFO  save_to_file     False
2023-03-02 23:25:02,014   INFO  wandb_project    pointrcnn_hindsight_p2_squashlevel_bce_sigmoid
2023-03-02 23:25:02,014   INFO  wandb_group      None
2023-03-02 23:25:02,014   INFO  hq_path          None
2023-03-02 23:25:02,014   INFO  cfg.ROOT_DIR: /home/tz98/projects/continual-DA/downstream/OpenPCDet
2023-03-02 23:25:02,014   INFO  cfg.LOCAL_RANK: 0
2023-03-02 23:25:02,014   INFO  cfg.CLASS_NAMES: ['car', 'pedestrian']
2023-03-02 23:25:02,014   INFO  
cfg.DATA_CONFIG = edict()
2023-03-02 23:25:02,014   INFO  cfg.DATA_CONFIG.DATASET: Ithaca365Dataset
2023-03-02 23:25:02,014   INFO  cfg.DATA_CONFIG.DATA_PATH: ../data/ithaca365
2023-03-02 23:25:02,014   INFO  cfg.DATA_CONFIG.VERSION: v1.1
2023-03-02 23:25:02,014   INFO  cfg.DATA_CONFIG.MAX_SWEEPS: 1
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.PRED_VELOCITY: False
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.SET_NAN_VELOCITY_TO_ZEROS: True
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.FILTER_MIN_POINTS_IN_GT: 1
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.FOV_POINTS_ONLY: True
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.CONSTANT_REFLEX: 100.0
2023-03-02 23:25:02,015   INFO  
cfg.DATA_CONFIG.DATA_SPLIT = edict()
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val
2023-03-02 23:25:02,015   INFO  
cfg.DATA_CONFIG.INFO_PATH = edict()
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['ithaca365_infos_1sweeps_train.pkl']
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['ithaca365_infos_1sweeps_val.pkl']
2023-03-02 23:25:02,015   INFO  
cfg.DATA_CONFIG.LOAD_HISTORY = edict()
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.LIMIT_NUM: 5
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.VOXEL_SIZE: -1
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.FORWARD_ONLY: True
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.CACHE_ROOT: /scratch/hindsight_travis_cache/
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.HISTORY_AUG: True
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.DATA_PATH: ../data/ithaca365/v1.1/best_pos_history
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [0, -40, -3, 90.4, 40, 1]
2023-03-02 23:25:02,015   INFO  cfg.DATA_CONFIG.BALANCED_RESAMPLING: False
2023-03-02 23:25:02,015   INFO  
cfg.DATA_CONFIG.DATA_AUGMENTOR = edict()
2023-03-02 23:25:02,016   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']
2023-03-02 23:25:02,016   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'DB_INFO_PATH': ['ithaca365_dbinfos_1sweeps_withvelo.pkl'], 'PREPARE': {'filter_by_min_points': ['car:5', 'truck:5', 'bus:5', 'pedestrian:5', 'bicyclist:5']}, 'SAMPLE_GROUPS': ['car:5', 'truck:5', 'bus:5', 'pedestrian:10', 'bicyclist:5'], 'NUM_POINT_FEATURES': 5, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': True}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.3925, 0.3925]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}, {'NAME': 'point_quantize', 'VOXEL_SIZE': 0.3}]
2023-03-02 23:25:02,016   INFO  
cfg.DATA_CONFIG.POINT_FEATURE_ENCODING = edict()
2023-03-02 23:25:02,016   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding
2023-03-02 23:25:02,016   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity']
2023-03-02 23:25:02,016   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity', 'timestamp']
2023-03-02 23:25:02,016   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'sample_points', 'NUM_POINTS': {'train': 16384, 'test': 16384}}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': False}}]
2023-03-02 23:25:02,016   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: cfgs/dataset_configs/ithaca365_dataset_hindsight.yaml
2023-03-02 23:25:02,016   INFO  cfg.DATA_CONFIG.GET_ITEM_LIST: ['points', 'p2_score', 'history_scans']
2023-03-02 23:25:02,016   INFO  cfg.DATA_CONFIG.LOAD_P2_SCORE: /home/kzl6/datasets/ithaca365/p2_score_fw70_5m_20hist
2023-03-02 23:25:02,016   INFO  
cfg.MODEL = edict()
2023-03-02 23:25:02,016   INFO  cfg.MODEL.NAME: PointRCNN
2023-03-02 23:25:02,016   INFO  
cfg.MODEL.HISTORY_QUERY = edict()
2023-03-02 23:25:02,016   INFO  cfg.MODEL.HISTORY_QUERY.NAME: SparseResUQueryNet
2023-03-02 23:25:02,016   INFO  cfg.MODEL.HISTORY_QUERY.history_backbone: Res16UNet14E
2023-03-02 23:25:02,016   INFO  
cfg.MODEL.HISTORY_QUERY.history_backbone_config = edict()
2023-03-02 23:25:02,016   INFO  cfg.MODEL.HISTORY_QUERY.history_backbone_config.bn_momentum: 0.05
2023-03-02 23:25:02,016   INFO  cfg.MODEL.HISTORY_QUERY.history_backbone_config.conv1_kernel_size: 3
2023-03-02 23:25:02,016   INFO  cfg.MODEL.HISTORY_QUERY.history_backbone_config.final_feature_size: 64
2023-03-02 23:25:02,016   INFO  cfg.MODEL.HISTORY_QUERY.simple_conv_kernel_size: 5
2023-03-02 23:25:02,016   INFO  cfg.MODEL.HISTORY_QUERY.extra_conv: False
2023-03-02 23:25:02,017   INFO  cfg.MODEL.HISTORY_QUERY.mode: update_point_features
2023-03-02 23:25:02,017   INFO  
cfg.MODEL.HISTORY_QUERY.P2_LOSS_CONFIG = edict()
2023-03-02 23:25:02,017   INFO  cfg.MODEL.HISTORY_QUERY.P2_LOSS_CONFIG.LOSS_FN: bce
2023-03-02 23:25:02,017   INFO  cfg.MODEL.HISTORY_QUERY.SIGMOID: True
2023-03-02 23:25:02,017   INFO  
cfg.MODEL.BACKBONE_3D = edict()
2023-03-02 23:25:02,017   INFO  cfg.MODEL.BACKBONE_3D.NAME: PointNet2MSG
2023-03-02 23:25:02,017   INFO  
cfg.MODEL.BACKBONE_3D.SA_CONFIG = edict()
2023-03-02 23:25:02,017   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.NPOINTS: [4096, 1024, 256, 64]
2023-03-02 23:25:02,017   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.RADIUS: [[0.1, 0.5], [0.5, 1.0], [1.0, 2.0], [2.0, 4.0]]
2023-03-02 23:25:02,017   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.NSAMPLE: [[16, 32], [16, 32], [16, 32], [16, 32]]
2023-03-02 23:25:02,017   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.MLPS: [[[16, 16, 32], [32, 32, 64]], [[64, 64, 128], [64, 96, 128]], [[128, 196, 256], [128, 196, 256]], [[256, 256, 512], [256, 384, 512]]]
2023-03-02 23:25:02,017   INFO  cfg.MODEL.BACKBONE_3D.FP_MLPS: [[128, 128], [256, 256], [512, 512], [512, 512]]
2023-03-02 23:25:02,017   INFO  
cfg.MODEL.POINT_HEAD = edict()
2023-03-02 23:25:02,018   INFO  cfg.MODEL.POINT_HEAD.NAME: PointHeadBox
2023-03-02 23:25:02,018   INFO  cfg.MODEL.POINT_HEAD.CLS_FC: [256, 256]
2023-03-02 23:25:02,018   INFO  cfg.MODEL.POINT_HEAD.REG_FC: [256, 256]
2023-03-02 23:25:02,018   INFO  cfg.MODEL.POINT_HEAD.CLASS_AGNOSTIC: False
2023-03-02 23:25:02,018   INFO  cfg.MODEL.POINT_HEAD.USE_POINT_FEATURES_BEFORE_FUSION: False
2023-03-02 23:25:02,018   INFO  
cfg.MODEL.POINT_HEAD.TARGET_CONFIG = edict()
2023-03-02 23:25:02,019   INFO  cfg.MODEL.POINT_HEAD.TARGET_CONFIG.GT_EXTRA_WIDTH: [0.2, 0.2, 0.2]
2023-03-02 23:25:02,020   INFO  cfg.MODEL.POINT_HEAD.TARGET_CONFIG.BOX_CODER: PointResidualCoder
2023-03-02 23:25:02,020   INFO  
cfg.MODEL.POINT_HEAD.TARGET_CONFIG.BOX_CODER_CONFIG = edict()
2023-03-02 23:25:02,020   INFO  cfg.MODEL.POINT_HEAD.TARGET_CONFIG.BOX_CODER_CONFIG.use_mean_size: True
2023-03-02 23:25:02,020   INFO  cfg.MODEL.POINT_HEAD.TARGET_CONFIG.BOX_CODER_CONFIG.mean_size: [[3.9, 1.6, 1.56], [0.8, 0.6, 1.73], [1.76, 0.6, 1.73]]
2023-03-02 23:25:02,020   INFO  
cfg.MODEL.POINT_HEAD.LOSS_CONFIG = edict()
2023-03-02 23:25:02,020   INFO  cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_REG: WeightedSmoothL1Loss
2023-03-02 23:25:02,020   INFO  
cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_WEIGHTS = edict()
2023-03-02 23:25:02,020   INFO  cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.point_cls_weight: 1.0
2023-03-02 23:25:02,021   INFO  cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.point_box_weight: 1.0
2023-03-02 23:25:02,021   INFO  cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
2023-03-02 23:25:02,021   INFO  
cfg.MODEL.ROI_HEAD = edict()
2023-03-02 23:25:02,021   INFO  cfg.MODEL.ROI_HEAD.NAME: PointRCNNHead
2023-03-02 23:25:02,021   INFO  cfg.MODEL.ROI_HEAD.CLASS_AGNOSTIC: True
2023-03-02 23:25:02,021   INFO  
cfg.MODEL.ROI_HEAD.ROI_POINT_POOL = edict()
2023-03-02 23:25:02,021   INFO  cfg.MODEL.ROI_HEAD.ROI_POINT_POOL.POOL_EXTRA_WIDTH: [0.0, 0.0, 0.0]
2023-03-02 23:25:02,021   INFO  cfg.MODEL.ROI_HEAD.ROI_POINT_POOL.NUM_SAMPLED_POINTS: 512
2023-03-02 23:25:02,021   INFO  cfg.MODEL.ROI_HEAD.ROI_POINT_POOL.DEPTH_NORMALIZER: 70.0
2023-03-02 23:25:02,021   INFO  cfg.MODEL.ROI_HEAD.XYZ_UP_LAYER: [128, 128]
2023-03-02 23:25:02,021   INFO  cfg.MODEL.ROI_HEAD.CLS_FC: [256, 256]
2023-03-02 23:25:02,021   INFO  cfg.MODEL.ROI_HEAD.REG_FC: [256, 256]
2023-03-02 23:25:02,021   INFO  cfg.MODEL.ROI_HEAD.DP_RATIO: 0.0
2023-03-02 23:25:02,021   INFO  cfg.MODEL.ROI_HEAD.USE_BN: False
2023-03-02 23:25:02,021   INFO  
cfg.MODEL.ROI_HEAD.SA_CONFIG = edict()
2023-03-02 23:25:02,021   INFO  cfg.MODEL.ROI_HEAD.SA_CONFIG.NPOINTS: [128, 32, -1]
2023-03-02 23:25:02,021   INFO  cfg.MODEL.ROI_HEAD.SA_CONFIG.RADIUS: [0.2, 0.4, 100]
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.SA_CONFIG.NSAMPLE: [16, 16, 16]
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.SA_CONFIG.MLPS: [[128, 128, 128], [128, 128, 256], [256, 256, 512]]
2023-03-02 23:25:02,022   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG = edict()
2023-03-02 23:25:02,022   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN = edict()
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_TYPE: nms_gpu
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.MULTI_CLASSES_NMS: False
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_PRE_MAXSIZE: 9000
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_POST_MAXSIZE: 512
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_THRESH: 0.8
2023-03-02 23:25:02,022   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST = edict()
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_TYPE: nms_gpu
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.MULTI_CLASSES_NMS: False
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_PRE_MAXSIZE: 9000
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_POST_MAXSIZE: 100
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_THRESH: 0.85
2023-03-02 23:25:02,022   INFO  
cfg.MODEL.ROI_HEAD.TARGET_CONFIG = edict()
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.BOX_CODER: ResidualCoder
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.ROI_PER_IMAGE: 128
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.FG_RATIO: 0.5
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.SAMPLE_ROI_BY_EACH_CLASS: True
2023-03-02 23:25:02,022   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_SCORE_TYPE: cls
2023-03-02 23:25:02,023   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_FG_THRESH: 0.6
2023-03-02 23:25:02,023   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_BG_THRESH: 0.45
2023-03-02 23:25:02,023   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_BG_THRESH_LO: 0.1
2023-03-02 23:25:02,023   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.HARD_BG_RATIO: 0.8
2023-03-02 23:25:02,023   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.REG_FG_THRESH: 0.55
2023-03-02 23:25:02,023   INFO  
cfg.MODEL.ROI_HEAD.LOSS_CONFIG = edict()
2023-03-02 23:25:02,023   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.CLS_LOSS: BinaryCrossEntropy
2023-03-02 23:25:02,023   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.REG_LOSS: smooth-l1
2023-03-02 23:25:02,023   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.CORNER_LOSS_REGULARIZATION: True
2023-03-02 23:25:02,023   INFO  
cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS = edict()
2023-03-02 23:25:02,023   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_cls_weight: 1.0
2023-03-02 23:25:02,023   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_reg_weight: 1.0
2023-03-02 23:25:02,023   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_corner_weight: 1.0
2023-03-02 23:25:02,023   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
2023-03-02 23:25:02,023   INFO  
cfg.MODEL.POST_PROCESSING = edict()
2023-03-02 23:25:02,023   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
2023-03-02 23:25:02,023   INFO  cfg.MODEL.POST_PROCESSING.SCORE_THRESH: 0.1
2023-03-02 23:25:02,023   INFO  cfg.MODEL.POST_PROCESSING.OUTPUT_RAW_SCORE: False
2023-03-02 23:25:02,023   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: ithaca365
2023-03-02 23:25:02,023   INFO  
cfg.MODEL.POST_PROCESSING.NMS_CONFIG = edict()
2023-03-02 23:25:02,023   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.MULTI_CLASSES_NMS: False
2023-03-02 23:25:02,023   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: nms_gpu
2023-03-02 23:25:02,024   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: 0.1
2023-03-02 23:25:02,024   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: 4096
2023-03-02 23:25:02,024   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: 500
2023-03-02 23:25:02,024   INFO  
cfg.OPTIMIZATION = edict()
2023-03-02 23:25:02,024   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 2
2023-03-02 23:25:02,024   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 60
2023-03-02 23:25:02,024   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle
2023-03-02 23:25:02,024   INFO  cfg.OPTIMIZATION.LR: 0.01
2023-03-02 23:25:02,024   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01
2023-03-02 23:25:02,024   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9
2023-03-02 23:25:02,024   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]
2023-03-02 23:25:02,024   INFO  cfg.OPTIMIZATION.PCT_START: 0.4
2023-03-02 23:25:02,024   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10
2023-03-02 23:25:02,024   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]
2023-03-02 23:25:02,024   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1
2023-03-02 23:25:02,024   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07
2023-03-02 23:25:02,024   INFO  cfg.OPTIMIZATION.LR_WARMUP: False
2023-03-02 23:25:02,024   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1
2023-03-02 23:25:02,024   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 10
2023-03-02 23:25:02,024   INFO  cfg.TAG: pointrcnn_hindsight_p2_squashlevel_bce_sigmoid
2023-03-02 23:25:02,024   INFO  cfg.EXP_GROUP_PATH: ithaca365_models
wandb: Currently logged in as: travis10. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/tz98/projects/continual-DA/downstream/OpenPCDet/tools/wandb/run-20230302_232504-15z6mfqg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ithaca365_models_pointrcnn_hindsight_p2_squashlevel_bce_sigmoid_default
wandb: ⭐️ View project at https://wandb.ai/travis10/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid
wandb: 🚀 View run at https://wandb.ai/travis10/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/runs/15z6mfqg
wandb: WARNING Found log directory outside of given root_logdir, dropping given root_logdir for event file in /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/tensorboard
2023-03-02 23:25:09,955   INFO  Database filter by min points car: 13604 => 9198
2023-03-02 23:25:09,956   INFO  Database filter by min points pedestrian: 2926 => 2501
2023-03-02 23:25:09,959   INFO  Loading Ithaca365 dataset
2023-03-02 23:25:10,038   INFO  Total samples for Ithaca365 dataset: 4445
2023-03-02 23:25:13,008   INFO  DistributedDataParallel(
  (module): PointRCNN(
    (history_query): SparseResUQueryNet(
      (history_backbone): Res16UNet14E(
        (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
        (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block1): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
          )
        )
        (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block2): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block3): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block4): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
          )
        )
        (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block5): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block6): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block7): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block8): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (relu): MinkowskiReLU()
        (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
      )
      (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
      (p2_backbone): Sequential(
        (0): Linear(in_features=68, out_features=32, bias=True)
        (1): ReLU()
        (2): Linear(in_features=32, out_features=1, bias=True)
        (3): Sigmoid()
      )
      (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (vfe): None
    (backbone_3d): PointNet2MSG(
      (SA_modules): ModuleList(
        (0): PointnetSAModuleMSG(
          (groupers): ModuleList(
            (0): QueryAndGroup()
            (1): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
            (1): Sequential(
              (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (1): PointnetSAModuleMSG(
          (groupers): ModuleList(
            (0): QueryAndGroup()
            (1): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
            (1): Sequential(
              (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (2): PointnetSAModuleMSG(
          (groupers): ModuleList(
            (0): QueryAndGroup()
            (1): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
            (1): Sequential(
              (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (3): PointnetSAModuleMSG(
          (groupers): ModuleList(
            (0): QueryAndGroup()
            (1): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
            (1): Sequential(
              (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
      )
      (FP_modules): ModuleList(
        (0): PointnetFPModule(
          (mlp): Sequential(
            (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
          )
        )
        (1): PointnetFPModule(
          (mlp): Sequential(
            (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
          )
        )
        (2): PointnetFPModule(
          (mlp): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
          )
        )
        (3): PointnetFPModule(
          (mlp): Sequential(
            (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
          )
        )
      )
    )
    (map_to_bev_module): None
    (pfe): None
    (backbone_2d): None
    (dense_head): None
    (point_head): PointHeadBox(
      (cls_loss_func): SigmoidFocalClassificationLoss()
      (reg_loss_func): WeightedSmoothL1Loss()
      (cls_layers): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=256, out_features=256, bias=False)
        (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU()
        (6): Linear(in_features=256, out_features=2, bias=True)
      )
      (box_layers): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=256, out_features=256, bias=False)
        (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU()
        (6): Linear(in_features=256, out_features=8, bias=True)
      )
    )
    (roi_head): PointRCNNHead(
      (proposal_target_layer): ProposalTargetLayer()
      (reg_loss_func): WeightedSmoothL1Loss()
      (SA_modules): ModuleList(
        (0): PointnetSAModule(
          (groupers): ModuleList(
            (0): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (1): PointnetSAModule(
          (groupers): ModuleList(
            (0): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (2): PointnetSAModule(
          (groupers): ModuleList(
            (0): GroupAll()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
      )
      (xyz_up_layer): Sequential(
        (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
        (1): ReLU()
        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        (3): ReLU()
      )
      (merge_down_layer): Sequential(
        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
        (1): ReLU()
      )
      (cls_layers): Sequential(
        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.0, inplace=False)
        (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
      )
      (reg_layers): Sequential(
        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.0, inplace=False)
        (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
      )
      (roipoint_pool3d_layer): RoIPointPool3d()
    )
  )
)
2023-03-02 23:25:13,019   INFO  **********************Start training ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid(default)**********************
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
wandb: Network error (ReadTimeout), entering retry loop.
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
2023-03-03 22:30:08,283   INFO  **********************End training ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid(default)**********************



2023-03-03 22:30:08,285   INFO  **********************Start evaluation ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid(default)**********************
2023-03-03 22:30:08,286   INFO  Loading Ithaca365 dataset
2023-03-03 22:30:08,395   INFO  Total samples for Ithaca365 dataset: 1644
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING Found log directory outside of given root_logdir, dropping given root_logdir for event file in /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/eval/eval_with_train/tensorboard_val
2023-03-03 22:30:08,419   INFO  ==> Loading parameters from checkpoint /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/ckpt/checkpoint_epoch_40.pth to CPU
2023-03-03 22:30:09,930   INFO  ==> Checkpoint trained from version: pcdet+0.3.0+0000000
2023-03-03 22:30:11,243   INFO  ==> Done (loaded 502/502)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
      (3): Sigmoid()
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
      (3): Sigmoid()
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
      (3): Sigmoid()
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
2023-03-03 22:30:11,338   INFO  *************** EPOCH 40 EVALUATION *****************
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
      (3): Sigmoid()
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
eval:   0%|                                                                                       | 0/206 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
eval:   0%|                                                                | 0/206 [00:10<?, ?it/s, recall_0.3=(3, 3) / 5]eval:   0%|▎                                                       | 1/206 [00:10<36:19, 10.63s/it, recall_0.3=(3, 3) / 5]eval:   0%|▎                                                    | 1/206 [00:11<36:19, 10.63s/it, recall_0.3=(12, 12) / 23]eval:   1%|▌                                                    | 2/206 [00:11<17:03,  5.02s/it, recall_0.3=(12, 12) / 23]eval:   1%|▌                                                    | 2/206 [00:12<17:03,  5.02s/it, recall_0.3=(16, 16) / 30]eval:   1%|▊                                                    | 3/206 [00:12<11:08,  3.29s/it, recall_0.3=(16, 16) / 30]eval:   1%|▊                                                    | 3/206 [00:14<11:08,  3.29s/it, recall_0.3=(20, 20) / 36]eval:   2%|█                                                    | 4/206 [00:14<08:23,  2.49s/it, recall_0.3=(20, 20) / 36]eval:   2%|█                                                    | 4/206 [00:16<08:23,  2.49s/it, recall_0.3=(25, 25) / 43]eval:   2%|█▎                                                   | 5/206 [00:16<08:28,  2.53s/it, recall_0.3=(25, 25) / 43]eval:   2%|█▎                                                   | 5/206 [00:18<08:28,  2.53s/it, recall_0.3=(28, 28) / 48]eval:   3%|█▌                                                   | 6/206 [00:18<07:03,  2.12s/it, recall_0.3=(28, 28) / 48]eval:   3%|█▌                                                   | 6/206 [00:19<07:03,  2.12s/it, recall_0.3=(31, 31) / 53]eval:   3%|█▊                                                   | 7/206 [00:19<06:04,  1.83s/it, recall_0.3=(31, 31) / 53]eval:   3%|█▊                                                   | 7/206 [00:20<06:04,  1.83s/it, recall_0.3=(31, 31) / 56]eval:   4%|██                                                   | 8/206 [00:20<05:09,  1.56s/it, recall_0.3=(31, 31) / 56]eval:   4%|██                                                   | 8/206 [00:21<05:09,  1.56s/it, recall_0.3=(31, 31) / 56]eval:   4%|██▎                                                  | 9/206 [00:21<04:16,  1.30s/it, recall_0.3=(31, 31) / 56]eval:   4%|██▎                                                  | 9/206 [00:22<04:16,  1.30s/it, recall_0.3=(31, 31) / 56]eval:   5%|██▌                                                 | 10/206 [00:22<03:53,  1.19s/it, recall_0.3=(31, 31) / 56]eval:   5%|██▌                                                 | 10/206 [00:23<03:53,  1.19s/it, recall_0.3=(32, 31) / 58]eval:   5%|██▊                                                 | 11/206 [00:23<03:50,  1.18s/it, recall_0.3=(32, 31) / 58]eval:   5%|██▊                                                 | 11/206 [00:24<03:50,  1.18s/it, recall_0.3=(32, 31) / 61]eval:   6%|███                                                 | 12/206 [00:24<03:44,  1.16s/it, recall_0.3=(32, 31) / 61]eval:   6%|███                                                 | 12/206 [00:25<03:44,  1.16s/it, recall_0.3=(35, 34) / 67]eval:   6%|███▎                                                | 13/206 [00:25<03:41,  1.15s/it, recall_0.3=(35, 34) / 67]eval:   6%|███▎                                                | 13/206 [00:26<03:41,  1.15s/it, recall_0.3=(38, 37) / 72]eval:   7%|███▌                                                | 14/206 [00:26<03:18,  1.04s/it, recall_0.3=(38, 37) / 72]eval:   7%|███▌                                                | 14/206 [00:27<03:18,  1.04s/it, recall_0.3=(40, 39) / 75]eval:   7%|███▊                                                | 15/206 [00:27<03:19,  1.05s/it, recall_0.3=(40, 39) / 75]eval:   7%|███▊                                                | 15/206 [00:28<03:19,  1.05s/it, recall_0.3=(42, 41) / 77]eval:   8%|████                                                | 16/206 [00:28<03:05,  1.02it/s, recall_0.3=(42, 41) / 77]eval:   8%|████                                                | 16/206 [00:33<03:05,  1.02it/s, recall_0.3=(42, 41) / 80]eval:   8%|████▎                                               | 17/206 [00:33<07:15,  2.30s/it, recall_0.3=(42, 41) / 80]eval:   8%|████▎                                               | 17/206 [00:34<07:15,  2.30s/it, recall_0.3=(43, 42) / 83]eval:   9%|████▌                                               | 18/206 [00:35<06:29,  2.07s/it, recall_0.3=(43, 42) / 83]eval:   9%|████▌                                               | 18/206 [00:36<06:29,  2.07s/it, recall_0.3=(44, 43) / 85]eval:   9%|████▊                                               | 19/206 [00:36<05:42,  1.83s/it, recall_0.3=(44, 43) / 85]eval:   9%|████▊                                               | 19/206 [00:37<05:42,  1.83s/it, recall_0.3=(45, 44) / 87]eval:  10%|█████                                               | 20/206 [00:37<05:01,  1.62s/it, recall_0.3=(45, 44) / 87]eval:  10%|█████                                               | 20/206 [00:41<05:01,  1.62s/it, recall_0.3=(49, 48) / 92]eval:  10%|█████▎                                              | 21/206 [00:41<07:03,  2.29s/it, recall_0.3=(49, 48) / 92]eval:  10%|█████▏                                             | 21/206 [00:42<07:03,  2.29s/it, recall_0.3=(54, 53) / 103]eval:  11%|█████▍                                             | 22/206 [00:42<05:55,  1.93s/it, recall_0.3=(54, 53) / 103]eval:  11%|█████▍                                             | 22/206 [00:43<05:55,  1.93s/it, recall_0.3=(64, 63) / 125]eval:  11%|█████▋                                             | 23/206 [00:43<05:05,  1.67s/it, recall_0.3=(64, 63) / 125]eval:  11%|█████▋                                             | 23/206 [00:44<05:05,  1.67s/it, recall_0.3=(70, 69) / 133]eval:  12%|█████▉                                             | 24/206 [00:44<04:32,  1.50s/it, recall_0.3=(70, 69) / 133]eval:  12%|█████▉                                             | 24/206 [00:48<04:32,  1.50s/it, recall_0.3=(78, 77) / 145]eval:  12%|██████▏                                            | 25/206 [00:48<07:05,  2.35s/it, recall_0.3=(78, 77) / 145]eval:  12%|██████▏                                            | 25/206 [00:50<07:05,  2.35s/it, recall_0.3=(80, 79) / 153]eval:  13%|██████▍                                            | 26/206 [00:50<06:03,  2.02s/it, recall_0.3=(80, 79) / 153]eval:  13%|██████▍                                            | 26/206 [00:51<06:03,  2.02s/it, recall_0.3=(83, 82) / 156]eval:  13%|██████▋                                            | 27/206 [00:51<05:12,  1.74s/it, recall_0.3=(83, 82) / 156]eval:  13%|██████▋                                            | 27/206 [00:52<05:12,  1.74s/it, recall_0.3=(88, 87) / 163]eval:  14%|██████▉                                            | 28/206 [00:52<04:41,  1.58s/it, recall_0.3=(88, 87) / 163]eval:  14%|██████▉                                            | 28/206 [00:56<04:41,  1.58s/it, recall_0.3=(95, 94) / 171]eval:  14%|███████▏                                           | 29/206 [00:56<06:29,  2.20s/it, recall_0.3=(95, 94) / 171]eval:  14%|███████▏                                           | 29/206 [00:57<06:29,  2.20s/it, recall_0.3=(98, 97) / 174]eval:  15%|███████▍                                           | 30/206 [00:57<05:25,  1.85s/it, recall_0.3=(98, 97) / 174]eval:  15%|███████▎                                          | 30/206 [00:57<05:25,  1.85s/it, recall_0.3=(100, 99) / 177]eval:  15%|███████▌                                          | 31/206 [00:57<04:33,  1.56s/it, recall_0.3=(100, 99) / 177]eval:  15%|███████▌                                          | 31/206 [00:58<04:33,  1.56s/it, recall_0.3=(100, 99) / 179]eval:  16%|███████▊                                          | 32/206 [00:58<03:56,  1.36s/it, recall_0.3=(100, 99) / 179]eval:  16%|███████▌                                         | 32/206 [00:59<03:56,  1.36s/it, recall_0.3=(103, 102) / 182]eval:  16%|███████▊                                         | 33/206 [00:59<03:37,  1.26s/it, recall_0.3=(103, 102) / 182]eval:  16%|███████▊                                         | 33/206 [01:00<03:37,  1.26s/it, recall_0.3=(104, 103) / 184]eval:  17%|████████                                         | 34/206 [01:00<03:24,  1.19s/it, recall_0.3=(104, 103) / 184]eval:  17%|████████                                         | 34/206 [01:02<03:24,  1.19s/it, recall_0.3=(104, 103) / 184]eval:  17%|████████▎                                        | 35/206 [01:02<03:31,  1.24s/it, recall_0.3=(104, 103) / 184]eval:  17%|████████▎                                        | 35/206 [01:03<03:31,  1.24s/it, recall_0.3=(105, 104) / 189]eval:  17%|████████▌                                        | 36/206 [01:03<03:27,  1.22s/it, recall_0.3=(105, 104) / 189]eval:  17%|████████▌                                        | 36/206 [01:08<03:27,  1.22s/it, recall_0.3=(105, 104) / 189]eval:  18%|████████▊                                        | 37/206 [01:08<06:48,  2.41s/it, recall_0.3=(105, 104) / 189]eval:  18%|████████▊                                        | 37/206 [01:09<06:48,  2.41s/it, recall_0.3=(105, 104) / 189]eval:  18%|█████████                                        | 38/206 [01:09<05:50,  2.09s/it, recall_0.3=(105, 104) / 189]eval:  18%|█████████                                        | 38/206 [01:11<05:50,  2.09s/it, recall_0.3=(105, 104) / 189]eval:  19%|█████████▎                                       | 39/206 [01:11<05:02,  1.81s/it, recall_0.3=(105, 104) / 189]eval:  19%|█████████▎                                       | 39/206 [01:12<05:02,  1.81s/it, recall_0.3=(105, 104) / 189]eval:  19%|█████████▌                                       | 40/206 [01:12<04:39,  1.68s/it, recall_0.3=(105, 104) / 189]eval:  19%|█████████▌                                       | 40/206 [01:14<04:39,  1.68s/it, recall_0.3=(106, 105) / 193]eval:  20%|█████████▊                                       | 41/206 [01:14<04:37,  1.68s/it, recall_0.3=(106, 105) / 193]eval:  20%|█████████▊                                       | 41/206 [01:15<04:37,  1.68s/it, recall_0.3=(108, 107) / 197]eval:  20%|█████████▉                                       | 42/206 [01:15<04:12,  1.54s/it, recall_0.3=(108, 107) / 197]eval:  20%|█████████▉                                       | 42/206 [01:16<04:12,  1.54s/it, recall_0.3=(115, 114) / 220]eval:  21%|██████████▏                                      | 43/206 [01:16<03:45,  1.38s/it, recall_0.3=(115, 114) / 220]eval:  21%|██████████▏                                      | 43/206 [01:17<03:45,  1.38s/it, recall_0.3=(126, 125) / 236]eval:  21%|██████████▍                                      | 44/206 [01:17<03:22,  1.25s/it, recall_0.3=(126, 125) / 236]eval:  21%|██████████▍                                      | 44/206 [01:19<03:22,  1.25s/it, recall_0.3=(138, 137) / 255]eval:  22%|██████████▋                                      | 45/206 [01:19<04:17,  1.60s/it, recall_0.3=(138, 137) / 255]eval:  22%|██████████▋                                      | 45/206 [01:20<04:17,  1.60s/it, recall_0.3=(143, 142) / 263]eval:  22%|██████████▉                                      | 46/206 [01:20<03:57,  1.48s/it, recall_0.3=(143, 142) / 263]eval:  22%|██████████▉                                      | 46/206 [01:22<03:57,  1.48s/it, recall_0.3=(148, 147) / 274]eval:  23%|███████████▏                                     | 47/206 [01:22<03:36,  1.36s/it, recall_0.3=(148, 147) / 274]eval:  23%|███████████▏                                     | 47/206 [01:23<03:36,  1.36s/it, recall_0.3=(153, 152) / 284]eval:  23%|███████████▍                                     | 48/206 [01:23<03:34,  1.36s/it, recall_0.3=(153, 152) / 284]eval:  23%|███████████▍                                     | 48/206 [01:24<03:34,  1.36s/it, recall_0.3=(158, 157) / 290]eval:  24%|███████████▋                                     | 49/206 [01:24<03:28,  1.33s/it, recall_0.3=(158, 157) / 290]eval:  24%|███████████▋                                     | 49/206 [01:28<03:28,  1.33s/it, recall_0.3=(159, 158) / 292]eval:  24%|███████████▉                                     | 50/206 [01:28<05:14,  2.01s/it, recall_0.3=(159, 158) / 292]eval:  24%|███████████▉                                     | 50/206 [01:29<05:14,  2.01s/it, recall_0.3=(161, 160) / 296]eval:  25%|████████████▏                                    | 51/206 [01:29<04:36,  1.79s/it, recall_0.3=(161, 160) / 296]eval:  25%|████████████▏                                    | 51/206 [01:30<04:36,  1.79s/it, recall_0.3=(163, 162) / 300]eval:  25%|████████████▎                                    | 52/206 [01:30<03:51,  1.50s/it, recall_0.3=(163, 162) / 300]eval:  25%|████████████▎                                    | 52/206 [01:31<03:51,  1.50s/it, recall_0.3=(168, 167) / 308]eval:  26%|████████████▌                                    | 53/206 [01:31<03:27,  1.35s/it, recall_0.3=(168, 167) / 308]eval:  26%|████████████▌                                    | 53/206 [01:33<03:27,  1.35s/it, recall_0.3=(171, 170) / 314]eval:  26%|████████████▊                                    | 54/206 [01:33<04:11,  1.66s/it, recall_0.3=(171, 170) / 314]eval:  26%|████████████▊                                    | 54/206 [01:34<04:11,  1.66s/it, recall_0.3=(172, 171) / 317]eval:  27%|█████████████                                    | 55/206 [01:34<03:24,  1.35s/it, recall_0.3=(172, 171) / 317]eval:  27%|█████████████                                    | 55/206 [01:35<03:24,  1.35s/it, recall_0.3=(181, 181) / 331]eval:  27%|█████████████▎                                   | 56/206 [01:35<03:05,  1.23s/it, recall_0.3=(181, 181) / 331]eval:  27%|█████████████▎                                   | 56/206 [01:36<03:05,  1.23s/it, recall_0.3=(182, 182) / 335]eval:  28%|█████████████▌                                   | 57/206 [01:36<02:55,  1.18s/it, recall_0.3=(182, 182) / 335]eval:  28%|█████████████▌                                   | 57/206 [01:41<02:55,  1.18s/it, recall_0.3=(182, 182) / 337]eval:  28%|█████████████▊                                   | 58/206 [01:41<06:05,  2.47s/it, recall_0.3=(182, 182) / 337]eval:  28%|█████████████▊                                   | 58/206 [01:42<06:05,  2.47s/it, recall_0.3=(185, 185) / 349]eval:  29%|██████████████                                   | 59/206 [01:42<04:57,  2.03s/it, recall_0.3=(185, 185) / 349]eval:  29%|██████████████                                   | 59/206 [01:43<04:57,  2.03s/it, recall_0.3=(196, 196) / 362]eval:  29%|██████████████▎                                  | 60/206 [01:43<04:07,  1.69s/it, recall_0.3=(196, 196) / 362]eval:  29%|██████████████▎                                  | 60/206 [01:44<04:07,  1.69s/it, recall_0.3=(205, 205) / 374]eval:  30%|██████████████▌                                  | 61/206 [01:44<03:35,  1.48s/it, recall_0.3=(205, 205) / 374]eval:  30%|██████████████▌                                  | 61/206 [01:48<03:35,  1.48s/it, recall_0.3=(214, 214) / 391]eval:  30%|██████████████▋                                  | 62/206 [01:48<05:06,  2.13s/it, recall_0.3=(214, 214) / 391]eval:  30%|██████████████▋                                  | 62/206 [01:49<05:06,  2.13s/it, recall_0.3=(221, 221) / 408]eval:  31%|██████████████▉                                  | 63/206 [01:49<04:06,  1.72s/it, recall_0.3=(221, 221) / 408]eval:  31%|██████████████▉                                  | 63/206 [01:50<04:06,  1.72s/it, recall_0.3=(229, 229) / 422]eval:  31%|███████████████▏                                 | 64/206 [01:50<03:34,  1.51s/it, recall_0.3=(229, 229) / 422]eval:  31%|███████████████▏                                 | 64/206 [01:51<03:34,  1.51s/it, recall_0.3=(241, 241) / 438]eval:  32%|███████████████▍                                 | 65/206 [01:51<03:13,  1.37s/it, recall_0.3=(241, 241) / 438]eval:  32%|███████████████▍                                 | 65/206 [01:54<03:13,  1.37s/it, recall_0.3=(249, 249) / 450]eval:  32%|███████████████▋                                 | 66/206 [01:54<04:26,  1.90s/it, recall_0.3=(249, 249) / 450]eval:  32%|███████████████▋                                 | 66/206 [01:55<04:26,  1.90s/it, recall_0.3=(256, 256) / 464]eval:  33%|███████████████▉                                 | 67/206 [01:55<03:49,  1.65s/it, recall_0.3=(256, 256) / 464]eval:  33%|███████████████▉                                 | 67/206 [01:56<03:49,  1.65s/it, recall_0.3=(259, 259) / 468]eval:  33%|████████████████▏                                | 68/206 [01:56<03:21,  1.46s/it, recall_0.3=(259, 259) / 468]eval:  33%|████████████████▏                                | 68/206 [01:57<03:21,  1.46s/it, recall_0.3=(260, 260) / 471]eval:  33%|████████████████▍                                | 69/206 [01:57<03:12,  1.41s/it, recall_0.3=(260, 260) / 471]eval:  33%|████████████████▍                                | 69/206 [02:00<03:12,  1.41s/it, recall_0.3=(261, 261) / 473]eval:  34%|████████████████▋                                | 70/206 [02:00<03:57,  1.75s/it, recall_0.3=(261, 261) / 473]eval:  34%|████████████████▋                                | 70/206 [02:01<03:57,  1.75s/it, recall_0.3=(263, 263) / 476]eval:  34%|████████████████▉                                | 71/206 [02:01<03:26,  1.53s/it, recall_0.3=(263, 263) / 476]eval:  34%|████████████████▉                                | 71/206 [02:02<03:26,  1.53s/it, recall_0.3=(264, 264) / 479]eval:  35%|█████████████████▏                               | 72/206 [02:02<02:59,  1.34s/it, recall_0.3=(264, 264) / 479]eval:  35%|█████████████████▏                               | 72/206 [02:03<02:59,  1.34s/it, recall_0.3=(264, 264) / 479]eval:  35%|█████████████████▎                               | 73/206 [02:03<02:50,  1.28s/it, recall_0.3=(264, 264) / 479]eval:  35%|█████████████████▎                               | 73/206 [02:05<02:50,  1.28s/it, recall_0.3=(264, 264) / 481]eval:  36%|█████████████████▌                               | 74/206 [02:05<03:12,  1.46s/it, recall_0.3=(264, 264) / 481]eval:  36%|█████████████████▌                               | 74/206 [02:06<03:12,  1.46s/it, recall_0.3=(265, 265) / 484]eval:  36%|█████████████████▊                               | 75/206 [02:06<02:48,  1.29s/it, recall_0.3=(265, 265) / 484]eval:  36%|█████████████████▊                               | 75/206 [02:07<02:48,  1.29s/it, recall_0.3=(267, 267) / 488]eval:  37%|██████████████████                               | 76/206 [02:07<02:36,  1.20s/it, recall_0.3=(267, 267) / 488]eval:  37%|██████████████████                               | 76/206 [02:08<02:36,  1.20s/it, recall_0.3=(268, 268) / 492]eval:  37%|██████████████████▎                              | 77/206 [02:08<02:34,  1.20s/it, recall_0.3=(268, 268) / 492]eval:  37%|██████████████████▎                              | 77/206 [02:14<02:34,  1.20s/it, recall_0.3=(269, 269) / 494]eval:  38%|██████████████████▌                              | 78/206 [02:14<05:29,  2.57s/it, recall_0.3=(269, 269) / 494]eval:  38%|██████████████████▌                              | 78/206 [02:15<05:29,  2.57s/it, recall_0.3=(276, 276) / 504]eval:  38%|██████████████████▊                              | 79/206 [02:15<04:37,  2.19s/it, recall_0.3=(276, 276) / 504]eval:  38%|██████████████████▊                              | 79/206 [02:16<04:37,  2.19s/it, recall_0.3=(279, 279) / 510]eval:  39%|███████████████████                              | 80/206 [02:16<04:04,  1.94s/it, recall_0.3=(279, 279) / 510]eval:  39%|███████████████████                              | 80/206 [02:18<04:04,  1.94s/it, recall_0.3=(283, 283) / 516]eval:  39%|███████████████████▎                             | 81/206 [02:18<03:36,  1.73s/it, recall_0.3=(283, 283) / 516]eval:  39%|███████████████████▎                             | 81/206 [02:19<03:36,  1.73s/it, recall_0.3=(288, 288) / 523]eval:  40%|███████████████████▌                             | 82/206 [02:19<03:20,  1.62s/it, recall_0.3=(288, 288) / 523]eval:  40%|███████████████████▌                             | 82/206 [02:20<03:20,  1.62s/it, recall_0.3=(294, 294) / 529]eval:  40%|███████████████████▋                             | 83/206 [02:20<03:06,  1.52s/it, recall_0.3=(294, 294) / 529]eval:  40%|███████████████████▋                             | 83/206 [02:21<03:06,  1.52s/it, recall_0.3=(309, 309) / 553]eval:  41%|███████████████████▉                             | 84/206 [02:21<02:48,  1.38s/it, recall_0.3=(309, 309) / 553]eval:  41%|███████████████████▉                             | 84/206 [02:22<02:48,  1.38s/it, recall_0.3=(322, 322) / 572]eval:  41%|████████████████████▏                            | 85/206 [02:22<02:42,  1.34s/it, recall_0.3=(322, 322) / 572]eval:  41%|████████████████████▏                            | 85/206 [02:24<02:42,  1.34s/it, recall_0.3=(335, 335) / 589]eval:  42%|████████████████████▍                            | 86/206 [02:24<02:35,  1.30s/it, recall_0.3=(335, 335) / 589]eval:  42%|████████████████████▍                            | 86/206 [02:24<02:35,  1.30s/it, recall_0.3=(343, 343) / 601]eval:  42%|████████████████████▋                            | 87/206 [02:24<02:17,  1.15s/it, recall_0.3=(343, 343) / 601]eval:  42%|████████████████████▋                            | 87/206 [02:30<02:17,  1.15s/it, recall_0.3=(351, 351) / 616]eval:  43%|████████████████████▉                            | 88/206 [02:30<04:51,  2.47s/it, recall_0.3=(351, 351) / 616]eval:  43%|████████████████████▉                            | 88/206 [02:31<04:51,  2.47s/it, recall_0.3=(357, 357) / 625]eval:  43%|█████████████████████▏                           | 89/206 [02:31<03:58,  2.04s/it, recall_0.3=(357, 357) / 625]eval:  43%|█████████████████████▏                           | 89/206 [02:32<03:58,  2.04s/it, recall_0.3=(360, 360) / 632]eval:  44%|█████████████████████▍                           | 90/206 [02:32<03:31,  1.82s/it, recall_0.3=(360, 360) / 632]eval:  44%|█████████████████████▍                           | 90/206 [02:33<03:31,  1.82s/it, recall_0.3=(363, 363) / 636]eval:  44%|█████████████████████▋                           | 91/206 [02:33<02:56,  1.54s/it, recall_0.3=(363, 363) / 636]eval:  44%|█████████████████████▋                           | 91/206 [02:36<02:56,  1.54s/it, recall_0.3=(364, 364) / 638]eval:  45%|█████████████████████▉                           | 92/206 [02:36<03:46,  1.99s/it, recall_0.3=(364, 364) / 638]eval:  45%|█████████████████████▉                           | 92/206 [02:37<03:46,  1.99s/it, recall_0.3=(366, 367) / 641]eval:  45%|██████████████████████                           | 93/206 [02:37<03:10,  1.69s/it, recall_0.3=(366, 367) / 641]eval:  45%|██████████████████████                           | 93/206 [02:38<03:10,  1.69s/it, recall_0.3=(369, 370) / 644]eval:  46%|██████████████████████▎                          | 94/206 [02:38<02:43,  1.46s/it, recall_0.3=(369, 370) / 644]eval:  46%|██████████████████████▎                          | 94/206 [02:39<02:43,  1.46s/it, recall_0.3=(372, 373) / 647]eval:  46%|██████████████████████▌                          | 95/206 [02:39<02:31,  1.36s/it, recall_0.3=(372, 373) / 647]eval:  46%|██████████████████████▌                          | 95/206 [02:41<02:31,  1.36s/it, recall_0.3=(379, 380) / 655]eval:  47%|██████████████████████▊                          | 96/206 [02:41<02:35,  1.41s/it, recall_0.3=(379, 380) / 655]eval:  47%|██████████████████████▊                          | 96/206 [02:42<02:35,  1.41s/it, recall_0.3=(383, 384) / 659]eval:  47%|███████████████████████                          | 97/206 [02:42<02:27,  1.36s/it, recall_0.3=(383, 384) / 659]eval:  47%|███████████████████████                          | 97/206 [02:43<02:27,  1.36s/it, recall_0.3=(384, 385) / 661]eval:  48%|███████████████████████▎                         | 98/206 [02:43<02:25,  1.35s/it, recall_0.3=(384, 385) / 661]eval:  48%|███████████████████████▎                         | 98/206 [02:44<02:25,  1.35s/it, recall_0.3=(389, 390) / 667]eval:  48%|███████████████████████▌                         | 99/206 [02:44<02:12,  1.23s/it, recall_0.3=(389, 390) / 667]eval:  48%|███████████████████████▌                         | 99/206 [02:48<02:12,  1.23s/it, recall_0.3=(391, 392) / 670]eval:  49%|███████████████████████▎                        | 100/206 [02:48<03:18,  1.88s/it, recall_0.3=(391, 392) / 670]eval:  49%|███████████████████████▎                        | 100/206 [02:49<03:18,  1.88s/it, recall_0.3=(393, 394) / 673]eval:  49%|███████████████████████▌                        | 101/206 [02:49<02:48,  1.60s/it, recall_0.3=(393, 394) / 673]eval:  49%|███████████████████████▌                        | 101/206 [02:50<02:48,  1.60s/it, recall_0.3=(396, 397) / 681]eval:  50%|███████████████████████▊                        | 102/206 [02:50<02:26,  1.40s/it, recall_0.3=(396, 397) / 681]eval:  50%|███████████████████████▊                        | 102/206 [02:50<02:26,  1.40s/it, recall_0.3=(410, 411) / 700]eval:  50%|████████████████████████                        | 103/206 [02:50<02:04,  1.21s/it, recall_0.3=(410, 411) / 700]eval:  50%|████████████████████████                        | 103/206 [02:55<02:04,  1.21s/it, recall_0.3=(423, 424) / 717]eval:  50%|████████████████████████▏                       | 104/206 [02:55<03:51,  2.27s/it, recall_0.3=(423, 424) / 717]eval:  50%|████████████████████████▏                       | 104/206 [02:56<03:51,  2.27s/it, recall_0.3=(438, 439) / 743]eval:  51%|████████████████████████▍                       | 105/206 [02:56<03:04,  1.82s/it, recall_0.3=(438, 439) / 743]eval:  51%|████████████████████████▍                       | 105/206 [02:57<03:04,  1.82s/it, recall_0.3=(441, 442) / 752]eval:  51%|████████████████████████▋                       | 106/206 [02:57<02:34,  1.55s/it, recall_0.3=(441, 442) / 752]eval:  51%|████████████████████████▋                       | 106/206 [02:58<02:34,  1.55s/it, recall_0.3=(449, 450) / 763]eval:  52%|████████████████████████▉                       | 107/206 [02:58<02:20,  1.42s/it, recall_0.3=(449, 450) / 763]eval:  52%|████████████████████████▉                       | 107/206 [03:03<02:20,  1.42s/it, recall_0.3=(455, 456) / 772]eval:  52%|█████████████████████████▏                      | 108/206 [03:03<03:54,  2.40s/it, recall_0.3=(455, 456) / 772]eval:  52%|█████████████████████████▏                      | 108/206 [03:04<03:54,  2.40s/it, recall_0.3=(462, 463) / 781]eval:  53%|█████████████████████████▍                      | 109/206 [03:04<03:16,  2.02s/it, recall_0.3=(462, 463) / 781]eval:  53%|█████████████████████████▍                      | 109/206 [03:05<03:16,  2.02s/it, recall_0.3=(464, 465) / 784]eval:  53%|█████████████████████████▋                      | 110/206 [03:05<02:41,  1.68s/it, recall_0.3=(464, 465) / 784]eval:  53%|█████████████████████████▋                      | 110/206 [03:05<02:41,  1.68s/it, recall_0.3=(468, 469) / 790]eval:  54%|█████████████████████████▊                      | 111/206 [03:05<02:13,  1.41s/it, recall_0.3=(468, 469) / 790]eval:  54%|█████████████████████████▊                      | 111/206 [03:08<02:13,  1.41s/it, recall_0.3=(468, 469) / 795]eval:  54%|██████████████████████████                      | 112/206 [03:08<02:50,  1.82s/it, recall_0.3=(468, 469) / 795]eval:  54%|██████████████████████████                      | 112/206 [03:10<02:50,  1.82s/it, recall_0.3=(469, 470) / 800]eval:  55%|██████████████████████████▎                     | 113/206 [03:10<02:35,  1.68s/it, recall_0.3=(469, 470) / 800]eval:  55%|██████████████████████████▎                     | 113/206 [03:10<02:35,  1.68s/it, recall_0.3=(470, 471) / 805]eval:  55%|██████████████████████████▌                     | 114/206 [03:10<02:09,  1.41s/it, recall_0.3=(470, 471) / 805]eval:  55%|██████████████████████████▌                     | 114/206 [03:11<02:09,  1.41s/it, recall_0.3=(473, 474) / 812]eval:  56%|██████████████████████████▊                     | 115/206 [03:11<01:49,  1.21s/it, recall_0.3=(473, 474) / 812]eval:  56%|██████████████████████████▊                     | 115/206 [03:13<01:49,  1.21s/it, recall_0.3=(475, 476) / 816]eval:  56%|███████████████████████████                     | 116/206 [03:13<02:17,  1.53s/it, recall_0.3=(475, 476) / 816]eval:  56%|███████████████████████████                     | 116/206 [03:15<02:17,  1.53s/it, recall_0.3=(479, 480) / 821]eval:  57%|███████████████████████████▎                    | 117/206 [03:15<02:09,  1.46s/it, recall_0.3=(479, 480) / 821]eval:  57%|███████████████████████████▎                    | 117/206 [03:16<02:09,  1.46s/it, recall_0.3=(480, 481) / 824]eval:  57%|███████████████████████████▍                    | 118/206 [03:16<02:02,  1.40s/it, recall_0.3=(480, 481) / 824]eval:  57%|███████████████████████████▍                    | 118/206 [03:17<02:02,  1.40s/it, recall_0.3=(483, 484) / 828]eval:  58%|███████████████████████████▋                    | 119/206 [03:17<01:58,  1.37s/it, recall_0.3=(483, 484) / 828]eval:  58%|███████████████████████████▋                    | 119/206 [03:18<01:58,  1.37s/it, recall_0.3=(493, 494) / 840]eval:  58%|███████████████████████████▉                    | 120/206 [03:18<01:50,  1.29s/it, recall_0.3=(493, 494) / 840]eval:  58%|███████████████████████████▉                    | 120/206 [03:19<01:50,  1.29s/it, recall_0.3=(504, 505) / 852]eval:  59%|████████████████████████████▏                   | 121/206 [03:19<01:45,  1.24s/it, recall_0.3=(504, 505) / 852]eval:  59%|████████████████████████████▏                   | 121/206 [03:20<01:45,  1.24s/it, recall_0.3=(513, 514) / 867]eval:  59%|████████████████████████████▍                   | 122/206 [03:20<01:38,  1.17s/it, recall_0.3=(513, 514) / 867]eval:  59%|████████████████████████████▍                   | 122/206 [03:21<01:38,  1.17s/it, recall_0.3=(528, 530) / 900]eval:  60%|████████████████████████████▋                   | 123/206 [03:21<01:32,  1.11s/it, recall_0.3=(528, 530) / 900]eval:  60%|████████████████████████████▋                   | 123/206 [03:23<01:32,  1.11s/it, recall_0.3=(539, 541) / 923]eval:  60%|████████████████████████████▉                   | 124/206 [03:23<01:36,  1.18s/it, recall_0.3=(539, 541) / 923]eval:  60%|████████████████████████████▉                   | 124/206 [03:24<01:36,  1.18s/it, recall_0.3=(548, 549) / 943]eval:  61%|█████████████████████████████▏                  | 125/206 [03:24<01:32,  1.14s/it, recall_0.3=(548, 549) / 943]eval:  61%|█████████████████████████████▏                  | 125/206 [03:25<01:32,  1.14s/it, recall_0.3=(552, 553) / 947]eval:  61%|█████████████████████████████▎                  | 126/206 [03:25<01:34,  1.18s/it, recall_0.3=(552, 553) / 947]eval:  61%|█████████████████████████████▎                  | 126/206 [03:26<01:34,  1.18s/it, recall_0.3=(557, 558) / 954]eval:  62%|█████████████████████████████▌                  | 127/206 [03:26<01:37,  1.23s/it, recall_0.3=(557, 558) / 954]eval:  62%|█████████████████████████████▌                  | 127/206 [03:28<01:37,  1.23s/it, recall_0.3=(562, 563) / 962]eval:  62%|█████████████████████████████▊                  | 128/206 [03:28<01:51,  1.43s/it, recall_0.3=(562, 563) / 962]eval:  62%|█████████████████████████████▊                  | 128/206 [03:30<01:51,  1.43s/it, recall_0.3=(567, 568) / 970]eval:  63%|██████████████████████████████                  | 129/206 [03:30<01:46,  1.38s/it, recall_0.3=(567, 568) / 970]eval:  63%|██████████████████████████████                  | 129/206 [03:31<01:46,  1.38s/it, recall_0.3=(569, 570) / 976]eval:  63%|██████████████████████████████▎                 | 130/206 [03:31<01:41,  1.34s/it, recall_0.3=(569, 570) / 976]eval:  63%|██████████████████████████████▎                 | 130/206 [03:32<01:41,  1.34s/it, recall_0.3=(570, 571) / 978]eval:  64%|██████████████████████████████▌                 | 131/206 [03:32<01:35,  1.27s/it, recall_0.3=(570, 571) / 978]eval:  64%|██████████████████████████████▌                 | 131/206 [03:33<01:35,  1.27s/it, recall_0.3=(570, 572) / 980]eval:  64%|██████████████████████████████▊                 | 132/206 [03:33<01:38,  1.34s/it, recall_0.3=(570, 572) / 980]eval:  64%|██████████████████████████████▊                 | 132/206 [03:34<01:38,  1.34s/it, recall_0.3=(571, 573) / 984]eval:  65%|██████████████████████████████▉                 | 133/206 [03:34<01:28,  1.22s/it, recall_0.3=(571, 573) / 984]eval:  65%|██████████████████████████████▉                 | 133/206 [03:35<01:28,  1.22s/it, recall_0.3=(571, 573) / 987]eval:  65%|███████████████████████████████▏                | 134/206 [03:35<01:24,  1.17s/it, recall_0.3=(571, 573) / 987]eval:  65%|███████████████████████████████▏                | 134/206 [03:36<01:24,  1.17s/it, recall_0.3=(575, 577) / 997]eval:  66%|███████████████████████████████▍                | 135/206 [03:36<01:14,  1.06s/it, recall_0.3=(575, 577) / 997]eval:  66%|███████████████████████████████▍                | 135/206 [03:39<01:14,  1.06s/it, recall_0.3=(575, 577) / 999]eval:  66%|███████████████████████████████▋                | 136/206 [03:39<01:48,  1.55s/it, recall_0.3=(575, 577) / 999]eval:  66%|███████████████████████████████                | 136/206 [03:40<01:48,  1.55s/it, recall_0.3=(577, 579) / 1004]eval:  67%|███████████████████████████████▎               | 137/206 [03:40<01:38,  1.43s/it, recall_0.3=(577, 579) / 1004]eval:  67%|███████████████████████████████▎               | 137/206 [03:41<01:38,  1.43s/it, recall_0.3=(578, 580) / 1009]eval:  67%|███████████████████████████████▍               | 138/206 [03:41<01:29,  1.32s/it, recall_0.3=(578, 580) / 1009]eval:  67%|███████████████████████████████▍               | 138/206 [03:42<01:29,  1.32s/it, recall_0.3=(581, 583) / 1015]eval:  67%|███████████████████████████████▋               | 139/206 [03:42<01:24,  1.26s/it, recall_0.3=(581, 583) / 1015]eval:  67%|███████████████████████████████▋               | 139/206 [03:44<01:24,  1.26s/it, recall_0.3=(587, 589) / 1026]eval:  68%|███████████████████████████████▉               | 140/206 [03:44<01:38,  1.50s/it, recall_0.3=(587, 589) / 1026]eval:  68%|███████████████████████████████▉               | 140/206 [03:46<01:38,  1.50s/it, recall_0.3=(595, 597) / 1040]eval:  68%|████████████████████████████████▏              | 141/206 [03:46<01:40,  1.54s/it, recall_0.3=(595, 597) / 1040]eval:  68%|████████████████████████████████▏              | 141/206 [03:47<01:40,  1.54s/it, recall_0.3=(604, 605) / 1053]eval:  69%|████████████████████████████████▍              | 142/206 [03:47<01:32,  1.45s/it, recall_0.3=(604, 605) / 1053]eval:  69%|████████████████████████████████▍              | 142/206 [03:48<01:32,  1.45s/it, recall_0.3=(618, 619) / 1076]eval:  69%|████████████████████████████████▋              | 143/206 [03:48<01:24,  1.34s/it, recall_0.3=(618, 619) / 1076]eval:  69%|████████████████████████████████▋              | 143/206 [03:50<01:24,  1.34s/it, recall_0.3=(629, 629) / 1093]eval:  70%|████████████████████████████████▊              | 144/206 [03:50<01:32,  1.49s/it, recall_0.3=(629, 629) / 1093]eval:  70%|████████████████████████████████▊              | 144/206 [03:53<01:32,  1.49s/it, recall_0.3=(637, 637) / 1104]eval:  70%|█████████████████████████████████              | 145/206 [03:53<01:53,  1.86s/it, recall_0.3=(637, 637) / 1104]eval:  70%|█████████████████████████████████              | 145/206 [03:54<01:53,  1.86s/it, recall_0.3=(642, 642) / 1121]eval:  71%|█████████████████████████████████▎             | 146/206 [03:54<01:36,  1.61s/it, recall_0.3=(642, 642) / 1121]eval:  71%|█████████████████████████████████▎             | 146/206 [03:55<01:36,  1.61s/it, recall_0.3=(643, 643) / 1123]eval:  71%|█████████████████████████████████▌             | 147/206 [03:55<01:26,  1.47s/it, recall_0.3=(643, 643) / 1123]eval:  71%|█████████████████████████████████▌             | 147/206 [03:56<01:26,  1.47s/it, recall_0.3=(647, 647) / 1131]eval:  72%|█████████████████████████████████▊             | 148/206 [03:56<01:14,  1.28s/it, recall_0.3=(647, 647) / 1131]eval:  72%|█████████████████████████████████▊             | 148/206 [04:02<01:14,  1.28s/it, recall_0.3=(649, 649) / 1134]eval:  72%|█████████████████████████████████▉             | 149/206 [04:02<02:33,  2.69s/it, recall_0.3=(649, 649) / 1134]eval:  72%|█████████████████████████████████▉             | 149/206 [04:03<02:33,  2.69s/it, recall_0.3=(652, 652) / 1137]eval:  73%|██████████████████████████████████▏            | 150/206 [04:03<02:01,  2.18s/it, recall_0.3=(652, 652) / 1137]eval:  73%|██████████████████████████████████▏            | 150/206 [04:04<02:01,  2.18s/it, recall_0.3=(655, 655) / 1142]eval:  73%|██████████████████████████████████▍            | 151/206 [04:04<01:39,  1.82s/it, recall_0.3=(655, 655) / 1142]eval:  73%|██████████████████████████████████▍            | 151/206 [04:05<01:39,  1.82s/it, recall_0.3=(656, 656) / 1145]eval:  74%|██████████████████████████████████▋            | 152/206 [04:05<01:25,  1.58s/it, recall_0.3=(656, 656) / 1145]eval:  74%|██████████████████████████████████▋            | 152/206 [04:06<01:25,  1.58s/it, recall_0.3=(659, 659) / 1150]eval:  74%|██████████████████████████████████▉            | 153/206 [04:06<01:13,  1.38s/it, recall_0.3=(659, 659) / 1150]eval:  74%|██████████████████████████████████▉            | 153/206 [04:07<01:13,  1.38s/it, recall_0.3=(661, 661) / 1154]eval:  75%|███████████████████████████████████▏           | 154/206 [04:07<01:04,  1.24s/it, recall_0.3=(661, 661) / 1154]eval:  75%|███████████████████████████████████▏           | 154/206 [04:08<01:04,  1.24s/it, recall_0.3=(663, 662) / 1157]eval:  75%|███████████████████████████████████▎           | 155/206 [04:08<00:59,  1.16s/it, recall_0.3=(663, 662) / 1157]eval:  75%|███████████████████████████████████▎           | 155/206 [04:08<00:59,  1.16s/it, recall_0.3=(666, 664) / 1162]eval:  76%|███████████████████████████████████▌           | 156/206 [04:08<00:54,  1.08s/it, recall_0.3=(666, 664) / 1162]eval:  76%|███████████████████████████████████▌           | 156/206 [04:12<00:54,  1.08s/it, recall_0.3=(669, 667) / 1166]eval:  76%|███████████████████████████████████▊           | 157/206 [04:12<01:32,  1.89s/it, recall_0.3=(669, 667) / 1166]eval:  76%|███████████████████████████████████▊           | 157/206 [04:13<01:32,  1.89s/it, recall_0.3=(670, 668) / 1168]eval:  77%|████████████████████████████████████           | 158/206 [04:13<01:18,  1.64s/it, recall_0.3=(670, 668) / 1168]eval:  77%|████████████████████████████████████           | 158/206 [04:14<01:18,  1.64s/it, recall_0.3=(670, 668) / 1168]eval:  77%|████████████████████████████████████▎          | 159/206 [04:14<01:10,  1.50s/it, recall_0.3=(670, 668) / 1168]eval:  77%|████████████████████████████████████▎          | 159/206 [04:16<01:10,  1.50s/it, recall_0.3=(672, 671) / 1172]eval:  78%|████████████████████████████████████▌          | 160/206 [04:16<01:05,  1.43s/it, recall_0.3=(672, 671) / 1172]eval:  78%|████████████████████████████████████▌          | 160/206 [04:17<01:05,  1.43s/it, recall_0.3=(675, 674) / 1177]eval:  78%|████████████████████████████████████▋          | 161/206 [04:17<01:04,  1.43s/it, recall_0.3=(675, 674) / 1177]eval:  78%|████████████████████████████████████▋          | 161/206 [04:18<01:04,  1.43s/it, recall_0.3=(684, 683) / 1189]eval:  79%|████████████████████████████████████▉          | 162/206 [04:18<00:55,  1.27s/it, recall_0.3=(684, 683) / 1189]eval:  79%|████████████████████████████████████▉          | 162/206 [04:19<00:55,  1.27s/it, recall_0.3=(695, 694) / 1206]eval:  79%|█████████████████████████████████████▏         | 163/206 [04:19<00:48,  1.13s/it, recall_0.3=(695, 694) / 1206]eval:  79%|█████████████████████████████████████▏         | 163/206 [04:20<00:48,  1.13s/it, recall_0.3=(705, 704) / 1222]eval:  80%|█████████████████████████████████████▍         | 164/206 [04:20<00:46,  1.10s/it, recall_0.3=(705, 704) / 1222]eval:  80%|█████████████████████████████████████▍         | 164/206 [04:24<00:46,  1.10s/it, recall_0.3=(712, 711) / 1233]eval:  80%|█████████████████████████████████████▋         | 165/206 [04:24<01:22,  2.01s/it, recall_0.3=(712, 711) / 1233]eval:  80%|█████████████████████████████████████▋         | 165/206 [04:25<01:22,  2.01s/it, recall_0.3=(720, 719) / 1253]eval:  81%|█████████████████████████████████████▊         | 166/206 [04:25<01:09,  1.74s/it, recall_0.3=(720, 719) / 1253]eval:  81%|█████████████████████████████████████▊         | 166/206 [04:26<01:09,  1.74s/it, recall_0.3=(727, 726) / 1268]eval:  81%|██████████████████████████████████████         | 167/206 [04:26<01:00,  1.56s/it, recall_0.3=(727, 726) / 1268]eval:  81%|██████████████████████████████████████         | 167/206 [04:27<01:00,  1.56s/it, recall_0.3=(731, 730) / 1280]eval:  82%|██████████████████████████████████████▎        | 168/206 [04:27<00:53,  1.42s/it, recall_0.3=(731, 730) / 1280]eval:  82%|██████████████████████████████████████▎        | 168/206 [04:33<00:53,  1.42s/it, recall_0.3=(732, 731) / 1290]eval:  82%|██████████████████████████████████████▌        | 169/206 [04:33<01:40,  2.70s/it, recall_0.3=(732, 731) / 1290]eval:  82%|██████████████████████████████████████▌        | 169/206 [04:34<01:40,  2.70s/it, recall_0.3=(734, 733) / 1298]eval:  83%|██████████████████████████████████████▊        | 170/206 [04:34<01:18,  2.18s/it, recall_0.3=(734, 733) / 1298]eval:  83%|██████████████████████████████████████▊        | 170/206 [04:35<01:18,  2.18s/it, recall_0.3=(741, 740) / 1310]eval:  83%|███████████████████████████████████████        | 171/206 [04:35<01:05,  1.87s/it, recall_0.3=(741, 740) / 1310]eval:  83%|███████████████████████████████████████        | 171/206 [04:36<01:05,  1.87s/it, recall_0.3=(743, 742) / 1315]eval:  83%|███████████████████████████████████████▏       | 172/206 [04:36<00:56,  1.66s/it, recall_0.3=(743, 742) / 1315]eval:  83%|███████████████████████████████████████▏       | 172/206 [04:37<00:56,  1.66s/it, recall_0.3=(744, 743) / 1319]eval:  84%|███████████████████████████████████████▍       | 173/206 [04:37<00:46,  1.42s/it, recall_0.3=(744, 743) / 1319]eval:  84%|███████████████████████████████████████▍       | 173/206 [04:38<00:46,  1.42s/it, recall_0.3=(747, 746) / 1323]eval:  84%|███████████████████████████████████████▋       | 174/206 [04:38<00:40,  1.26s/it, recall_0.3=(747, 746) / 1323]eval:  84%|███████████████████████████████████████▋       | 174/206 [04:39<00:40,  1.26s/it, recall_0.3=(749, 748) / 1328]eval:  85%|███████████████████████████████████████▉       | 175/206 [04:39<00:36,  1.16s/it, recall_0.3=(749, 748) / 1328]eval:  85%|███████████████████████████████████████▉       | 175/206 [04:40<00:36,  1.16s/it, recall_0.3=(750, 749) / 1333]eval:  85%|████████████████████████████████████████▏      | 176/206 [04:40<00:33,  1.11s/it, recall_0.3=(750, 749) / 1333]eval:  85%|████████████████████████████████████████▏      | 176/206 [04:41<00:33,  1.11s/it, recall_0.3=(752, 751) / 1335]eval:  86%|████████████████████████████████████████▍      | 177/206 [04:41<00:31,  1.09s/it, recall_0.3=(752, 751) / 1335]eval:  86%|████████████████████████████████████████▍      | 177/206 [04:42<00:31,  1.09s/it, recall_0.3=(753, 752) / 1339]eval:  86%|████████████████████████████████████████▌      | 178/206 [04:42<00:30,  1.09s/it, recall_0.3=(753, 752) / 1339]eval:  86%|████████████████████████████████████████▌      | 178/206 [04:43<00:30,  1.09s/it, recall_0.3=(753, 752) / 1341]eval:  87%|████████████████████████████████████████▊      | 179/206 [04:43<00:30,  1.13s/it, recall_0.3=(753, 752) / 1341]eval:  87%|████████████████████████████████████████▊      | 179/206 [04:44<00:30,  1.13s/it, recall_0.3=(756, 755) / 1346]eval:  87%|█████████████████████████████████████████      | 180/206 [04:44<00:27,  1.07s/it, recall_0.3=(756, 755) / 1346]eval:  87%|█████████████████████████████████████████      | 180/206 [04:47<00:27,  1.07s/it, recall_0.3=(756, 755) / 1346]eval:  88%|█████████████████████████████████████████▎     | 181/206 [04:47<00:39,  1.59s/it, recall_0.3=(756, 755) / 1346]eval:  88%|█████████████████████████████████████████▎     | 181/206 [04:49<00:39,  1.59s/it, recall_0.3=(759, 758) / 1354]eval:  88%|█████████████████████████████████████████▌     | 182/206 [04:49<00:39,  1.66s/it, recall_0.3=(759, 758) / 1354]eval:  88%|█████████████████████████████████████████▌     | 182/206 [04:50<00:39,  1.66s/it, recall_0.3=(761, 760) / 1361]eval:  89%|█████████████████████████████████████████▊     | 183/206 [04:50<00:34,  1.49s/it, recall_0.3=(761, 760) / 1361]eval:  89%|█████████████████████████████████████████▊     | 183/206 [04:51<00:34,  1.49s/it, recall_0.3=(765, 764) / 1386]eval:  89%|█████████████████████████████████████████▉     | 184/206 [04:51<00:30,  1.39s/it, recall_0.3=(765, 764) / 1386]eval:  89%|█████████████████████████████████████████▉     | 184/206 [04:53<00:30,  1.39s/it, recall_0.3=(772, 771) / 1401]eval:  90%|██████████████████████████████████████████▏    | 185/206 [04:53<00:32,  1.55s/it, recall_0.3=(772, 771) / 1401]eval:  90%|██████████████████████████████████████████▏    | 185/206 [04:56<00:32,  1.55s/it, recall_0.3=(782, 781) / 1415]eval:  90%|██████████████████████████████████████████▍    | 186/206 [04:56<00:37,  1.85s/it, recall_0.3=(782, 781) / 1415]eval:  90%|██████████████████████████████████████████▍    | 186/206 [04:57<00:37,  1.85s/it, recall_0.3=(787, 786) / 1427]eval:  91%|██████████████████████████████████████████▋    | 187/206 [04:57<00:32,  1.70s/it, recall_0.3=(787, 786) / 1427]eval:  91%|██████████████████████████████████████████▋    | 187/206 [04:58<00:32,  1.70s/it, recall_0.3=(788, 787) / 1436]eval:  91%|██████████████████████████████████████████▉    | 188/206 [04:58<00:27,  1.54s/it, recall_0.3=(788, 787) / 1436]eval:  91%|██████████████████████████████████████████▉    | 188/206 [04:59<00:27,  1.54s/it, recall_0.3=(791, 790) / 1440]eval:  92%|███████████████████████████████████████████    | 189/206 [04:59<00:23,  1.38s/it, recall_0.3=(791, 790) / 1440]eval:  92%|███████████████████████████████████████████    | 189/206 [05:03<00:23,  1.38s/it, recall_0.3=(794, 793) / 1446]eval:  92%|███████████████████████████████████████████▎   | 190/206 [05:03<00:35,  2.22s/it, recall_0.3=(794, 793) / 1446]eval:  92%|███████████████████████████████████████████▎   | 190/206 [05:04<00:35,  2.22s/it, recall_0.3=(796, 795) / 1450]eval:  93%|███████████████████████████████████████████▌   | 191/206 [05:04<00:28,  1.89s/it, recall_0.3=(796, 795) / 1450]eval:  93%|███████████████████████████████████████████▌   | 191/206 [05:05<00:28,  1.89s/it, recall_0.3=(797, 796) / 1452]eval:  93%|███████████████████████████████████████████▊   | 192/206 [05:05<00:22,  1.61s/it, recall_0.3=(797, 796) / 1452]eval:  93%|███████████████████████████████████████████▊   | 192/206 [05:06<00:22,  1.61s/it, recall_0.3=(798, 797) / 1455]eval:  94%|████████████████████████████████████████████   | 193/206 [05:06<00:18,  1.39s/it, recall_0.3=(798, 797) / 1455]eval:  94%|████████████████████████████████████████████   | 193/206 [05:07<00:18,  1.39s/it, recall_0.3=(798, 797) / 1455]eval:  94%|████████████████████████████████████████████▎  | 194/206 [05:07<00:14,  1.21s/it, recall_0.3=(798, 797) / 1455]eval:  94%|████████████████████████████████████████████▎  | 194/206 [05:08<00:14,  1.21s/it, recall_0.3=(798, 797) / 1455]eval:  95%|████████████████████████████████████████████▍  | 195/206 [05:08<00:12,  1.10s/it, recall_0.3=(798, 797) / 1455]eval:  95%|████████████████████████████████████████████▍  | 195/206 [05:09<00:12,  1.10s/it, recall_0.3=(798, 797) / 1455]eval:  95%|████████████████████████████████████████████▋  | 196/206 [05:09<00:09,  1.01it/s, recall_0.3=(798, 797) / 1455]eval:  95%|████████████████████████████████████████████▋  | 196/206 [05:10<00:09,  1.01it/s, recall_0.3=(798, 797) / 1455]eval:  96%|████████████████████████████████████████████▉  | 197/206 [05:10<00:08,  1.05it/s, recall_0.3=(798, 797) / 1455]eval:  96%|████████████████████████████████████████████▉  | 197/206 [05:10<00:08,  1.05it/s, recall_0.3=(800, 799) / 1458]eval:  96%|█████████████████████████████████████████████▏ | 198/206 [05:10<00:07,  1.09it/s, recall_0.3=(800, 799) / 1458]eval:  96%|█████████████████████████████████████████████▏ | 198/206 [05:11<00:07,  1.09it/s, recall_0.3=(804, 803) / 1463]eval:  97%|█████████████████████████████████████████████▍ | 199/206 [05:11<00:06,  1.13it/s, recall_0.3=(804, 803) / 1463]eval:  97%|█████████████████████████████████████████████▍ | 199/206 [05:12<00:06,  1.13it/s, recall_0.3=(804, 803) / 1465]eval:  97%|█████████████████████████████████████████████▋ | 200/206 [05:12<00:05,  1.14it/s, recall_0.3=(804, 803) / 1465]eval:  97%|█████████████████████████████████████████████▋ | 200/206 [05:13<00:05,  1.14it/s, recall_0.3=(804, 803) / 1465]eval:  98%|█████████████████████████████████████████████▊ | 201/206 [05:13<00:04,  1.16it/s, recall_0.3=(804, 803) / 1465]eval:  98%|█████████████████████████████████████████████▊ | 201/206 [05:14<00:04,  1.16it/s, recall_0.3=(805, 804) / 1468]eval:  98%|██████████████████████████████████████████████ | 202/206 [05:14<00:03,  1.26it/s, recall_0.3=(805, 804) / 1468]eval:  98%|██████████████████████████████████████████████ | 202/206 [05:14<00:03,  1.26it/s, recall_0.3=(808, 807) / 1471]eval:  99%|██████████████████████████████████████████████▎| 203/206 [05:14<00:02,  1.40it/s, recall_0.3=(808, 807) / 1471]eval:  99%|██████████████████████████████████████████████▎| 203/206 [05:14<00:02,  1.40it/s, recall_0.3=(810, 809) / 1474]eval:  99%|██████████████████████████████████████████████▌| 204/206 [05:14<00:01,  1.60it/s, recall_0.3=(810, 809) / 1474]eval:  99%|██████████████████████████████████████████████▌| 204/206 [05:15<00:01,  1.60it/s, recall_0.3=(811, 810) / 1477]eval: 100%|██████████████████████████████████████████████▊| 205/206 [05:15<00:00,  1.83it/s, recall_0.3=(811, 810) / 1477]eval: 100%|██████████████████████████████████████████████▊| 205/206 [05:15<00:00,  1.83it/s, recall_0.3=(811, 810) / 1478]eval: 100%|███████████████████████████████████████████████| 206/206 [05:15<00:00,  2.17it/s, recall_0.3=(811, 810) / 1478]eval: 100%|███████████████████████████████████████████████| 206/206 [05:15<00:00,  1.53s/it, recall_0.3=(811, 810) / 1478]
2023-03-03 22:35:27,449   INFO  *************** Performance of EPOCH 40 *****************
2023-03-03 22:35:27,450   INFO  Generate label finished(sec_per_example: 0.1922 second).
2023-03-03 22:35:27,450   INFO  recall_roi_0.3: 0.554552
2023-03-03 22:35:27,450   INFO  recall_rcnn_0.3: 0.555437
2023-03-03 22:35:27,451   INFO  recall_roi_0.5: 0.451824
2023-03-03 22:35:27,451   INFO  recall_rcnn_0.5: 0.471130
2023-03-03 22:35:27,451   INFO  recall_roi_0.7: 0.212009
2023-03-03 22:35:27,451   INFO  recall_rcnn_0.7: 0.258590
2023-03-03 22:35:27,452   INFO  Average predicted number of objects(1644 samples): 4.895
======
Loading Ithaca365 tables for version v1.1...
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
      (3): Sigmoid()
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
      (3): Sigmoid()
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
      (3): Sigmoid()
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
6 category,
1 attribute,
4 visibility,
25839 instance,
3 sensor,
3 calibrated_sensor,
760811 ego_pose,
40 log,
40 scene,
6576 sample,
2282433 sample_data,
25839 sample_annotation,
1 map,
2579 location,
Done loading in 46.841 seconds.
======
Reverse indexing ...
Done reverse indexing in 6.6 seconds.
======
2023-03-03 22:36:23,202   INFO  The predictions of NuScenes have been saved to /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/eval/eval_with_train/epoch_40/val/final_result/data/results_nusc.json
Initializing nuScenes detection evaluation
Loaded results from /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/eval/eval_with_train/epoch_40/val/final_result/data/results_nusc.json. Found detections for 1644 samples.
Loading annotations for val split from nuScenes version: v1.1
  0%|                                                                                            | 0/1644 [00:00<?, ?it/s] 33%|██████████████████████████▏                                                     | 538/1644 [00:00<00:00, 5378.45it/s] 66%|███████████████████████████████████████████████████▊                           | 1077/1644 [00:00<00:00, 5385.07it/s]100%|███████████████████████████████████████████████████████████████████████████████| 1644/1644 [00:00<00:00, 5531.40it/s]
Loaded ground truth annotations for 1644 samples.
Filtering predictions
Detection range: (0, 30)
=> Original number of boxes: 8048
=> After distance based filtering: 2473
=> After LIDAR and RADAR points based filtering: 2473
Detection range: (30, 50)
=> Original number of boxes: 8048
=> After distance based filtering: 2610
=> After LIDAR and RADAR points based filtering: 2610
Detection range: (50, 80)
=> Original number of boxes: 8048
=> After distance based filtering: 2500
=> After LIDAR and RADAR points based filtering: 2500
Detection range: (0, 80)
=> Original number of boxes: 8048
=> After distance based filtering: 7583
=> After LIDAR and RADAR points based filtering: 7583
Filtering ground truth annotations
Detection range: (0, 30)
=> Original number of boxes: 6018
=> After distance based filtering: 1648
=> After LIDAR and RADAR points based filtering: 1648
Detection range: (30, 50)
=> Original number of boxes: 6018
=> After distance based filtering: 1660
=> After LIDAR and RADAR points based filtering: 1660
Detection range: (50, 80)
=> Original number of boxes: 6018
=> After distance based filtering: 1493
=> After LIDAR and RADAR points based filtering: 1493
Detection range: (0, 80)
=> Original number of boxes: 6018
=> After distance based filtering: 4801
=> After LIDAR and RADAR points based filtering: 4801
Accumulating metric data...
Calculating metrics...
Saving metrics to: /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/eval/eval_with_train/epoch_40/val/final_result/data
mAP: 0.1418
mATE: 0.7247
mASE: 0.7283
mAOE: 0.8964
NDS: 0.1793
Eval time: 2.9s

Per-class results:
Object Class	Det. Range	AP	ATE	ASE	AOE
car         	(0, 30)   	0.666	0.205	0.104	0.244
car         	(30, 50)  	0.460	0.261	0.086	0.377
car         	(50, 80)  	0.275	0.317	0.070	0.692
car         	(0, 80)   	0.478	0.245	0.095	0.369
truck       	(0, 30)   	0.000	1.000	1.000	1.000
truck       	(30, 50)  	0.000	1.000	1.000	1.000
truck       	(50, 80)  	0.000	1.000	1.000	1.000
truck       	(0, 80)   	0.000	1.000	1.000	1.000
bus         	(0, 30)   	0.000	1.000	1.000	1.000
bus         	(30, 50)  	0.000	1.000	1.000	1.000
bus         	(50, 80)  	0.000	1.000	1.000	1.000
bus         	(0, 80)   	0.000	1.000	1.000	1.000
pedestrian  	(0, 30)   	0.527	0.092	0.264	0.822
pedestrian  	(30, 50)  	0.343	0.108	0.283	1.145
pedestrian  	(50, 80)  	0.137	0.138	0.306	1.509
pedestrian  	(0, 80)   	0.373	0.103	0.275	1.009
motorcyclist	(0, 30)   	0.000	1.000	1.000	1.000
motorcyclist	(30, 50)  	0.000	1.000	1.000	1.000
motorcyclist	(50, 80)  	0.000	1.000	1.000	1.000
motorcyclist	(0, 80)   	0.000	1.000	1.000	1.000
bicyclist   	(0, 30)   	0.000	1.000	1.000	1.000
bicyclist   	(30, 50)  	0.000	1.000	1.000	1.000
bicyclist   	(50, 80)  	0.000	1.000	1.000	1.000
bicyclist   	(0, 80)   	0.000	1.000	1.000	1.000
2023-03-03 22:36:32,212   INFO  ----------------Nuscene detection_by_range results-----------------
***car
range (0, 30) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.20, 0.10, 0.24 | 61.04, 66.16, 69.38, 69.76 | mean AP: 0.6658306982049109
range (30, 50) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.26, 0.09, 0.38 | 38.87, 45.63, 48.91, 50.49 | mean AP: 0.4597713460869226
range (50, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.32, 0.07, 0.69 | 20.18, 27.58, 30.02, 32.03 | mean AP: 0.2745263561535924
range (0, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.24, 0.10, 0.37 | 41.08, 47.46, 50.60, 52.13 | mean AP: 0.4781765450687071
***pedestrian
range (0, 30) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.09, 0.26, 0.82 | 52.58, 52.58, 52.69, 52.84 | mean AP: 0.5267542816067468
range (30, 50) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.11, 0.28, 1.14 | 33.69, 33.69, 33.70, 36.07 | mean AP: 0.3428866540116702
range (50, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.14, 0.31, 1.51 | 13.64, 13.64, 13.64, 13.96 | mean AP: 0.13719892763777228
range (0, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.10, 0.27, 1.01 | 36.89, 36.89, 36.94, 38.35 | mean AP: 0.37267424617348394
--------------average performance-------------
trans_err:	 0.7247
scale_err:	 0.7283
orient_err:	 0.8964
mAP:	 0.1418
NDS:	 0.1793
--------------table log summary-------------
***car
match 1.0m:	(0, 30), (30, 50), (50, 80), (0, 80)
66.16, 45.63, 27.58, 47.46
***pedestrian
match 1.0m:	(0, 30), (30, 50), (50, 80), (0, 80)
52.58, 33.69, 13.64, 36.89

2023-03-03 22:36:32,213   INFO  Result is save to /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/eval/eval_with_train/epoch_40/val
2023-03-03 22:36:32,213   INFO  ****************Evaluation done.*****************
2023-03-03 22:36:32,225   INFO  Epoch 40 has been evaluated
2023-03-03 22:36:32,228   INFO  ==> Loading parameters from checkpoint /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/ckpt/checkpoint_epoch_50.pth to CPU
2023-03-03 22:36:32,330   INFO  ==> Checkpoint trained from version: pcdet+0.3.0+0000000
2023-03-03 22:36:33,507   INFO  ==> Done (loaded 502/502)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
      (3): Sigmoid()
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
2023-03-03 22:36:33,521   INFO  *************** EPOCH 50 EVALUATION *****************
eval:   0%|                                                                                       | 0/206 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
eval:   0%|                                                                | 0/206 [00:10<?, ?it/s, recall_0.3=(3, 3) / 5]eval:   0%|▎                                                       | 1/206 [00:10<35:59, 10.53s/it, recall_0.3=(3, 3) / 5]eval:   0%|▎                                                    | 1/206 [00:11<35:59, 10.53s/it, recall_0.3=(14, 14) / 23]eval:   1%|▌                                                    | 2/206 [00:11<17:10,  5.05s/it, recall_0.3=(14, 14) / 23]eval:   1%|▌                                                    | 2/206 [00:12<17:10,  5.05s/it, recall_0.3=(19, 19) / 30]eval:   1%|▊                                                    | 3/206 [00:12<11:08,  3.29s/it, recall_0.3=(19, 19) / 30]eval:   1%|▊                                                    | 3/206 [00:14<11:08,  3.29s/it, recall_0.3=(23, 23) / 36]eval:   2%|█                                                    | 4/206 [00:14<08:10,  2.43s/it, recall_0.3=(23, 23) / 36]eval:   2%|█                                                    | 4/206 [00:19<08:10,  2.43s/it, recall_0.3=(28, 28) / 43]eval:   2%|█▎                                                   | 5/206 [00:19<11:19,  3.38s/it, recall_0.3=(28, 28) / 43]eval:   2%|█▎                                                   | 5/206 [00:20<11:19,  3.38s/it, recall_0.3=(31, 31) / 48]eval:   3%|█▌                                                   | 6/206 [00:20<08:58,  2.69s/it, recall_0.3=(31, 31) / 48]eval:   3%|█▌                                                   | 6/206 [00:21<08:58,  2.69s/it, recall_0.3=(36, 36) / 53]eval:   3%|█▊                                                   | 7/206 [00:21<07:28,  2.26s/it, recall_0.3=(36, 36) / 53]eval:   3%|█▊                                                   | 7/206 [00:23<07:28,  2.26s/it, recall_0.3=(37, 37) / 56]eval:   4%|██                                                   | 8/206 [00:23<06:24,  1.94s/it, recall_0.3=(37, 37) / 56]eval:   4%|██                                                   | 8/206 [00:24<06:24,  1.94s/it, recall_0.3=(37, 37) / 56]eval:   4%|██▎                                                  | 9/206 [00:24<05:21,  1.63s/it, recall_0.3=(37, 37) / 56]eval:   4%|██▎                                                  | 9/206 [00:25<05:21,  1.63s/it, recall_0.3=(37, 37) / 56]eval:   5%|██▌                                                 | 10/206 [00:25<04:52,  1.49s/it, recall_0.3=(37, 37) / 56]eval:   5%|██▌                                                 | 10/206 [00:26<04:52,  1.49s/it, recall_0.3=(37, 37) / 58]eval:   5%|██▊                                                 | 11/206 [00:26<04:27,  1.37s/it, recall_0.3=(37, 37) / 58]eval:   5%|██▊                                                 | 11/206 [00:27<04:27,  1.37s/it, recall_0.3=(37, 37) / 61]eval:   6%|███                                                 | 12/206 [00:27<04:04,  1.26s/it, recall_0.3=(37, 37) / 61]eval:   6%|███                                                 | 12/206 [00:28<04:04,  1.26s/it, recall_0.3=(40, 40) / 67]eval:   6%|███▎                                                | 13/206 [00:28<03:57,  1.23s/it, recall_0.3=(40, 40) / 67]eval:   6%|███▎                                                | 13/206 [00:29<03:57,  1.23s/it, recall_0.3=(42, 43) / 72]eval:   7%|███▌                                                | 14/206 [00:29<03:43,  1.17s/it, recall_0.3=(42, 43) / 72]eval:   7%|███▌                                                | 14/206 [00:30<03:43,  1.17s/it, recall_0.3=(44, 45) / 75]eval:   7%|███▊                                                | 15/206 [00:30<03:39,  1.15s/it, recall_0.3=(44, 45) / 75]eval:   7%|███▊                                                | 15/206 [00:31<03:39,  1.15s/it, recall_0.3=(46, 47) / 77]eval:   8%|████                                                | 16/206 [00:31<03:35,  1.14s/it, recall_0.3=(46, 47) / 77]eval:   8%|████                                                | 16/206 [00:36<03:35,  1.14s/it, recall_0.3=(46, 47) / 80]eval:   8%|████▎                                               | 17/206 [00:36<07:00,  2.23s/it, recall_0.3=(46, 47) / 80]eval:   8%|████▎                                               | 17/206 [00:37<07:00,  2.23s/it, recall_0.3=(47, 48) / 83]eval:   9%|████▌                                               | 18/206 [00:37<06:12,  1.98s/it, recall_0.3=(47, 48) / 83]eval:   9%|████▌                                               | 18/206 [00:39<06:12,  1.98s/it, recall_0.3=(48, 49) / 85]eval:   9%|████▊                                               | 19/206 [00:39<05:30,  1.77s/it, recall_0.3=(48, 49) / 85]eval:   9%|████▊                                               | 19/206 [00:40<05:30,  1.77s/it, recall_0.3=(49, 50) / 87]eval:  10%|█████                                               | 20/206 [00:40<05:01,  1.62s/it, recall_0.3=(49, 50) / 87]eval:  10%|█████                                               | 20/206 [00:43<05:01,  1.62s/it, recall_0.3=(53, 54) / 92]eval:  10%|█████▎                                              | 21/206 [00:43<06:32,  2.12s/it, recall_0.3=(53, 54) / 92]eval:  10%|█████▏                                             | 21/206 [00:44<06:32,  2.12s/it, recall_0.3=(60, 61) / 103]eval:  11%|█████▍                                             | 22/206 [00:44<05:27,  1.78s/it, recall_0.3=(60, 61) / 103]eval:  11%|█████▍                                             | 22/206 [00:45<05:27,  1.78s/it, recall_0.3=(71, 72) / 125]eval:  11%|█████▋                                             | 23/206 [00:45<04:17,  1.41s/it, recall_0.3=(71, 72) / 125]eval:  11%|█████▋                                             | 23/206 [00:46<04:17,  1.41s/it, recall_0.3=(78, 79) / 133]eval:  12%|█████▉                                             | 24/206 [00:46<03:46,  1.24s/it, recall_0.3=(78, 79) / 133]eval:  12%|█████▉                                             | 24/206 [00:49<03:46,  1.24s/it, recall_0.3=(86, 87) / 145]eval:  12%|██████▏                                            | 25/206 [00:49<05:40,  1.88s/it, recall_0.3=(86, 87) / 145]eval:  12%|██████▏                                            | 25/206 [00:50<05:40,  1.88s/it, recall_0.3=(90, 91) / 153]eval:  13%|██████▍                                            | 26/206 [00:50<04:46,  1.59s/it, recall_0.3=(90, 91) / 153]eval:  13%|██████▍                                            | 26/206 [00:51<04:46,  1.59s/it, recall_0.3=(93, 94) / 156]eval:  13%|██████▋                                            | 27/206 [00:51<04:21,  1.46s/it, recall_0.3=(93, 94) / 156]eval:  13%|██████▋                                            | 27/206 [00:52<04:21,  1.46s/it, recall_0.3=(97, 98) / 163]eval:  14%|██████▉                                            | 28/206 [00:52<03:56,  1.33s/it, recall_0.3=(97, 98) / 163]eval:  14%|██████▋                                          | 28/206 [00:57<03:56,  1.33s/it, recall_0.3=(104, 105) / 171]eval:  14%|██████▉                                          | 29/206 [00:57<06:51,  2.32s/it, recall_0.3=(104, 105) / 171]eval:  14%|██████▉                                          | 29/206 [00:58<06:51,  2.32s/it, recall_0.3=(107, 108) / 174]eval:  15%|███████▏                                         | 30/206 [00:58<05:41,  1.94s/it, recall_0.3=(107, 108) / 174]eval:  15%|███████▏                                         | 30/206 [00:59<05:41,  1.94s/it, recall_0.3=(109, 110) / 177]eval:  15%|███████▎                                         | 31/206 [00:59<04:51,  1.67s/it, recall_0.3=(109, 110) / 177]eval:  15%|███████▎                                         | 31/206 [01:00<04:51,  1.67s/it, recall_0.3=(109, 110) / 179]eval:  16%|███████▌                                         | 32/206 [01:00<04:07,  1.42s/it, recall_0.3=(109, 110) / 179]eval:  16%|███████▌                                         | 32/206 [01:00<04:07,  1.42s/it, recall_0.3=(112, 113) / 182]eval:  16%|███████▊                                         | 33/206 [01:01<03:36,  1.25s/it, recall_0.3=(112, 113) / 182]eval:  16%|███████▊                                         | 33/206 [01:01<03:36,  1.25s/it, recall_0.3=(113, 114) / 184]eval:  17%|████████                                         | 34/206 [01:01<03:09,  1.10s/it, recall_0.3=(113, 114) / 184]eval:  17%|████████                                         | 34/206 [01:02<03:09,  1.10s/it, recall_0.3=(113, 114) / 184]eval:  17%|████████▎                                        | 35/206 [01:02<03:00,  1.06s/it, recall_0.3=(113, 114) / 184]eval:  17%|████████▎                                        | 35/206 [01:03<03:00,  1.06s/it, recall_0.3=(116, 117) / 189]eval:  17%|████████▌                                        | 36/206 [01:03<03:08,  1.11s/it, recall_0.3=(116, 117) / 189]eval:  17%|████████▌                                        | 36/206 [01:06<03:08,  1.11s/it, recall_0.3=(116, 117) / 189]eval:  18%|████████▊                                        | 37/206 [01:06<04:09,  1.48s/it, recall_0.3=(116, 117) / 189]eval:  18%|████████▊                                        | 37/206 [01:07<04:09,  1.48s/it, recall_0.3=(116, 117) / 189]eval:  18%|█████████                                        | 38/206 [01:07<03:43,  1.33s/it, recall_0.3=(116, 117) / 189]eval:  18%|█████████                                        | 38/206 [01:08<03:43,  1.33s/it, recall_0.3=(116, 117) / 189]eval:  19%|█████████▎                                       | 39/206 [01:08<03:19,  1.19s/it, recall_0.3=(116, 117) / 189]eval:  19%|█████████▎                                       | 39/206 [01:09<03:19,  1.19s/it, recall_0.3=(116, 117) / 189]eval:  19%|█████████▌                                       | 40/206 [01:09<03:06,  1.12s/it, recall_0.3=(116, 117) / 189]eval:  19%|█████████▌                                       | 40/206 [01:10<03:06,  1.12s/it, recall_0.3=(117, 118) / 193]eval:  20%|█████████▊                                       | 41/206 [01:10<03:13,  1.17s/it, recall_0.3=(117, 118) / 193]eval:  20%|█████████▊                                       | 41/206 [01:11<03:13,  1.17s/it, recall_0.3=(120, 121) / 197]eval:  20%|█████████▉                                       | 42/206 [01:11<03:27,  1.27s/it, recall_0.3=(120, 121) / 197]eval:  20%|█████████▉                                       | 42/206 [01:13<03:27,  1.27s/it, recall_0.3=(130, 131) / 220]eval:  21%|██████████▏                                      | 43/206 [01:13<03:32,  1.30s/it, recall_0.3=(130, 131) / 220]eval:  21%|██████████▏                                      | 43/206 [01:17<03:32,  1.30s/it, recall_0.3=(144, 145) / 236]eval:  21%|██████████▍                                      | 44/206 [01:17<05:34,  2.06s/it, recall_0.3=(144, 145) / 236]eval:  21%|██████████▍                                      | 44/206 [01:18<05:34,  2.06s/it, recall_0.3=(156, 157) / 255]eval:  22%|██████████▋                                      | 45/206 [01:18<04:47,  1.79s/it, recall_0.3=(156, 157) / 255]eval:  22%|██████████▋                                      | 45/206 [01:19<04:47,  1.79s/it, recall_0.3=(160, 161) / 263]eval:  22%|██████████▉                                      | 46/206 [01:19<04:12,  1.58s/it, recall_0.3=(160, 161) / 263]eval:  22%|██████████▉                                      | 46/206 [01:21<04:12,  1.58s/it, recall_0.3=(167, 168) / 274]eval:  23%|███████████▏                                     | 47/206 [01:21<04:26,  1.68s/it, recall_0.3=(167, 168) / 274]eval:  23%|███████████▏                                     | 47/206 [01:24<04:26,  1.68s/it, recall_0.3=(172, 173) / 284]eval:  23%|███████████▍                                     | 48/206 [01:24<05:47,  2.20s/it, recall_0.3=(172, 173) / 284]eval:  23%|███████████▍                                     | 48/206 [01:26<05:47,  2.20s/it, recall_0.3=(177, 178) / 290]eval:  24%|███████████▋                                     | 49/206 [01:26<05:06,  1.96s/it, recall_0.3=(177, 178) / 290]eval:  24%|███████████▋                                     | 49/206 [01:27<05:06,  1.96s/it, recall_0.3=(178, 179) / 292]eval:  24%|███████████▉                                     | 50/206 [01:27<04:27,  1.72s/it, recall_0.3=(178, 179) / 292]eval:  24%|███████████▉                                     | 50/206 [01:28<04:27,  1.72s/it, recall_0.3=(180, 181) / 296]eval:  25%|████████████▏                                    | 51/206 [01:28<03:58,  1.54s/it, recall_0.3=(180, 181) / 296]eval:  25%|████████████▏                                    | 51/206 [01:29<03:58,  1.54s/it, recall_0.3=(182, 183) / 300]eval:  25%|████████████▎                                    | 52/206 [01:29<03:37,  1.41s/it, recall_0.3=(182, 183) / 300]eval:  25%|████████████▎                                    | 52/206 [01:30<03:37,  1.41s/it, recall_0.3=(187, 188) / 308]eval:  26%|████████████▌                                    | 53/206 [01:30<03:20,  1.31s/it, recall_0.3=(187, 188) / 308]eval:  26%|████████████▌                                    | 53/206 [01:32<03:20,  1.31s/it, recall_0.3=(190, 191) / 314]eval:  26%|████████████▊                                    | 54/206 [01:32<03:32,  1.40s/it, recall_0.3=(190, 191) / 314]eval:  26%|████████████▊                                    | 54/206 [01:33<03:32,  1.40s/it, recall_0.3=(191, 192) / 317]eval:  27%|█████████████                                    | 55/206 [01:33<03:15,  1.29s/it, recall_0.3=(191, 192) / 317]eval:  27%|█████████████                                    | 55/206 [01:35<03:15,  1.29s/it, recall_0.3=(199, 200) / 331]eval:  27%|█████████████▎                                   | 56/206 [01:35<03:40,  1.47s/it, recall_0.3=(199, 200) / 331]eval:  27%|█████████████▎                                   | 56/206 [01:36<03:40,  1.47s/it, recall_0.3=(200, 201) / 335]eval:  28%|█████████████▌                                   | 57/206 [01:36<03:23,  1.37s/it, recall_0.3=(200, 201) / 335]eval:  28%|█████████████▌                                   | 57/206 [01:40<03:23,  1.37s/it, recall_0.3=(201, 202) / 337]eval:  28%|█████████████▊                                   | 58/206 [01:40<05:29,  2.23s/it, recall_0.3=(201, 202) / 337]eval:  28%|█████████████▊                                   | 58/206 [01:41<05:29,  2.23s/it, recall_0.3=(205, 208) / 349]eval:  29%|██████████████                                   | 59/206 [01:41<04:30,  1.84s/it, recall_0.3=(205, 208) / 349]eval:  29%|██████████████                                   | 59/206 [01:42<04:30,  1.84s/it, recall_0.3=(215, 218) / 362]eval:  29%|██████████████▎                                  | 60/206 [01:42<03:49,  1.57s/it, recall_0.3=(215, 218) / 362]eval:  29%|██████████████▎                                  | 60/206 [01:43<03:49,  1.57s/it, recall_0.3=(227, 230) / 374]eval:  30%|██████████████▌                                  | 61/206 [01:43<03:26,  1.42s/it, recall_0.3=(227, 230) / 374]eval:  30%|██████████████▌                                  | 61/206 [01:46<03:26,  1.42s/it, recall_0.3=(239, 242) / 391]eval:  30%|██████████████▋                                  | 62/206 [01:46<04:53,  2.04s/it, recall_0.3=(239, 242) / 391]eval:  30%|██████████████▋                                  | 62/206 [01:47<04:53,  2.04s/it, recall_0.3=(249, 252) / 408]eval:  31%|██████████████▉                                  | 63/206 [01:47<04:06,  1.73s/it, recall_0.3=(249, 252) / 408]eval:  31%|██████████████▉                                  | 63/206 [01:48<04:06,  1.73s/it, recall_0.3=(258, 261) / 422]eval:  31%|███████████████▏                                 | 64/206 [01:48<03:37,  1.53s/it, recall_0.3=(258, 261) / 422]eval:  31%|███████████████▏                                 | 64/206 [01:49<03:37,  1.53s/it, recall_0.3=(271, 274) / 438]eval:  32%|███████████████▍                                 | 65/206 [01:49<03:09,  1.35s/it, recall_0.3=(271, 274) / 438]eval:  32%|███████████████▍                                 | 65/206 [01:52<03:09,  1.35s/it, recall_0.3=(280, 283) / 450]eval:  32%|███████████████▋                                 | 66/206 [01:52<04:11,  1.80s/it, recall_0.3=(280, 283) / 450]eval:  32%|███████████████▋                                 | 66/206 [01:53<04:11,  1.80s/it, recall_0.3=(287, 290) / 464]eval:  33%|███████████████▉                                 | 67/206 [01:53<03:40,  1.59s/it, recall_0.3=(287, 290) / 464]eval:  33%|███████████████▉                                 | 67/206 [01:55<03:40,  1.59s/it, recall_0.3=(290, 293) / 468]eval:  33%|████████████████▏                                | 68/206 [01:55<03:28,  1.51s/it, recall_0.3=(290, 293) / 468]eval:  33%|████████████████▏                                | 68/206 [01:56<03:28,  1.51s/it, recall_0.3=(291, 294) / 471]eval:  33%|████████████████▍                                | 69/206 [01:56<03:11,  1.40s/it, recall_0.3=(291, 294) / 471]eval:  33%|████████████████▍                                | 69/206 [01:59<03:11,  1.40s/it, recall_0.3=(292, 295) / 473]eval:  34%|████████████████▋                                | 70/206 [01:59<04:28,  1.97s/it, recall_0.3=(292, 295) / 473]eval:  34%|████████████████▋                                | 70/206 [02:00<04:28,  1.97s/it, recall_0.3=(294, 297) / 476]eval:  34%|████████████████▉                                | 71/206 [02:00<03:50,  1.71s/it, recall_0.3=(294, 297) / 476]eval:  34%|████████████████▉                                | 71/206 [02:01<03:50,  1.71s/it, recall_0.3=(295, 298) / 479]eval:  35%|█████████████████▏                               | 72/206 [02:01<03:30,  1.57s/it, recall_0.3=(295, 298) / 479]eval:  35%|█████████████████▏                               | 72/206 [02:02<03:30,  1.57s/it, recall_0.3=(295, 298) / 479]eval:  35%|█████████████████▎                               | 73/206 [02:02<03:04,  1.39s/it, recall_0.3=(295, 298) / 479]eval:  35%|█████████████████▎                               | 73/206 [02:04<03:04,  1.39s/it, recall_0.3=(295, 298) / 481]eval:  36%|█████████████████▌                               | 74/206 [02:04<02:56,  1.34s/it, recall_0.3=(295, 298) / 481]eval:  36%|█████████████████▌                               | 74/206 [02:04<02:56,  1.34s/it, recall_0.3=(296, 299) / 484]eval:  36%|█████████████████▊                               | 75/206 [02:05<02:39,  1.22s/it, recall_0.3=(296, 299) / 484]eval:  36%|█████████████████▊                               | 75/206 [02:06<02:39,  1.22s/it, recall_0.3=(299, 301) / 488]eval:  37%|██████████████████                               | 76/206 [02:06<02:29,  1.15s/it, recall_0.3=(299, 301) / 488]eval:  37%|██████████████████                               | 76/206 [02:07<02:29,  1.15s/it, recall_0.3=(300, 302) / 492]eval:  37%|██████████████████▎                              | 77/206 [02:07<02:27,  1.15s/it, recall_0.3=(300, 302) / 492]eval:  37%|██████████████████▎                              | 77/206 [02:12<02:27,  1.15s/it, recall_0.3=(301, 303) / 494]eval:  38%|██████████████████▌                              | 78/206 [02:12<04:56,  2.32s/it, recall_0.3=(301, 303) / 494]eval:  38%|██████████████████▌                              | 78/206 [02:13<04:56,  2.32s/it, recall_0.3=(308, 310) / 504]eval:  38%|██████████████████▊                              | 79/206 [02:13<04:02,  1.91s/it, recall_0.3=(308, 310) / 504]eval:  38%|██████████████████▊                              | 79/206 [02:14<04:02,  1.91s/it, recall_0.3=(311, 313) / 510]eval:  39%|███████████████████                              | 80/206 [02:14<03:20,  1.59s/it, recall_0.3=(311, 313) / 510]eval:  39%|███████████████████                              | 80/206 [02:14<03:20,  1.59s/it, recall_0.3=(316, 318) / 516]eval:  39%|███████████████████▎                             | 81/206 [02:14<02:54,  1.40s/it, recall_0.3=(316, 318) / 516]eval:  39%|███████████████████▎                             | 81/206 [02:17<02:54,  1.40s/it, recall_0.3=(323, 325) / 523]eval:  40%|███████████████████▌                             | 82/206 [02:17<03:52,  1.88s/it, recall_0.3=(323, 325) / 523]eval:  40%|███████████████████▌                             | 82/206 [02:18<03:52,  1.88s/it, recall_0.3=(329, 331) / 529]eval:  40%|███████████████████▋                             | 83/206 [02:18<03:18,  1.61s/it, recall_0.3=(329, 331) / 529]eval:  40%|███████████████████▋                             | 83/206 [02:19<03:18,  1.61s/it, recall_0.3=(343, 345) / 553]eval:  41%|███████████████████▉                             | 84/206 [02:19<02:48,  1.38s/it, recall_0.3=(343, 345) / 553]eval:  41%|███████████████████▉                             | 84/206 [02:20<02:48,  1.38s/it, recall_0.3=(357, 359) / 572]eval:  41%|████████████████████▏                            | 85/206 [02:20<02:33,  1.27s/it, recall_0.3=(357, 359) / 572]eval:  41%|████████████████████▏                            | 85/206 [02:22<02:33,  1.27s/it, recall_0.3=(370, 372) / 589]eval:  42%|████████████████████▍                            | 86/206 [02:22<03:04,  1.53s/it, recall_0.3=(370, 372) / 589]eval:  42%|████████████████████▍                            | 86/206 [02:23<03:04,  1.53s/it, recall_0.3=(379, 381) / 601]eval:  42%|████████████████████▋                            | 87/206 [02:23<02:38,  1.33s/it, recall_0.3=(379, 381) / 601]eval:  42%|████████████████████▋                            | 87/206 [02:24<02:38,  1.33s/it, recall_0.3=(387, 389) / 616]eval:  43%|████████████████████▉                            | 88/206 [02:24<02:27,  1.25s/it, recall_0.3=(387, 389) / 616]eval:  43%|████████████████████▉                            | 88/206 [02:27<02:27,  1.25s/it, recall_0.3=(392, 394) / 625]eval:  43%|█████████████████████▏                           | 89/206 [02:27<03:05,  1.59s/it, recall_0.3=(392, 394) / 625]eval:  43%|█████████████████████▏                           | 89/206 [02:31<03:05,  1.59s/it, recall_0.3=(395, 397) / 632]eval:  44%|█████████████████████▍                           | 90/206 [02:31<04:47,  2.48s/it, recall_0.3=(395, 397) / 632]eval:  44%|█████████████████████▍                           | 90/206 [02:32<04:47,  2.48s/it, recall_0.3=(398, 400) / 636]eval:  44%|█████████████████████▋                           | 91/206 [02:32<03:52,  2.02s/it, recall_0.3=(398, 400) / 636]eval:  44%|█████████████████████▋                           | 91/206 [02:33<03:52,  2.02s/it, recall_0.3=(399, 401) / 638]eval:  45%|█████████████████████▉                           | 92/206 [02:33<03:17,  1.73s/it, recall_0.3=(399, 401) / 638]eval:  45%|█████████████████████▉                           | 92/206 [02:34<03:17,  1.73s/it, recall_0.3=(401, 403) / 641]eval:  45%|██████████████████████                           | 93/206 [02:34<02:51,  1.52s/it, recall_0.3=(401, 403) / 641]eval:  45%|██████████████████████                           | 93/206 [02:35<02:51,  1.52s/it, recall_0.3=(404, 406) / 644]eval:  46%|██████████████████████▎                          | 94/206 [02:35<02:34,  1.38s/it, recall_0.3=(404, 406) / 644]eval:  46%|██████████████████████▎                          | 94/206 [02:36<02:34,  1.38s/it, recall_0.3=(407, 409) / 647]eval:  46%|██████████████████████▌                          | 95/206 [02:36<02:17,  1.24s/it, recall_0.3=(407, 409) / 647]eval:  46%|██████████████████████▌                          | 95/206 [02:37<02:17,  1.24s/it, recall_0.3=(413, 415) / 655]eval:  47%|██████████████████████▊                          | 96/206 [02:37<02:04,  1.13s/it, recall_0.3=(413, 415) / 655]eval:  47%|██████████████████████▊                          | 96/206 [02:38<02:04,  1.13s/it, recall_0.3=(417, 419) / 659]eval:  47%|███████████████████████                          | 97/206 [02:38<02:05,  1.15s/it, recall_0.3=(417, 419) / 659]eval:  47%|███████████████████████                          | 97/206 [02:42<02:05,  1.15s/it, recall_0.3=(418, 420) / 661]eval:  48%|███████████████████████▎                         | 98/206 [02:42<03:30,  1.95s/it, recall_0.3=(418, 420) / 661]eval:  48%|███████████████████████▎                         | 98/206 [02:43<03:30,  1.95s/it, recall_0.3=(423, 425) / 667]eval:  48%|███████████████████████▌                         | 99/206 [02:43<02:53,  1.62s/it, recall_0.3=(423, 425) / 667]eval:  48%|███████████████████████▌                         | 99/206 [02:44<02:53,  1.62s/it, recall_0.3=(425, 427) / 670]eval:  49%|███████████████████████▎                        | 100/206 [02:44<02:33,  1.45s/it, recall_0.3=(425, 427) / 670]eval:  49%|███████████████████████▎                        | 100/206 [02:45<02:33,  1.45s/it, recall_0.3=(427, 429) / 673]eval:  49%|███████████████████████▌                        | 101/206 [02:45<02:21,  1.35s/it, recall_0.3=(427, 429) / 673]eval:  49%|███████████████████████▌                        | 101/206 [02:47<02:21,  1.35s/it, recall_0.3=(430, 432) / 681]eval:  50%|███████████████████████▊                        | 102/206 [02:47<02:41,  1.56s/it, recall_0.3=(430, 432) / 681]eval:  50%|███████████████████████▊                        | 102/206 [02:48<02:41,  1.56s/it, recall_0.3=(440, 442) / 700]eval:  50%|████████████████████████                        | 103/206 [02:48<02:21,  1.37s/it, recall_0.3=(440, 442) / 700]eval:  50%|████████████████████████                        | 103/206 [02:49<02:21,  1.37s/it, recall_0.3=(452, 454) / 717]eval:  50%|████████████████████████▏                       | 104/206 [02:49<02:08,  1.26s/it, recall_0.3=(452, 454) / 717]eval:  50%|████████████████████████▏                       | 104/206 [02:51<02:08,  1.26s/it, recall_0.3=(468, 470) / 743]eval:  51%|████████████████████████▍                       | 105/206 [02:51<02:23,  1.42s/it, recall_0.3=(468, 470) / 743]eval:  51%|████████████████████████▍                       | 105/206 [02:52<02:23,  1.42s/it, recall_0.3=(471, 474) / 752]eval:  51%|████████████████████████▋                       | 106/206 [02:52<02:25,  1.45s/it, recall_0.3=(471, 474) / 752]eval:  51%|████████████████████████▋                       | 106/206 [02:53<02:25,  1.45s/it, recall_0.3=(478, 481) / 763]eval:  52%|████████████████████████▉                       | 107/206 [02:53<02:10,  1.32s/it, recall_0.3=(478, 481) / 763]eval:  52%|████████████████████████▉                       | 107/206 [02:55<02:10,  1.32s/it, recall_0.3=(485, 488) / 772]eval:  52%|█████████████████████████▏                      | 108/206 [02:55<02:07,  1.30s/it, recall_0.3=(485, 488) / 772]eval:  52%|█████████████████████████▏                      | 108/206 [02:57<02:07,  1.30s/it, recall_0.3=(492, 495) / 781]eval:  53%|█████████████████████████▍                      | 109/206 [02:57<02:32,  1.57s/it, recall_0.3=(492, 495) / 781]eval:  53%|█████████████████████████▍                      | 109/206 [02:59<02:32,  1.57s/it, recall_0.3=(494, 497) / 784]eval:  53%|█████████████████████████▋                      | 110/206 [02:59<02:40,  1.68s/it, recall_0.3=(494, 497) / 784]eval:  53%|█████████████████████████▋                      | 110/206 [03:00<02:40,  1.68s/it, recall_0.3=(498, 501) / 790]eval:  54%|█████████████████████████▊                      | 111/206 [03:00<02:14,  1.41s/it, recall_0.3=(498, 501) / 790]eval:  54%|█████████████████████████▊                      | 111/206 [03:01<02:14,  1.41s/it, recall_0.3=(498, 501) / 795]eval:  54%|██████████████████████████                      | 112/206 [03:01<02:01,  1.29s/it, recall_0.3=(498, 501) / 795]eval:  54%|██████████████████████████                      | 112/206 [03:02<02:01,  1.29s/it, recall_0.3=(499, 502) / 800]eval:  55%|██████████████████████████▎                     | 113/206 [03:02<01:55,  1.24s/it, recall_0.3=(499, 502) / 800]eval:  55%|██████████████████████████▎                     | 113/206 [03:03<01:55,  1.24s/it, recall_0.3=(500, 503) / 805]eval:  55%|██████████████████████████▌                     | 114/206 [03:03<01:43,  1.12s/it, recall_0.3=(500, 503) / 805]eval:  55%|██████████████████████████▌                     | 114/206 [03:04<01:43,  1.12s/it, recall_0.3=(503, 506) / 812]eval:  56%|██████████████████████████▊                     | 115/206 [03:04<01:41,  1.12s/it, recall_0.3=(503, 506) / 812]eval:  56%|██████████████████████████▊                     | 115/206 [03:05<01:41,  1.12s/it, recall_0.3=(505, 508) / 816]eval:  56%|███████████████████████████                     | 116/206 [03:05<01:52,  1.25s/it, recall_0.3=(505, 508) / 816]eval:  56%|███████████████████████████                     | 116/206 [03:07<01:52,  1.25s/it, recall_0.3=(510, 513) / 821]eval:  57%|███████████████████████████▎                    | 117/206 [03:07<01:52,  1.26s/it, recall_0.3=(510, 513) / 821]eval:  57%|███████████████████████████▎                    | 117/206 [03:08<01:52,  1.26s/it, recall_0.3=(511, 514) / 824]eval:  57%|███████████████████████████▍                    | 118/206 [03:08<01:45,  1.20s/it, recall_0.3=(511, 514) / 824]eval:  57%|███████████████████████████▍                    | 118/206 [03:09<01:45,  1.20s/it, recall_0.3=(514, 517) / 828]eval:  58%|███████████████████████████▋                    | 119/206 [03:09<01:45,  1.21s/it, recall_0.3=(514, 517) / 828]eval:  58%|███████████████████████████▋                    | 119/206 [03:12<01:45,  1.21s/it, recall_0.3=(523, 526) / 840]eval:  58%|███████████████████████████▉                    | 120/206 [03:12<02:27,  1.71s/it, recall_0.3=(523, 526) / 840]eval:  58%|███████████████████████████▉                    | 120/206 [03:13<02:27,  1.71s/it, recall_0.3=(535, 538) / 852]eval:  59%|████████████████████████████▏                   | 121/206 [03:13<02:11,  1.55s/it, recall_0.3=(535, 538) / 852]eval:  59%|████████████████████████████▏                   | 121/206 [03:14<02:11,  1.55s/it, recall_0.3=(545, 548) / 867]eval:  59%|████████████████████████████▍                   | 122/206 [03:14<02:01,  1.45s/it, recall_0.3=(545, 548) / 867]eval:  59%|████████████████████████████▍                   | 122/206 [03:15<02:01,  1.45s/it, recall_0.3=(558, 561) / 900]eval:  60%|████████████████████████████▋                   | 123/206 [03:15<01:53,  1.37s/it, recall_0.3=(558, 561) / 900]eval:  60%|████████████████████████████▋                   | 123/206 [03:18<01:53,  1.37s/it, recall_0.3=(568, 571) / 923]eval:  60%|████████████████████████████▉                   | 124/206 [03:18<02:20,  1.72s/it, recall_0.3=(568, 571) / 923]eval:  60%|████████████████████████████▉                   | 124/206 [03:19<02:20,  1.72s/it, recall_0.3=(579, 582) / 943]eval:  61%|█████████████████████████████▏                  | 125/206 [03:19<02:01,  1.49s/it, recall_0.3=(579, 582) / 943]eval:  61%|█████████████████████████████▏                  | 125/206 [03:20<02:01,  1.49s/it, recall_0.3=(583, 586) / 947]eval:  61%|█████████████████████████████▎                  | 126/206 [03:20<01:53,  1.42s/it, recall_0.3=(583, 586) / 947]eval:  61%|█████████████████████████████▎                  | 126/206 [03:21<01:53,  1.42s/it, recall_0.3=(588, 591) / 954]eval:  62%|█████████████████████████████▌                  | 127/206 [03:21<01:45,  1.34s/it, recall_0.3=(588, 591) / 954]eval:  62%|█████████████████████████████▌                  | 127/206 [03:24<01:45,  1.34s/it, recall_0.3=(593, 596) / 962]eval:  62%|█████████████████████████████▊                  | 128/206 [03:24<02:16,  1.75s/it, recall_0.3=(593, 596) / 962]eval:  62%|█████████████████████████████▊                  | 128/206 [03:27<02:16,  1.75s/it, recall_0.3=(598, 601) / 970]eval:  63%|██████████████████████████████                  | 129/206 [03:27<02:44,  2.13s/it, recall_0.3=(598, 601) / 970]eval:  63%|██████████████████████████████                  | 129/206 [03:30<02:44,  2.13s/it, recall_0.3=(600, 603) / 976]eval:  63%|██████████████████████████████▎                 | 130/206 [03:30<02:54,  2.30s/it, recall_0.3=(600, 603) / 976]eval:  63%|██████████████████████████████▎                 | 130/206 [03:31<02:54,  2.30s/it, recall_0.3=(601, 604) / 978]eval:  64%|██████████████████████████████▌                 | 131/206 [03:31<02:26,  1.96s/it, recall_0.3=(601, 604) / 978]eval:  64%|██████████████████████████████▌                 | 131/206 [03:32<02:26,  1.96s/it, recall_0.3=(601, 604) / 980]eval:  64%|██████████████████████████████▊                 | 132/206 [03:32<02:05,  1.69s/it, recall_0.3=(601, 604) / 980]eval:  64%|██████████████████████████████▊                 | 132/206 [03:33<02:05,  1.69s/it, recall_0.3=(602, 605) / 984]eval:  65%|██████████████████████████████▉                 | 133/206 [03:33<01:50,  1.51s/it, recall_0.3=(602, 605) / 984]eval:  65%|██████████████████████████████▉                 | 133/206 [03:34<01:50,  1.51s/it, recall_0.3=(602, 605) / 987]eval:  65%|███████████████████████████████▏                | 134/206 [03:34<01:43,  1.44s/it, recall_0.3=(602, 605) / 987]eval:  65%|███████████████████████████████▏                | 134/206 [03:35<01:43,  1.44s/it, recall_0.3=(606, 609) / 997]eval:  66%|███████████████████████████████▍                | 135/206 [03:35<01:34,  1.33s/it, recall_0.3=(606, 609) / 997]eval:  66%|███████████████████████████████▍                | 135/206 [03:36<01:34,  1.33s/it, recall_0.3=(606, 609) / 999]eval:  66%|███████████████████████████████▋                | 136/206 [03:36<01:28,  1.27s/it, recall_0.3=(606, 609) / 999]eval:  66%|███████████████████████████████                | 136/206 [03:37<01:28,  1.27s/it, recall_0.3=(609, 612) / 1004]eval:  67%|███████████████████████████████▎               | 137/206 [03:37<01:22,  1.19s/it, recall_0.3=(609, 612) / 1004]eval:  67%|███████████████████████████████▎               | 137/206 [03:42<01:22,  1.19s/it, recall_0.3=(609, 612) / 1009]eval:  67%|███████████████████████████████▍               | 138/206 [03:42<02:26,  2.16s/it, recall_0.3=(609, 612) / 1009]eval:  67%|███████████████████████████████▍               | 138/206 [03:43<02:26,  2.16s/it, recall_0.3=(612, 615) / 1015]eval:  67%|███████████████████████████████▋               | 139/206 [03:43<02:03,  1.84s/it, recall_0.3=(612, 615) / 1015]eval:  67%|███████████████████████████████▋               | 139/206 [03:44<02:03,  1.84s/it, recall_0.3=(619, 622) / 1026]eval:  68%|███████████████████████████████▉               | 140/206 [03:44<01:39,  1.51s/it, recall_0.3=(619, 622) / 1026]eval:  68%|███████████████████████████████▉               | 140/206 [03:45<01:39,  1.51s/it, recall_0.3=(628, 630) / 1040]eval:  68%|████████████████████████████████▏              | 141/206 [03:45<01:28,  1.36s/it, recall_0.3=(628, 630) / 1040]eval:  68%|████████████████████████████████▏              | 141/206 [03:47<01:28,  1.36s/it, recall_0.3=(639, 641) / 1053]eval:  69%|████████████████████████████████▍              | 142/206 [03:47<01:35,  1.49s/it, recall_0.3=(639, 641) / 1053]eval:  69%|████████████████████████████████▍              | 142/206 [03:48<01:35,  1.49s/it, recall_0.3=(655, 657) / 1076]eval:  69%|████████████████████████████████▋              | 143/206 [03:48<01:25,  1.36s/it, recall_0.3=(655, 657) / 1076]eval:  69%|████████████████████████████████▋              | 143/206 [03:49<01:25,  1.36s/it, recall_0.3=(668, 669) / 1093]eval:  70%|████████████████████████████████▊              | 144/206 [03:49<01:16,  1.23s/it, recall_0.3=(668, 669) / 1093]eval:  70%|████████████████████████████████▊              | 144/206 [03:50<01:16,  1.23s/it, recall_0.3=(674, 675) / 1104]eval:  70%|█████████████████████████████████              | 145/206 [03:50<01:25,  1.40s/it, recall_0.3=(674, 675) / 1104]eval:  70%|█████████████████████████████████              | 145/206 [03:54<01:25,  1.40s/it, recall_0.3=(680, 681) / 1121]eval:  71%|█████████████████████████████████▎             | 146/206 [03:54<02:00,  2.01s/it, recall_0.3=(680, 681) / 1121]eval:  71%|█████████████████████████████████▎             | 146/206 [03:55<02:00,  2.01s/it, recall_0.3=(681, 682) / 1123]eval:  71%|█████████████████████████████████▌             | 147/206 [03:55<01:42,  1.74s/it, recall_0.3=(681, 682) / 1123]eval:  71%|█████████████████████████████████▌             | 147/206 [03:56<01:42,  1.74s/it, recall_0.3=(685, 687) / 1131]eval:  72%|█████████████████████████████████▊             | 148/206 [03:56<01:30,  1.55s/it, recall_0.3=(685, 687) / 1131]eval:  72%|█████████████████████████████████▊             | 148/206 [03:58<01:30,  1.55s/it, recall_0.3=(687, 689) / 1134]eval:  72%|█████████████████████████████████▉             | 149/206 [03:58<01:39,  1.74s/it, recall_0.3=(687, 689) / 1134]eval:  72%|█████████████████████████████████▉             | 149/206 [03:59<01:39,  1.74s/it, recall_0.3=(690, 692) / 1137]eval:  73%|██████████████████████████████████▏            | 150/206 [03:59<01:23,  1.50s/it, recall_0.3=(690, 692) / 1137]eval:  73%|██████████████████████████████████▏            | 150/206 [04:00<01:23,  1.50s/it, recall_0.3=(694, 696) / 1142]eval:  73%|██████████████████████████████████▍            | 151/206 [04:00<01:08,  1.25s/it, recall_0.3=(694, 696) / 1142]eval:  73%|██████████████████████████████████▍            | 151/206 [04:00<01:08,  1.25s/it, recall_0.3=(695, 697) / 1145]eval:  74%|██████████████████████████████████▋            | 152/206 [04:00<00:59,  1.10s/it, recall_0.3=(695, 697) / 1145]eval:  74%|██████████████████████████████████▋            | 152/206 [04:02<00:59,  1.10s/it, recall_0.3=(698, 700) / 1150]eval:  74%|██████████████████████████████████▉            | 153/206 [04:02<00:57,  1.08s/it, recall_0.3=(698, 700) / 1150]eval:  74%|██████████████████████████████████▉            | 153/206 [04:02<00:57,  1.08s/it, recall_0.3=(700, 702) / 1154]eval:  75%|███████████████████████████████████▏           | 154/206 [04:02<00:51,  1.00it/s, recall_0.3=(700, 702) / 1154]eval:  75%|███████████████████████████████████▏           | 154/206 [04:04<00:51,  1.00it/s, recall_0.3=(702, 704) / 1157]eval:  75%|███████████████████████████████████▎           | 155/206 [04:04<00:58,  1.14s/it, recall_0.3=(702, 704) / 1157]eval:  75%|███████████████████████████████████▎           | 155/206 [04:05<00:58,  1.14s/it, recall_0.3=(705, 707) / 1162]eval:  76%|███████████████████████████████████▌           | 156/206 [04:05<00:54,  1.10s/it, recall_0.3=(705, 707) / 1162]eval:  76%|███████████████████████████████████▌           | 156/206 [04:06<00:54,  1.10s/it, recall_0.3=(708, 710) / 1166]eval:  76%|███████████████████████████████████▊           | 157/206 [04:06<00:59,  1.20s/it, recall_0.3=(708, 710) / 1166]eval:  76%|███████████████████████████████████▊           | 157/206 [04:08<00:59,  1.20s/it, recall_0.3=(709, 711) / 1168]eval:  77%|████████████████████████████████████           | 158/206 [04:08<01:07,  1.41s/it, recall_0.3=(709, 711) / 1168]eval:  77%|████████████████████████████████████           | 158/206 [04:12<01:07,  1.41s/it, recall_0.3=(709, 711) / 1168]eval:  77%|████████████████████████████████████▎          | 159/206 [04:12<01:33,  2.00s/it, recall_0.3=(709, 711) / 1168]eval:  77%|████████████████████████████████████▎          | 159/206 [04:13<01:33,  2.00s/it, recall_0.3=(712, 714) / 1172]eval:  78%|████████████████████████████████████▌          | 160/206 [04:13<01:19,  1.74s/it, recall_0.3=(712, 714) / 1172]eval:  78%|████████████████████████████████████▌          | 160/206 [04:14<01:19,  1.74s/it, recall_0.3=(716, 718) / 1177]eval:  78%|████████████████████████████████████▋          | 161/206 [04:14<01:08,  1.52s/it, recall_0.3=(716, 718) / 1177]eval:  78%|████████████████████████████████████▋          | 161/206 [04:14<01:08,  1.52s/it, recall_0.3=(725, 727) / 1189]eval:  79%|████████████████████████████████████▉          | 162/206 [04:14<00:56,  1.29s/it, recall_0.3=(725, 727) / 1189]eval:  79%|████████████████████████████████████▉          | 162/206 [04:17<00:56,  1.29s/it, recall_0.3=(736, 738) / 1206]eval:  79%|█████████████████████████████████████▏         | 163/206 [04:17<01:18,  1.82s/it, recall_0.3=(736, 738) / 1206]eval:  79%|█████████████████████████████████████▏         | 163/206 [04:18<01:18,  1.82s/it, recall_0.3=(747, 749) / 1222]eval:  80%|█████████████████████████████████████▍         | 164/206 [04:18<01:05,  1.56s/it, recall_0.3=(747, 749) / 1222]eval:  80%|█████████████████████████████████████▍         | 164/206 [04:19<01:05,  1.56s/it, recall_0.3=(754, 756) / 1233]eval:  80%|█████████████████████████████████████▋         | 165/206 [04:19<00:55,  1.36s/it, recall_0.3=(754, 756) / 1233]eval:  80%|█████████████████████████████████████▋         | 165/206 [04:20<00:55,  1.36s/it, recall_0.3=(762, 764) / 1253]eval:  81%|█████████████████████████████████████▊         | 166/206 [04:20<00:49,  1.23s/it, recall_0.3=(762, 764) / 1253]eval:  81%|█████████████████████████████████████▊         | 166/206 [04:25<00:49,  1.23s/it, recall_0.3=(769, 771) / 1268]eval:  81%|██████████████████████████████████████         | 167/206 [04:25<01:33,  2.39s/it, recall_0.3=(769, 771) / 1268]eval:  81%|██████████████████████████████████████         | 167/206 [04:26<01:33,  2.39s/it, recall_0.3=(773, 775) / 1280]eval:  82%|██████████████████████████████████████▎        | 168/206 [04:26<01:14,  1.97s/it, recall_0.3=(773, 775) / 1280]eval:  82%|██████████████████████████████████████▎        | 168/206 [04:27<01:14,  1.97s/it, recall_0.3=(775, 778) / 1290]eval:  82%|██████████████████████████████████████▌        | 169/206 [04:27<01:02,  1.69s/it, recall_0.3=(775, 778) / 1290]eval:  82%|██████████████████████████████████████▌        | 169/206 [04:28<01:02,  1.69s/it, recall_0.3=(777, 780) / 1298]eval:  83%|██████████████████████████████████████▊        | 170/206 [04:28<00:53,  1.49s/it, recall_0.3=(777, 780) / 1298]eval:  83%|██████████████████████████████████████▊        | 170/206 [04:33<00:53,  1.49s/it, recall_0.3=(784, 787) / 1310]eval:  83%|███████████████████████████████████████        | 171/206 [04:33<01:25,  2.44s/it, recall_0.3=(784, 787) / 1310]eval:  83%|███████████████████████████████████████        | 171/206 [04:34<01:25,  2.44s/it, recall_0.3=(786, 789) / 1315]eval:  83%|███████████████████████████████████████▏       | 172/206 [04:34<01:09,  2.04s/it, recall_0.3=(786, 789) / 1315]eval:  83%|███████████████████████████████████████▏       | 172/206 [04:35<01:09,  2.04s/it, recall_0.3=(788, 791) / 1319]eval:  84%|███████████████████████████████████████▍       | 173/206 [04:35<00:57,  1.76s/it, recall_0.3=(788, 791) / 1319]eval:  84%|███████████████████████████████████████▍       | 173/206 [04:36<00:57,  1.76s/it, recall_0.3=(791, 794) / 1323]eval:  84%|███████████████████████████████████████▋       | 174/206 [04:36<00:49,  1.54s/it, recall_0.3=(791, 794) / 1323]eval:  84%|███████████████████████████████████████▋       | 174/206 [04:37<00:49,  1.54s/it, recall_0.3=(793, 796) / 1328]eval:  85%|███████████████████████████████████████▉       | 175/206 [04:37<00:41,  1.35s/it, recall_0.3=(793, 796) / 1328]eval:  85%|███████████████████████████████████████▉       | 175/206 [04:38<00:41,  1.35s/it, recall_0.3=(794, 797) / 1333]eval:  85%|████████████████████████████████████████▏      | 176/206 [04:38<00:36,  1.21s/it, recall_0.3=(794, 797) / 1333]eval:  85%|████████████████████████████████████████▏      | 176/206 [04:39<00:36,  1.21s/it, recall_0.3=(795, 798) / 1335]eval:  86%|████████████████████████████████████████▍      | 177/206 [04:39<00:32,  1.13s/it, recall_0.3=(795, 798) / 1335]eval:  86%|████████████████████████████████████████▍      | 177/206 [04:40<00:32,  1.13s/it, recall_0.3=(797, 800) / 1339]eval:  86%|████████████████████████████████████████▌      | 178/206 [04:40<00:29,  1.06s/it, recall_0.3=(797, 800) / 1339]eval:  86%|████████████████████████████████████████▌      | 178/206 [04:43<00:29,  1.06s/it, recall_0.3=(797, 800) / 1341]eval:  87%|████████████████████████████████████████▊      | 179/206 [04:43<00:48,  1.79s/it, recall_0.3=(797, 800) / 1341]eval:  87%|████████████████████████████████████████▊      | 179/206 [04:44<00:48,  1.79s/it, recall_0.3=(799, 802) / 1346]eval:  87%|█████████████████████████████████████████      | 180/206 [04:44<00:39,  1.51s/it, recall_0.3=(799, 802) / 1346]eval:  87%|█████████████████████████████████████████      | 180/206 [04:45<00:39,  1.51s/it, recall_0.3=(799, 802) / 1346]eval:  88%|█████████████████████████████████████████▎     | 181/206 [04:45<00:33,  1.36s/it, recall_0.3=(799, 802) / 1346]eval:  88%|█████████████████████████████████████████▎     | 181/206 [04:46<00:33,  1.36s/it, recall_0.3=(803, 806) / 1354]eval:  88%|█████████████████████████████████████████▌     | 182/206 [04:46<00:30,  1.25s/it, recall_0.3=(803, 806) / 1354]eval:  88%|█████████████████████████████████████████▌     | 182/206 [04:48<00:30,  1.25s/it, recall_0.3=(806, 809) / 1361]eval:  89%|█████████████████████████████████████████▊     | 183/206 [04:48<00:33,  1.46s/it, recall_0.3=(806, 809) / 1361]eval:  89%|█████████████████████████████████████████▊     | 183/206 [04:49<00:33,  1.46s/it, recall_0.3=(810, 813) / 1386]eval:  89%|█████████████████████████████████████████▉     | 184/206 [04:49<00:29,  1.33s/it, recall_0.3=(810, 813) / 1386]eval:  89%|█████████████████████████████████████████▉     | 184/206 [04:50<00:29,  1.33s/it, recall_0.3=(819, 822) / 1401]eval:  90%|██████████████████████████████████████████▏    | 185/206 [04:50<00:25,  1.21s/it, recall_0.3=(819, 822) / 1401]eval:  90%|██████████████████████████████████████████▏    | 185/206 [04:51<00:25,  1.21s/it, recall_0.3=(828, 832) / 1415]eval:  90%|██████████████████████████████████████████▍    | 186/206 [04:51<00:23,  1.16s/it, recall_0.3=(828, 832) / 1415]eval:  90%|██████████████████████████████████████████▍    | 186/206 [04:55<00:23,  1.16s/it, recall_0.3=(836, 840) / 1427]eval:  91%|██████████████████████████████████████████▋    | 187/206 [04:55<00:36,  1.94s/it, recall_0.3=(836, 840) / 1427]eval:  91%|██████████████████████████████████████████▋    | 187/206 [04:56<00:36,  1.94s/it, recall_0.3=(837, 841) / 1436]eval:  91%|██████████████████████████████████████████▉    | 188/206 [04:56<00:30,  1.69s/it, recall_0.3=(837, 841) / 1436]eval:  91%|██████████████████████████████████████████▉    | 188/206 [04:57<00:30,  1.69s/it, recall_0.3=(840, 844) / 1440]eval:  92%|███████████████████████████████████████████    | 189/206 [04:57<00:25,  1.51s/it, recall_0.3=(840, 844) / 1440]eval:  92%|███████████████████████████████████████████    | 189/206 [04:58<00:25,  1.51s/it, recall_0.3=(843, 847) / 1446]eval:  92%|███████████████████████████████████████████▎   | 190/206 [04:58<00:21,  1.37s/it, recall_0.3=(843, 847) / 1446]eval:  92%|███████████████████████████████████████████▎   | 190/206 [05:01<00:21,  1.37s/it, recall_0.3=(845, 849) / 1450]eval:  93%|███████████████████████████████████████████▌   | 191/206 [05:01<00:28,  1.91s/it, recall_0.3=(845, 849) / 1450]eval:  93%|███████████████████████████████████████████▌   | 191/206 [05:02<00:28,  1.91s/it, recall_0.3=(846, 850) / 1452]eval:  93%|███████████████████████████████████████████▊   | 192/206 [05:02<00:23,  1.66s/it, recall_0.3=(846, 850) / 1452]eval:  93%|███████████████████████████████████████████▊   | 192/206 [05:04<00:23,  1.66s/it, recall_0.3=(847, 851) / 1455]eval:  94%|████████████████████████████████████████████   | 193/206 [05:04<00:19,  1.51s/it, recall_0.3=(847, 851) / 1455]eval:  94%|████████████████████████████████████████████   | 193/206 [05:05<00:19,  1.51s/it, recall_0.3=(847, 851) / 1455]eval:  94%|████████████████████████████████████████████▎  | 194/206 [05:05<00:15,  1.32s/it, recall_0.3=(847, 851) / 1455]eval:  94%|████████████████████████████████████████████▎  | 194/206 [05:06<00:15,  1.32s/it, recall_0.3=(847, 851) / 1455]eval:  95%|████████████████████████████████████████████▍  | 195/206 [05:06<00:13,  1.25s/it, recall_0.3=(847, 851) / 1455]eval:  95%|████████████████████████████████████████████▍  | 195/206 [05:07<00:13,  1.25s/it, recall_0.3=(847, 851) / 1455]eval:  95%|████████████████████████████████████████████▋  | 196/206 [05:07<00:11,  1.16s/it, recall_0.3=(847, 851) / 1455]eval:  95%|████████████████████████████████████████████▋  | 196/206 [05:07<00:11,  1.16s/it, recall_0.3=(847, 851) / 1455]eval:  96%|████████████████████████████████████████████▉  | 197/206 [05:07<00:09,  1.07s/it, recall_0.3=(847, 851) / 1455]eval:  96%|████████████████████████████████████████████▉  | 197/206 [05:08<00:09,  1.07s/it, recall_0.3=(849, 853) / 1458]eval:  96%|█████████████████████████████████████████████▏ | 198/206 [05:08<00:08,  1.02s/it, recall_0.3=(849, 853) / 1458]eval:  96%|█████████████████████████████████████████████▏ | 198/206 [05:09<00:08,  1.02s/it, recall_0.3=(853, 857) / 1463]eval:  97%|█████████████████████████████████████████████▍ | 199/206 [05:09<00:07,  1.01s/it, recall_0.3=(853, 857) / 1463]eval:  97%|█████████████████████████████████████████████▍ | 199/206 [05:10<00:07,  1.01s/it, recall_0.3=(853, 857) / 1465]eval:  97%|█████████████████████████████████████████████▋ | 200/206 [05:10<00:05,  1.07it/s, recall_0.3=(853, 857) / 1465]eval:  97%|█████████████████████████████████████████████▋ | 200/206 [05:11<00:05,  1.07it/s, recall_0.3=(853, 857) / 1465]eval:  98%|█████████████████████████████████████████████▊ | 201/206 [05:11<00:04,  1.14it/s, recall_0.3=(853, 857) / 1465]eval:  98%|█████████████████████████████████████████████▊ | 201/206 [05:12<00:04,  1.14it/s, recall_0.3=(854, 858) / 1468]eval:  98%|██████████████████████████████████████████████ | 202/206 [05:12<00:03,  1.17it/s, recall_0.3=(854, 858) / 1468]eval:  98%|██████████████████████████████████████████████ | 202/206 [05:12<00:03,  1.17it/s, recall_0.3=(857, 861) / 1471]eval:  99%|██████████████████████████████████████████████▎| 203/206 [05:12<00:02,  1.31it/s, recall_0.3=(857, 861) / 1471]eval:  99%|██████████████████████████████████████████████▎| 203/206 [05:13<00:02,  1.31it/s, recall_0.3=(859, 863) / 1474]eval:  99%|██████████████████████████████████████████████▌| 204/206 [05:13<00:01,  1.43it/s, recall_0.3=(859, 863) / 1474]eval:  99%|██████████████████████████████████████████████▌| 204/206 [05:13<00:01,  1.43it/s, recall_0.3=(860, 864) / 1477]eval: 100%|██████████████████████████████████████████████▊| 205/206 [05:13<00:00,  1.58it/s, recall_0.3=(860, 864) / 1477]eval: 100%|██████████████████████████████████████████████▊| 205/206 [05:14<00:00,  1.58it/s, recall_0.3=(860, 864) / 1478]eval: 100%|███████████████████████████████████████████████| 206/206 [05:14<00:00,  1.83it/s, recall_0.3=(860, 864) / 1478]eval: 100%|███████████████████████████████████████████████| 206/206 [05:14<00:00,  1.53s/it, recall_0.3=(860, 864) / 1478]
2023-03-03 22:41:49,896   INFO  *************** Performance of EPOCH 50 *****************
2023-03-03 22:41:49,897   INFO  Generate label finished(sec_per_example: 0.1924 second).
2023-03-03 22:41:49,898   INFO  recall_roi_0.3: 0.594580
2023-03-03 22:41:49,898   INFO  recall_rcnn_0.3: 0.596706
2023-03-03 22:41:49,899   INFO  recall_roi_0.5: 0.509033
2023-03-03 22:41:49,899   INFO  recall_rcnn_0.5: 0.524265
2023-03-03 22:41:49,899   INFO  recall_roi_0.7: 0.281792
2023-03-03 22:41:49,900   INFO  recall_rcnn_0.7: 0.329083
2023-03-03 22:41:49,901   INFO  Average predicted number of objects(1644 samples): 4.031
======
Loading Ithaca365 tables for version v1.1...
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
      (3): Sigmoid()
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
      (3): Sigmoid()
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
      (3): Sigmoid()
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
6 category,
1 attribute,
4 visibility,
25839 instance,
3 sensor,
3 calibrated_sensor,
760811 ego_pose,
40 log,
40 scene,
6576 sample,
2282433 sample_data,
25839 sample_annotation,
1 map,
2579 location,
Done loading in 56.774 seconds.
======
Reverse indexing ...
Done reverse indexing in 6.6 seconds.
======
2023-03-03 22:42:54,644   INFO  The predictions of NuScenes have been saved to /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/eval/eval_with_train/epoch_50/val/final_result/data/results_nusc.json
Initializing nuScenes detection evaluation
Loaded results from /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/eval/eval_with_train/epoch_50/val/final_result/data/results_nusc.json. Found detections for 1644 samples.
Loading annotations for val split from nuScenes version: v1.1
  0%|                                                                                            | 0/1644 [00:00<?, ?it/s] 33%|██████████████████████████▍                                                     | 544/1644 [00:00<00:00, 5433.75it/s] 66%|████████████████████████████████████████████████████▎                          | 1088/1644 [00:00<00:00, 5254.72it/s]100%|███████████████████████████████████████████████████████████████████████████████| 1644/1644 [00:00<00:00, 5411.38it/s]
Loaded ground truth annotations for 1644 samples.
Filtering predictions
Detection range: (0, 30)
=> Original number of boxes: 6627
=> After distance based filtering: 2031
=> After LIDAR and RADAR points based filtering: 2031
Detection range: (30, 50)
=> Original number of boxes: 6627
=> After distance based filtering: 2341
=> After LIDAR and RADAR points based filtering: 2341
Detection range: (50, 80)
=> Original number of boxes: 6627
=> After distance based filtering: 1929
=> After LIDAR and RADAR points based filtering: 1929
Detection range: (0, 80)
=> Original number of boxes: 6627
=> After distance based filtering: 6301
=> After LIDAR and RADAR points based filtering: 6301
Filtering ground truth annotations
Detection range: (0, 30)
=> Original number of boxes: 6018
=> After distance based filtering: 1648
=> After LIDAR and RADAR points based filtering: 1648
Detection range: (30, 50)
=> Original number of boxes: 6018
=> After distance based filtering: 1660
=> After LIDAR and RADAR points based filtering: 1660
Detection range: (50, 80)
=> Original number of boxes: 6018
=> After distance based filtering: 1493
=> After LIDAR and RADAR points based filtering: 1493
Detection range: (0, 80)
=> Original number of boxes: 6018
=> After distance based filtering: 4801
=> After LIDAR and RADAR points based filtering: 4801
Accumulating metric data...
Calculating metrics...
Saving metrics to: /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/eval/eval_with_train/epoch_50/val/final_result/data
mAP: 0.1668
mATE: 0.7128
mASE: 0.7269
mAOE: 0.8818
NDS: 0.1965
Eval time: 3.3s

Per-class results:
Object Class	Det. Range	AP	ATE	ASE	AOE
car         	(0, 30)   	0.736	0.153	0.101	0.195
car         	(30, 50)  	0.541	0.193	0.083	0.392
car         	(50, 80)  	0.344	0.263	0.079	0.629
car         	(0, 80)   	0.551	0.186	0.094	0.330
truck       	(0, 30)   	0.000	1.000	1.000	1.000
truck       	(30, 50)  	0.000	1.000	1.000	1.000
truck       	(50, 80)  	0.000	1.000	1.000	1.000
truck       	(0, 80)   	0.000	1.000	1.000	1.000
bus         	(0, 30)   	0.000	1.000	1.000	1.000
bus         	(30, 50)  	0.000	1.000	1.000	1.000
bus         	(50, 80)  	0.000	1.000	1.000	1.000
bus         	(0, 80)   	0.000	1.000	1.000	1.000
pedestrian  	(0, 30)   	0.592	0.078	0.260	0.768
pedestrian  	(30, 50)  	0.449	0.097	0.272	1.105
pedestrian  	(50, 80)  	0.171	0.130	0.294	1.403
pedestrian  	(0, 80)   	0.450	0.091	0.268	0.960
motorcyclist	(0, 30)   	0.000	1.000	1.000	1.000
motorcyclist	(30, 50)  	0.000	1.000	1.000	1.000
motorcyclist	(50, 80)  	0.000	1.000	1.000	1.000
motorcyclist	(0, 80)   	0.000	1.000	1.000	1.000
bicyclist   	(0, 30)   	0.000	1.000	1.000	1.000
bicyclist   	(30, 50)  	0.000	1.000	1.000	1.000
bicyclist   	(50, 80)  	0.000	1.000	1.000	1.000
bicyclist   	(0, 80)   	0.000	1.000	1.000	1.000
2023-03-03 22:43:03,099   INFO  ----------------Nuscene detection_by_range results-----------------
***car
range (0, 30) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.15, 0.10, 0.20 | 69.12, 73.20, 75.53, 76.46 | mean AP: 0.7357742223070425
range (30, 50) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.19, 0.08, 0.39 | 47.89, 53.36, 56.43, 58.72 | mean AP: 0.5410143967451159
range (50, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.26, 0.08, 0.63 | 28.03, 33.72, 36.90, 38.92 | mean AP: 0.3439107805987578
range (0, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.19, 0.09, 0.33 | 49.24, 54.36, 57.49, 59.46 | mean AP: 0.5513779808885658
***pedestrian
range (0, 30) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.08, 0.26, 0.77 | 58.97, 58.97, 59.11, 59.86 | mean AP: 0.5922463557960481
range (30, 50) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.10, 0.27, 1.10 | 43.98, 43.98, 44.05, 47.42 | mean AP: 0.4485781091026913
range (50, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.13, 0.29, 1.40 | 16.92, 16.92, 17.14, 17.41 | mean AP: 0.17096571289592324
range (0, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.09, 0.27, 0.96 | 44.50, 44.50, 44.61, 46.24 | mean AP: 0.4496130827987812
--------------average performance-------------
trans_err:	 0.7128
scale_err:	 0.7269
orient_err:	 0.8818
mAP:	 0.1668
NDS:	 0.1965
--------------table log summary-------------
***car
match 1.0m:	(0, 30), (30, 50), (50, 80), (0, 80)
73.20, 53.36, 33.72, 54.36
***pedestrian
match 1.0m:	(0, 30), (30, 50), (50, 80), (0, 80)
58.97, 43.98, 16.92, 44.50

2023-03-03 22:43:03,100   INFO  Result is save to /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/eval/eval_with_train/epoch_50/val
2023-03-03 22:43:03,101   INFO  ****************Evaluation done.*****************
2023-03-03 22:43:03,111   INFO  Epoch 50 has been evaluated
2023-03-03 22:43:03,114   INFO  ==> Loading parameters from checkpoint /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/ckpt/checkpoint_epoch_60.pth to CPU
2023-03-03 22:43:03,222   INFO  ==> Checkpoint trained from version: pcdet+0.3.0+0000000
2023-03-03 22:43:04,454   INFO  ==> Done (loaded 502/502)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
      (3): Sigmoid()
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
2023-03-03 22:43:04,468   INFO  *************** EPOCH 60 EVALUATION *****************
eval:   0%|                                                                                       | 0/206 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
eval:   0%|                                                                | 0/206 [00:08<?, ?it/s, recall_0.3=(3, 3) / 5]eval:   0%|▎                                                       | 1/206 [00:08<29:56,  8.76s/it, recall_0.3=(3, 3) / 5]eval:   0%|▎                                                    | 1/206 [00:09<29:56,  8.76s/it, recall_0.3=(16, 16) / 23]eval:   1%|▌                                                    | 2/206 [00:09<14:10,  4.17s/it, recall_0.3=(16, 16) / 23]eval:   1%|▌                                                    | 2/206 [00:10<14:10,  4.17s/it, recall_0.3=(21, 21) / 30]eval:   1%|▊                                                    | 3/206 [00:10<09:11,  2.71s/it, recall_0.3=(21, 21) / 30]eval:   1%|▊                                                    | 3/206 [00:11<09:11,  2.71s/it, recall_0.3=(25, 25) / 36]eval:   2%|█                                                    | 4/206 [00:11<06:54,  2.05s/it, recall_0.3=(25, 25) / 36]eval:   2%|█                                                    | 4/206 [00:16<06:54,  2.05s/it, recall_0.3=(30, 30) / 43]eval:   2%|█▎                                                   | 5/206 [00:16<10:12,  3.05s/it, recall_0.3=(30, 30) / 43]eval:   2%|█▎                                                   | 5/206 [00:17<10:12,  3.05s/it, recall_0.3=(33, 33) / 48]eval:   3%|█▌                                                   | 6/206 [00:17<08:03,  2.42s/it, recall_0.3=(33, 33) / 48]eval:   3%|█▌                                                   | 6/206 [00:18<08:03,  2.42s/it, recall_0.3=(37, 37) / 53]eval:   3%|█▊                                                   | 7/206 [00:18<06:39,  2.01s/it, recall_0.3=(37, 37) / 53]eval:   3%|█▊                                                   | 7/206 [00:19<06:39,  2.01s/it, recall_0.3=(37, 37) / 56]eval:   4%|██                                                   | 8/206 [00:20<05:40,  1.72s/it, recall_0.3=(37, 37) / 56]eval:   4%|██                                                   | 8/206 [00:20<05:40,  1.72s/it, recall_0.3=(37, 37) / 56]eval:   4%|██▎                                                  | 9/206 [00:20<04:47,  1.46s/it, recall_0.3=(37, 37) / 56]eval:   4%|██▎                                                  | 9/206 [00:21<04:47,  1.46s/it, recall_0.3=(37, 37) / 56]eval:   5%|██▌                                                 | 10/206 [00:21<04:13,  1.29s/it, recall_0.3=(37, 37) / 56]eval:   5%|██▌                                                 | 10/206 [00:22<04:13,  1.29s/it, recall_0.3=(38, 38) / 58]eval:   5%|██▊                                                 | 11/206 [00:22<03:54,  1.20s/it, recall_0.3=(38, 38) / 58]eval:   5%|██▊                                                 | 11/206 [00:23<03:54,  1.20s/it, recall_0.3=(38, 38) / 61]eval:   6%|███                                                 | 12/206 [00:23<03:37,  1.12s/it, recall_0.3=(38, 38) / 61]eval:   6%|███                                                 | 12/206 [00:25<03:37,  1.12s/it, recall_0.3=(41, 41) / 67]eval:   6%|███▎                                                | 13/206 [00:25<03:52,  1.20s/it, recall_0.3=(41, 41) / 67]eval:   6%|███▎                                                | 13/206 [00:26<03:52,  1.20s/it, recall_0.3=(42, 43) / 72]eval:   7%|███▌                                                | 14/206 [00:26<03:47,  1.19s/it, recall_0.3=(42, 43) / 72]eval:   7%|███▌                                                | 14/206 [00:27<03:47,  1.19s/it, recall_0.3=(43, 44) / 75]eval:   7%|███▊                                                | 15/206 [00:27<03:53,  1.22s/it, recall_0.3=(43, 44) / 75]eval:   7%|███▊                                                | 15/206 [00:28<03:53,  1.22s/it, recall_0.3=(45, 46) / 77]eval:   8%|████                                                | 16/206 [00:28<03:41,  1.17s/it, recall_0.3=(45, 46) / 77]eval:   8%|████                                                | 16/206 [00:31<03:41,  1.17s/it, recall_0.3=(45, 46) / 80]eval:   8%|████▎                                               | 17/206 [00:31<05:38,  1.79s/it, recall_0.3=(45, 46) / 80]eval:   8%|████▎                                               | 17/206 [00:32<05:38,  1.79s/it, recall_0.3=(46, 47) / 83]eval:   9%|████▌                                               | 18/206 [00:32<04:49,  1.54s/it, recall_0.3=(46, 47) / 83]eval:   9%|████▌                                               | 18/206 [00:34<04:49,  1.54s/it, recall_0.3=(47, 48) / 85]eval:   9%|████▊                                               | 19/206 [00:34<04:37,  1.49s/it, recall_0.3=(47, 48) / 85]eval:   9%|████▊                                               | 19/206 [00:35<04:37,  1.49s/it, recall_0.3=(48, 49) / 87]eval:  10%|█████                                               | 20/206 [00:35<04:25,  1.43s/it, recall_0.3=(48, 49) / 87]eval:  10%|█████                                               | 20/206 [00:36<04:25,  1.43s/it, recall_0.3=(52, 53) / 92]eval:  10%|█████▎                                              | 21/206 [00:36<04:25,  1.44s/it, recall_0.3=(52, 53) / 92]eval:  10%|█████▏                                             | 21/206 [00:38<04:25,  1.44s/it, recall_0.3=(58, 59) / 103]eval:  11%|█████▍                                             | 22/206 [00:38<04:13,  1.38s/it, recall_0.3=(58, 59) / 103]eval:  11%|█████▍                                             | 22/206 [00:39<04:13,  1.38s/it, recall_0.3=(68, 69) / 125]eval:  11%|█████▋                                             | 23/206 [00:39<03:49,  1.26s/it, recall_0.3=(68, 69) / 125]eval:  11%|█████▋                                             | 23/206 [00:40<03:49,  1.26s/it, recall_0.3=(74, 75) / 133]eval:  12%|█████▉                                             | 24/206 [00:40<03:28,  1.14s/it, recall_0.3=(74, 75) / 133]eval:  12%|█████▉                                             | 24/206 [00:40<03:28,  1.14s/it, recall_0.3=(84, 85) / 145]eval:  12%|██████▏                                            | 25/206 [00:40<02:57,  1.02it/s, recall_0.3=(84, 85) / 145]eval:  12%|██████▏                                            | 25/206 [00:41<02:57,  1.02it/s, recall_0.3=(88, 89) / 153]eval:  13%|██████▍                                            | 26/206 [00:41<02:41,  1.11it/s, recall_0.3=(88, 89) / 153]eval:  13%|██████▍                                            | 26/206 [00:42<02:41,  1.11it/s, recall_0.3=(91, 92) / 156]eval:  13%|██████▋                                            | 27/206 [00:42<02:49,  1.06it/s, recall_0.3=(91, 92) / 156]eval:  13%|██████▋                                            | 27/206 [00:43<02:49,  1.06it/s, recall_0.3=(97, 98) / 163]eval:  14%|██████▉                                            | 28/206 [00:43<03:02,  1.02s/it, recall_0.3=(97, 98) / 163]eval:  14%|██████▋                                          | 28/206 [00:44<03:02,  1.02s/it, recall_0.3=(104, 105) / 171]eval:  14%|██████▉                                          | 29/206 [00:44<03:07,  1.06s/it, recall_0.3=(104, 105) / 171]eval:  14%|██████▉                                          | 29/206 [00:46<03:07,  1.06s/it, recall_0.3=(107, 108) / 174]eval:  15%|███████▏                                         | 30/206 [00:46<03:18,  1.13s/it, recall_0.3=(107, 108) / 174]eval:  15%|███████▏                                         | 30/206 [00:47<03:18,  1.13s/it, recall_0.3=(109, 110) / 177]eval:  15%|███████▎                                         | 31/206 [00:47<03:17,  1.13s/it, recall_0.3=(109, 110) / 177]eval:  15%|███████▎                                         | 31/206 [00:48<03:17,  1.13s/it, recall_0.3=(109, 110) / 179]eval:  16%|███████▌                                         | 32/206 [00:48<03:25,  1.18s/it, recall_0.3=(109, 110) / 179]eval:  16%|███████▌                                         | 32/206 [00:49<03:25,  1.18s/it, recall_0.3=(112, 113) / 182]eval:  16%|███████▊                                         | 33/206 [00:49<03:12,  1.11s/it, recall_0.3=(112, 113) / 182]eval:  16%|███████▊                                         | 33/206 [00:50<03:12,  1.11s/it, recall_0.3=(113, 114) / 184]eval:  17%|████████                                         | 34/206 [00:50<02:46,  1.03it/s, recall_0.3=(113, 114) / 184]eval:  17%|████████                                         | 34/206 [00:50<02:46,  1.03it/s, recall_0.3=(113, 114) / 184]eval:  17%|████████▎                                        | 35/206 [00:50<02:31,  1.13it/s, recall_0.3=(113, 114) / 184]eval:  17%|████████▎                                        | 35/206 [00:54<02:31,  1.13it/s, recall_0.3=(116, 117) / 189]eval:  17%|████████▌                                        | 36/206 [00:54<05:05,  1.79s/it, recall_0.3=(116, 117) / 189]eval:  17%|████████▌                                        | 36/206 [00:55<05:05,  1.79s/it, recall_0.3=(116, 117) / 189]eval:  18%|████████▊                                        | 37/206 [00:55<04:25,  1.57s/it, recall_0.3=(116, 117) / 189]eval:  18%|████████▊                                        | 37/206 [00:56<04:25,  1.57s/it, recall_0.3=(116, 117) / 189]eval:  18%|█████████                                        | 38/206 [00:56<03:57,  1.41s/it, recall_0.3=(116, 117) / 189]eval:  18%|█████████                                        | 38/206 [00:57<03:57,  1.41s/it, recall_0.3=(116, 117) / 189]eval:  19%|█████████▎                                       | 39/206 [00:57<03:41,  1.33s/it, recall_0.3=(116, 117) / 189]eval:  19%|█████████▎                                       | 39/206 [01:01<03:41,  1.33s/it, recall_0.3=(116, 117) / 189]eval:  19%|█████████▌                                       | 40/206 [01:01<05:22,  1.94s/it, recall_0.3=(116, 117) / 189]eval:  19%|█████████▌                                       | 40/206 [01:02<05:22,  1.94s/it, recall_0.3=(117, 118) / 193]eval:  20%|█████████▊                                       | 41/206 [01:02<04:31,  1.65s/it, recall_0.3=(117, 118) / 193]eval:  20%|█████████▊                                       | 41/206 [01:03<04:31,  1.65s/it, recall_0.3=(120, 121) / 197]eval:  20%|█████████▉                                       | 42/206 [01:03<04:07,  1.51s/it, recall_0.3=(120, 121) / 197]eval:  20%|█████████▉                                       | 42/206 [01:04<04:07,  1.51s/it, recall_0.3=(129, 130) / 220]eval:  21%|██████████▏                                      | 43/206 [01:04<03:42,  1.36s/it, recall_0.3=(129, 130) / 220]eval:  21%|██████████▏                                      | 43/206 [01:08<03:42,  1.36s/it, recall_0.3=(143, 144) / 236]eval:  21%|██████████▍                                      | 44/206 [01:08<05:32,  2.05s/it, recall_0.3=(143, 144) / 236]eval:  21%|██████████▍                                      | 44/206 [01:09<05:32,  2.05s/it, recall_0.3=(155, 156) / 255]eval:  22%|██████████▋                                      | 45/206 [01:09<04:36,  1.72s/it, recall_0.3=(155, 156) / 255]eval:  22%|██████████▋                                      | 45/206 [01:09<04:36,  1.72s/it, recall_0.3=(159, 160) / 263]eval:  22%|██████████▉                                      | 46/206 [01:09<03:57,  1.48s/it, recall_0.3=(159, 160) / 263]eval:  22%|██████████▉                                      | 46/206 [01:10<03:57,  1.48s/it, recall_0.3=(165, 167) / 274]eval:  23%|███████████▏                                     | 47/206 [01:10<03:28,  1.31s/it, recall_0.3=(165, 167) / 274]eval:  23%|███████████▏                                     | 47/206 [01:15<03:28,  1.31s/it, recall_0.3=(171, 173) / 284]eval:  23%|███████████▍                                     | 48/206 [01:15<05:46,  2.20s/it, recall_0.3=(171, 173) / 284]eval:  23%|███████████▍                                     | 48/206 [01:16<05:46,  2.20s/it, recall_0.3=(176, 178) / 290]eval:  24%|███████████▋                                     | 49/206 [01:16<04:44,  1.81s/it, recall_0.3=(176, 178) / 290]eval:  24%|███████████▋                                     | 49/206 [01:16<04:44,  1.81s/it, recall_0.3=(177, 179) / 292]eval:  24%|███████████▉                                     | 50/206 [01:16<03:59,  1.54s/it, recall_0.3=(177, 179) / 292]eval:  24%|███████████▉                                     | 50/206 [01:18<03:59,  1.54s/it, recall_0.3=(179, 181) / 296]eval:  25%|████████████▏                                    | 51/206 [01:18<03:43,  1.44s/it, recall_0.3=(179, 181) / 296]eval:  25%|████████████▏                                    | 51/206 [01:20<03:43,  1.44s/it, recall_0.3=(181, 183) / 300]eval:  25%|████████████▎                                    | 52/206 [01:20<04:08,  1.61s/it, recall_0.3=(181, 183) / 300]eval:  25%|████████████▎                                    | 52/206 [01:21<04:08,  1.61s/it, recall_0.3=(186, 188) / 308]eval:  26%|████████████▌                                    | 53/206 [01:21<03:43,  1.46s/it, recall_0.3=(186, 188) / 308]eval:  26%|████████████▌                                    | 53/206 [01:22<03:43,  1.46s/it, recall_0.3=(189, 191) / 314]eval:  26%|████████████▊                                    | 54/206 [01:22<03:12,  1.27s/it, recall_0.3=(189, 191) / 314]eval:  26%|████████████▊                                    | 54/206 [01:22<03:12,  1.27s/it, recall_0.3=(190, 192) / 317]eval:  27%|█████████████                                    | 55/206 [01:22<02:44,  1.09s/it, recall_0.3=(190, 192) / 317]eval:  27%|█████████████                                    | 55/206 [01:24<02:44,  1.09s/it, recall_0.3=(199, 201) / 331]eval:  27%|█████████████▎                                   | 56/206 [01:24<03:23,  1.36s/it, recall_0.3=(199, 201) / 331]eval:  27%|█████████████▎                                   | 56/206 [01:25<03:23,  1.36s/it, recall_0.3=(200, 202) / 335]eval:  28%|█████████████▌                                   | 57/206 [01:25<03:04,  1.24s/it, recall_0.3=(200, 202) / 335]eval:  28%|█████████████▌                                   | 57/206 [01:26<03:04,  1.24s/it, recall_0.3=(201, 202) / 337]eval:  28%|█████████████▊                                   | 58/206 [01:26<02:57,  1.20s/it, recall_0.3=(201, 202) / 337]eval:  28%|█████████████▊                                   | 58/206 [01:27<02:57,  1.20s/it, recall_0.3=(206, 207) / 349]eval:  29%|██████████████                                   | 59/206 [01:27<02:53,  1.18s/it, recall_0.3=(206, 207) / 349]eval:  29%|██████████████                                   | 59/206 [01:28<02:53,  1.18s/it, recall_0.3=(216, 217) / 362]eval:  29%|██████████████▎                                  | 60/206 [01:28<02:42,  1.11s/it, recall_0.3=(216, 217) / 362]eval:  29%|██████████████▎                                  | 60/206 [01:30<02:42,  1.11s/it, recall_0.3=(228, 229) / 374]eval:  30%|██████████████▌                                  | 61/206 [01:30<02:44,  1.13s/it, recall_0.3=(228, 229) / 374]eval:  30%|██████████████▌                                  | 61/206 [01:31<02:44,  1.13s/it, recall_0.3=(239, 240) / 391]eval:  30%|██████████████▋                                  | 62/206 [01:31<02:38,  1.10s/it, recall_0.3=(239, 240) / 391]eval:  30%|██████████████▋                                  | 62/206 [01:32<02:38,  1.10s/it, recall_0.3=(249, 250) / 408]eval:  31%|██████████████▉                                  | 63/206 [01:32<02:37,  1.10s/it, recall_0.3=(249, 250) / 408]eval:  31%|██████████████▉                                  | 63/206 [01:36<02:37,  1.10s/it, recall_0.3=(257, 258) / 422]eval:  31%|███████████████▏                                 | 64/206 [01:36<04:50,  2.04s/it, recall_0.3=(257, 258) / 422]eval:  31%|███████████████▏                                 | 64/206 [01:37<04:50,  2.04s/it, recall_0.3=(271, 272) / 438]eval:  32%|███████████████▍                                 | 65/206 [01:37<04:04,  1.73s/it, recall_0.3=(271, 272) / 438]eval:  32%|███████████████▍                                 | 65/206 [01:38<04:04,  1.73s/it, recall_0.3=(280, 281) / 450]eval:  32%|███████████████▋                                 | 66/206 [01:38<03:34,  1.53s/it, recall_0.3=(280, 281) / 450]eval:  32%|███████████████▋                                 | 66/206 [01:39<03:34,  1.53s/it, recall_0.3=(288, 289) / 464]eval:  33%|███████████████▉                                 | 67/206 [01:39<03:16,  1.42s/it, recall_0.3=(288, 289) / 464]eval:  33%|███████████████▉                                 | 67/206 [01:43<03:16,  1.42s/it, recall_0.3=(290, 291) / 468]eval:  33%|████████████████▏                                | 68/206 [01:43<05:12,  2.26s/it, recall_0.3=(290, 291) / 468]eval:  33%|████████████████▏                                | 68/206 [01:44<05:12,  2.26s/it, recall_0.3=(291, 292) / 471]eval:  33%|████████████████▍                                | 69/206 [01:44<04:17,  1.88s/it, recall_0.3=(291, 292) / 471]eval:  33%|████████████████▍                                | 69/206 [01:46<04:17,  1.88s/it, recall_0.3=(292, 293) / 473]eval:  34%|████████████████▋                                | 70/206 [01:46<03:52,  1.71s/it, recall_0.3=(292, 293) / 473]eval:  34%|████████████████▋                                | 70/206 [01:47<03:52,  1.71s/it, recall_0.3=(294, 295) / 476]eval:  34%|████████████████▉                                | 71/206 [01:47<03:22,  1.50s/it, recall_0.3=(294, 295) / 476]eval:  34%|████████████████▉                                | 71/206 [01:50<03:22,  1.50s/it, recall_0.3=(295, 296) / 479]eval:  35%|█████████████████▏                               | 72/206 [01:50<04:29,  2.01s/it, recall_0.3=(295, 296) / 479]eval:  35%|█████████████████▏                               | 72/206 [01:51<04:29,  2.01s/it, recall_0.3=(295, 296) / 479]eval:  35%|█████████████████▎                               | 73/206 [01:51<03:43,  1.68s/it, recall_0.3=(295, 296) / 479]eval:  35%|█████████████████▎                               | 73/206 [01:52<03:43,  1.68s/it, recall_0.3=(295, 296) / 481]eval:  36%|█████████████████▌                               | 74/206 [01:52<03:11,  1.45s/it, recall_0.3=(295, 296) / 481]eval:  36%|█████████████████▌                               | 74/206 [01:53<03:11,  1.45s/it, recall_0.3=(296, 297) / 484]eval:  36%|█████████████████▊                               | 75/206 [01:53<02:57,  1.35s/it, recall_0.3=(296, 297) / 484]eval:  36%|█████████████████▊                               | 75/206 [01:54<02:57,  1.35s/it, recall_0.3=(298, 299) / 488]eval:  37%|██████████████████                               | 76/206 [01:54<02:52,  1.33s/it, recall_0.3=(298, 299) / 488]eval:  37%|██████████████████                               | 76/206 [01:55<02:52,  1.33s/it, recall_0.3=(299, 300) / 492]eval:  37%|██████████████████▎                              | 77/206 [01:55<02:35,  1.21s/it, recall_0.3=(299, 300) / 492]eval:  37%|██████████████████▎                              | 77/206 [01:56<02:35,  1.21s/it, recall_0.3=(300, 301) / 494]eval:  38%|██████████████████▌                              | 78/206 [01:56<02:23,  1.12s/it, recall_0.3=(300, 301) / 494]eval:  38%|██████████████████▌                              | 78/206 [01:57<02:23,  1.12s/it, recall_0.3=(306, 307) / 504]eval:  38%|██████████████████▊                              | 79/206 [01:57<02:21,  1.11s/it, recall_0.3=(306, 307) / 504]eval:  38%|██████████████████▊                              | 79/206 [02:00<02:21,  1.11s/it, recall_0.3=(310, 311) / 510]eval:  39%|███████████████████                              | 80/206 [02:00<03:13,  1.53s/it, recall_0.3=(310, 311) / 510]eval:  39%|███████████████████                              | 80/206 [02:00<03:13,  1.53s/it, recall_0.3=(315, 316) / 516]eval:  39%|███████████████████▎                             | 81/206 [02:00<02:42,  1.30s/it, recall_0.3=(315, 316) / 516]eval:  39%|███████████████████▎                             | 81/206 [02:01<02:42,  1.30s/it, recall_0.3=(322, 323) / 523]eval:  40%|███████████████████▌                             | 82/206 [02:01<02:29,  1.20s/it, recall_0.3=(322, 323) / 523]eval:  40%|███████████████████▌                             | 82/206 [02:02<02:29,  1.20s/it, recall_0.3=(328, 329) / 529]eval:  40%|███████████████████▋                             | 83/206 [02:02<02:21,  1.15s/it, recall_0.3=(328, 329) / 529]eval:  40%|███████████████████▋                             | 83/206 [02:03<02:21,  1.15s/it, recall_0.3=(339, 340) / 553]eval:  41%|███████████████████▉                             | 84/206 [02:03<02:18,  1.14s/it, recall_0.3=(339, 340) / 553]eval:  41%|███████████████████▉                             | 84/206 [02:05<02:18,  1.14s/it, recall_0.3=(353, 354) / 572]eval:  41%|████████████████████▏                            | 85/206 [02:05<02:46,  1.38s/it, recall_0.3=(353, 354) / 572]eval:  41%|████████████████████▏                            | 85/206 [02:06<02:46,  1.38s/it, recall_0.3=(366, 367) / 589]eval:  42%|████████████████████▍                            | 86/206 [02:06<02:28,  1.24s/it, recall_0.3=(366, 367) / 589]eval:  42%|████████████████████▍                            | 86/206 [02:07<02:28,  1.24s/it, recall_0.3=(374, 375) / 601]eval:  42%|████████████████████▋                            | 87/206 [02:07<02:19,  1.17s/it, recall_0.3=(374, 375) / 601]eval:  42%|████████████████████▋                            | 87/206 [02:09<02:19,  1.17s/it, recall_0.3=(384, 386) / 616]eval:  43%|████████████████████▉                            | 88/206 [02:09<02:41,  1.37s/it, recall_0.3=(384, 386) / 616]eval:  43%|████████████████████▉                            | 88/206 [02:13<02:41,  1.37s/it, recall_0.3=(389, 392) / 625]eval:  43%|█████████████████████▏                           | 89/206 [02:13<04:14,  2.18s/it, recall_0.3=(389, 392) / 625]eval:  43%|█████████████████████▏                           | 89/206 [02:14<04:14,  2.18s/it, recall_0.3=(392, 395) / 632]eval:  44%|█████████████████████▍                           | 90/206 [02:14<03:34,  1.85s/it, recall_0.3=(392, 395) / 632]eval:  44%|█████████████████████▍                           | 90/206 [02:15<03:34,  1.85s/it, recall_0.3=(395, 398) / 636]eval:  44%|█████████████████████▋                           | 91/206 [02:15<02:50,  1.48s/it, recall_0.3=(395, 398) / 636]eval:  44%|█████████████████████▋                           | 91/206 [02:16<02:50,  1.48s/it, recall_0.3=(396, 399) / 638]eval:  45%|█████████████████████▉                           | 92/206 [02:16<02:26,  1.29s/it, recall_0.3=(396, 399) / 638]eval:  45%|█████████████████████▉                           | 92/206 [02:17<02:26,  1.29s/it, recall_0.3=(398, 401) / 641]eval:  45%|██████████████████████                           | 93/206 [02:17<02:09,  1.15s/it, recall_0.3=(398, 401) / 641]eval:  45%|██████████████████████                           | 93/206 [02:18<02:09,  1.15s/it, recall_0.3=(401, 404) / 644]eval:  46%|██████████████████████▎                          | 94/206 [02:18<02:00,  1.07s/it, recall_0.3=(401, 404) / 644]eval:  46%|██████████████████████▎                          | 94/206 [02:18<02:00,  1.07s/it, recall_0.3=(404, 407) / 647]eval:  46%|██████████████████████▌                          | 95/206 [02:18<01:50,  1.01it/s, recall_0.3=(404, 407) / 647]eval:  46%|██████████████████████▌                          | 95/206 [02:19<01:50,  1.01it/s, recall_0.3=(411, 414) / 655]eval:  47%|██████████████████████▊                          | 96/206 [02:19<01:43,  1.07it/s, recall_0.3=(411, 414) / 655]eval:  47%|██████████████████████▊                          | 96/206 [02:20<01:43,  1.07it/s, recall_0.3=(415, 418) / 659]eval:  47%|███████████████████████                          | 97/206 [02:20<01:48,  1.01it/s, recall_0.3=(415, 418) / 659]eval:  47%|███████████████████████                          | 97/206 [02:22<01:48,  1.01it/s, recall_0.3=(416, 419) / 661]eval:  48%|███████████████████████▎                         | 98/206 [02:22<01:58,  1.09s/it, recall_0.3=(416, 419) / 661]eval:  48%|███████████████████████▎                         | 98/206 [02:22<01:58,  1.09s/it, recall_0.3=(421, 424) / 667]eval:  48%|███████████████████████▌                         | 99/206 [02:22<01:48,  1.01s/it, recall_0.3=(421, 424) / 667]eval:  48%|███████████████████████▌                         | 99/206 [02:23<01:48,  1.01s/it, recall_0.3=(423, 426) / 670]eval:  49%|███████████████████████▎                        | 100/206 [02:23<01:43,  1.02it/s, recall_0.3=(423, 426) / 670]eval:  49%|███████████████████████▎                        | 100/206 [02:27<01:43,  1.02it/s, recall_0.3=(425, 428) / 673]eval:  49%|███████████████████████▌                        | 101/206 [02:27<03:08,  1.80s/it, recall_0.3=(425, 428) / 673]eval:  49%|███████████████████████▌                        | 101/206 [02:28<03:08,  1.80s/it, recall_0.3=(429, 432) / 681]eval:  50%|███████████████████████▊                        | 102/206 [02:28<02:43,  1.57s/it, recall_0.3=(429, 432) / 681]eval:  50%|███████████████████████▊                        | 102/206 [02:29<02:43,  1.57s/it, recall_0.3=(439, 442) / 700]eval:  50%|████████████████████████                        | 103/206 [02:29<02:18,  1.34s/it, recall_0.3=(439, 442) / 700]eval:  50%|████████████████████████                        | 103/206 [02:30<02:18,  1.34s/it, recall_0.3=(451, 454) / 717]eval:  50%|████████████████████████▏                       | 104/206 [02:30<02:12,  1.30s/it, recall_0.3=(451, 454) / 717]eval:  50%|████████████████████████▏                       | 104/206 [02:34<02:12,  1.30s/it, recall_0.3=(465, 469) / 743]eval:  51%|████████████████████████▍                       | 105/206 [02:34<03:22,  2.01s/it, recall_0.3=(465, 469) / 743]eval:  51%|████████████████████████▍                       | 105/206 [02:35<03:22,  2.01s/it, recall_0.3=(468, 472) / 752]eval:  51%|████████████████████████▋                       | 106/206 [02:35<02:51,  1.72s/it, recall_0.3=(468, 472) / 752]eval:  51%|████████████████████████▋                       | 106/206 [02:36<02:51,  1.72s/it, recall_0.3=(477, 481) / 763]eval:  52%|████████████████████████▉                       | 107/206 [02:36<02:28,  1.50s/it, recall_0.3=(477, 481) / 763]eval:  52%|████████████████████████▉                       | 107/206 [02:37<02:28,  1.50s/it, recall_0.3=(483, 487) / 772]eval:  52%|█████████████████████████▏                      | 108/206 [02:37<02:13,  1.37s/it, recall_0.3=(483, 487) / 772]eval:  52%|█████████████████████████▏                      | 108/206 [02:41<02:13,  1.37s/it, recall_0.3=(490, 494) / 781]eval:  53%|█████████████████████████▍                      | 109/206 [02:41<03:32,  2.19s/it, recall_0.3=(490, 494) / 781]eval:  53%|█████████████████████████▍                      | 109/206 [02:42<03:32,  2.19s/it, recall_0.3=(492, 496) / 784]eval:  53%|█████████████████████████▋                      | 110/206 [02:42<02:56,  1.84s/it, recall_0.3=(492, 496) / 784]eval:  53%|█████████████████████████▋                      | 110/206 [02:43<02:56,  1.84s/it, recall_0.3=(496, 500) / 790]eval:  54%|█████████████████████████▊                      | 111/206 [02:43<02:29,  1.57s/it, recall_0.3=(496, 500) / 790]eval:  54%|█████████████████████████▊                      | 111/206 [02:44<02:29,  1.57s/it, recall_0.3=(496, 500) / 795]eval:  54%|██████████████████████████                      | 112/206 [02:44<02:13,  1.42s/it, recall_0.3=(496, 500) / 795]eval:  54%|██████████████████████████                      | 112/206 [02:45<02:13,  1.42s/it, recall_0.3=(497, 501) / 800]eval:  55%|██████████████████████████▎                     | 113/206 [02:45<02:02,  1.31s/it, recall_0.3=(497, 501) / 800]eval:  55%|██████████████████████████▎                     | 113/206 [02:46<02:02,  1.31s/it, recall_0.3=(498, 502) / 805]eval:  55%|██████████████████████████▌                     | 114/206 [02:46<01:47,  1.17s/it, recall_0.3=(498, 502) / 805]eval:  55%|██████████████████████████▌                     | 114/206 [02:47<01:47,  1.17s/it, recall_0.3=(501, 505) / 812]eval:  56%|██████████████████████████▊                     | 115/206 [02:47<01:43,  1.13s/it, recall_0.3=(501, 505) / 812]eval:  56%|██████████████████████████▊                     | 115/206 [02:48<01:43,  1.13s/it, recall_0.3=(503, 507) / 816]eval:  56%|███████████████████████████                     | 116/206 [02:48<01:38,  1.10s/it, recall_0.3=(503, 507) / 816]eval:  56%|███████████████████████████                     | 116/206 [02:49<01:38,  1.10s/it, recall_0.3=(508, 512) / 821]eval:  57%|███████████████████████████▎                    | 117/206 [02:49<01:35,  1.08s/it, recall_0.3=(508, 512) / 821]eval:  57%|███████████████████████████▎                    | 117/206 [02:50<01:35,  1.08s/it, recall_0.3=(509, 513) / 824]eval:  57%|███████████████████████████▍                    | 118/206 [02:50<01:34,  1.08s/it, recall_0.3=(509, 513) / 824]eval:  57%|███████████████████████████▍                    | 118/206 [02:51<01:34,  1.08s/it, recall_0.3=(512, 516) / 828]eval:  58%|███████████████████████████▋                    | 119/206 [02:51<01:32,  1.06s/it, recall_0.3=(512, 516) / 828]eval:  58%|███████████████████████████▋                    | 119/206 [02:52<01:32,  1.06s/it, recall_0.3=(521, 525) / 840]eval:  58%|███████████████████████████▉                    | 120/206 [02:52<01:24,  1.02it/s, recall_0.3=(521, 525) / 840]eval:  58%|███████████████████████████▉                    | 120/206 [02:55<01:24,  1.02it/s, recall_0.3=(533, 537) / 852]eval:  59%|████████████████████████████▏                   | 121/206 [02:55<02:19,  1.64s/it, recall_0.3=(533, 537) / 852]eval:  59%|████████████████████████████▏                   | 121/206 [02:56<02:19,  1.64s/it, recall_0.3=(542, 546) / 867]eval:  59%|████████████████████████████▍                   | 122/206 [02:56<02:01,  1.44s/it, recall_0.3=(542, 546) / 867]eval:  59%|████████████████████████████▍                   | 122/206 [02:57<02:01,  1.44s/it, recall_0.3=(552, 556) / 900]eval:  60%|████████████████████████████▋                   | 123/206 [02:57<01:50,  1.34s/it, recall_0.3=(552, 556) / 900]eval:  60%|████████████████████████████▋                   | 123/206 [02:58<01:50,  1.34s/it, recall_0.3=(565, 569) / 923]eval:  60%|████████████████████████████▉                   | 124/206 [02:58<01:40,  1.23s/it, recall_0.3=(565, 569) / 923]eval:  60%|████████████████████████████▉                   | 124/206 [03:02<01:40,  1.23s/it, recall_0.3=(575, 579) / 943]eval:  61%|█████████████████████████████▏                  | 125/206 [03:02<02:51,  2.12s/it, recall_0.3=(575, 579) / 943]eval:  61%|█████████████████████████████▏                  | 125/206 [03:03<02:51,  2.12s/it, recall_0.3=(579, 583) / 947]eval:  61%|█████████████████████████████▎                  | 126/206 [03:03<02:27,  1.85s/it, recall_0.3=(579, 583) / 947]eval:  61%|█████████████████████████████▎                  | 126/206 [03:05<02:27,  1.85s/it, recall_0.3=(584, 588) / 954]eval:  62%|█████████████████████████████▌                  | 127/206 [03:05<02:10,  1.65s/it, recall_0.3=(584, 588) / 954]eval:  62%|█████████████████████████████▌                  | 127/206 [03:06<02:10,  1.65s/it, recall_0.3=(589, 593) / 962]eval:  62%|█████████████████████████████▊                  | 128/206 [03:06<02:00,  1.55s/it, recall_0.3=(589, 593) / 962]eval:  62%|█████████████████████████████▊                  | 128/206 [03:09<02:00,  1.55s/it, recall_0.3=(594, 598) / 970]eval:  63%|██████████████████████████████                  | 129/206 [03:09<02:36,  2.03s/it, recall_0.3=(594, 598) / 970]eval:  63%|██████████████████████████████                  | 129/206 [03:10<02:36,  2.03s/it, recall_0.3=(596, 600) / 976]eval:  63%|██████████████████████████████▎                 | 130/206 [03:10<02:09,  1.71s/it, recall_0.3=(596, 600) / 976]eval:  63%|██████████████████████████████▎                 | 130/206 [03:11<02:09,  1.71s/it, recall_0.3=(597, 601) / 978]eval:  64%|██████████████████████████████▌                 | 131/206 [03:11<01:47,  1.43s/it, recall_0.3=(597, 601) / 978]eval:  64%|██████████████████████████████▌                 | 131/206 [03:12<01:47,  1.43s/it, recall_0.3=(597, 602) / 980]eval:  64%|██████████████████████████████▊                 | 132/206 [03:12<01:32,  1.25s/it, recall_0.3=(597, 602) / 980]eval:  64%|██████████████████████████████▊                 | 132/206 [03:15<01:32,  1.25s/it, recall_0.3=(598, 603) / 984]eval:  65%|██████████████████████████████▉                 | 133/206 [03:15<02:07,  1.75s/it, recall_0.3=(598, 603) / 984]eval:  65%|██████████████████████████████▉                 | 133/206 [03:16<02:07,  1.75s/it, recall_0.3=(598, 603) / 987]eval:  65%|███████████████████████████████▏                | 134/206 [03:16<01:47,  1.49s/it, recall_0.3=(598, 603) / 987]eval:  65%|███████████████████████████████▏                | 134/206 [03:17<01:47,  1.49s/it, recall_0.3=(602, 607) / 997]eval:  66%|███████████████████████████████▍                | 135/206 [03:17<01:35,  1.35s/it, recall_0.3=(602, 607) / 997]eval:  66%|███████████████████████████████▍                | 135/206 [03:18<01:35,  1.35s/it, recall_0.3=(602, 607) / 999]eval:  66%|███████████████████████████████▋                | 136/206 [03:18<01:28,  1.27s/it, recall_0.3=(602, 607) / 999]eval:  66%|███████████████████████████████                | 136/206 [03:19<01:28,  1.27s/it, recall_0.3=(604, 609) / 1004]eval:  67%|███████████████████████████████▎               | 137/206 [03:19<01:25,  1.24s/it, recall_0.3=(604, 609) / 1004]eval:  67%|███████████████████████████████▎               | 137/206 [03:20<01:25,  1.24s/it, recall_0.3=(604, 609) / 1009]eval:  67%|███████████████████████████████▍               | 138/206 [03:20<01:19,  1.17s/it, recall_0.3=(604, 609) / 1009]eval:  67%|███████████████████████████████▍               | 138/206 [03:21<01:19,  1.17s/it, recall_0.3=(608, 613) / 1015]eval:  67%|███████████████████████████████▋               | 139/206 [03:21<01:15,  1.13s/it, recall_0.3=(608, 613) / 1015]eval:  67%|███████████████████████████████▋               | 139/206 [03:22<01:15,  1.13s/it, recall_0.3=(615, 620) / 1026]eval:  68%|███████████████████████████████▉               | 140/206 [03:22<01:12,  1.10s/it, recall_0.3=(615, 620) / 1026]eval:  68%|███████████████████████████████▉               | 140/206 [03:24<01:12,  1.10s/it, recall_0.3=(624, 629) / 1040]eval:  68%|████████████████████████████████▏              | 141/206 [03:24<01:27,  1.35s/it, recall_0.3=(624, 629) / 1040]eval:  68%|████████████████████████████████▏              | 141/206 [03:25<01:27,  1.35s/it, recall_0.3=(635, 640) / 1053]eval:  69%|████████████████████████████████▍              | 142/206 [03:25<01:24,  1.33s/it, recall_0.3=(635, 640) / 1053]eval:  69%|████████████████████████████████▍              | 142/206 [03:26<01:24,  1.33s/it, recall_0.3=(649, 654) / 1076]eval:  69%|████████████████████████████████▋              | 143/206 [03:26<01:18,  1.24s/it, recall_0.3=(649, 654) / 1076]eval:  69%|████████████████████████████████▋              | 143/206 [03:27<01:18,  1.24s/it, recall_0.3=(661, 666) / 1093]eval:  70%|████████████████████████████████▊              | 144/206 [03:27<01:11,  1.15s/it, recall_0.3=(661, 666) / 1093]eval:  70%|████████████████████████████████▊              | 144/206 [03:28<01:11,  1.15s/it, recall_0.3=(667, 672) / 1104]eval:  70%|█████████████████████████████████              | 145/206 [03:28<01:14,  1.21s/it, recall_0.3=(667, 672) / 1104]eval:  70%|█████████████████████████████████              | 145/206 [03:29<01:14,  1.21s/it, recall_0.3=(674, 679) / 1121]eval:  71%|█████████████████████████████████▎             | 146/206 [03:29<01:05,  1.10s/it, recall_0.3=(674, 679) / 1121]eval:  71%|█████████████████████████████████▎             | 146/206 [03:30<01:05,  1.10s/it, recall_0.3=(675, 680) / 1123]eval:  71%|█████████████████████████████████▌             | 147/206 [03:30<01:06,  1.13s/it, recall_0.3=(675, 680) / 1123]eval:  71%|█████████████████████████████████▌             | 147/206 [03:32<01:06,  1.13s/it, recall_0.3=(679, 684) / 1131]eval:  72%|█████████████████████████████████▊             | 148/206 [03:32<01:20,  1.40s/it, recall_0.3=(679, 684) / 1131]eval:  72%|█████████████████████████████████▊             | 148/206 [03:37<01:20,  1.40s/it, recall_0.3=(681, 686) / 1134]eval:  72%|█████████████████████████████████▉             | 149/206 [03:37<02:07,  2.23s/it, recall_0.3=(681, 686) / 1134]eval:  72%|█████████████████████████████████▉             | 149/206 [03:38<02:07,  2.23s/it, recall_0.3=(684, 689) / 1137]eval:  73%|██████████████████████████████████▏            | 150/206 [03:38<01:45,  1.88s/it, recall_0.3=(684, 689) / 1137]eval:  73%|██████████████████████████████████▏            | 150/206 [03:39<01:45,  1.88s/it, recall_0.3=(688, 693) / 1142]eval:  73%|██████████████████████████████████▍            | 151/206 [03:39<01:26,  1.56s/it, recall_0.3=(688, 693) / 1142]eval:  73%|██████████████████████████████████▍            | 151/206 [03:39<01:26,  1.56s/it, recall_0.3=(689, 694) / 1145]eval:  74%|██████████████████████████████████▋            | 152/206 [03:39<01:11,  1.33s/it, recall_0.3=(689, 694) / 1145]eval:  74%|██████████████████████████████████▋            | 152/206 [03:40<01:11,  1.33s/it, recall_0.3=(692, 697) / 1150]eval:  74%|██████████████████████████████████▉            | 153/206 [03:40<01:00,  1.14s/it, recall_0.3=(692, 697) / 1150]eval:  74%|██████████████████████████████████▉            | 153/206 [03:41<01:00,  1.14s/it, recall_0.3=(694, 699) / 1154]eval:  75%|███████████████████████████████████▏           | 154/206 [03:41<00:52,  1.00s/it, recall_0.3=(694, 699) / 1154]eval:  75%|███████████████████████████████████▏           | 154/206 [03:42<00:52,  1.00s/it, recall_0.3=(696, 701) / 1157]eval:  75%|███████████████████████████████████▎           | 155/206 [03:42<00:49,  1.03it/s, recall_0.3=(696, 701) / 1157]eval:  75%|███████████████████████████████████▎           | 155/206 [03:42<00:49,  1.03it/s, recall_0.3=(699, 704) / 1162]eval:  76%|███████████████████████████████████▌           | 156/206 [03:42<00:46,  1.08it/s, recall_0.3=(699, 704) / 1162]eval:  76%|███████████████████████████████████▌           | 156/206 [03:43<00:46,  1.08it/s, recall_0.3=(702, 707) / 1166]eval:  76%|███████████████████████████████████▊           | 157/206 [03:43<00:45,  1.07it/s, recall_0.3=(702, 707) / 1166]eval:  76%|███████████████████████████████████▊           | 157/206 [03:45<00:45,  1.07it/s, recall_0.3=(703, 708) / 1168]eval:  77%|████████████████████████████████████           | 158/206 [03:45<00:49,  1.02s/it, recall_0.3=(703, 708) / 1168]eval:  77%|████████████████████████████████████           | 158/206 [03:46<00:49,  1.02s/it, recall_0.3=(703, 708) / 1168]eval:  77%|████████████████████████████████████▎          | 159/206 [03:46<00:48,  1.03s/it, recall_0.3=(703, 708) / 1168]eval:  77%|████████████████████████████████████▎          | 159/206 [03:48<00:48,  1.03s/it, recall_0.3=(706, 711) / 1172]eval:  78%|████████████████████████████████████▌          | 160/206 [03:48<01:12,  1.58s/it, recall_0.3=(706, 711) / 1172]eval:  78%|████████████████████████████████████▌          | 160/206 [03:49<01:12,  1.58s/it, recall_0.3=(710, 715) / 1177]eval:  78%|████████████████████████████████████▋          | 161/206 [03:49<01:02,  1.38s/it, recall_0.3=(710, 715) / 1177]eval:  78%|████████████████████████████████████▋          | 161/206 [03:50<01:02,  1.38s/it, recall_0.3=(719, 724) / 1189]eval:  79%|████████████████████████████████████▉          | 162/206 [03:50<00:54,  1.24s/it, recall_0.3=(719, 724) / 1189]eval:  79%|████████████████████████████████████▉          | 162/206 [03:51<00:54,  1.24s/it, recall_0.3=(730, 735) / 1206]eval:  79%|█████████████████████████████████████▏         | 163/206 [03:51<00:47,  1.11s/it, recall_0.3=(730, 735) / 1206]eval:  79%|█████████████████████████████████████▏         | 163/206 [03:54<00:47,  1.11s/it, recall_0.3=(741, 746) / 1222]eval:  80%|█████████████████████████████████████▍         | 164/206 [03:54<01:03,  1.51s/it, recall_0.3=(741, 746) / 1222]eval:  80%|█████████████████████████████████████▍         | 164/206 [03:55<01:03,  1.51s/it, recall_0.3=(748, 753) / 1233]eval:  80%|█████████████████████████████████████▋         | 165/206 [03:55<00:56,  1.37s/it, recall_0.3=(748, 753) / 1233]eval:  80%|█████████████████████████████████████▋         | 165/206 [03:56<00:56,  1.37s/it, recall_0.3=(756, 761) / 1253]eval:  81%|█████████████████████████████████████▊         | 166/206 [03:56<00:50,  1.26s/it, recall_0.3=(756, 761) / 1253]eval:  81%|█████████████████████████████████████▊         | 166/206 [03:57<00:50,  1.26s/it, recall_0.3=(763, 768) / 1268]eval:  81%|██████████████████████████████████████         | 167/206 [03:57<00:45,  1.17s/it, recall_0.3=(763, 768) / 1268]eval:  81%|██████████████████████████████████████         | 167/206 [03:58<00:45,  1.17s/it, recall_0.3=(767, 772) / 1280]eval:  82%|██████████████████████████████████████▎        | 168/206 [03:58<00:52,  1.38s/it, recall_0.3=(767, 772) / 1280]eval:  82%|██████████████████████████████████████▎        | 168/206 [04:03<00:52,  1.38s/it, recall_0.3=(769, 774) / 1290]eval:  82%|██████████████████████████████████████▌        | 169/206 [04:03<01:28,  2.39s/it, recall_0.3=(769, 774) / 1290]eval:  82%|██████████████████████████████████████▌        | 169/206 [04:04<01:28,  2.39s/it, recall_0.3=(771, 776) / 1298]eval:  83%|██████████████████████████████████████▊        | 170/206 [04:04<01:11,  1.99s/it, recall_0.3=(771, 776) / 1298]eval:  83%|██████████████████████████████████████▊        | 170/206 [04:05<01:11,  1.99s/it, recall_0.3=(778, 783) / 1310]eval:  83%|███████████████████████████████████████        | 171/206 [04:05<00:59,  1.69s/it, recall_0.3=(778, 783) / 1310]eval:  83%|███████████████████████████████████████        | 171/206 [04:06<00:59,  1.69s/it, recall_0.3=(781, 787) / 1315]eval:  83%|███████████████████████████████████████▏       | 172/206 [04:06<00:52,  1.56s/it, recall_0.3=(781, 787) / 1315]eval:  83%|███████████████████████████████████████▏       | 172/206 [04:07<00:52,  1.56s/it, recall_0.3=(783, 789) / 1319]eval:  84%|███████████████████████████████████████▍       | 173/206 [04:07<00:44,  1.35s/it, recall_0.3=(783, 789) / 1319]eval:  84%|███████████████████████████████████████▍       | 173/206 [04:08<00:44,  1.35s/it, recall_0.3=(786, 792) / 1323]eval:  84%|███████████████████████████████████████▋       | 174/206 [04:08<00:41,  1.28s/it, recall_0.3=(786, 792) / 1323]eval:  84%|███████████████████████████████████████▋       | 174/206 [04:09<00:41,  1.28s/it, recall_0.3=(788, 794) / 1328]eval:  85%|███████████████████████████████████████▉       | 175/206 [04:09<00:36,  1.17s/it, recall_0.3=(788, 794) / 1328]eval:  85%|███████████████████████████████████████▉       | 175/206 [04:10<00:36,  1.17s/it, recall_0.3=(789, 795) / 1333]eval:  85%|████████████████████████████████████████▏      | 176/206 [04:10<00:33,  1.11s/it, recall_0.3=(789, 795) / 1333]eval:  85%|████████████████████████████████████████▏      | 176/206 [04:11<00:33,  1.11s/it, recall_0.3=(791, 797) / 1335]eval:  86%|████████████████████████████████████████▍      | 177/206 [04:11<00:31,  1.08s/it, recall_0.3=(791, 797) / 1335]eval:  86%|████████████████████████████████████████▍      | 177/206 [04:12<00:31,  1.08s/it, recall_0.3=(793, 799) / 1339]eval:  86%|████████████████████████████████████████▌      | 178/206 [04:12<00:29,  1.05s/it, recall_0.3=(793, 799) / 1339]eval:  86%|████████████████████████████████████████▌      | 178/206 [04:13<00:29,  1.05s/it, recall_0.3=(793, 799) / 1341]eval:  87%|████████████████████████████████████████▊      | 179/206 [04:13<00:28,  1.04s/it, recall_0.3=(793, 799) / 1341]eval:  87%|████████████████████████████████████████▊      | 179/206 [04:14<00:28,  1.04s/it, recall_0.3=(796, 802) / 1346]eval:  87%|█████████████████████████████████████████      | 180/206 [04:14<00:24,  1.07it/s, recall_0.3=(796, 802) / 1346]eval:  87%|█████████████████████████████████████████      | 180/206 [04:19<00:24,  1.07it/s, recall_0.3=(796, 802) / 1346]eval:  88%|█████████████████████████████████████████▎     | 181/206 [04:19<00:53,  2.12s/it, recall_0.3=(796, 802) / 1346]eval:  88%|█████████████████████████████████████████▎     | 181/206 [04:20<00:53,  2.12s/it, recall_0.3=(799, 805) / 1354]eval:  88%|█████████████████████████████████████████▌     | 182/206 [04:20<00:42,  1.77s/it, recall_0.3=(799, 805) / 1354]eval:  88%|█████████████████████████████████████████▌     | 182/206 [04:21<00:42,  1.77s/it, recall_0.3=(802, 808) / 1361]eval:  89%|█████████████████████████████████████████▊     | 183/206 [04:21<00:35,  1.55s/it, recall_0.3=(802, 808) / 1361]eval:  89%|█████████████████████████████████████████▊     | 183/206 [04:22<00:35,  1.55s/it, recall_0.3=(806, 812) / 1386]eval:  89%|█████████████████████████████████████████▉     | 184/206 [04:22<00:29,  1.34s/it, recall_0.3=(806, 812) / 1386]eval:  89%|█████████████████████████████████████████▉     | 184/206 [04:24<00:29,  1.34s/it, recall_0.3=(814, 820) / 1401]eval:  90%|██████████████████████████████████████████▏    | 185/206 [04:24<00:36,  1.75s/it, recall_0.3=(814, 820) / 1401]eval:  90%|██████████████████████████████████████████▏    | 185/206 [04:25<00:36,  1.75s/it, recall_0.3=(822, 828) / 1415]eval:  90%|██████████████████████████████████████████▍    | 186/206 [04:25<00:29,  1.50s/it, recall_0.3=(822, 828) / 1415]eval:  90%|██████████████████████████████████████████▍    | 186/206 [04:27<00:29,  1.50s/it, recall_0.3=(830, 836) / 1427]eval:  91%|██████████████████████████████████████████▋    | 187/206 [04:27<00:26,  1.41s/it, recall_0.3=(830, 836) / 1427]eval:  91%|██████████████████████████████████████████▋    | 187/206 [04:28<00:26,  1.41s/it, recall_0.3=(831, 837) / 1436]eval:  91%|██████████████████████████████████████████▉    | 188/206 [04:28<00:23,  1.30s/it, recall_0.3=(831, 837) / 1436]eval:  91%|██████████████████████████████████████████▉    | 188/206 [04:31<00:23,  1.30s/it, recall_0.3=(834, 840) / 1440]eval:  92%|███████████████████████████████████████████    | 189/206 [04:31<00:32,  1.91s/it, recall_0.3=(834, 840) / 1440]eval:  92%|███████████████████████████████████████████    | 189/206 [04:32<00:32,  1.91s/it, recall_0.3=(837, 843) / 1446]eval:  92%|███████████████████████████████████████████▎   | 190/206 [04:32<00:27,  1.71s/it, recall_0.3=(837, 843) / 1446]eval:  92%|███████████████████████████████████████████▎   | 190/206 [04:33<00:27,  1.71s/it, recall_0.3=(839, 845) / 1450]eval:  93%|███████████████████████████████████████████▌   | 191/206 [04:33<00:22,  1.51s/it, recall_0.3=(839, 845) / 1450]eval:  93%|███████████████████████████████████████████▌   | 191/206 [04:34<00:22,  1.51s/it, recall_0.3=(840, 846) / 1452]eval:  93%|███████████████████████████████████████████▊   | 192/206 [04:34<00:18,  1.34s/it, recall_0.3=(840, 846) / 1452]eval:  93%|███████████████████████████████████████████▊   | 192/206 [04:35<00:18,  1.34s/it, recall_0.3=(841, 847) / 1455]eval:  94%|████████████████████████████████████████████   | 193/206 [04:35<00:15,  1.19s/it, recall_0.3=(841, 847) / 1455]eval:  94%|████████████████████████████████████████████   | 193/206 [04:36<00:15,  1.19s/it, recall_0.3=(841, 847) / 1455]eval:  94%|████████████████████████████████████████████▎  | 194/206 [04:36<00:12,  1.03s/it, recall_0.3=(841, 847) / 1455]eval:  94%|████████████████████████████████████████████▎  | 194/206 [04:36<00:12,  1.03s/it, recall_0.3=(841, 847) / 1455]eval:  95%|████████████████████████████████████████████▍  | 195/206 [04:36<00:10,  1.04it/s, recall_0.3=(841, 847) / 1455]eval:  95%|████████████████████████████████████████████▍  | 195/206 [04:37<00:10,  1.04it/s, recall_0.3=(841, 847) / 1455]eval:  95%|████████████████████████████████████████████▋  | 196/206 [04:37<00:09,  1.10it/s, recall_0.3=(841, 847) / 1455]eval:  95%|████████████████████████████████████████████▋  | 196/206 [04:38<00:09,  1.10it/s, recall_0.3=(841, 847) / 1455]eval:  96%|████████████████████████████████████████████▉  | 197/206 [04:38<00:08,  1.12it/s, recall_0.3=(841, 847) / 1455]eval:  96%|████████████████████████████████████████████▉  | 197/206 [04:39<00:08,  1.12it/s, recall_0.3=(843, 849) / 1458]eval:  96%|█████████████████████████████████████████████▏ | 198/206 [04:39<00:07,  1.05it/s, recall_0.3=(843, 849) / 1458]eval:  96%|█████████████████████████████████████████████▏ | 198/206 [04:40<00:07,  1.05it/s, recall_0.3=(847, 853) / 1463]eval:  97%|█████████████████████████████████████████████▍ | 199/206 [04:41<00:07,  1.06s/it, recall_0.3=(847, 853) / 1463]eval:  97%|█████████████████████████████████████████████▍ | 199/206 [04:42<00:07,  1.06s/it, recall_0.3=(847, 853) / 1465]eval:  97%|█████████████████████████████████████████████▋ | 200/206 [04:42<00:07,  1.26s/it, recall_0.3=(847, 853) / 1465]eval:  97%|█████████████████████████████████████████████▋ | 200/206 [04:43<00:07,  1.26s/it, recall_0.3=(847, 853) / 1465]eval:  98%|█████████████████████████████████████████████▊ | 201/206 [04:43<00:06,  1.25s/it, recall_0.3=(847, 853) / 1465]eval:  98%|█████████████████████████████████████████████▊ | 201/206 [04:44<00:06,  1.25s/it, recall_0.3=(848, 854) / 1468]eval:  98%|██████████████████████████████████████████████ | 202/206 [04:44<00:04,  1.15s/it, recall_0.3=(848, 854) / 1468]eval:  98%|██████████████████████████████████████████████ | 202/206 [04:45<00:04,  1.15s/it, recall_0.3=(851, 857) / 1471]eval:  99%|██████████████████████████████████████████████▎| 203/206 [04:45<00:03,  1.09s/it, recall_0.3=(851, 857) / 1471]eval:  99%|██████████████████████████████████████████████▎| 203/206 [04:46<00:03,  1.09s/it, recall_0.3=(853, 859) / 1474]eval:  99%|██████████████████████████████████████████████▌| 204/206 [04:46<00:02,  1.01s/it, recall_0.3=(853, 859) / 1474]eval:  99%|██████████████████████████████████████████████▌| 204/206 [04:48<00:02,  1.01s/it, recall_0.3=(854, 860) / 1477]eval: 100%|██████████████████████████████████████████████▊| 205/206 [04:48<00:01,  1.12s/it, recall_0.3=(854, 860) / 1477]eval: 100%|██████████████████████████████████████████████▊| 205/206 [04:48<00:01,  1.12s/it, recall_0.3=(854, 860) / 1478]eval: 100%|███████████████████████████████████████████████| 206/206 [04:48<00:00,  1.05it/s, recall_0.3=(854, 860) / 1478]eval: 100%|███████████████████████████████████████████████| 206/206 [04:50<00:00,  1.41s/it, recall_0.3=(854, 860) / 1478]
2023-03-03 22:48:25,532   INFO  *************** Performance of EPOCH 60 *****************
2023-03-03 22:48:25,533   INFO  Generate label finished(sec_per_example: 0.1953 second).
2023-03-03 22:48:25,533   INFO  recall_roi_0.3: 0.592278
2023-03-03 22:48:25,533   INFO  recall_rcnn_0.3: 0.595820
2023-03-03 22:48:25,534   INFO  recall_roi_0.5: 0.502480
2023-03-03 22:48:25,534   INFO  recall_rcnn_0.5: 0.517003
2023-03-03 22:48:25,534   INFO  recall_roi_0.7: 0.289940
2023-03-03 22:48:25,534   INFO  recall_rcnn_0.7: 0.334396
2023-03-03 22:48:25,535   INFO  Average predicted number of objects(1644 samples): 4.016
======
Loading Ithaca365 tables for version v1.1...
6 category,
1 attribute,
4 visibility,
25839 instance,
3 sensor,
3 calibrated_sensor,
760811 ego_pose,
40 log,
40 scene,
6576 sample,
2282433 sample_data,
25839 sample_annotation,
1 map,
2579 location,
Done loading in 45.713 seconds.
======
Reverse indexing ...
Done reverse indexing in 6.2 seconds.
======
2023-03-03 22:49:18,784   INFO  The predictions of NuScenes have been saved to /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/eval/eval_with_train/epoch_60/val/final_result/data/results_nusc.json
Initializing nuScenes detection evaluation
Loaded results from /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/eval/eval_with_train/epoch_60/val/final_result/data/results_nusc.json. Found detections for 1644 samples.
Loading annotations for val split from nuScenes version: v1.1
  0%|                                                                                            | 0/1644 [00:00<?, ?it/s] 36%|████████████████████████████▉                                                   | 594/1644 [00:00<00:00, 5934.47it/s] 72%|█████████████████████████████████████████████████████████                      | 1188/1644 [00:00<00:00, 5200.45it/s]100%|███████████████████████████████████████████████████████████████████████████████| 1644/1644 [00:00<00:00, 5659.22it/s]
Loaded ground truth annotations for 1644 samples.
Filtering predictions
Detection range: (0, 30)
=> Original number of boxes: 6603
=> After distance based filtering: 2029
=> After LIDAR and RADAR points based filtering: 2029
Detection range: (30, 50)
=> Original number of boxes: 6603
=> After distance based filtering: 2261
=> After LIDAR and RADAR points based filtering: 2261
Detection range: (50, 80)
=> Original number of boxes: 6603
=> After distance based filtering: 1962
=> After LIDAR and RADAR points based filtering: 1962
Detection range: (0, 80)
=> Original number of boxes: 6603
=> After distance based filtering: 6252
=> After LIDAR and RADAR points based filtering: 6252
Filtering ground truth annotations
Detection range: (0, 30)
=> Original number of boxes: 6018
=> After distance based filtering: 1648
=> After LIDAR and RADAR points based filtering: 1648
Detection range: (30, 50)
=> Original number of boxes: 6018
=> After distance based filtering: 1660
=> After LIDAR and RADAR points based filtering: 1660
Detection range: (50, 80)
=> Original number of boxes: 6018
=> After distance based filtering: 1493
=> After LIDAR and RADAR points based filtering: 1493
Detection range: (0, 80)
=> Original number of boxes: 6018
=> After distance based filtering: 4801
=> After LIDAR and RADAR points based filtering: 4801
Accumulating metric data...
Calculating metrics...
Saving metrics to: /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/eval/eval_with_train/epoch_60/val/final_result/data
mAP: 0.1649
mATE: 0.7103
mASE: 0.7264
mAOE: 0.8863
NDS: 0.1953
Eval time: 3.0s

Per-class results:
Object Class	Det. Range	AP	ATE	ASE	AOE
car         	(0, 30)   	0.737	0.132	0.096	0.160
car         	(30, 50)  	0.539	0.181	0.083	0.330
car         	(50, 80)  	0.346	0.248	0.071	0.562
car         	(0, 80)   	0.555	0.169	0.091	0.293
truck       	(0, 30)   	0.000	1.000	1.000	1.000
truck       	(30, 50)  	0.000	1.000	1.000	1.000
truck       	(50, 80)  	0.000	1.000	1.000	1.000
truck       	(0, 80)   	0.000	1.000	1.000	1.000
bus         	(0, 30)   	0.000	1.000	1.000	1.000
bus         	(30, 50)  	0.000	1.000	1.000	1.000
bus         	(50, 80)  	0.000	1.000	1.000	1.000
bus         	(0, 80)   	0.000	1.000	1.000	1.000
pedestrian  	(0, 30)   	0.590	0.082	0.258	0.845
pedestrian  	(30, 50)  	0.427	0.097	0.270	1.132
pedestrian  	(50, 80)  	0.160	0.116	0.282	1.365
pedestrian  	(0, 80)   	0.435	0.092	0.267	1.025
motorcyclist	(0, 30)   	0.000	1.000	1.000	1.000
motorcyclist	(30, 50)  	0.000	1.000	1.000	1.000
motorcyclist	(50, 80)  	0.000	1.000	1.000	1.000
motorcyclist	(0, 80)   	0.000	1.000	1.000	1.000
bicyclist   	(0, 30)   	0.000	1.000	1.000	1.000
bicyclist   	(30, 50)  	0.000	1.000	1.000	1.000
bicyclist   	(50, 80)  	0.000	1.000	1.000	1.000
bicyclist   	(0, 80)   	0.000	1.000	1.000	1.000
2023-03-03 22:49:26,703   INFO  ----------------Nuscene detection_by_range results-----------------
***car
range (0, 30) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.13, 0.10, 0.16 | 70.54, 72.84, 75.58, 75.76 | mean AP: 0.7368045401318444
range (30, 50) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.18, 0.08, 0.33 | 48.34, 52.85, 56.08, 58.35 | mean AP: 0.5390360225650368
range (50, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.25, 0.07, 0.56 | 28.33, 33.81, 37.21, 39.14 | mean AP: 0.3462270059985694
range (0, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.17, 0.09, 0.29 | 50.33, 54.47, 57.84, 59.17 | mean AP: 0.55451483221939
***pedestrian
range (0, 30) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.08, 0.26, 0.84 | 58.50, 58.50, 59.06, 59.81 | mean AP: 0.5897129492796034
range (30, 50) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.10, 0.27, 1.13 | 41.63, 41.63, 42.01, 45.48 | mean AP: 0.4268705808961263
range (50, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.12, 0.28, 1.37 | 15.83, 15.83, 15.83, 16.47 | mean AP: 0.15988273696014474
range (0, 80) error@trans, scale, orient | AP@0.5, 1.0, 2.0, 4.0
0.09, 0.27, 1.02 | 42.74, 42.74, 43.41, 45.11 | mean AP: 0.4349955236108029
--------------average performance-------------
trans_err:	 0.7103
scale_err:	 0.7264
orient_err:	 0.8863
mAP:	 0.1649
NDS:	 0.1953
--------------table log summary-------------
***car
match 1.0m:	(0, 30), (30, 50), (50, 80), (0, 80)
72.84, 52.85, 33.81, 54.47
***pedestrian
match 1.0m:	(0, 30), (30, 50), (50, 80), (0, 80)
58.50, 41.63, 15.83, 42.74

2023-03-03 22:49:26,704   INFO  Result is save to /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/eval/eval_with_train/epoch_60/val
2023-03-03 22:49:26,704   INFO  ****************Evaluation done.*****************
2023-03-03 22:49:26,714   INFO  Epoch 60 has been evaluated
Wait 30 seconds for next check (progress: 0.0 / 0 minutes): /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/default/ckpt 2023-03-03 22:49:56,748   INFO  **********************End evaluation ithaca365_models/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid(default)**********************
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:             eval/eval_with_train/tensorboard_val/NDS ▁██
wandb:     eval/eval_with_train/tensorboard_val/global_step ▁▅█
wandb:             eval/eval_with_train/tensorboard_val/mAP ▁█▇
wandb:      eval/eval_with_train/tensorboard_val/orient_err █▁▃
wandb: eval/eval_with_train/tensorboard_val/recall/rcnn_0.3 ▁██
wandb: eval/eval_with_train/tensorboard_val/recall/rcnn_0.5 ▁█▇
wandb: eval/eval_with_train/tensorboard_val/recall/rcnn_0.7 ▁██
wandb:  eval/eval_with_train/tensorboard_val/recall/roi_0.3 ▁██
wandb:  eval/eval_with_train/tensorboard_val/recall/roi_0.5 ▁█▇
wandb:  eval/eval_with_train/tensorboard_val/recall/roi_0.7 ▁▇█
wandb:       eval/eval_with_train/tensorboard_val/scale_err █▃▁
wandb:       eval/eval_with_train/tensorboard_val/trans_err █▂▁
wandb:                                          global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:                              meta_data/learning_rate ▂▂▂▂▃▃▄▄▅▆▆▇▇███████▇▇▇▇▆▆▅▅▄▄▃▃▃▂▂▂▁▁▁▁
wandb:                                           train/loss █▇▇█▇▇▇▇▇▆▇▇█▆██▆▇▇▇▇▇▄▇▁▄▇▇▇▄▇▆▇▄▇▇▅▇▇▇
wandb:                                        train/p2_loss █▆▇▇▇▇▇▇▇▆▇▇█▆██▆▇▇▇▇▇▄▇▁▄▇▇▇▄▇▆▇▄▇▇▅▇▇▇
wandb:                                 train/point_loss_box ▆█▄▇▆▄▇▄▄▆▃▄▇▂▇▃▃▆▆▇▆▅▄▃▄▄▄▄▄▅▁▆▄▄▂▄▂▂▃▄
wandb:                                 train/point_loss_cls █▅▃▅▂▅▅▃▅▂▃▄▃▄▄▄▃▄▅▅▆▁▂▂▃▂▂▃▂▁▂▂▃▂▃▂▃▄▂▂
wandb:                       train/point_loss_cls_margin_p2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                  train/point_pos_num ▁▂▁▁▁▁▁▂▃▃▂▁▁▂▁▂▃▁▁▂▁▃▅▁█▇▁▂▁▅▄▄▂▅▄▂▄▁▂▂
wandb:                               train/point_total_loss █▅▃▅▂▅▅▃▅▂▃▄▃▄▄▄▃▄▅▅▆▁▂▂▃▂▂▃▂▁▂▂▃▂▃▂▃▄▂▂
wandb:                                      train/rcnn_loss ▂▄▅▆▄▆▃▂▃▅▃▃█▂▃▂▄▃▃▂▂▅▄▁▅▄▃▄▃▁▃▄▂▂▁▂▁▁▂▃
wandb:                                  train/rcnn_loss_cls ▄▃▆▂▃▄▅▄▃▅▄▇█▄▂▆█▃▅▄▄▄▃▅▁▃▃▆▄▃▄▅▃▃▄▁▁▃▂▃
wandb:                               train/rcnn_loss_corner ▄█▅▃▄▅▃▆▇▆▅▄▃▆▄▅▂▄▅▄▃▃▄▃▄▃▃▂▂▁▁▂▂▂▅▃▃▂▁▂
wandb:                                  train/rcnn_loss_reg ▂▅▅█▅▇▂▂▄▅▃▃█▂▅▁▃▄▃▂▂▆▅▁▇▅▄▄▃▁▃▅▂▂▁▃▂▁▃▄
wandb: 
wandb: Run summary:
wandb:             eval/eval_with_train/tensorboard_val/NDS 0.1953
wandb:     eval/eval_with_train/tensorboard_val/global_step 60
wandb:             eval/eval_with_train/tensorboard_val/mAP 0.16492
wandb:      eval/eval_with_train/tensorboard_val/orient_err 0.88629
wandb: eval/eval_with_train/tensorboard_val/recall/rcnn_0.3 0.59582
wandb: eval/eval_with_train/tensorboard_val/recall/rcnn_0.5 0.517
wandb: eval/eval_with_train/tensorboard_val/recall/rcnn_0.7 0.3344
wandb:  eval/eval_with_train/tensorboard_val/recall/roi_0.3 0.59228
wandb:  eval/eval_with_train/tensorboard_val/recall/roi_0.5 0.50248
wandb:  eval/eval_with_train/tensorboard_val/recall/roi_0.7 0.28994
wandb:       eval/eval_with_train/tensorboard_val/scale_err 0.72638
wandb:       eval/eval_with_train/tensorboard_val/trans_err 0.71029
wandb:                                          global_step 33360
wandb:                              meta_data/learning_rate 0.0
wandb:                                           train/loss -37.91494
wandb:                                        train/p2_loss -39.63125
wandb:                                 train/point_loss_box 0.82128
wandb:                                 train/point_loss_cls 0.02592
wandb:                       train/point_loss_cls_margin_p2 0.0
wandb:                                  train/point_pos_num 22454.0
wandb:                               train/point_total_loss 0.02592
wandb:                                      train/rcnn_loss 0.8691
wandb:                                  train/rcnn_loss_cls 0.13677
wandb:                               train/rcnn_loss_corner 0.06292
wandb:                                  train/rcnn_loss_reg 0.66942
wandb: 
wandb: Synced ithaca365_models_pointrcnn_hindsight_p2_squashlevel_bce_sigmoid_default: https://wandb.ai/travis10/pointrcnn_hindsight_p2_squashlevel_bce_sigmoid/runs/15z6mfqg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)
wandb: Find logs at: ./wandb/run-20230302_232504-15z6mfqg/logs
INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.
INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish
/home/tz98/anaconda3/envs/continual-da/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:70: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.004386425018310547 seconds
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 0, "group_rank": 0, "worker_id": "932912", "role": "default", "hostname": "nikola-compute-15.cs.cornell.edu", "state": "SUCCEEDED", "total_run_time": 84323, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [0], \"role_rank\": [0], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 1, "group_rank": 0, "worker_id": "932913", "role": "default", "hostname": "nikola-compute-15.cs.cornell.edu", "state": "SUCCEEDED", "total_run_time": 84323, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [1], \"role_rank\": [1], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 2, "group_rank": 0, "worker_id": "932914", "role": "default", "hostname": "nikola-compute-15.cs.cornell.edu", "state": "SUCCEEDED", "total_run_time": 84323, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [2], \"role_rank\": [2], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 3, "group_rank": 0, "worker_id": "932915", "role": "default", "hostname": "nikola-compute-15.cs.cornell.edu", "state": "SUCCEEDED", "total_run_time": 84323, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [3], \"role_rank\": [3], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "AGENT", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": null, "group_rank": 0, "worker_id": null, "role": "default", "hostname": "nikola-compute-15.cs.cornell.edu", "state": "SUCCEEDED", "total_run_time": 84323, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\"}", "agent_restarts": 0}}
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
