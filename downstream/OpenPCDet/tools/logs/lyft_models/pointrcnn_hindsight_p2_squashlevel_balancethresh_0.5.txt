+ NGPUS=4
+ PY_ARGS='--cfg_file cfgs/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5.yaml --wandb_project pointrcnn_hindsight_p2_balancethresh_0.5'
+ true
+ PORT=11266
++ nc -z 127.0.0.1 11266
++ echo 1
+ status=1
+ '[' 1 '!=' 0 ']'
+ break
+ echo 11266
11266
+ python -m torch.distributed.launch --nproc_per_node=4 --rdzv_endpoint=localhost:11266 train.py --launcher pytorch --cfg_file cfgs/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5.yaml --wandb_project pointrcnn_hindsight_p2_balancethresh_0.5
/home/tz98/anaconda3/envs/continual-da/lib/python3.8/site-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : train.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 4
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : localhost:11266
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_zpw7qxb_/none_6hx_2vd3
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/home/tz98/anaconda3/envs/continual-da/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=localhost
  master_port=11266
  group_rank=0
  group_world_size=1
  local_ranks=[0, 1, 2, 3]
  role_ranks=[0, 1, 2, 3]
  global_ranks=[0, 1, 2, 3]
  role_world_sizes=[4, 4, 4, 4]
  global_world_sizes=[4, 4, 4, 4]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_zpw7qxb_/none_6hx_2vd3/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_zpw7qxb_/none_6hx_2vd3/attempt_0/1/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_zpw7qxb_/none_6hx_2vd3/attempt_0/2/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_zpw7qxb_/none_6hx_2vd3/attempt_0/3/error.json
2023-02-21 20:54:14,356   INFO  **********************Start logging**********************
2023-02-21 20:54:14,356   INFO  CUDA_VISIBLE_DEVICES=0,1,2,3
2023-02-21 20:54:14,357   INFO  total_batch_size: 8
2023-02-21 20:54:14,357   INFO  cfg_file         cfgs/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5.yaml
2023-02-21 20:54:14,357   INFO  batch_size       2
2023-02-21 20:54:14,357   INFO  epochs           60
2023-02-21 20:54:14,357   INFO  workers          4
2023-02-21 20:54:14,357   INFO  extra_tag        default
2023-02-21 20:54:14,357   INFO  ckpt             None
2023-02-21 20:54:14,357   INFO  pretrained_model None
2023-02-21 20:54:14,357   INFO  launcher         pytorch
2023-02-21 20:54:14,357   INFO  tcp_port         18888
2023-02-21 20:54:14,358   INFO  sync_bn          False
2023-02-21 20:54:14,358   INFO  fix_random_seed  False
2023-02-21 20:54:14,358   INFO  ckpt_save_interval 10
2023-02-21 20:54:14,358   INFO  local_rank       0
2023-02-21 20:54:14,358   INFO  max_ckpt_save_num 30
2023-02-21 20:54:14,358   INFO  merge_all_iters_to_one_epoch False
2023-02-21 20:54:14,358   INFO  set_cfgs         None
2023-02-21 20:54:14,358   INFO  empty_cache_every -1
2023-02-21 20:54:14,358   INFO  max_waiting_mins 0
2023-02-21 20:54:14,358   INFO  start_epoch      0
2023-02-21 20:54:14,358   INFO  num_epochs_to_eval 0
2023-02-21 20:54:14,359   INFO  save_to_file     False
2023-02-21 20:54:14,359   INFO  wandb_project    pointrcnn_hindsight_p2_balancethresh_0.5
2023-02-21 20:54:14,359   INFO  wandb_group      None
2023-02-21 20:54:14,359   INFO  hq_path          None
2023-02-21 20:54:14,359   INFO  cfg.ROOT_DIR: /home/tz98/projects/continual-DA/downstream/OpenPCDet
2023-02-21 20:54:14,359   INFO  cfg.LOCAL_RANK: 0
2023-02-21 20:54:14,359   INFO  cfg.CLASS_NAMES: ['Car', 'Pedestrian']
2023-02-21 20:54:14,359   INFO  
cfg.DATA_CONFIG = edict()
2023-02-21 20:54:14,359   INFO  cfg.DATA_CONFIG.DATASET: KittiDataset
2023-02-21 20:54:14,359   INFO  cfg.DATA_CONFIG.DATA_PATH: ../data/lyft
2023-02-21 20:54:14,360   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [0, -40, -3, 90.4, 40, 1]
2023-02-21 20:54:14,360   INFO  
cfg.DATA_CONFIG.DATA_SPLIT = edict()
2023-02-21 20:54:14,360   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train
2023-02-21 20:54:14,360   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val
2023-02-21 20:54:14,360   INFO  
cfg.DATA_CONFIG.INFO_PATH = edict()
2023-02-21 20:54:14,360   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['kitti_infos_train.pkl']
2023-02-21 20:54:14,360   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['kitti_infos_val.pkl']
2023-02-21 20:54:14,360   INFO  
cfg.DATA_CONFIG.LOAD_HISTORY = edict()
2023-02-21 20:54:14,360   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.DATA_PATH: ../data/lyft/training/combined_lidar
2023-02-21 20:54:14,360   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.LIMIT_NUM: 5
2023-02-21 20:54:14,361   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.TRANS_MAT_PATH: ../data/lyft/training/trans_mat
2023-02-21 20:54:14,361   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.VOXEL_SIZE: -1
2023-02-21 20:54:14,361   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.FORWARD_ONLY: True
2023-02-21 20:54:14,361   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.CACHE_ROOT: /scratch/hindsight_travis_cache/
2023-02-21 20:54:14,361   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.HISTORY_AUG: True
2023-02-21 20:54:14,361   INFO  cfg.DATA_CONFIG.GET_ITEM_LIST: ['points', 'p2_score', 'history_scans']
2023-02-21 20:54:14,361   INFO  cfg.DATA_CONFIG.FOV_POINTS_ONLY: True
2023-02-21 20:54:14,361   INFO  
cfg.DATA_CONFIG.DATA_AUGMENTOR = edict()
2023-02-21 20:54:14,361   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']
2023-02-21 20:54:14,361   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'USE_ROAD_PLANE': True, 'DB_INFO_PATH': ['kitti_dbinfos_train.pkl'], 'PREPARE': {'filter_by_min_points': ['Car:5', 'Pedestrian:5', 'Cyclist:5'], 'filter_by_difficulty': []}, 'VALIDATE_NUM_POINT_LIMIT': {'Car': 10, 'Pedestrian': 3, 'Cyclist': 3}, 'SAMPLE_GROUPS': ['Car:10', 'Pedestrian:5', 'Cyclist:5'], 'VALIDATE_EXTRA_OFFSET': [0.0, 0.0, 0.2], 'VALIDATE_EXTRA_WIDTH': [0.3, 0.3, 0.5], 'NUM_POINT_FEATURES': 4, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': True}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}, {'NAME': 'point_quantize', 'VOXEL_SIZE': 0.3}]
2023-02-21 20:54:14,361   INFO  
cfg.DATA_CONFIG.POINT_FEATURE_ENCODING = edict()
2023-02-21 20:54:14,362   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding
2023-02-21 20:54:14,362   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity']
2023-02-21 20:54:14,362   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity']
2023-02-21 20:54:14,362   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'sample_points', 'NUM_POINTS': {'train': 16384, 'test': 16384}}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': False}}]
2023-02-21 20:54:14,362   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: cfgs/dataset_configs/lyft_dataset_hindsight.yaml
2023-02-21 20:54:14,362   INFO  cfg.DATA_CONFIG.load_p2_score: /home/yy785/datasets/lyft_release_test/training/pp_score_fw70_2m_r0.3
2023-02-21 20:54:14,362   INFO  cfg.DATA_CONFIG.load_p2_test_score: /home/yy785/datasets/lyft_release_test/training/pp_score_fw70_2m_r0.3_test
2023-02-21 20:54:14,362   INFO  
cfg.MODEL = edict()
2023-02-21 20:54:14,362   INFO  cfg.MODEL.NAME: PointRCNN
2023-02-21 20:54:14,362   INFO  
cfg.MODEL.HISTORY_QUERY = edict()
2023-02-21 20:54:14,362   INFO  cfg.MODEL.HISTORY_QUERY.NAME: SparseResUQueryNet
2023-02-21 20:54:14,362   INFO  cfg.MODEL.HISTORY_QUERY.history_backbone: Res16UNet14E
2023-02-21 20:54:14,362   INFO  
cfg.MODEL.HISTORY_QUERY.history_backbone_config = edict()
2023-02-21 20:54:14,363   INFO  cfg.MODEL.HISTORY_QUERY.history_backbone_config.bn_momentum: 0.05
2023-02-21 20:54:14,363   INFO  cfg.MODEL.HISTORY_QUERY.history_backbone_config.conv1_kernel_size: 3
2023-02-21 20:54:14,363   INFO  cfg.MODEL.HISTORY_QUERY.history_backbone_config.final_feature_size: 64
2023-02-21 20:54:14,363   INFO  cfg.MODEL.HISTORY_QUERY.simple_conv_kernel_size: 5
2023-02-21 20:54:14,363   INFO  cfg.MODEL.HISTORY_QUERY.extra_conv: False
2023-02-21 20:54:14,363   INFO  cfg.MODEL.HISTORY_QUERY.mode: update_point_features
2023-02-21 20:54:14,363   INFO  
cfg.MODEL.HISTORY_QUERY.P2_LOSS_CONFIG = edict()
2023-02-21 20:54:14,363   INFO  cfg.MODEL.HISTORY_QUERY.P2_LOSS_CONFIG.LOSS_FN: l1
2023-02-21 20:54:14,363   INFO  cfg.MODEL.HISTORY_QUERY.P2_LOSS_CONFIG.BALANCE_THRESHOLD: 0.5
2023-02-21 20:54:14,363   INFO  
cfg.MODEL.BACKBONE_3D = edict()
2023-02-21 20:54:14,363   INFO  cfg.MODEL.BACKBONE_3D.NAME: PointNet2MSG
2023-02-21 20:54:14,363   INFO  
cfg.MODEL.BACKBONE_3D.SA_CONFIG = edict()
2023-02-21 20:54:14,363   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.NPOINTS: [4096, 1024, 256, 64]
2023-02-21 20:54:14,364   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.RADIUS: [[0.1, 0.5], [0.5, 1.0], [1.0, 2.0], [2.0, 4.0]]
2023-02-21 20:54:14,364   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.NSAMPLE: [[16, 32], [16, 32], [16, 32], [16, 32]]
2023-02-21 20:54:14,364   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.MLPS: [[[16, 16, 32], [32, 32, 64]], [[64, 64, 128], [64, 96, 128]], [[128, 196, 256], [128, 196, 256]], [[256, 256, 512], [256, 384, 512]]]
2023-02-21 20:54:14,364   INFO  cfg.MODEL.BACKBONE_3D.FP_MLPS: [[128, 128], [256, 256], [512, 512], [512, 512]]
2023-02-21 20:54:14,364   INFO  
cfg.MODEL.POINT_HEAD = edict()
2023-02-21 20:54:14,364   INFO  cfg.MODEL.POINT_HEAD.NAME: PointHeadBox
2023-02-21 20:54:14,364   INFO  cfg.MODEL.POINT_HEAD.CLS_FC: [256, 256]
2023-02-21 20:54:14,364   INFO  cfg.MODEL.POINT_HEAD.REG_FC: [256, 256]
2023-02-21 20:54:14,364   INFO  cfg.MODEL.POINT_HEAD.CLASS_AGNOSTIC: False
2023-02-21 20:54:14,364   INFO  cfg.MODEL.POINT_HEAD.USE_POINT_FEATURES_BEFORE_FUSION: False
2023-02-21 20:54:14,364   INFO  
cfg.MODEL.POINT_HEAD.TARGET_CONFIG = edict()
2023-02-21 20:54:14,364   INFO  cfg.MODEL.POINT_HEAD.TARGET_CONFIG.GT_EXTRA_WIDTH: [0.2, 0.2, 0.2]
2023-02-21 20:54:14,365   INFO  cfg.MODEL.POINT_HEAD.TARGET_CONFIG.BOX_CODER: PointResidualCoder
2023-02-21 20:54:14,365   INFO  
cfg.MODEL.POINT_HEAD.TARGET_CONFIG.BOX_CODER_CONFIG = edict()
2023-02-21 20:54:14,365   INFO  cfg.MODEL.POINT_HEAD.TARGET_CONFIG.BOX_CODER_CONFIG.use_mean_size: True
2023-02-21 20:54:14,365   INFO  cfg.MODEL.POINT_HEAD.TARGET_CONFIG.BOX_CODER_CONFIG.mean_size: [[3.9, 1.6, 1.56], [0.8, 0.6, 1.73], [1.76, 0.6, 1.73]]
2023-02-21 20:54:14,365   INFO  
cfg.MODEL.POINT_HEAD.LOSS_CONFIG = edict()
2023-02-21 20:54:14,365   INFO  cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_REG: WeightedSmoothL1Loss
2023-02-21 20:54:14,365   INFO  
cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_WEIGHTS = edict()
2023-02-21 20:54:14,365   INFO  cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.point_cls_weight: 1.0
2023-02-21 20:54:14,365   INFO  cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.point_box_weight: 1.0
2023-02-21 20:54:14,365   INFO  cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
2023-02-21 20:54:14,365   INFO  
cfg.MODEL.ROI_HEAD = edict()
2023-02-21 20:54:14,365   INFO  cfg.MODEL.ROI_HEAD.NAME: PointRCNNHead
2023-02-21 20:54:14,365   INFO  cfg.MODEL.ROI_HEAD.CLASS_AGNOSTIC: True
2023-02-21 20:54:14,366   INFO  
cfg.MODEL.ROI_HEAD.ROI_POINT_POOL = edict()
2023-02-21 20:54:14,366   INFO  cfg.MODEL.ROI_HEAD.ROI_POINT_POOL.POOL_EXTRA_WIDTH: [0.0, 0.0, 0.0]
2023-02-21 20:54:14,366   INFO  cfg.MODEL.ROI_HEAD.ROI_POINT_POOL.NUM_SAMPLED_POINTS: 512
2023-02-21 20:54:14,366   INFO  cfg.MODEL.ROI_HEAD.ROI_POINT_POOL.DEPTH_NORMALIZER: 70.0
2023-02-21 20:54:14,366   INFO  cfg.MODEL.ROI_HEAD.XYZ_UP_LAYER: [128, 128]
2023-02-21 20:54:14,366   INFO  cfg.MODEL.ROI_HEAD.CLS_FC: [256, 256]
2023-02-21 20:54:14,366   INFO  cfg.MODEL.ROI_HEAD.REG_FC: [256, 256]
2023-02-21 20:54:14,366   INFO  cfg.MODEL.ROI_HEAD.DP_RATIO: 0.0
2023-02-21 20:54:14,366   INFO  cfg.MODEL.ROI_HEAD.USE_BN: False
2023-02-21 20:54:14,366   INFO  
cfg.MODEL.ROI_HEAD.SA_CONFIG = edict()
2023-02-21 20:54:14,366   INFO  cfg.MODEL.ROI_HEAD.SA_CONFIG.NPOINTS: [128, 32, -1]
2023-02-21 20:54:14,366   INFO  cfg.MODEL.ROI_HEAD.SA_CONFIG.RADIUS: [0.2, 0.4, 100]
2023-02-21 20:54:14,366   INFO  cfg.MODEL.ROI_HEAD.SA_CONFIG.NSAMPLE: [16, 16, 16]
2023-02-21 20:54:14,367   INFO  cfg.MODEL.ROI_HEAD.SA_CONFIG.MLPS: [[128, 128, 128], [128, 128, 256], [256, 256, 512]]
2023-02-21 20:54:14,367   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG = edict()
2023-02-21 20:54:14,367   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN = edict()
2023-02-21 20:54:14,367   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_TYPE: nms_gpu
2023-02-21 20:54:14,367   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.MULTI_CLASSES_NMS: False
2023-02-21 20:54:14,367   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_PRE_MAXSIZE: 9000
2023-02-21 20:54:14,367   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_POST_MAXSIZE: 512
2023-02-21 20:54:14,367   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_THRESH: 0.8
2023-02-21 20:54:14,367   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST = edict()
2023-02-21 20:54:14,367   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_TYPE: nms_gpu
2023-02-21 20:54:14,367   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.MULTI_CLASSES_NMS: False
2023-02-21 20:54:14,367   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_PRE_MAXSIZE: 9000
2023-02-21 20:54:14,367   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_POST_MAXSIZE: 100
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_THRESH: 0.85
2023-02-21 20:54:14,368   INFO  
cfg.MODEL.ROI_HEAD.TARGET_CONFIG = edict()
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.BOX_CODER: ResidualCoder
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.ROI_PER_IMAGE: 128
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.FG_RATIO: 0.5
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.SAMPLE_ROI_BY_EACH_CLASS: True
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_SCORE_TYPE: cls
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_FG_THRESH: 0.6
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_BG_THRESH: 0.45
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_BG_THRESH_LO: 0.1
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.HARD_BG_RATIO: 0.8
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.REG_FG_THRESH: 0.55
2023-02-21 20:54:14,368   INFO  
cfg.MODEL.ROI_HEAD.LOSS_CONFIG = edict()
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.CLS_LOSS: BinaryCrossEntropy
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.REG_LOSS: smooth-l1
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.CORNER_LOSS_REGULARIZATION: True
2023-02-21 20:54:14,368   INFO  
cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS = edict()
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_cls_weight: 1.0
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_reg_weight: 1.0
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_corner_weight: 1.0
2023-02-21 20:54:14,368   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
2023-02-21 20:54:14,368   INFO  
cfg.MODEL.POST_PROCESSING = edict()
2023-02-21 20:54:14,368   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
2023-02-21 20:54:14,368   INFO  cfg.MODEL.POST_PROCESSING.SCORE_THRESH: 0.1
2023-02-21 20:54:14,368   INFO  cfg.MODEL.POST_PROCESSING.OUTPUT_RAW_SCORE: False
2023-02-21 20:54:14,368   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: kitti
2023-02-21 20:54:14,368   INFO  
cfg.MODEL.POST_PROCESSING.NMS_CONFIG = edict()
2023-02-21 20:54:14,369   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.MULTI_CLASSES_NMS: False
2023-02-21 20:54:14,369   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: nms_gpu
2023-02-21 20:54:14,369   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: 0.1
2023-02-21 20:54:14,369   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: 4096
2023-02-21 20:54:14,369   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: 500
2023-02-21 20:54:14,369   INFO  
cfg.OPTIMIZATION = edict()
2023-02-21 20:54:14,369   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 2
2023-02-21 20:54:14,369   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 60
2023-02-21 20:54:14,369   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle
2023-02-21 20:54:14,369   INFO  cfg.OPTIMIZATION.LR: 0.01
2023-02-21 20:54:14,369   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01
2023-02-21 20:54:14,369   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9
2023-02-21 20:54:14,369   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]
2023-02-21 20:54:14,369   INFO  cfg.OPTIMIZATION.PCT_START: 0.4
2023-02-21 20:54:14,369   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10
2023-02-21 20:54:14,369   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]
2023-02-21 20:54:14,369   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1
2023-02-21 20:54:14,369   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07
2023-02-21 20:54:14,369   INFO  cfg.OPTIMIZATION.LR_WARMUP: False
2023-02-21 20:54:14,369   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1
2023-02-21 20:54:14,369   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 10
2023-02-21 20:54:14,369   INFO  cfg.TAG: pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5
2023-02-21 20:54:14,370   INFO  cfg.EXP_GROUP_PATH: lyft_models
wandb: Currently logged in as: travis10. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/tz98/projects/continual-DA/downstream/OpenPCDet/tools/wandb/run-20230221_205421-1a8fux57
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyft_models_pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5_default
wandb: ⭐️ View project at https://wandb.ai/travis10/pointrcnn_hindsight_p2_balancethresh_0.5
wandb: 🚀 View run at https://wandb.ai/travis10/pointrcnn_hindsight_p2_balancethresh_0.5/runs/1a8fux57
wandb: WARNING Found log directory outside of given root_logdir, dropping given root_logdir for event file in /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5/default/tensorboard
2023-02-21 20:54:28,076   INFO  Database filter by min points Car: 117109 => 116379
2023-02-21 20:54:28,080   INFO  Database filter by min points Pedestrian: 2931 => 2925
2023-02-21 20:54:28,097   INFO  Database filter by difficulty Car: 116379 => 116379
2023-02-21 20:54:28,098   INFO  Database filter by difficulty Pedestrian: 2925 => 2925
2023-02-21 20:54:28,116   INFO  Loading KITTI dataset
2023-02-21 20:54:28,439   INFO  Total samples for KITTI dataset: 11873
2023-02-21 20:54:31,681   INFO  DistributedDataParallel(
  (module): PointRCNN(
    (history_query): SparseResUQueryNet(
      (history_backbone): Res16UNet14E(
        (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
        (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block1): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
          )
        )
        (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block2): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block3): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block4): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
          )
        )
        (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block5): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block6): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block7): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block8): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (relu): MinkowskiReLU()
        (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
      )
      (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
      (p2_backbone): Sequential(
        (0): Linear(in_features=68, out_features=32, bias=True)
        (1): ReLU()
        (2): Linear(in_features=32, out_features=1, bias=True)
      )
      (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (vfe): None
    (backbone_3d): PointNet2MSG(
      (SA_modules): ModuleList(
        (0): PointnetSAModuleMSG(
          (groupers): ModuleList(
            (0): QueryAndGroup()
            (1): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
            (1): Sequential(
              (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (1): PointnetSAModuleMSG(
          (groupers): ModuleList(
            (0): QueryAndGroup()
            (1): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
            (1): Sequential(
              (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (2): PointnetSAModuleMSG(
          (groupers): ModuleList(
            (0): QueryAndGroup()
            (1): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
            (1): Sequential(
              (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (3): PointnetSAModuleMSG(
          (groupers): ModuleList(
            (0): QueryAndGroup()
            (1): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
            (1): Sequential(
              (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
      )
      (FP_modules): ModuleList(
        (0): PointnetFPModule(
          (mlp): Sequential(
            (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
          )
        )
        (1): PointnetFPModule(
          (mlp): Sequential(
            (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
          )
        )
        (2): PointnetFPModule(
          (mlp): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
          )
        )
        (3): PointnetFPModule(
          (mlp): Sequential(
            (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
          )
        )
      )
    )
    (map_to_bev_module): None
    (pfe): None
    (backbone_2d): None
    (dense_head): None
    (point_head): PointHeadBox(
      (cls_loss_func): SigmoidFocalClassificationLoss()
      (reg_loss_func): WeightedSmoothL1Loss()
      (cls_layers): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=256, out_features=256, bias=False)
        (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU()
        (6): Linear(in_features=256, out_features=2, bias=True)
      )
      (box_layers): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=256, out_features=256, bias=False)
        (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU()
        (6): Linear(in_features=256, out_features=8, bias=True)
      )
    )
    (roi_head): PointRCNNHead(
      (proposal_target_layer): ProposalTargetLayer()
      (reg_loss_func): WeightedSmoothL1Loss()
      (SA_modules): ModuleList(
        (0): PointnetSAModule(
          (groupers): ModuleList(
            (0): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (1): PointnetSAModule(
          (groupers): ModuleList(
            (0): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (2): PointnetSAModule(
          (groupers): ModuleList(
            (0): GroupAll()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
      )
      (xyz_up_layer): Sequential(
        (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
        (1): ReLU()
        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        (3): ReLU()
      )
      (merge_down_layer): Sequential(
        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
        (1): ReLU()
      )
      (cls_layers): Sequential(
        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.0, inplace=False)
        (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
      )
      (reg_layers): Sequential(
        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.0, inplace=False)
        (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
      )
      (roipoint_pool3d_layer): RoIPointPool3d()
    )
  )
)
2023-02-21 20:54:31,691   INFO  **********************Start training lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5(default)**********************
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
wandb: Network error (ReadTimeout), entering retry loop.
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
wandb: Network error (ReadTimeout), entering retry loop.
+ NGPUS=4
+ PY_ARGS='--cfg_file cfgs/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5.yaml --ckpt ../output/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5/default/ckpt/checkpoint_epoch_40.pth --wandb_project pointrcnn_hindsight_p2_balancethresh_0.5_2'
+ true
+ PORT=43028
++ nc -z 127.0.0.1 43028
++ echo 1
+ status=1
+ '[' 1 '!=' 0 ']'
+ break
+ echo 43028
43028
+ python -m torch.distributed.launch --nproc_per_node=4 --rdzv_endpoint=localhost:43028 train.py --launcher pytorch --cfg_file cfgs/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5.yaml --ckpt ../output/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5/default/ckpt/checkpoint_epoch_40.pth --wandb_project pointrcnn_hindsight_p2_balancethresh_0.5_2
/home/tz98/anaconda3/envs/continual-da/lib/python3.8/site-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : train.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 4
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : localhost:43028
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_qkrpoi9v/none_cndhf8_1
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/home/tz98/anaconda3/envs/continual-da/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=localhost
  master_port=43028
  group_rank=0
  group_world_size=1
  local_ranks=[0, 1, 2, 3]
  role_ranks=[0, 1, 2, 3]
  global_ranks=[0, 1, 2, 3]
  role_world_sizes=[4, 4, 4, 4]
  global_world_sizes=[4, 4, 4, 4]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_qkrpoi9v/none_cndhf8_1/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_qkrpoi9v/none_cndhf8_1/attempt_0/1/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_qkrpoi9v/none_cndhf8_1/attempt_0/2/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_qkrpoi9v/none_cndhf8_1/attempt_0/3/error.json
2023-02-28 16:14:43,099   INFO  **********************Start logging**********************
2023-02-28 16:14:43,100   INFO  CUDA_VISIBLE_DEVICES=0,1,2,3
2023-02-28 16:14:43,100   INFO  total_batch_size: 8
2023-02-28 16:14:43,100   INFO  cfg_file         cfgs/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5.yaml
2023-02-28 16:14:43,100   INFO  batch_size       2
2023-02-28 16:14:43,100   INFO  epochs           60
2023-02-28 16:14:43,100   INFO  workers          4
2023-02-28 16:14:43,100   INFO  extra_tag        default
2023-02-28 16:14:43,100   INFO  ckpt             ../output/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5/default/ckpt/checkpoint_epoch_40.pth
2023-02-28 16:14:43,100   INFO  pretrained_model None
2023-02-28 16:14:43,100   INFO  launcher         pytorch
2023-02-28 16:14:43,100   INFO  tcp_port         18888
2023-02-28 16:14:43,101   INFO  sync_bn          False
2023-02-28 16:14:43,101   INFO  fix_random_seed  False
2023-02-28 16:14:43,101   INFO  ckpt_save_interval 10
2023-02-28 16:14:43,101   INFO  local_rank       0
2023-02-28 16:14:43,101   INFO  max_ckpt_save_num 30
2023-02-28 16:14:43,101   INFO  merge_all_iters_to_one_epoch False
2023-02-28 16:14:43,101   INFO  set_cfgs         None
2023-02-28 16:14:43,101   INFO  empty_cache_every -1
2023-02-28 16:14:43,101   INFO  max_waiting_mins 0
2023-02-28 16:14:43,101   INFO  start_epoch      0
2023-02-28 16:14:43,101   INFO  num_epochs_to_eval 0
2023-02-28 16:14:43,101   INFO  save_to_file     False
2023-02-28 16:14:43,102   INFO  wandb_project    pointrcnn_hindsight_p2_balancethresh_0.5_2
2023-02-28 16:14:43,102   INFO  wandb_group      None
2023-02-28 16:14:43,102   INFO  hq_path          None
2023-02-28 16:14:43,102   INFO  cfg.ROOT_DIR: /home/tz98/projects/continual-DA/downstream/OpenPCDet
2023-02-28 16:14:43,102   INFO  cfg.LOCAL_RANK: 0
2023-02-28 16:14:43,102   INFO  cfg.CLASS_NAMES: ['Car', 'Pedestrian']
2023-02-28 16:14:43,102   INFO  
cfg.DATA_CONFIG = edict()
2023-02-28 16:14:43,102   INFO  cfg.DATA_CONFIG.DATASET: KittiDataset
2023-02-28 16:14:43,102   INFO  cfg.DATA_CONFIG.DATA_PATH: ../data/lyft
2023-02-28 16:14:43,102   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [0, -40, -3, 90.4, 40, 1]
2023-02-28 16:14:43,102   INFO  
cfg.DATA_CONFIG.DATA_SPLIT = edict()
2023-02-28 16:14:43,102   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train
2023-02-28 16:14:43,102   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val
2023-02-28 16:14:43,103   INFO  
cfg.DATA_CONFIG.INFO_PATH = edict()
2023-02-28 16:14:43,103   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['kitti_infos_train.pkl']
2023-02-28 16:14:43,103   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['kitti_infos_val.pkl']
2023-02-28 16:14:43,103   INFO  
cfg.DATA_CONFIG.LOAD_HISTORY = edict()
2023-02-28 16:14:43,103   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.DATA_PATH: ../data/lyft/training/combined_lidar
2023-02-28 16:14:43,103   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.LIMIT_NUM: 5
2023-02-28 16:14:43,103   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.TRANS_MAT_PATH: ../data/lyft/training/trans_mat
2023-02-28 16:14:43,103   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.VOXEL_SIZE: -1
2023-02-28 16:14:43,103   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.FORWARD_ONLY: True
2023-02-28 16:14:43,103   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.CACHE_ROOT: /scratch/hindsight_travis_cache/
2023-02-28 16:14:43,103   INFO  cfg.DATA_CONFIG.LOAD_HISTORY.HISTORY_AUG: True
2023-02-28 16:14:43,103   INFO  cfg.DATA_CONFIG.GET_ITEM_LIST: ['points', 'p2_score', 'history_scans']
2023-02-28 16:14:43,103   INFO  cfg.DATA_CONFIG.FOV_POINTS_ONLY: True
2023-02-28 16:14:43,103   INFO  
cfg.DATA_CONFIG.DATA_AUGMENTOR = edict()
2023-02-28 16:14:43,103   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']
2023-02-28 16:14:43,104   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'USE_ROAD_PLANE': True, 'DB_INFO_PATH': ['kitti_dbinfos_train.pkl'], 'PREPARE': {'filter_by_min_points': ['Car:5', 'Pedestrian:5', 'Cyclist:5'], 'filter_by_difficulty': []}, 'VALIDATE_NUM_POINT_LIMIT': {'Car': 10, 'Pedestrian': 3, 'Cyclist': 3}, 'SAMPLE_GROUPS': ['Car:10', 'Pedestrian:5', 'Cyclist:5'], 'VALIDATE_EXTRA_OFFSET': [0.0, 0.0, 0.2], 'VALIDATE_EXTRA_WIDTH': [0.3, 0.3, 0.5], 'NUM_POINT_FEATURES': 4, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': True}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}, {'NAME': 'point_quantize', 'VOXEL_SIZE': 0.3}]
2023-02-28 16:14:43,104   INFO  
cfg.DATA_CONFIG.POINT_FEATURE_ENCODING = edict()
2023-02-28 16:14:43,104   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding
2023-02-28 16:14:43,104   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity']
2023-02-28 16:14:43,104   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity']
2023-02-28 16:14:43,104   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'sample_points', 'NUM_POINTS': {'train': 16384, 'test': 16384}}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': False}}]
2023-02-28 16:14:43,104   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: cfgs/dataset_configs/lyft_dataset_hindsight.yaml
2023-02-28 16:14:43,104   INFO  cfg.DATA_CONFIG.load_p2_score: /home/yy785/datasets/lyft_release_test/training/pp_score_fw70_2m_r0.3
2023-02-28 16:14:43,104   INFO  cfg.DATA_CONFIG.load_p2_test_score: /home/yy785/datasets/lyft_release_test/training/pp_score_fw70_2m_r0.3_test
2023-02-28 16:14:43,104   INFO  
cfg.MODEL = edict()
2023-02-28 16:14:43,104   INFO  cfg.MODEL.NAME: PointRCNN
2023-02-28 16:14:43,104   INFO  
cfg.MODEL.HISTORY_QUERY = edict()
2023-02-28 16:14:43,104   INFO  cfg.MODEL.HISTORY_QUERY.NAME: SparseResUQueryNet
2023-02-28 16:14:43,105   INFO  cfg.MODEL.HISTORY_QUERY.history_backbone: Res16UNet14E
2023-02-28 16:14:43,105   INFO  
cfg.MODEL.HISTORY_QUERY.history_backbone_config = edict()
2023-02-28 16:14:43,105   INFO  cfg.MODEL.HISTORY_QUERY.history_backbone_config.bn_momentum: 0.05
2023-02-28 16:14:43,105   INFO  cfg.MODEL.HISTORY_QUERY.history_backbone_config.conv1_kernel_size: 3
2023-02-28 16:14:43,105   INFO  cfg.MODEL.HISTORY_QUERY.history_backbone_config.final_feature_size: 64
2023-02-28 16:14:43,105   INFO  cfg.MODEL.HISTORY_QUERY.simple_conv_kernel_size: 5
2023-02-28 16:14:43,105   INFO  cfg.MODEL.HISTORY_QUERY.extra_conv: False
2023-02-28 16:14:43,105   INFO  cfg.MODEL.HISTORY_QUERY.mode: update_point_features
2023-02-28 16:14:43,105   INFO  
cfg.MODEL.HISTORY_QUERY.P2_LOSS_CONFIG = edict()
2023-02-28 16:14:43,105   INFO  cfg.MODEL.HISTORY_QUERY.P2_LOSS_CONFIG.LOSS_FN: l1
2023-02-28 16:14:43,105   INFO  cfg.MODEL.HISTORY_QUERY.P2_LOSS_CONFIG.BALANCE_THRESHOLD: 0.5
2023-02-28 16:14:43,105   INFO  
cfg.MODEL.BACKBONE_3D = edict()
2023-02-28 16:14:43,105   INFO  cfg.MODEL.BACKBONE_3D.NAME: PointNet2MSG
2023-02-28 16:14:43,105   INFO  
cfg.MODEL.BACKBONE_3D.SA_CONFIG = edict()
2023-02-28 16:14:43,106   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.NPOINTS: [4096, 1024, 256, 64]
2023-02-28 16:14:43,106   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.RADIUS: [[0.1, 0.5], [0.5, 1.0], [1.0, 2.0], [2.0, 4.0]]
2023-02-28 16:14:43,106   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.NSAMPLE: [[16, 32], [16, 32], [16, 32], [16, 32]]
2023-02-28 16:14:43,106   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.MLPS: [[[16, 16, 32], [32, 32, 64]], [[64, 64, 128], [64, 96, 128]], [[128, 196, 256], [128, 196, 256]], [[256, 256, 512], [256, 384, 512]]]
2023-02-28 16:14:43,106   INFO  cfg.MODEL.BACKBONE_3D.FP_MLPS: [[128, 128], [256, 256], [512, 512], [512, 512]]
2023-02-28 16:14:43,106   INFO  
cfg.MODEL.POINT_HEAD = edict()
2023-02-28 16:14:43,106   INFO  cfg.MODEL.POINT_HEAD.NAME: PointHeadBox
2023-02-28 16:14:43,106   INFO  cfg.MODEL.POINT_HEAD.CLS_FC: [256, 256]
2023-02-28 16:14:43,106   INFO  cfg.MODEL.POINT_HEAD.REG_FC: [256, 256]
2023-02-28 16:14:43,106   INFO  cfg.MODEL.POINT_HEAD.CLASS_AGNOSTIC: False
2023-02-28 16:14:43,106   INFO  cfg.MODEL.POINT_HEAD.USE_POINT_FEATURES_BEFORE_FUSION: False
2023-02-28 16:14:43,106   INFO  
cfg.MODEL.POINT_HEAD.TARGET_CONFIG = edict()
2023-02-28 16:14:43,106   INFO  cfg.MODEL.POINT_HEAD.TARGET_CONFIG.GT_EXTRA_WIDTH: [0.2, 0.2, 0.2]
2023-02-28 16:14:43,106   INFO  cfg.MODEL.POINT_HEAD.TARGET_CONFIG.BOX_CODER: PointResidualCoder
2023-02-28 16:14:43,107   INFO  
cfg.MODEL.POINT_HEAD.TARGET_CONFIG.BOX_CODER_CONFIG = edict()
2023-02-28 16:14:43,107   INFO  cfg.MODEL.POINT_HEAD.TARGET_CONFIG.BOX_CODER_CONFIG.use_mean_size: True
2023-02-28 16:14:43,107   INFO  cfg.MODEL.POINT_HEAD.TARGET_CONFIG.BOX_CODER_CONFIG.mean_size: [[3.9, 1.6, 1.56], [0.8, 0.6, 1.73], [1.76, 0.6, 1.73]]
2023-02-28 16:14:43,107   INFO  
cfg.MODEL.POINT_HEAD.LOSS_CONFIG = edict()
2023-02-28 16:14:43,107   INFO  cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_REG: WeightedSmoothL1Loss
2023-02-28 16:14:43,107   INFO  
cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_WEIGHTS = edict()
2023-02-28 16:14:43,107   INFO  cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.point_cls_weight: 1.0
2023-02-28 16:14:43,107   INFO  cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.point_box_weight: 1.0
2023-02-28 16:14:43,107   INFO  cfg.MODEL.POINT_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
2023-02-28 16:14:43,107   INFO  
cfg.MODEL.ROI_HEAD = edict()
2023-02-28 16:14:43,107   INFO  cfg.MODEL.ROI_HEAD.NAME: PointRCNNHead
2023-02-28 16:14:43,107   INFO  cfg.MODEL.ROI_HEAD.CLASS_AGNOSTIC: True
2023-02-28 16:14:43,107   INFO  
cfg.MODEL.ROI_HEAD.ROI_POINT_POOL = edict()
2023-02-28 16:14:43,107   INFO  cfg.MODEL.ROI_HEAD.ROI_POINT_POOL.POOL_EXTRA_WIDTH: [0.0, 0.0, 0.0]
2023-02-28 16:14:43,107   INFO  cfg.MODEL.ROI_HEAD.ROI_POINT_POOL.NUM_SAMPLED_POINTS: 512
2023-02-28 16:14:43,107   INFO  cfg.MODEL.ROI_HEAD.ROI_POINT_POOL.DEPTH_NORMALIZER: 70.0
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.XYZ_UP_LAYER: [128, 128]
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.CLS_FC: [256, 256]
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.REG_FC: [256, 256]
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.DP_RATIO: 0.0
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.USE_BN: False
2023-02-28 16:14:43,108   INFO  
cfg.MODEL.ROI_HEAD.SA_CONFIG = edict()
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.SA_CONFIG.NPOINTS: [128, 32, -1]
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.SA_CONFIG.RADIUS: [0.2, 0.4, 100]
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.SA_CONFIG.NSAMPLE: [16, 16, 16]
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.SA_CONFIG.MLPS: [[128, 128, 128], [128, 128, 256], [256, 256, 512]]
2023-02-28 16:14:43,108   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG = edict()
2023-02-28 16:14:43,108   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN = edict()
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_TYPE: nms_gpu
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.MULTI_CLASSES_NMS: False
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_PRE_MAXSIZE: 9000
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_POST_MAXSIZE: 512
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_THRESH: 0.8
2023-02-28 16:14:43,108   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST = edict()
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_TYPE: nms_gpu
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.MULTI_CLASSES_NMS: False
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_PRE_MAXSIZE: 9000
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_POST_MAXSIZE: 100
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_THRESH: 0.85
2023-02-28 16:14:43,108   INFO  
cfg.MODEL.ROI_HEAD.TARGET_CONFIG = edict()
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.BOX_CODER: ResidualCoder
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.ROI_PER_IMAGE: 128
2023-02-28 16:14:43,108   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.FG_RATIO: 0.5
2023-02-28 16:14:43,109   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.SAMPLE_ROI_BY_EACH_CLASS: True
2023-02-28 16:14:43,109   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_SCORE_TYPE: cls
2023-02-28 16:14:43,109   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_FG_THRESH: 0.6
2023-02-28 16:14:43,109   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_BG_THRESH: 0.45
2023-02-28 16:14:43,109   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_BG_THRESH_LO: 0.1
2023-02-28 16:14:43,109   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.HARD_BG_RATIO: 0.8
2023-02-28 16:14:43,109   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.REG_FG_THRESH: 0.55
2023-02-28 16:14:43,109   INFO  
cfg.MODEL.ROI_HEAD.LOSS_CONFIG = edict()
2023-02-28 16:14:43,109   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.CLS_LOSS: BinaryCrossEntropy
2023-02-28 16:14:43,109   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.REG_LOSS: smooth-l1
2023-02-28 16:14:43,109   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.CORNER_LOSS_REGULARIZATION: True
2023-02-28 16:14:43,109   INFO  
cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS = edict()
2023-02-28 16:14:43,109   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_cls_weight: 1.0
2023-02-28 16:14:43,109   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_reg_weight: 1.0
2023-02-28 16:14:43,109   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_corner_weight: 1.0
2023-02-28 16:14:43,109   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
2023-02-28 16:14:43,109   INFO  
cfg.MODEL.POST_PROCESSING = edict()
2023-02-28 16:14:43,109   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
2023-02-28 16:14:43,109   INFO  cfg.MODEL.POST_PROCESSING.SCORE_THRESH: 0.1
2023-02-28 16:14:43,109   INFO  cfg.MODEL.POST_PROCESSING.OUTPUT_RAW_SCORE: False
2023-02-28 16:14:43,109   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: kitti
2023-02-28 16:14:43,109   INFO  
cfg.MODEL.POST_PROCESSING.NMS_CONFIG = edict()
2023-02-28 16:14:43,109   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.MULTI_CLASSES_NMS: False
2023-02-28 16:14:43,109   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: nms_gpu
2023-02-28 16:14:43,109   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: 0.1
2023-02-28 16:14:43,109   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: 4096
2023-02-28 16:14:43,109   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: 500
2023-02-28 16:14:43,109   INFO  
cfg.OPTIMIZATION = edict()
2023-02-28 16:14:43,110   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 2
2023-02-28 16:14:43,110   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 60
2023-02-28 16:14:43,110   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle
2023-02-28 16:14:43,110   INFO  cfg.OPTIMIZATION.LR: 0.01
2023-02-28 16:14:43,110   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01
2023-02-28 16:14:43,110   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9
2023-02-28 16:14:43,110   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]
2023-02-28 16:14:43,110   INFO  cfg.OPTIMIZATION.PCT_START: 0.4
2023-02-28 16:14:43,110   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10
2023-02-28 16:14:43,110   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]
2023-02-28 16:14:43,110   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1
2023-02-28 16:14:43,110   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07
2023-02-28 16:14:43,110   INFO  cfg.OPTIMIZATION.LR_WARMUP: False
2023-02-28 16:14:43,110   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1
2023-02-28 16:14:43,110   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 10
2023-02-28 16:14:43,110   INFO  cfg.TAG: pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5
2023-02-28 16:14:43,110   INFO  cfg.EXP_GROUP_PATH: lyft_models
wandb: Currently logged in as: travis10. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/tz98/projects/continual-DA/downstream/OpenPCDet/tools/wandb/run-20230228_161448-bmk5jchx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyft_models_pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5_default
wandb: ⭐️ View project at https://wandb.ai/travis10/pointrcnn_hindsight_p2_balancethresh_0.5_2
wandb: 🚀 View run at https://wandb.ai/travis10/pointrcnn_hindsight_p2_balancethresh_0.5_2/runs/bmk5jchx
wandb: WARNING Found log directory outside of given root_logdir, dropping given root_logdir for event file in /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5/default/tensorboard
2023-02-28 16:14:54,763   INFO  Database filter by min points Car: 117109 => 116379
2023-02-28 16:14:54,766   INFO  Database filter by min points Pedestrian: 2931 => 2925
2023-02-28 16:14:54,778   INFO  Database filter by difficulty Car: 116379 => 116379
2023-02-28 16:14:54,779   INFO  Database filter by difficulty Pedestrian: 2925 => 2925
2023-02-28 16:14:54,796   INFO  Loading KITTI dataset
2023-02-28 16:14:55,144   INFO  Total samples for KITTI dataset: 11873
2023-02-28 16:15:04,776   INFO  ==> Loading parameters from checkpoint ../output/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5/default/ckpt/checkpoint_epoch_40.pth to CPU
2023-02-28 16:15:05,093   INFO  ==> Loading optimizer parameters from checkpoint ../output/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5/default/ckpt/checkpoint_epoch_40.pth to CPU
==> Checkpoint trained from version: pcdet+0.3.0+0000000
==> Checkpoint trained from version: pcdet+0.3.0+0000000
==> Checkpoint trained from version: pcdet+0.3.0+0000000
2023-02-28 16:15:05,183   INFO  ==> Done
==> Checkpoint trained from version: pcdet+0.3.0+0000000
2023-02-28 16:15:05,435   INFO  DistributedDataParallel(
  (module): PointRCNN(
    (history_query): SparseResUQueryNet(
      (history_backbone): Res16UNet14E(
        (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
        (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block1): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
          )
        )
        (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block2): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block3): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block4): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
          )
        )
        (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block5): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block6): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block7): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
        (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
        (block8): Sequential(
          (0): BasicBlock(
            (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
            (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): MinkowskiReLU()
            (downsample): Sequential(
              (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
              (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
            )
          )
        )
        (relu): MinkowskiReLU()
        (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
      )
      (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
      (p2_backbone): Sequential(
        (0): Linear(in_features=68, out_features=32, bias=True)
        (1): ReLU()
        (2): Linear(in_features=32, out_features=1, bias=True)
      )
      (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (vfe): None
    (backbone_3d): PointNet2MSG(
      (SA_modules): ModuleList(
        (0): PointnetSAModuleMSG(
          (groupers): ModuleList(
            (0): QueryAndGroup()
            (1): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
            (1): Sequential(
              (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (1): PointnetSAModuleMSG(
          (groupers): ModuleList(
            (0): QueryAndGroup()
            (1): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
            (1): Sequential(
              (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (2): PointnetSAModuleMSG(
          (groupers): ModuleList(
            (0): QueryAndGroup()
            (1): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
            (1): Sequential(
              (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (3): PointnetSAModuleMSG(
          (groupers): ModuleList(
            (0): QueryAndGroup()
            (1): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
            (1): Sequential(
              (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
      )
      (FP_modules): ModuleList(
        (0): PointnetFPModule(
          (mlp): Sequential(
            (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
          )
        )
        (1): PointnetFPModule(
          (mlp): Sequential(
            (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
          )
        )
        (2): PointnetFPModule(
          (mlp): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
          )
        )
        (3): PointnetFPModule(
          (mlp): Sequential(
            (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
          )
        )
      )
    )
    (map_to_bev_module): None
    (pfe): None
    (backbone_2d): None
    (dense_head): None
    (point_head): PointHeadBox(
      (cls_loss_func): SigmoidFocalClassificationLoss()
      (reg_loss_func): WeightedSmoothL1Loss()
      (cls_layers): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=256, out_features=256, bias=False)
        (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU()
        (6): Linear(in_features=256, out_features=2, bias=True)
      )
      (box_layers): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=256, out_features=256, bias=False)
        (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU()
        (6): Linear(in_features=256, out_features=8, bias=True)
      )
    )
    (roi_head): PointRCNNHead(
      (proposal_target_layer): ProposalTargetLayer()
      (reg_loss_func): WeightedSmoothL1Loss()
      (SA_modules): ModuleList(
        (0): PointnetSAModule(
          (groupers): ModuleList(
            (0): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (1): PointnetSAModule(
          (groupers): ModuleList(
            (0): QueryAndGroup()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
        (2): PointnetSAModule(
          (groupers): ModuleList(
            (0): GroupAll()
          )
          (mlps): ModuleList(
            (0): Sequential(
              (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU()
              (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU()
              (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (8): ReLU()
            )
          )
        )
      )
      (xyz_up_layer): Sequential(
        (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
        (1): ReLU()
        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        (3): ReLU()
      )
      (merge_down_layer): Sequential(
        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
        (1): ReLU()
      )
      (cls_layers): Sequential(
        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.0, inplace=False)
        (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
      )
      (reg_layers): Sequential(
        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.0, inplace=False)
        (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
      )
      (roipoint_pool3d_layer): RoIPointPool3d()
    )
  )
)
2023-02-28 16:15:05,443   INFO  **********************Start training lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5(default)**********************
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
2023-03-01 01:59:58,862   INFO  **********************End training lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5(default)**********************



2023-03-01 01:59:58,863   INFO  **********************Start evaluation lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5(default)**********************
2023-03-01 01:59:58,926   INFO  Loading KITTI dataset
2023-03-01 01:59:59,197   INFO  Total samples for KITTI dataset: 2432
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING Found log directory outside of given root_logdir, dropping given root_logdir for event file in /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5/default/eval/eval_with_train/tensorboard_val
2023-03-01 01:59:59,249   INFO  ==> Loading parameters from checkpoint /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5/default/ckpt/checkpoint_epoch_40.pth to CPU
2023-03-01 01:59:59,897   INFO  ==> Checkpoint trained from version: pcdet+0.3.0+0000000
2023-03-01 02:00:01,200   INFO  ==> Done (loaded 502/502)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
2023-03-01 02:00:01,308   INFO  *************** EPOCH 40 EVALUATION *****************
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
eval:   0%|                                                                                       | 0/304 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
reading error 005850
eval:   0%|                                                                | 0/304 [00:03<?, ?it/s, recall_0.3=(2, 2) / 2]eval:   0%|▏                                                       | 1/304 [00:03<16:25,  3.25s/it, recall_0.3=(2, 2) / 2]eval:   0%|▏                                                       | 1/304 [00:03<16:25,  3.25s/it, recall_0.3=(4, 4) / 4]eval:   1%|▎                                                       | 2/304 [00:03<08:17,  1.65s/it, recall_0.3=(4, 4) / 4]reading error 017379
eval:   1%|▎                                                       | 2/304 [00:04<08:17,  1.65s/it, recall_0.3=(6, 6) / 6]eval:   1%|▌                                                       | 3/304 [00:04<05:39,  1.13s/it, recall_0.3=(6, 6) / 6]eval:   1%|▌                                                       | 3/304 [00:04<05:39,  1.13s/it, recall_0.3=(8, 8) / 8]eval:   1%|▋                                                       | 4/304 [00:04<04:30,  1.11it/s, recall_0.3=(8, 8) / 8]eval:   1%|▋                                                      | 4/304 [00:05<04:30,  1.11it/s, recall_0.3=(9, 9) / 10]eval:   2%|▉                                                      | 5/304 [00:05<03:26,  1.45it/s, recall_0.3=(9, 9) / 10]eval:   2%|▊                                                    | 5/304 [00:05<03:26,  1.45it/s, recall_0.3=(20, 20) / 23]eval:   2%|█                                                    | 6/304 [00:05<03:14,  1.53it/s, recall_0.3=(20, 20) / 23]eval:   2%|█                                                    | 6/304 [00:06<03:14,  1.53it/s, recall_0.3=(30, 30) / 33]eval:   2%|█▏                                                   | 7/304 [00:06<02:51,  1.73it/s, recall_0.3=(30, 30) / 33]eval:   2%|█▏                                                   | 7/304 [00:06<02:51,  1.73it/s, recall_0.3=(40, 40) / 43]eval:   3%|█▍                                                   | 8/304 [00:06<02:50,  1.73it/s, recall_0.3=(40, 40) / 43]eval:   3%|█▍                                                   | 8/304 [00:07<02:50,  1.73it/s, recall_0.3=(49, 49) / 53]eval:   3%|█▌                                                   | 9/304 [00:07<03:32,  1.39it/s, recall_0.3=(49, 49) / 53]eval:   3%|█▌                                                   | 9/304 [00:10<03:32,  1.39it/s, recall_0.3=(56, 56) / 60]eval:   3%|█▋                                                  | 10/304 [00:10<07:11,  1.47s/it, recall_0.3=(56, 56) / 60]eval:   3%|█▋                                                  | 10/304 [00:11<07:11,  1.47s/it, recall_0.3=(63, 63) / 67]eval:   4%|█▉                                                  | 11/304 [00:11<05:33,  1.14s/it, recall_0.3=(63, 63) / 67]eval:   4%|█▉                                                  | 11/304 [00:11<05:33,  1.14s/it, recall_0.3=(69, 69) / 73]eval:   4%|██                                                  | 12/304 [00:11<04:31,  1.08it/s, recall_0.3=(69, 69) / 73]eval:   4%|██                                                  | 12/304 [00:12<04:31,  1.08it/s, recall_0.3=(73, 73) / 79]eval:   4%|██▏                                                 | 13/304 [00:12<04:01,  1.21it/s, recall_0.3=(73, 73) / 79]eval:   4%|██▏                                                 | 13/304 [00:15<04:01,  1.21it/s, recall_0.3=(77, 77) / 83]eval:   5%|██▍                                                 | 14/304 [00:15<07:28,  1.55s/it, recall_0.3=(77, 77) / 83]eval:   5%|██▍                                                 | 14/304 [00:15<07:28,  1.55s/it, recall_0.3=(83, 83) / 91]eval:   5%|██▌                                                 | 15/304 [00:15<05:50,  1.21s/it, recall_0.3=(83, 83) / 91]eval:   5%|██▌                                                | 15/304 [00:16<05:50,  1.21s/it, recall_0.3=(90, 90) / 102]eval:   5%|██▋                                                | 16/304 [00:16<04:44,  1.01it/s, recall_0.3=(90, 90) / 102]eval:   5%|██▌                                              | 16/304 [00:16<04:44,  1.01it/s, recall_0.3=(101, 101) / 114]eval:   6%|██▋                                              | 17/304 [00:16<03:46,  1.27it/s, recall_0.3=(101, 101) / 114]eval:   6%|██▋                                              | 17/304 [00:18<03:46,  1.27it/s, recall_0.3=(109, 109) / 124]eval:   6%|██▉                                              | 18/304 [00:18<04:48,  1.01s/it, recall_0.3=(109, 109) / 124]eval:   6%|██▉                                              | 18/304 [00:18<04:48,  1.01s/it, recall_0.3=(118, 118) / 134]eval:   6%|███                                              | 19/304 [00:18<04:03,  1.17it/s, recall_0.3=(118, 118) / 134]eval:   6%|███                                              | 19/304 [00:19<04:03,  1.17it/s, recall_0.3=(128, 128) / 144]eval:   7%|███▏                                             | 20/304 [00:19<03:38,  1.30it/s, recall_0.3=(128, 128) / 144]eval:   7%|███▏                                             | 20/304 [00:20<03:38,  1.30it/s, recall_0.3=(136, 136) / 153]eval:   7%|███▍                                             | 21/304 [00:20<03:34,  1.32it/s, recall_0.3=(136, 136) / 153]eval:   7%|███▍                                             | 21/304 [00:22<03:34,  1.32it/s, recall_0.3=(144, 144) / 161]eval:   7%|███▌                                             | 22/304 [00:22<06:08,  1.31s/it, recall_0.3=(144, 144) / 161]eval:   7%|███▌                                             | 22/304 [00:23<06:08,  1.31s/it, recall_0.3=(148, 148) / 165]eval:   8%|███▋                                             | 23/304 [00:23<04:56,  1.06s/it, recall_0.3=(148, 148) / 165]eval:   8%|███▋                                             | 23/304 [00:23<04:56,  1.06s/it, recall_0.3=(151, 152) / 169]eval:   8%|███▊                                             | 24/304 [00:23<04:02,  1.16it/s, recall_0.3=(151, 152) / 169]eval:   8%|███▊                                             | 24/304 [00:24<04:02,  1.16it/s, recall_0.3=(155, 156) / 173]eval:   8%|████                                             | 25/304 [00:24<03:31,  1.32it/s, recall_0.3=(155, 156) / 173]eval:   8%|████                                             | 25/304 [00:26<03:31,  1.32it/s, recall_0.3=(157, 158) / 176]eval:   9%|████▏                                            | 26/304 [00:26<06:22,  1.37s/it, recall_0.3=(157, 158) / 176]eval:   9%|████▏                                            | 26/304 [00:27<06:22,  1.37s/it, recall_0.3=(157, 158) / 179]eval:   9%|████▎                                            | 27/304 [00:27<04:55,  1.06s/it, recall_0.3=(157, 158) / 179]eval:   9%|████▎                                            | 27/304 [00:27<04:55,  1.06s/it, recall_0.3=(159, 160) / 184]eval:   9%|████▌                                            | 28/304 [00:27<03:44,  1.23it/s, recall_0.3=(159, 160) / 184]eval:   9%|████▌                                            | 28/304 [00:27<03:44,  1.23it/s, recall_0.3=(162, 163) / 190]eval:  10%|████▋                                            | 29/304 [00:27<03:08,  1.46it/s, recall_0.3=(162, 163) / 190]eval:  10%|████▋                                            | 29/304 [00:32<03:08,  1.46it/s, recall_0.3=(166, 167) / 194]eval:  10%|████▊                                            | 30/304 [00:32<08:52,  1.94s/it, recall_0.3=(166, 167) / 194]eval:  10%|████▊                                            | 30/304 [00:33<08:52,  1.94s/it, recall_0.3=(173, 174) / 203]eval:  10%|████▉                                            | 31/304 [00:33<06:38,  1.46s/it, recall_0.3=(173, 174) / 203]eval:  10%|████▉                                            | 31/304 [00:33<06:38,  1.46s/it, recall_0.3=(183, 184) / 219]eval:  11%|█████▏                                           | 32/304 [00:33<05:05,  1.12s/it, recall_0.3=(183, 184) / 219]eval:  11%|█████▏                                           | 32/304 [00:33<05:05,  1.12s/it, recall_0.3=(199, 200) / 238]eval:  11%|█████▎                                           | 33/304 [00:33<04:03,  1.11it/s, recall_0.3=(199, 200) / 238]eval:  11%|█████▎                                           | 33/304 [00:36<04:03,  1.11it/s, recall_0.3=(211, 212) / 252]eval:  11%|█████▍                                           | 34/304 [00:36<06:29,  1.44s/it, recall_0.3=(211, 212) / 252]eval:  11%|█████▍                                           | 34/304 [00:36<06:29,  1.44s/it, recall_0.3=(218, 219) / 262]eval:  12%|█████▋                                           | 35/304 [00:36<05:08,  1.15s/it, recall_0.3=(218, 219) / 262]eval:  12%|█████▋                                           | 35/304 [00:37<05:08,  1.15s/it, recall_0.3=(223, 224) / 268]eval:  12%|█████▊                                           | 36/304 [00:37<04:13,  1.06it/s, recall_0.3=(223, 224) / 268]eval:  12%|█████▊                                           | 36/304 [00:37<04:13,  1.06it/s, recall_0.3=(226, 227) / 273]eval:  12%|█████▉                                           | 37/304 [00:37<03:27,  1.29it/s, recall_0.3=(226, 227) / 273]eval:  12%|█████▉                                           | 37/304 [00:40<03:27,  1.29it/s, recall_0.3=(228, 229) / 277]eval:  12%|██████▏                                          | 38/304 [00:40<06:04,  1.37s/it, recall_0.3=(228, 229) / 277]eval:  12%|██████▏                                          | 38/304 [00:41<06:04,  1.37s/it, recall_0.3=(230, 231) / 279]eval:  13%|██████▎                                          | 39/304 [00:41<04:54,  1.11s/it, recall_0.3=(230, 231) / 279]eval:  13%|██████▎                                          | 39/304 [00:41<04:54,  1.11s/it, recall_0.3=(232, 233) / 281]eval:  13%|██████▍                                          | 40/304 [00:41<03:53,  1.13it/s, recall_0.3=(232, 233) / 281]eval:  13%|██████▍                                          | 40/304 [00:41<03:53,  1.13it/s, recall_0.3=(234, 235) / 283]eval:  13%|██████▌                                          | 41/304 [00:41<03:04,  1.43it/s, recall_0.3=(234, 235) / 283]eval:  13%|██████▌                                          | 41/304 [00:43<03:04,  1.43it/s, recall_0.3=(236, 237) / 286]eval:  14%|██████▊                                          | 42/304 [00:43<03:58,  1.10it/s, recall_0.3=(236, 237) / 286]eval:  14%|██████▊                                          | 42/304 [00:43<03:58,  1.10it/s, recall_0.3=(238, 239) / 290]eval:  14%|██████▉                                          | 43/304 [00:43<03:04,  1.41it/s, recall_0.3=(238, 239) / 290]eval:  14%|██████▉                                          | 43/304 [00:43<03:04,  1.41it/s, recall_0.3=(240, 241) / 293]eval:  14%|███████                                          | 44/304 [00:43<02:40,  1.62it/s, recall_0.3=(240, 241) / 293]eval:  14%|███████                                          | 44/304 [00:44<02:40,  1.62it/s, recall_0.3=(242, 243) / 295]eval:  15%|███████▎                                         | 45/304 [00:44<02:26,  1.77it/s, recall_0.3=(242, 243) / 295]eval:  15%|███████▎                                         | 45/304 [00:45<02:26,  1.77it/s, recall_0.3=(245, 246) / 299]eval:  15%|███████▍                                         | 46/304 [00:45<03:31,  1.22it/s, recall_0.3=(245, 246) / 299]eval:  15%|███████▍                                         | 46/304 [00:45<03:31,  1.22it/s, recall_0.3=(249, 250) / 303]eval:  15%|███████▌                                         | 47/304 [00:45<02:43,  1.57it/s, recall_0.3=(249, 250) / 303]eval:  15%|███████▌                                         | 47/304 [00:46<02:43,  1.57it/s, recall_0.3=(252, 253) / 307]eval:  16%|███████▋                                         | 48/304 [00:46<02:12,  1.93it/s, recall_0.3=(252, 253) / 307]eval:  16%|███████▋                                         | 48/304 [00:46<02:12,  1.93it/s, recall_0.3=(253, 254) / 311]eval:  16%|███████▉                                         | 49/304 [00:46<01:52,  2.28it/s, recall_0.3=(253, 254) / 311]eval:  16%|███████▉                                         | 49/304 [00:48<01:52,  2.28it/s, recall_0.3=(254, 256) / 315]eval:  16%|████████                                         | 50/304 [00:48<04:32,  1.07s/it, recall_0.3=(254, 256) / 315]eval:  16%|████████                                         | 50/304 [00:49<04:32,  1.07s/it, recall_0.3=(256, 258) / 320]eval:  17%|████████▏                                        | 51/304 [00:49<03:39,  1.15it/s, recall_0.3=(256, 258) / 320]eval:  17%|████████▏                                        | 51/304 [00:49<03:39,  1.15it/s, recall_0.3=(261, 263) / 328]eval:  17%|████████▍                                        | 52/304 [00:49<03:12,  1.31it/s, recall_0.3=(261, 263) / 328]eval:  17%|████████▍                                        | 52/304 [00:50<03:12,  1.31it/s, recall_0.3=(263, 265) / 333]eval:  17%|████████▌                                        | 53/304 [00:50<02:42,  1.54it/s, recall_0.3=(263, 265) / 333]eval:  17%|████████▌                                        | 53/304 [00:52<02:42,  1.54it/s, recall_0.3=(264, 266) / 336]eval:  18%|████████▋                                        | 54/304 [00:52<05:00,  1.20s/it, recall_0.3=(264, 266) / 336]eval:  18%|████████▋                                        | 54/304 [00:53<05:00,  1.20s/it, recall_0.3=(264, 266) / 338]eval:  18%|████████▊                                        | 55/304 [00:53<04:12,  1.01s/it, recall_0.3=(264, 266) / 338]eval:  18%|████████▊                                        | 55/304 [00:53<04:12,  1.01s/it, recall_0.3=(264, 266) / 340]eval:  18%|█████████                                        | 56/304 [00:53<03:24,  1.21it/s, recall_0.3=(264, 266) / 340]eval:  18%|█████████                                        | 56/304 [00:54<03:24,  1.21it/s, recall_0.3=(268, 269) / 346]eval:  19%|█████████▏                                       | 57/304 [00:54<02:53,  1.42it/s, recall_0.3=(268, 269) / 346]eval:  19%|█████████▏                                       | 57/304 [00:56<02:53,  1.42it/s, recall_0.3=(276, 277) / 355]eval:  19%|█████████▎                                       | 58/304 [00:56<05:19,  1.30s/it, recall_0.3=(276, 277) / 355]eval:  19%|█████████▎                                       | 58/304 [00:56<05:19,  1.30s/it, recall_0.3=(288, 289) / 367]eval:  19%|█████████▌                                       | 59/304 [00:56<04:00,  1.02it/s, recall_0.3=(288, 289) / 367]eval:  19%|█████████▌                                       | 59/304 [00:57<04:00,  1.02it/s, recall_0.3=(300, 301) / 381]eval:  20%|█████████▋                                       | 60/304 [00:57<03:07,  1.30it/s, recall_0.3=(300, 301) / 381]eval:  20%|█████████▋                                       | 60/304 [00:57<03:07,  1.30it/s, recall_0.3=(309, 310) / 394]eval:  20%|█████████▊                                       | 61/304 [00:57<02:39,  1.52it/s, recall_0.3=(309, 310) / 394]eval:  20%|█████████▊                                       | 61/304 [01:01<02:39,  1.52it/s, recall_0.3=(317, 318) / 406]eval:  20%|█████████▉                                       | 62/304 [01:01<06:25,  1.59s/it, recall_0.3=(317, 318) / 406]eval:  20%|█████████▉                                       | 62/304 [01:01<06:25,  1.59s/it, recall_0.3=(323, 324) / 412]eval:  21%|██████████▏                                      | 63/304 [01:01<04:54,  1.22s/it, recall_0.3=(323, 324) / 412]eval:  21%|██████████▏                                      | 63/304 [01:02<04:54,  1.22s/it, recall_0.3=(326, 327) / 416]eval:  21%|██████████▎                                      | 64/304 [01:02<03:46,  1.06it/s, recall_0.3=(326, 327) / 416]eval:  21%|██████████▎                                      | 64/304 [01:02<03:46,  1.06it/s, recall_0.3=(330, 331) / 424]eval:  21%|██████████▍                                      | 65/304 [01:02<02:58,  1.34it/s, recall_0.3=(330, 331) / 424]eval:  21%|██████████▍                                      | 65/304 [01:04<02:58,  1.34it/s, recall_0.3=(343, 344) / 443]eval:  22%|██████████▋                                      | 66/304 [01:04<04:54,  1.24s/it, recall_0.3=(343, 344) / 443]eval:  22%|██████████▋                                      | 66/304 [01:05<04:54,  1.24s/it, recall_0.3=(358, 359) / 463]eval:  22%|██████████▊                                      | 67/304 [01:05<03:53,  1.02it/s, recall_0.3=(358, 359) / 463]eval:  22%|██████████▊                                      | 67/304 [01:05<03:53,  1.02it/s, recall_0.3=(368, 369) / 478]eval:  22%|██████████▉                                      | 68/304 [01:05<03:04,  1.28it/s, recall_0.3=(368, 369) / 478]eval:  22%|██████████▉                                      | 68/304 [01:05<03:04,  1.28it/s, recall_0.3=(379, 380) / 494]eval:  23%|███████████                                      | 69/304 [01:05<02:37,  1.50it/s, recall_0.3=(379, 380) / 494]eval:  23%|███████████                                      | 69/304 [01:09<02:37,  1.50it/s, recall_0.3=(386, 387) / 504]eval:  23%|███████████▎                                     | 70/304 [01:09<06:22,  1.63s/it, recall_0.3=(386, 387) / 504]eval:  23%|███████████▎                                     | 70/304 [01:09<06:22,  1.63s/it, recall_0.3=(390, 391) / 509]eval:  23%|███████████▍                                     | 71/304 [01:09<04:43,  1.21s/it, recall_0.3=(390, 391) / 509]eval:  23%|███████████▍                                     | 71/304 [01:10<04:43,  1.21s/it, recall_0.3=(394, 395) / 513]eval:  24%|███████████▌                                     | 72/304 [01:10<03:39,  1.06it/s, recall_0.3=(394, 395) / 513]eval:  24%|███████████▌                                     | 72/304 [01:10<03:39,  1.06it/s, recall_0.3=(400, 401) / 519]eval:  24%|███████████▊                                     | 73/304 [01:10<03:01,  1.28it/s, recall_0.3=(400, 401) / 519]eval:  24%|███████████▊                                     | 73/304 [01:14<03:01,  1.28it/s, recall_0.3=(404, 405) / 525]eval:  24%|███████████▉                                     | 74/304 [01:14<06:37,  1.73s/it, recall_0.3=(404, 405) / 525]eval:  24%|███████████▉                                     | 74/304 [01:14<06:37,  1.73s/it, recall_0.3=(406, 407) / 527]eval:  25%|████████████                                     | 75/304 [01:14<04:52,  1.28s/it, recall_0.3=(406, 407) / 527]eval:  25%|████████████                                     | 75/304 [01:15<04:52,  1.28s/it, recall_0.3=(408, 409) / 531]eval:  25%|████████████▎                                    | 76/304 [01:15<03:40,  1.03it/s, recall_0.3=(408, 409) / 531]eval:  25%|████████████▎                                    | 76/304 [01:15<03:40,  1.03it/s, recall_0.3=(414, 415) / 537]eval:  25%|████████████▍                                    | 77/304 [01:15<02:56,  1.29it/s, recall_0.3=(414, 415) / 537]eval:  25%|████████████▍                                    | 77/304 [01:18<02:56,  1.29it/s, recall_0.3=(419, 420) / 543]eval:  26%|████████████▌                                    | 78/304 [01:18<05:18,  1.41s/it, recall_0.3=(419, 420) / 543]eval:  26%|████████████▌                                    | 78/304 [01:18<05:18,  1.41s/it, recall_0.3=(423, 424) / 549]eval:  26%|████████████▋                                    | 79/304 [01:18<04:04,  1.09s/it, recall_0.3=(423, 424) / 549]eval:  26%|████████████▋                                    | 79/304 [01:18<04:04,  1.09s/it, recall_0.3=(427, 428) / 554]eval:  26%|████████████▉                                    | 80/304 [01:18<03:11,  1.17it/s, recall_0.3=(427, 428) / 554]eval:  26%|████████████▉                                    | 80/304 [01:19<03:11,  1.17it/s, recall_0.3=(430, 431) / 557]eval:  27%|█████████████                                    | 81/304 [01:19<02:30,  1.48it/s, recall_0.3=(430, 431) / 557]eval:  27%|█████████████                                    | 81/304 [01:22<02:30,  1.48it/s, recall_0.3=(432, 433) / 559]eval:  27%|█████████████▏                                   | 82/304 [01:22<05:38,  1.52s/it, recall_0.3=(432, 433) / 559]eval:  27%|█████████████▏                                   | 82/304 [01:23<05:38,  1.52s/it, recall_0.3=(439, 440) / 566]eval:  27%|█████████████▍                                   | 83/304 [01:23<04:33,  1.24s/it, recall_0.3=(439, 440) / 566]eval:  27%|█████████████▍                                   | 83/304 [01:23<04:33,  1.24s/it, recall_0.3=(448, 449) / 576]eval:  28%|█████████████▌                                   | 84/304 [01:23<03:48,  1.04s/it, recall_0.3=(448, 449) / 576]eval:  28%|█████████████▌                                   | 84/304 [01:24<03:48,  1.04s/it, recall_0.3=(458, 459) / 586]eval:  28%|█████████████▋                                   | 85/304 [01:24<03:12,  1.14it/s, recall_0.3=(458, 459) / 586]eval:  28%|█████████████▋                                   | 85/304 [01:26<03:12,  1.14it/s, recall_0.3=(465, 466) / 593]eval:  28%|█████████████▊                                   | 86/304 [01:26<05:01,  1.38s/it, recall_0.3=(465, 466) / 593]eval:  28%|█████████████▊                                   | 86/304 [01:27<05:01,  1.38s/it, recall_0.3=(471, 472) / 600]eval:  29%|██████████████                                   | 87/304 [01:27<04:02,  1.12s/it, recall_0.3=(471, 472) / 600]eval:  29%|██████████████                                   | 87/304 [01:28<04:02,  1.12s/it, recall_0.3=(479, 480) / 608]eval:  29%|██████████████▏                                  | 88/304 [01:28<03:30,  1.02it/s, recall_0.3=(479, 480) / 608]eval:  29%|██████████████▏                                  | 88/304 [01:28<03:30,  1.02it/s, recall_0.3=(485, 486) / 614]eval:  29%|██████████████▎                                  | 89/304 [01:28<02:59,  1.20it/s, recall_0.3=(485, 486) / 614]eval:  29%|██████████████▎                                  | 89/304 [01:32<02:59,  1.20it/s, recall_0.3=(488, 489) / 617]eval:  30%|██████████████▌                                  | 90/304 [01:32<05:49,  1.63s/it, recall_0.3=(488, 489) / 617]eval:  30%|██████████████▌                                  | 90/304 [01:32<05:49,  1.63s/it, recall_0.3=(490, 491) / 619]eval:  30%|██████████████▋                                  | 91/304 [01:32<04:19,  1.22s/it, recall_0.3=(490, 491) / 619]eval:  30%|██████████████▋                                  | 91/304 [01:32<04:19,  1.22s/it, recall_0.3=(491, 492) / 621]eval:  30%|██████████████▊                                  | 92/304 [01:32<03:16,  1.08it/s, recall_0.3=(491, 492) / 621]eval:  30%|██████████████▊                                  | 92/304 [01:33<03:16,  1.08it/s, recall_0.3=(491, 492) / 623]eval:  31%|██████████████▉                                  | 93/304 [01:33<02:59,  1.17it/s, recall_0.3=(491, 492) / 623]eval:  31%|██████████████▉                                  | 93/304 [01:35<02:59,  1.17it/s, recall_0.3=(491, 492) / 623]eval:  31%|███████████████▏                                 | 94/304 [01:35<04:53,  1.40s/it, recall_0.3=(491, 492) / 623]eval:  31%|███████████████▏                                 | 94/304 [01:36<04:53,  1.40s/it, recall_0.3=(493, 494) / 625]eval:  31%|███████████████▎                                 | 95/304 [01:36<03:48,  1.09s/it, recall_0.3=(493, 494) / 625]eval:  31%|███████████████▎                                 | 95/304 [01:36<03:48,  1.09s/it, recall_0.3=(496, 497) / 628]eval:  32%|███████████████▍                                 | 96/304 [01:36<02:54,  1.19it/s, recall_0.3=(496, 497) / 628]eval:  32%|███████████████▍                                 | 96/304 [01:36<02:54,  1.19it/s, recall_0.3=(498, 499) / 631]eval:  32%|███████████████▋                                 | 97/304 [01:36<02:21,  1.47it/s, recall_0.3=(498, 499) / 631]eval:  32%|███████████████▋                                 | 97/304 [01:37<02:21,  1.47it/s, recall_0.3=(501, 502) / 635]eval:  32%|███████████████▊                                 | 98/304 [01:37<02:39,  1.29it/s, recall_0.3=(501, 502) / 635]eval:  32%|███████████████▊                                 | 98/304 [01:38<02:39,  1.29it/s, recall_0.3=(503, 504) / 637]eval:  33%|███████████████▉                                 | 99/304 [01:38<02:08,  1.59it/s, recall_0.3=(503, 504) / 637]eval:  33%|███████████████▉                                 | 99/304 [01:38<02:08,  1.59it/s, recall_0.3=(505, 506) / 639]eval:  33%|███████████████▊                                | 100/304 [01:38<01:43,  1.97it/s, recall_0.3=(505, 506) / 639]eval:  33%|███████████████▊                                | 100/304 [01:38<01:43,  1.97it/s, recall_0.3=(507, 508) / 641]eval:  33%|███████████████▉                                | 101/304 [01:38<01:34,  2.15it/s, recall_0.3=(507, 508) / 641]eval:  33%|███████████████▉                                | 101/304 [01:40<01:34,  2.15it/s, recall_0.3=(509, 510) / 643]eval:  34%|████████████████                                | 102/304 [01:40<02:46,  1.21it/s, recall_0.3=(509, 510) / 643]eval:  34%|████████████████                                | 102/304 [01:40<02:46,  1.21it/s, recall_0.3=(512, 513) / 647]eval:  34%|████████████████▎                               | 103/304 [01:40<02:13,  1.51it/s, recall_0.3=(512, 513) / 647]eval:  34%|████████████████▎                               | 103/304 [01:40<02:13,  1.51it/s, recall_0.3=(521, 522) / 660]eval:  34%|████████████████▍                               | 104/304 [01:40<01:47,  1.87it/s, recall_0.3=(521, 522) / 660]eval:  34%|████████████████▍                               | 104/304 [01:41<01:47,  1.87it/s, recall_0.3=(534, 535) / 686]eval:  35%|████████████████▌                               | 105/304 [01:41<01:25,  2.32it/s, recall_0.3=(534, 535) / 686]eval:  35%|████████████████▌                               | 105/304 [01:41<01:25,  2.32it/s, recall_0.3=(548, 549) / 710]eval:  35%|████████████████▋                               | 106/304 [01:41<01:53,  1.75it/s, recall_0.3=(548, 549) / 710]eval:  35%|████████████████▋                               | 106/304 [01:42<01:53,  1.75it/s, recall_0.3=(562, 563) / 734]eval:  35%|████████████████▉                               | 107/304 [01:42<01:30,  2.19it/s, recall_0.3=(562, 563) / 734]eval:  35%|████████████████▉                               | 107/304 [01:42<01:30,  2.19it/s, recall_0.3=(576, 577) / 759]eval:  36%|█████████████████                               | 108/304 [01:42<01:15,  2.61it/s, recall_0.3=(576, 577) / 759]eval:  36%|█████████████████                               | 108/304 [01:42<01:15,  2.61it/s, recall_0.3=(592, 593) / 782]eval:  36%|█████████████████▏                              | 109/304 [01:42<01:03,  3.07it/s, recall_0.3=(592, 593) / 782]eval:  36%|█████████████████▏                              | 109/304 [01:43<01:03,  3.07it/s, recall_0.3=(606, 607) / 808]eval:  36%|█████████████████▎                              | 110/304 [01:43<01:57,  1.66it/s, recall_0.3=(606, 607) / 808]eval:  36%|█████████████████▎                              | 110/304 [01:43<01:57,  1.66it/s, recall_0.3=(606, 607) / 808]eval:  37%|█████████████████▌                              | 111/304 [01:44<01:31,  2.10it/s, recall_0.3=(606, 607) / 808]eval:  37%|█████████████████▌                              | 111/304 [01:44<01:31,  2.10it/s, recall_0.3=(606, 607) / 808]eval:  37%|█████████████████▋                              | 112/304 [01:44<01:20,  2.40it/s, recall_0.3=(606, 607) / 808]eval:  37%|█████████████████▋                              | 112/304 [01:44<01:20,  2.40it/s, recall_0.3=(607, 608) / 810]eval:  37%|█████████████████▊                              | 113/304 [01:44<01:09,  2.75it/s, recall_0.3=(607, 608) / 810]eval:  37%|█████████████████▊                              | 113/304 [01:46<01:09,  2.75it/s, recall_0.3=(608, 609) / 812]eval:  38%|██████████████████                              | 114/304 [01:46<02:16,  1.39it/s, recall_0.3=(608, 609) / 812]eval:  38%|██████████████████                              | 114/304 [01:46<02:16,  1.39it/s, recall_0.3=(612, 613) / 818]eval:  38%|██████████████████▏                             | 115/304 [01:46<01:49,  1.73it/s, recall_0.3=(612, 613) / 818]eval:  38%|██████████████████▏                             | 115/304 [01:46<01:49,  1.73it/s, recall_0.3=(617, 618) / 825]eval:  38%|██████████████████▎                             | 116/304 [01:46<01:30,  2.08it/s, recall_0.3=(617, 618) / 825]eval:  38%|██████████████████▎                             | 116/304 [01:46<01:30,  2.08it/s, recall_0.3=(621, 622) / 829]eval:  38%|██████████████████▍                             | 117/304 [01:46<01:16,  2.45it/s, recall_0.3=(621, 622) / 829]eval:  38%|██████████████████▍                             | 117/304 [01:47<01:16,  2.45it/s, recall_0.3=(625, 626) / 833]eval:  39%|██████████████████▋                             | 118/304 [01:47<01:46,  1.74it/s, recall_0.3=(625, 626) / 833]eval:  39%|██████████████████▋                             | 118/304 [01:48<01:46,  1.74it/s, recall_0.3=(626, 627) / 835]eval:  39%|██████████████████▊                             | 119/304 [01:48<01:28,  2.10it/s, recall_0.3=(626, 627) / 835]eval:  39%|██████████████████▊                             | 119/304 [01:48<01:28,  2.10it/s, recall_0.3=(626, 627) / 835]eval:  39%|██████████████████▉                             | 120/304 [01:48<01:12,  2.55it/s, recall_0.3=(626, 627) / 835]eval:  39%|██████████████████▉                             | 120/304 [01:48<01:12,  2.55it/s, recall_0.3=(626, 627) / 835]eval:  40%|███████████████████                             | 121/304 [01:48<01:01,  2.97it/s, recall_0.3=(626, 627) / 835]eval:  40%|███████████████████                             | 121/304 [01:50<01:01,  2.97it/s, recall_0.3=(627, 628) / 837]eval:  40%|███████████████████▎                            | 122/304 [01:50<02:37,  1.15it/s, recall_0.3=(627, 628) / 837]eval:  40%|███████████████████▎                            | 122/304 [01:50<02:37,  1.15it/s, recall_0.3=(632, 633) / 842]eval:  40%|███████████████████▍                            | 123/304 [01:50<02:04,  1.46it/s, recall_0.3=(632, 633) / 842]eval:  40%|███████████████████▍                            | 123/304 [01:50<02:04,  1.46it/s, recall_0.3=(639, 640) / 849]eval:  41%|███████████████████▌                            | 124/304 [01:50<01:36,  1.86it/s, recall_0.3=(639, 640) / 849]eval:  41%|███████████████████▌                            | 124/304 [01:51<01:36,  1.86it/s, recall_0.3=(643, 644) / 854]eval:  41%|███████████████████▋                            | 125/304 [01:51<01:16,  2.32it/s, recall_0.3=(643, 644) / 854]eval:  41%|███████████████████▋                            | 125/304 [01:52<01:16,  2.32it/s, recall_0.3=(649, 650) / 860]eval:  41%|███████████████████▉                            | 126/304 [01:52<01:49,  1.62it/s, recall_0.3=(649, 650) / 860]eval:  41%|███████████████████▉                            | 126/304 [01:52<01:49,  1.62it/s, recall_0.3=(653, 654) / 864]eval:  42%|████████████████████                            | 127/304 [01:52<01:26,  2.05it/s, recall_0.3=(653, 654) / 864]eval:  42%|████████████████████                            | 127/304 [01:52<01:26,  2.05it/s, recall_0.3=(655, 656) / 868]eval:  42%|████████████████████▏                           | 128/304 [01:52<01:12,  2.42it/s, recall_0.3=(655, 656) / 868]eval:  42%|████████████████████▏                           | 128/304 [01:52<01:12,  2.42it/s, recall_0.3=(660, 661) / 875]eval:  42%|████████████████████▎                           | 129/304 [01:52<01:06,  2.63it/s, recall_0.3=(660, 661) / 875]eval:  42%|████████████████████▎                           | 129/304 [01:54<01:06,  2.63it/s, recall_0.3=(666, 667) / 881]eval:  43%|████████████████████▌                           | 130/304 [01:54<01:48,  1.60it/s, recall_0.3=(666, 667) / 881]eval:  43%|████████████████████▌                           | 130/304 [01:54<01:48,  1.60it/s, recall_0.3=(671, 672) / 886]eval:  43%|████████████████████▋                           | 131/304 [01:54<01:29,  1.93it/s, recall_0.3=(671, 672) / 886]eval:  43%|████████████████████▋                           | 131/304 [01:57<01:29,  1.93it/s, recall_0.3=(679, 680) / 894]eval:  43%|████████████████████▊                           | 132/304 [01:57<03:58,  1.39s/it, recall_0.3=(679, 680) / 894]eval:  43%|████████████████████▊                           | 132/304 [01:58<03:58,  1.39s/it, recall_0.3=(685, 686) / 900]eval:  44%|█████████████████████                           | 133/304 [01:58<03:11,  1.12s/it, recall_0.3=(685, 686) / 900]eval:  44%|█████████████████████                           | 133/304 [01:58<03:11,  1.12s/it, recall_0.3=(688, 689) / 903]eval:  44%|█████████████████████▏                          | 134/304 [01:58<02:32,  1.11it/s, recall_0.3=(688, 689) / 903]eval:  44%|█████████████████████▏                          | 134/304 [01:58<02:32,  1.11it/s, recall_0.3=(689, 690) / 905]eval:  44%|█████████████████████▎                          | 135/304 [01:58<02:00,  1.40it/s, recall_0.3=(689, 690) / 905]eval:  44%|█████████████████████▎                          | 135/304 [02:01<02:00,  1.40it/s, recall_0.3=(689, 690) / 905]eval:  45%|█████████████████████▍                          | 136/304 [02:01<03:55,  1.40s/it, recall_0.3=(689, 690) / 905]eval:  45%|█████████████████████▍                          | 136/304 [02:02<03:55,  1.40s/it, recall_0.3=(689, 690) / 908]eval:  45%|█████████████████████▋                          | 137/304 [02:02<03:09,  1.14s/it, recall_0.3=(689, 690) / 908]eval:  45%|█████████████████████▋                          | 137/304 [02:03<03:09,  1.14s/it, recall_0.3=(692, 693) / 912]eval:  45%|█████████████████████▊                          | 138/304 [02:03<02:50,  1.03s/it, recall_0.3=(692, 693) / 912]eval:  45%|█████████████████████▊                          | 138/304 [02:03<02:50,  1.03s/it, recall_0.3=(698, 699) / 918]eval:  46%|█████████████████████▉                          | 139/304 [02:03<02:11,  1.26it/s, recall_0.3=(698, 699) / 918]eval:  46%|█████████████████████▉                          | 139/304 [02:05<02:11,  1.26it/s, recall_0.3=(704, 705) / 924]eval:  46%|██████████████████████                          | 140/304 [02:05<03:07,  1.14s/it, recall_0.3=(704, 705) / 924]eval:  46%|██████████████████████                          | 140/304 [02:05<03:07,  1.14s/it, recall_0.3=(708, 709) / 930]eval:  46%|██████████████████████▎                         | 141/304 [02:05<02:29,  1.09it/s, recall_0.3=(708, 709) / 930]eval:  46%|██████████████████████▎                         | 141/304 [02:06<02:29,  1.09it/s, recall_0.3=(708, 709) / 930]eval:  47%|██████████████████████▍                         | 142/304 [02:06<02:26,  1.11it/s, recall_0.3=(708, 709) / 930]eval:  47%|██████████████████████▍                         | 142/304 [02:07<02:26,  1.11it/s, recall_0.3=(708, 709) / 930]eval:  47%|██████████████████████▌                         | 143/304 [02:07<02:04,  1.29it/s, recall_0.3=(708, 709) / 930]eval:  47%|██████████████████████▌                         | 143/304 [02:07<02:04,  1.29it/s, recall_0.3=(708, 709) / 930]eval:  47%|██████████████████████▋                         | 144/304 [02:07<02:01,  1.32it/s, recall_0.3=(708, 709) / 930]eval:  47%|██████████████████████▋                         | 144/304 [02:08<02:01,  1.32it/s, recall_0.3=(708, 709) / 930]eval:  48%|██████████████████████▉                         | 145/304 [02:08<01:36,  1.65it/s, recall_0.3=(708, 709) / 930]eval:  48%|██████████████████████▉                         | 145/304 [02:08<01:36,  1.65it/s, recall_0.3=(708, 709) / 930]eval:  48%|███████████████████████                         | 146/304 [02:08<01:22,  1.90it/s, recall_0.3=(708, 709) / 930]eval:  48%|███████████████████████                         | 146/304 [02:08<01:22,  1.90it/s, recall_0.3=(712, 713) / 936]eval:  48%|███████████████████████▏                        | 147/304 [02:08<01:10,  2.22it/s, recall_0.3=(712, 713) / 936]eval:  48%|███████████████████████▏                        | 147/304 [02:11<01:10,  2.22it/s, recall_0.3=(718, 719) / 947]eval:  49%|███████████████████████▎                        | 148/304 [02:11<02:59,  1.15s/it, recall_0.3=(718, 719) / 947]eval:  49%|███████████████████████▎                        | 148/304 [02:11<02:59,  1.15s/it, recall_0.3=(726, 728) / 960]eval:  49%|███████████████████████▌                        | 149/304 [02:11<02:16,  1.13it/s, recall_0.3=(726, 728) / 960]eval:  49%|███████████████████████▌                        | 149/304 [02:12<02:16,  1.13it/s, recall_0.3=(734, 736) / 970]eval:  49%|███████████████████████▋                        | 150/304 [02:12<02:13,  1.15it/s, recall_0.3=(734, 736) / 970]eval:  49%|███████████████████████▋                        | 150/304 [02:12<02:13,  1.15it/s, recall_0.3=(740, 742) / 981]eval:  50%|███████████████████████▊                        | 151/304 [02:12<01:45,  1.45it/s, recall_0.3=(740, 742) / 981]eval:  50%|███████████████████████▊                        | 151/304 [02:15<01:45,  1.45it/s, recall_0.3=(747, 749) / 992]eval:  50%|████████████████████████                        | 152/304 [02:15<03:21,  1.33s/it, recall_0.3=(747, 749) / 992]eval:  50%|███████████████████████▌                       | 152/304 [02:16<03:21,  1.33s/it, recall_0.3=(754, 756) / 1001]eval:  50%|███████████████████████▋                       | 153/304 [02:16<02:41,  1.07s/it, recall_0.3=(754, 756) / 1001]eval:  50%|███████████████████████▋                       | 153/304 [02:16<02:41,  1.07s/it, recall_0.3=(760, 762) / 1011]eval:  51%|███████████████████████▊                       | 154/304 [02:16<02:04,  1.21it/s, recall_0.3=(760, 762) / 1011]eval:  51%|███████████████████████▊                       | 154/304 [02:16<02:04,  1.21it/s, recall_0.3=(769, 771) / 1022]eval:  51%|███████████████████████▉                       | 155/304 [02:16<01:39,  1.50it/s, recall_0.3=(769, 771) / 1022]eval:  51%|███████████████████████▉                       | 155/304 [02:22<01:39,  1.50it/s, recall_0.3=(777, 779) / 1030]eval:  51%|████████████████████████                       | 156/304 [02:22<05:07,  2.08s/it, recall_0.3=(777, 779) / 1030]eval:  51%|████████████████████████                       | 156/304 [02:22<05:07,  2.08s/it, recall_0.3=(785, 787) / 1038]eval:  52%|████████████████████████▎                      | 157/304 [02:22<03:52,  1.58s/it, recall_0.3=(785, 787) / 1038]eval:  52%|████████████████████████▎                      | 157/304 [02:22<03:52,  1.58s/it, recall_0.3=(792, 794) / 1046]eval:  52%|████████████████████████▍                      | 158/304 [02:22<02:55,  1.21s/it, recall_0.3=(792, 794) / 1046]eval:  52%|████████████████████████▍                      | 158/304 [02:23<02:55,  1.21s/it, recall_0.3=(796, 798) / 1050]eval:  52%|████████████████████████▌                      | 159/304 [02:23<02:19,  1.04it/s, recall_0.3=(796, 798) / 1050]eval:  52%|████████████████████████▌                      | 159/304 [02:27<02:19,  1.04it/s, recall_0.3=(799, 801) / 1053]eval:  53%|████████████████████████▋                      | 160/304 [02:27<04:37,  1.92s/it, recall_0.3=(799, 801) / 1053]eval:  53%|████████████████████████▋                      | 160/304 [02:27<04:37,  1.92s/it, recall_0.3=(799, 801) / 1053]eval:  53%|████████████████████████▉                      | 161/304 [02:27<03:30,  1.47s/it, recall_0.3=(799, 801) / 1053]eval:  53%|████████████████████████▉                      | 161/304 [02:28<03:30,  1.47s/it, recall_0.3=(799, 801) / 1053]eval:  53%|█████████████████████████                      | 162/304 [02:28<02:49,  1.20s/it, recall_0.3=(799, 801) / 1053]eval:  53%|█████████████████████████                      | 162/304 [02:28<02:49,  1.20s/it, recall_0.3=(800, 802) / 1055]eval:  54%|█████████████████████████▏                     | 163/304 [02:28<02:20,  1.00it/s, recall_0.3=(800, 802) / 1055]eval:  54%|█████████████████████████▏                     | 163/304 [02:29<02:20,  1.00it/s, recall_0.3=(802, 804) / 1059]eval:  54%|█████████████████████████▎                     | 164/304 [02:29<02:14,  1.04it/s, recall_0.3=(802, 804) / 1059]eval:  54%|█████████████████████████▎                     | 164/304 [02:30<02:14,  1.04it/s, recall_0.3=(806, 808) / 1067]eval:  54%|█████████████████████████▌                     | 165/304 [02:30<01:41,  1.37it/s, recall_0.3=(806, 808) / 1067]eval:  54%|█████████████████████████▌                     | 165/304 [02:30<01:41,  1.37it/s, recall_0.3=(814, 816) / 1075]eval:  55%|█████████████████████████▋                     | 166/304 [02:30<01:23,  1.64it/s, recall_0.3=(814, 816) / 1075]eval:  55%|█████████████████████████▋                     | 166/304 [02:30<01:23,  1.64it/s, recall_0.3=(822, 824) / 1083]eval:  55%|█████████████████████████▊                     | 167/304 [02:30<01:10,  1.94it/s, recall_0.3=(822, 824) / 1083]eval:  55%|█████████████████████████▊                     | 167/304 [02:31<01:10,  1.94it/s, recall_0.3=(828, 830) / 1091]eval:  55%|█████████████████████████▉                     | 168/304 [02:31<01:40,  1.36it/s, recall_0.3=(828, 830) / 1091]eval:  55%|█████████████████████████▉                     | 168/304 [02:32<01:40,  1.36it/s, recall_0.3=(834, 836) / 1099]eval:  56%|██████████████████████████▏                    | 169/304 [02:32<01:22,  1.63it/s, recall_0.3=(834, 836) / 1099]eval:  56%|██████████████████████████▏                    | 169/304 [02:32<01:22,  1.63it/s, recall_0.3=(838, 840) / 1105]eval:  56%|██████████████████████████▎                    | 170/304 [02:32<01:06,  2.01it/s, recall_0.3=(838, 840) / 1105]eval:  56%|██████████████████████████▎                    | 170/304 [02:32<01:06,  2.01it/s, recall_0.3=(840, 842) / 1107]eval:  56%|██████████████████████████▍                    | 171/304 [02:32<00:53,  2.50it/s, recall_0.3=(840, 842) / 1107]eval:  56%|██████████████████████████▍                    | 171/304 [02:33<00:53,  2.50it/s, recall_0.3=(845, 847) / 1112]eval:  57%|██████████████████████████▌                    | 172/304 [02:33<01:11,  1.85it/s, recall_0.3=(845, 847) / 1112]eval:  57%|██████████████████████████▌                    | 172/304 [02:33<01:11,  1.85it/s, recall_0.3=(851, 853) / 1120]eval:  57%|██████████████████████████▋                    | 173/304 [02:33<01:03,  2.06it/s, recall_0.3=(851, 853) / 1120]eval:  57%|██████████████████████████▋                    | 173/304 [02:34<01:03,  2.06it/s, recall_0.3=(858, 860) / 1128]eval:  57%|██████████████████████████▉                    | 174/304 [02:34<00:59,  2.19it/s, recall_0.3=(858, 860) / 1128]eval:  57%|██████████████████████████▉                    | 174/304 [02:34<00:59,  2.19it/s, recall_0.3=(863, 865) / 1134]eval:  58%|███████████████████████████                    | 175/304 [02:34<00:55,  2.30it/s, recall_0.3=(863, 865) / 1134]eval:  58%|███████████████████████████                    | 175/304 [02:36<00:55,  2.30it/s, recall_0.3=(867, 869) / 1138]eval:  58%|███████████████████████████▏                   | 176/304 [02:36<01:51,  1.15it/s, recall_0.3=(867, 869) / 1138]eval:  58%|███████████████████████████▏                   | 176/304 [02:36<01:51,  1.15it/s, recall_0.3=(871, 873) / 1142]eval:  58%|███████████████████████████▎                   | 177/304 [02:36<01:26,  1.46it/s, recall_0.3=(871, 873) / 1142]eval:  58%|███████████████████████████▎                   | 177/304 [02:37<01:26,  1.46it/s, recall_0.3=(871, 873) / 1142]eval:  59%|███████████████████████████▌                   | 178/304 [02:37<01:12,  1.73it/s, recall_0.3=(871, 873) / 1142]eval:  59%|███████████████████████████▌                   | 178/304 [02:37<01:12,  1.73it/s, recall_0.3=(871, 873) / 1142]eval:  59%|███████████████████████████▋                   | 179/304 [02:37<00:58,  2.13it/s, recall_0.3=(871, 873) / 1142]eval:  59%|███████████████████████████▋                   | 179/304 [02:39<00:58,  2.13it/s, recall_0.3=(873, 875) / 1145]eval:  59%|███████████████████████████▊                   | 180/304 [02:39<01:50,  1.12it/s, recall_0.3=(873, 875) / 1145]eval:  59%|███████████████████████████▊                   | 180/304 [02:39<01:50,  1.12it/s, recall_0.3=(875, 877) / 1147]eval:  60%|███████████████████████████▉                   | 181/304 [02:39<01:23,  1.48it/s, recall_0.3=(875, 877) / 1147]eval:  60%|███████████████████████████▉                   | 181/304 [02:39<01:23,  1.48it/s, recall_0.3=(877, 879) / 1149]eval:  60%|████████████████████████████▏                  | 182/304 [02:39<01:06,  1.84it/s, recall_0.3=(877, 879) / 1149]eval:  60%|████████████████████████████▏                  | 182/304 [02:39<01:06,  1.84it/s, recall_0.3=(877, 879) / 1149]eval:  60%|████████████████████████████▎                  | 183/304 [02:39<00:52,  2.33it/s, recall_0.3=(877, 879) / 1149]eval:  60%|████████████████████████████▎                  | 183/304 [02:41<00:52,  2.33it/s, recall_0.3=(877, 879) / 1149]eval:  61%|████████████████████████████▍                  | 184/304 [02:41<01:43,  1.16it/s, recall_0.3=(877, 879) / 1149]eval:  61%|████████████████████████████▍                  | 184/304 [02:41<01:43,  1.16it/s, recall_0.3=(877, 879) / 1149]eval:  61%|████████████████████████████▌                  | 185/304 [02:41<01:20,  1.48it/s, recall_0.3=(877, 879) / 1149]eval:  61%|████████████████████████████▌                  | 185/304 [02:42<01:20,  1.48it/s, recall_0.3=(877, 879) / 1149]eval:  61%|████████████████████████████▊                  | 186/304 [02:42<01:04,  1.82it/s, recall_0.3=(877, 879) / 1149]eval:  61%|████████████████████████████▊                  | 186/304 [02:42<01:04,  1.82it/s, recall_0.3=(877, 879) / 1149]eval:  62%|████████████████████████████▉                  | 187/304 [02:42<00:53,  2.18it/s, recall_0.3=(877, 879) / 1149]eval:  62%|████████████████████████████▉                  | 187/304 [02:43<00:53,  2.18it/s, recall_0.3=(877, 879) / 1149]eval:  62%|█████████████████████████████                  | 188/304 [02:43<01:13,  1.58it/s, recall_0.3=(877, 879) / 1149]eval:  62%|█████████████████████████████                  | 188/304 [02:43<01:13,  1.58it/s, recall_0.3=(877, 879) / 1149]eval:  62%|█████████████████████████████▏                 | 189/304 [02:43<00:57,  1.98it/s, recall_0.3=(877, 879) / 1149]eval:  62%|█████████████████████████████▏                 | 189/304 [02:43<00:57,  1.98it/s, recall_0.3=(877, 879) / 1149]eval:  62%|█████████████████████████████▍                 | 190/304 [02:43<00:48,  2.35it/s, recall_0.3=(877, 879) / 1149]eval:  62%|█████████████████████████████▍                 | 190/304 [02:45<00:48,  2.35it/s, recall_0.3=(877, 879) / 1149]eval:  63%|█████████████████████████████▌                 | 191/304 [02:45<01:18,  1.44it/s, recall_0.3=(877, 879) / 1149]eval:  63%|█████████████████████████████▌                 | 191/304 [02:46<01:18,  1.44it/s, recall_0.3=(881, 883) / 1153]eval:  63%|█████████████████████████████▋                 | 192/304 [02:46<01:29,  1.26it/s, recall_0.3=(881, 883) / 1153]eval:  63%|█████████████████████████████▋                 | 192/304 [02:46<01:29,  1.26it/s, recall_0.3=(885, 887) / 1157]eval:  63%|█████████████████████████████▊                 | 193/304 [02:46<01:09,  1.59it/s, recall_0.3=(885, 887) / 1157]eval:  63%|█████████████████████████████▊                 | 193/304 [02:46<01:09,  1.59it/s, recall_0.3=(889, 891) / 1161]eval:  64%|█████████████████████████████▉                 | 194/304 [02:46<01:02,  1.77it/s, recall_0.3=(889, 891) / 1161]eval:  64%|█████████████████████████████▉                 | 194/304 [02:47<01:02,  1.77it/s, recall_0.3=(893, 895) / 1165]eval:  64%|██████████████████████████████▏                | 195/304 [02:48<01:19,  1.37it/s, recall_0.3=(893, 895) / 1165]eval:  64%|██████████████████████████████▏                | 195/304 [02:49<01:19,  1.37it/s, recall_0.3=(896, 898) / 1169]eval:  64%|██████████████████████████████▎                | 196/304 [02:49<01:33,  1.15it/s, recall_0.3=(896, 898) / 1169]eval:  64%|██████████████████████████████▎                | 196/304 [02:49<01:33,  1.15it/s, recall_0.3=(898, 900) / 1171]eval:  65%|██████████████████████████████▍                | 197/304 [02:49<01:12,  1.48it/s, recall_0.3=(898, 900) / 1171]eval:  65%|██████████████████████████████▍                | 197/304 [02:50<01:12,  1.48it/s, recall_0.3=(899, 901) / 1173]eval:  65%|██████████████████████████████▌                | 198/304 [02:50<01:18,  1.35it/s, recall_0.3=(899, 901) / 1173]eval:  65%|██████████████████████████████▌                | 198/304 [02:51<01:18,  1.35it/s, recall_0.3=(899, 901) / 1173]eval:  65%|██████████████████████████████▊                | 199/304 [02:51<01:29,  1.17it/s, recall_0.3=(899, 901) / 1173]eval:  65%|██████████████████████████████▊                | 199/304 [02:52<01:29,  1.17it/s, recall_0.3=(900, 902) / 1175]eval:  66%|██████████████████████████████▉                | 200/304 [02:52<01:21,  1.27it/s, recall_0.3=(900, 902) / 1175]eval:  66%|██████████████████████████████▉                | 200/304 [02:52<01:21,  1.27it/s, recall_0.3=(902, 904) / 1177]eval:  66%|███████████████████████████████                | 201/304 [02:52<01:03,  1.63it/s, recall_0.3=(902, 904) / 1177]eval:  66%|███████████████████████████████                | 201/304 [02:52<01:03,  1.63it/s, recall_0.3=(903, 905) / 1179]eval:  66%|███████████████████████████████▏               | 202/304 [02:52<01:03,  1.61it/s, recall_0.3=(903, 905) / 1179]eval:  66%|███████████████████████████████▏               | 202/304 [02:54<01:03,  1.61it/s, recall_0.3=(905, 907) / 1181]eval:  67%|███████████████████████████████▍               | 203/304 [02:54<01:42,  1.02s/it, recall_0.3=(905, 907) / 1181]eval:  67%|███████████████████████████████▍               | 203/304 [02:56<01:42,  1.02s/it, recall_0.3=(907, 909) / 1183]eval:  67%|███████████████████████████████▌               | 204/304 [02:56<01:58,  1.19s/it, recall_0.3=(907, 909) / 1183]eval:  67%|███████████████████████████████▌               | 204/304 [02:56<01:58,  1.19s/it, recall_0.3=(907, 909) / 1183]eval:  67%|███████████████████████████████▋               | 205/304 [02:56<01:34,  1.05it/s, recall_0.3=(907, 909) / 1183]eval:  67%|███████████████████████████████▋               | 205/304 [02:57<01:34,  1.05it/s, recall_0.3=(907, 909) / 1183]eval:  68%|███████████████████████████████▊               | 206/304 [02:57<01:16,  1.29it/s, recall_0.3=(907, 909) / 1183]eval:  68%|███████████████████████████████▊               | 206/304 [02:57<01:16,  1.29it/s, recall_0.3=(907, 909) / 1183]eval:  68%|████████████████████████████████               | 207/304 [02:57<01:09,  1.40it/s, recall_0.3=(907, 909) / 1183]eval:  68%|████████████████████████████████               | 207/304 [02:58<01:09,  1.40it/s, recall_0.3=(907, 909) / 1183]eval:  68%|████████████████████████████████▏              | 208/304 [02:58<01:18,  1.23it/s, recall_0.3=(907, 909) / 1183]eval:  68%|████████████████████████████████▏              | 208/304 [02:59<01:18,  1.23it/s, recall_0.3=(909, 911) / 1198]eval:  69%|████████████████████████████████▎              | 209/304 [02:59<01:02,  1.52it/s, recall_0.3=(909, 911) / 1198]eval:  69%|████████████████████████████████▎              | 209/304 [02:59<01:02,  1.52it/s, recall_0.3=(916, 918) / 1216]eval:  69%|████████████████████████████████▍              | 210/304 [02:59<00:49,  1.91it/s, recall_0.3=(916, 918) / 1216]eval:  69%|████████████████████████████████▍              | 210/304 [03:01<00:49,  1.91it/s, recall_0.3=(924, 926) / 1229]eval:  69%|████████████████████████████████▌              | 211/304 [03:01<01:46,  1.15s/it, recall_0.3=(924, 926) / 1229]eval:  69%|████████████████████████████████▌              | 211/304 [03:03<01:46,  1.15s/it, recall_0.3=(936, 938) / 1242]eval:  70%|████████████████████████████████▊              | 212/304 [03:03<01:51,  1.21s/it, recall_0.3=(936, 938) / 1242]eval:  70%|████████████████████████████████▊              | 212/304 [03:03<01:51,  1.21s/it, recall_0.3=(944, 946) / 1251]eval:  70%|████████████████████████████████▉              | 213/304 [03:03<01:29,  1.02it/s, recall_0.3=(944, 946) / 1251]eval:  70%|████████████████████████████████▉              | 213/304 [03:04<01:29,  1.02it/s, recall_0.3=(952, 954) / 1262]eval:  70%|█████████████████████████████████              | 214/304 [03:04<01:10,  1.27it/s, recall_0.3=(952, 954) / 1262]eval:  70%|█████████████████████████████████              | 214/304 [03:04<01:10,  1.27it/s, recall_0.3=(959, 961) / 1271]eval:  71%|█████████████████████████████████▏             | 215/304 [03:04<01:09,  1.28it/s, recall_0.3=(959, 961) / 1271]eval:  71%|█████████████████████████████████▏             | 215/304 [03:05<01:09,  1.28it/s, recall_0.3=(968, 970) / 1282]eval:  71%|█████████████████████████████████▍             | 216/304 [03:05<00:52,  1.66it/s, recall_0.3=(968, 970) / 1282]eval:  71%|█████████████████████████████████▍             | 216/304 [03:05<00:52,  1.66it/s, recall_0.3=(980, 982) / 1294]eval:  71%|█████████████████████████████████▌             | 217/304 [03:05<00:41,  2.11it/s, recall_0.3=(980, 982) / 1294]eval:  71%|█████████████████████████████████▌             | 217/304 [03:05<00:41,  2.11it/s, recall_0.3=(990, 992) / 1304]eval:  72%|█████████████████████████████████▋             | 218/304 [03:05<00:33,  2.59it/s, recall_0.3=(990, 992) / 1304]eval:  72%|█████████████████████████████████▋             | 218/304 [03:06<00:33,  2.59it/s, recall_0.3=(994, 996) / 1309]eval:  72%|█████████████████████████████████▊             | 219/304 [03:06<01:03,  1.34it/s, recall_0.3=(994, 996) / 1309]eval:  72%|█████████████████████████████████▊             | 219/304 [03:08<01:03,  1.34it/s, recall_0.3=(994, 996) / 1309]eval:  72%|██████████████████████████████████             | 220/304 [03:08<01:30,  1.07s/it, recall_0.3=(994, 996) / 1309]eval:  72%|██████████████████████████████████             | 220/304 [03:09<01:30,  1.07s/it, recall_0.3=(994, 996) / 1309]eval:  73%|██████████████████████████████████▏            | 221/304 [03:09<01:10,  1.18it/s, recall_0.3=(994, 996) / 1309]eval:  73%|██████████████████████████████████▏            | 221/304 [03:09<01:10,  1.18it/s, recall_0.3=(994, 996) / 1309]eval:  73%|██████████████████████████████████▎            | 222/304 [03:09<00:53,  1.52it/s, recall_0.3=(994, 996) / 1309]eval:  73%|██████████████████████████████████▎            | 222/304 [03:10<00:53,  1.52it/s, recall_0.3=(996, 998) / 1311]eval:  73%|██████████████████████████████████▍            | 223/304 [03:10<00:54,  1.49it/s, recall_0.3=(996, 998) / 1311]eval:  73%|█████████████████████████████████▋            | 223/304 [03:11<00:54,  1.49it/s, recall_0.3=(998, 1000) / 1313]eval:  74%|█████████████████████████████████▉            | 224/304 [03:11<01:07,  1.18it/s, recall_0.3=(998, 1000) / 1313]eval:  74%|█████████████████████████████████▉            | 224/304 [03:11<01:07,  1.18it/s, recall_0.3=(999, 1001) / 1315]eval:  74%|██████████████████████████████████            | 225/304 [03:11<00:51,  1.53it/s, recall_0.3=(999, 1001) / 1315]eval:  74%|██████████████████████████████████            | 225/304 [03:11<00:51,  1.53it/s, recall_0.3=(999, 1001) / 1319]eval:  74%|██████████████████████████████████▏           | 226/304 [03:11<00:43,  1.78it/s, recall_0.3=(999, 1001) / 1319]eval:  74%|█████████████████████████████████▍           | 226/304 [03:12<00:43,  1.78it/s, recall_0.3=(1011, 1013) / 1336]eval:  75%|█████████████████████████████████▌           | 227/304 [03:12<00:43,  1.75it/s, recall_0.3=(1011, 1013) / 1336]eval:  75%|█████████████████████████████████▌           | 227/304 [03:13<00:43,  1.75it/s, recall_0.3=(1020, 1022) / 1348]eval:  75%|█████████████████████████████████▊           | 228/304 [03:13<00:49,  1.55it/s, recall_0.3=(1020, 1022) / 1348]eval:  75%|█████████████████████████████████▊           | 228/304 [03:13<00:49,  1.55it/s, recall_0.3=(1026, 1028) / 1355]eval:  75%|█████████████████████████████████▉           | 229/304 [03:13<00:40,  1.85it/s, recall_0.3=(1026, 1028) / 1355]eval:  75%|█████████████████████████████████▉           | 229/304 [03:15<00:40,  1.85it/s, recall_0.3=(1032, 1034) / 1361]eval:  76%|██████████████████████████████████           | 230/304 [03:15<01:02,  1.17it/s, recall_0.3=(1032, 1034) / 1361]eval:  76%|██████████████████████████████████           | 230/304 [03:16<01:02,  1.17it/s, recall_0.3=(1037, 1039) / 1367]eval:  76%|██████████████████████████████████▏          | 231/304 [03:16<01:15,  1.04s/it, recall_0.3=(1037, 1039) / 1367]eval:  76%|██████████████████████████████████▏          | 231/304 [03:16<01:15,  1.04s/it, recall_0.3=(1039, 1041) / 1370]eval:  76%|██████████████████████████████████▎          | 232/304 [03:16<00:59,  1.21it/s, recall_0.3=(1039, 1041) / 1370]eval:  76%|██████████████████████████████████▎          | 232/304 [03:17<00:59,  1.21it/s, recall_0.3=(1039, 1041) / 1370]eval:  77%|██████████████████████████████████▍          | 233/304 [03:17<00:47,  1.50it/s, recall_0.3=(1039, 1041) / 1370]eval:  77%|██████████████████████████████████▍          | 233/304 [03:18<00:47,  1.50it/s, recall_0.3=(1039, 1041) / 1370]eval:  77%|██████████████████████████████████▋          | 234/304 [03:18<00:52,  1.34it/s, recall_0.3=(1039, 1041) / 1370]eval:  77%|██████████████████████████████████▋          | 234/304 [03:19<00:52,  1.34it/s, recall_0.3=(1039, 1041) / 1370]eval:  77%|██████████████████████████████████▊          | 235/304 [03:19<01:08,  1.01it/s, recall_0.3=(1039, 1041) / 1370]eval:  77%|██████████████████████████████████▊          | 235/304 [03:19<01:08,  1.01it/s, recall_0.3=(1039, 1041) / 1370]eval:  78%|██████████████████████████████████▉          | 236/304 [03:19<00:51,  1.32it/s, recall_0.3=(1039, 1041) / 1370]eval:  78%|██████████████████████████████████▉          | 236/304 [03:20<00:51,  1.32it/s, recall_0.3=(1039, 1041) / 1370]eval:  78%|███████████████████████████████████          | 237/304 [03:20<00:41,  1.63it/s, recall_0.3=(1039, 1041) / 1370]eval:  78%|███████████████████████████████████          | 237/304 [03:21<00:41,  1.63it/s, recall_0.3=(1039, 1041) / 1370]eval:  78%|███████████████████████████████████▏         | 238/304 [03:21<00:58,  1.12it/s, recall_0.3=(1039, 1041) / 1370]eval:  78%|███████████████████████████████████▏         | 238/304 [03:22<00:58,  1.12it/s, recall_0.3=(1039, 1041) / 1370]eval:  79%|███████████████████████████████████▍         | 239/304 [03:22<01:03,  1.02it/s, recall_0.3=(1039, 1041) / 1370]eval:  79%|███████████████████████████████████▍         | 239/304 [03:23<01:03,  1.02it/s, recall_0.3=(1039, 1041) / 1370]eval:  79%|███████████████████████████████████▌         | 240/304 [03:23<00:57,  1.12it/s, recall_0.3=(1039, 1041) / 1370]eval:  79%|███████████████████████████████████▌         | 240/304 [03:24<00:57,  1.12it/s, recall_0.3=(1040, 1042) / 1372]eval:  79%|███████████████████████████████████▋         | 241/304 [03:24<00:48,  1.31it/s, recall_0.3=(1040, 1042) / 1372]eval:  79%|███████████████████████████████████▋         | 241/304 [03:26<00:48,  1.31it/s, recall_0.3=(1041, 1043) / 1374]eval:  80%|███████████████████████████████████▊         | 242/304 [03:26<01:10,  1.14s/it, recall_0.3=(1041, 1043) / 1374]eval:  80%|███████████████████████████████████▊         | 242/304 [03:26<01:10,  1.14s/it, recall_0.3=(1043, 1045) / 1376]eval:  80%|███████████████████████████████████▉         | 243/304 [03:26<00:56,  1.07it/s, recall_0.3=(1043, 1045) / 1376]eval:  80%|███████████████████████████████████▉         | 243/304 [03:26<00:56,  1.07it/s, recall_0.3=(1044, 1046) / 1378]eval:  80%|████████████████████████████████████         | 244/304 [03:26<00:43,  1.37it/s, recall_0.3=(1044, 1046) / 1378]eval:  80%|████████████████████████████████████         | 244/304 [03:27<00:43,  1.37it/s, recall_0.3=(1046, 1048) / 1382]eval:  81%|████████████████████████████████████▎        | 245/304 [03:27<00:35,  1.66it/s, recall_0.3=(1046, 1048) / 1382]eval:  81%|████████████████████████████████████▎        | 245/304 [03:29<00:35,  1.66it/s, recall_0.3=(1051, 1053) / 1387]eval:  81%|████████████████████████████████████▍        | 246/304 [03:29<01:10,  1.21s/it, recall_0.3=(1051, 1053) / 1387]eval:  81%|████████████████████████████████████▍        | 246/304 [03:30<01:10,  1.21s/it, recall_0.3=(1056, 1058) / 1393]eval:  81%|████████████████████████████████████▌        | 247/304 [03:30<00:58,  1.03s/it, recall_0.3=(1056, 1058) / 1393]eval:  81%|████████████████████████████████████▌        | 247/304 [03:30<00:58,  1.03s/it, recall_0.3=(1061, 1064) / 1401]eval:  82%|████████████████████████████████████▋        | 248/304 [03:30<00:47,  1.17it/s, recall_0.3=(1061, 1064) / 1401]eval:  82%|████████████████████████████████████▋        | 248/304 [03:31<00:47,  1.17it/s, recall_0.3=(1067, 1070) / 1408]eval:  82%|████████████████████████████████████▊        | 249/304 [03:31<00:41,  1.33it/s, recall_0.3=(1067, 1070) / 1408]eval:  82%|████████████████████████████████████▊        | 249/304 [03:32<00:41,  1.33it/s, recall_0.3=(1072, 1075) / 1413]eval:  82%|█████████████████████████████████████        | 250/304 [03:32<00:51,  1.05it/s, recall_0.3=(1072, 1075) / 1413]eval:  82%|█████████████████████████████████████        | 250/304 [03:33<00:51,  1.05it/s, recall_0.3=(1075, 1078) / 1416]eval:  83%|█████████████████████████████████████▏       | 251/304 [03:33<00:51,  1.04it/s, recall_0.3=(1075, 1078) / 1416]eval:  83%|█████████████████████████████████████▏       | 251/304 [03:34<00:51,  1.04it/s, recall_0.3=(1076, 1079) / 1418]eval:  83%|█████████████████████████████████████▎       | 252/304 [03:34<00:43,  1.18it/s, recall_0.3=(1076, 1079) / 1418]eval:  83%|█████████████████████████████████████▎       | 252/304 [03:34<00:43,  1.18it/s, recall_0.3=(1078, 1081) / 1420]eval:  83%|█████████████████████████████████████▍       | 253/304 [03:34<00:37,  1.35it/s, recall_0.3=(1078, 1081) / 1420]eval:  83%|█████████████████████████████████████▍       | 253/304 [03:36<00:37,  1.35it/s, recall_0.3=(1078, 1081) / 1420]eval:  84%|█████████████████████████████████████▌       | 254/304 [03:36<00:56,  1.14s/it, recall_0.3=(1078, 1081) / 1420]eval:  84%|█████████████████████████████████████▌       | 254/304 [03:37<00:56,  1.14s/it, recall_0.3=(1080, 1083) / 1422]eval:  84%|█████████████████████████████████████▋       | 255/304 [03:37<00:45,  1.07it/s, recall_0.3=(1080, 1083) / 1422]eval:  84%|█████████████████████████████████████▋       | 255/304 [03:37<00:45,  1.07it/s, recall_0.3=(1082, 1085) / 1424]eval:  84%|█████████████████████████████████████▉       | 256/304 [03:37<00:35,  1.33it/s, recall_0.3=(1082, 1085) / 1424]eval:  84%|█████████████████████████████████████▉       | 256/304 [03:38<00:35,  1.33it/s, recall_0.3=(1082, 1085) / 1424]eval:  85%|██████████████████████████████████████       | 257/304 [03:38<00:30,  1.56it/s, recall_0.3=(1082, 1085) / 1424]eval:  85%|██████████████████████████████████████       | 257/304 [03:40<00:30,  1.56it/s, recall_0.3=(1082, 1085) / 1424]eval:  85%|██████████████████████████████████████▏      | 258/304 [03:40<00:49,  1.08s/it, recall_0.3=(1082, 1085) / 1424]eval:  85%|██████████████████████████████████████▏      | 258/304 [03:40<00:49,  1.08s/it, recall_0.3=(1082, 1085) / 1424]eval:  85%|██████████████████████████████████████▎      | 259/304 [03:40<00:36,  1.24it/s, recall_0.3=(1082, 1085) / 1424]eval:  85%|██████████████████████████████████████▎      | 259/304 [03:40<00:36,  1.24it/s, recall_0.3=(1083, 1086) / 1426]eval:  86%|██████████████████████████████████████▍      | 260/304 [03:40<00:27,  1.63it/s, recall_0.3=(1083, 1086) / 1426]eval:  86%|██████████████████████████████████████▍      | 260/304 [03:40<00:27,  1.63it/s, recall_0.3=(1087, 1090) / 1430]eval:  86%|██████████████████████████████████████▋      | 261/304 [03:40<00:20,  2.07it/s, recall_0.3=(1087, 1090) / 1430]eval:  86%|██████████████████████████████████████▋      | 261/304 [03:42<00:20,  2.07it/s, recall_0.3=(1088, 1091) / 1432]eval:  86%|██████████████████████████████████████▊      | 262/304 [03:42<00:43,  1.03s/it, recall_0.3=(1088, 1091) / 1432]eval:  86%|██████████████████████████████████████▊      | 262/304 [03:43<00:43,  1.03s/it, recall_0.3=(1088, 1091) / 1432]eval:  87%|██████████████████████████████████████▉      | 263/304 [03:43<00:35,  1.16it/s, recall_0.3=(1088, 1091) / 1432]eval:  87%|██████████████████████████████████████▉      | 263/304 [03:43<00:35,  1.16it/s, recall_0.3=(1088, 1091) / 1432]eval:  87%|███████████████████████████████████████      | 264/304 [03:43<00:28,  1.40it/s, recall_0.3=(1088, 1091) / 1432]eval:  87%|███████████████████████████████████████      | 264/304 [03:44<00:28,  1.40it/s, recall_0.3=(1088, 1091) / 1432]eval:  87%|███████████████████████████████████████▏     | 265/304 [03:44<00:24,  1.56it/s, recall_0.3=(1088, 1091) / 1432]eval:  87%|███████████████████████████████████████▏     | 265/304 [03:45<00:24,  1.56it/s, recall_0.3=(1088, 1091) / 1432]eval:  88%|███████████████████████████████████████▍     | 266/304 [03:45<00:31,  1.22it/s, recall_0.3=(1088, 1091) / 1432]eval:  88%|███████████████████████████████████████▍     | 266/304 [03:45<00:31,  1.22it/s, recall_0.3=(1088, 1091) / 1432]eval:  88%|███████████████████████████████████████▌     | 267/304 [03:45<00:25,  1.47it/s, recall_0.3=(1088, 1091) / 1432]eval:  88%|███████████████████████████████████████▌     | 267/304 [03:46<00:25,  1.47it/s, recall_0.3=(1091, 1094) / 1435]eval:  88%|███████████████████████████████████████▋     | 268/304 [03:46<00:20,  1.73it/s, recall_0.3=(1091, 1094) / 1435]eval:  88%|███████████████████████████████████████▋     | 268/304 [03:46<00:20,  1.73it/s, recall_0.3=(1095, 1098) / 1439]eval:  88%|███████████████████████████████████████▊     | 269/304 [03:46<00:18,  1.94it/s, recall_0.3=(1095, 1098) / 1439]eval:  88%|███████████████████████████████████████▊     | 269/304 [03:47<00:18,  1.94it/s, recall_0.3=(1099, 1102) / 1443]eval:  89%|███████████████████████████████████████▉     | 270/304 [03:47<00:26,  1.30it/s, recall_0.3=(1099, 1102) / 1443]eval:  89%|███████████████████████████████████████▉     | 270/304 [03:48<00:26,  1.30it/s, recall_0.3=(1100, 1103) / 1445]eval:  89%|████████████████████████████████████████     | 271/304 [03:48<00:19,  1.66it/s, recall_0.3=(1100, 1103) / 1445]eval:  89%|████████████████████████████████████████     | 271/304 [03:48<00:19,  1.66it/s, recall_0.3=(1100, 1103) / 1449]eval:  89%|████████████████████████████████████████▎    | 272/304 [03:48<00:17,  1.86it/s, recall_0.3=(1100, 1103) / 1449]eval:  89%|████████████████████████████████████████▎    | 272/304 [03:48<00:17,  1.86it/s, recall_0.3=(1103, 1106) / 1453]eval:  90%|████████████████████████████████████████▍    | 273/304 [03:48<00:13,  2.23it/s, recall_0.3=(1103, 1106) / 1453]eval:  90%|████████████████████████████████████████▍    | 273/304 [03:51<00:13,  2.23it/s, recall_0.3=(1106, 1109) / 1457]eval:  90%|████████████████████████████████████████▌    | 274/304 [03:51<00:32,  1.07s/it, recall_0.3=(1106, 1109) / 1457]eval:  90%|████████████████████████████████████████▌    | 274/304 [03:51<00:32,  1.07s/it, recall_0.3=(1109, 1112) / 1460]eval:  90%|████████████████████████████████████████▋    | 275/304 [03:51<00:23,  1.23it/s, recall_0.3=(1109, 1112) / 1460]eval:  90%|████████████████████████████████████████▋    | 275/304 [03:51<00:23,  1.23it/s, recall_0.3=(1111, 1114) / 1462]eval:  91%|████████████████████████████████████████▊    | 276/304 [03:51<00:17,  1.58it/s, recall_0.3=(1111, 1114) / 1462]eval:  91%|████████████████████████████████████████▊    | 276/304 [03:52<00:17,  1.58it/s, recall_0.3=(1113, 1116) / 1464]eval:  91%|█████████████████████████████████████████    | 277/304 [03:52<00:15,  1.76it/s, recall_0.3=(1113, 1116) / 1464]eval:  91%|█████████████████████████████████████████    | 277/304 [03:53<00:15,  1.76it/s, recall_0.3=(1113, 1116) / 1464]eval:  91%|█████████████████████████████████████████▏   | 278/304 [03:53<00:19,  1.34it/s, recall_0.3=(1113, 1116) / 1464]eval:  91%|█████████████████████████████████████████▏   | 278/304 [03:53<00:19,  1.34it/s, recall_0.3=(1113, 1116) / 1464]eval:  92%|█████████████████████████████████████████▎   | 279/304 [03:53<00:18,  1.37it/s, recall_0.3=(1113, 1116) / 1464]eval:  92%|█████████████████████████████████████████▎   | 279/304 [03:54<00:18,  1.37it/s, recall_0.3=(1113, 1116) / 1464]eval:  92%|█████████████████████████████████████████▍   | 280/304 [03:54<00:13,  1.74it/s, recall_0.3=(1113, 1116) / 1464]eval:  92%|█████████████████████████████████████████▍   | 280/304 [03:54<00:13,  1.74it/s, recall_0.3=(1113, 1116) / 1464]eval:  92%|█████████████████████████████████████████▌   | 281/304 [03:54<00:10,  2.15it/s, recall_0.3=(1113, 1116) / 1464]eval:  92%|█████████████████████████████████████████▌   | 281/304 [03:56<00:10,  2.15it/s, recall_0.3=(1113, 1116) / 1464]eval:  93%|█████████████████████████████████████████▋   | 282/304 [03:56<00:18,  1.20it/s, recall_0.3=(1113, 1116) / 1464]eval:  93%|█████████████████████████████████████████▋   | 282/304 [03:56<00:18,  1.20it/s, recall_0.3=(1113, 1116) / 1464]eval:  93%|█████████████████████████████████████████▉   | 283/304 [03:56<00:14,  1.48it/s, recall_0.3=(1113, 1116) / 1464]eval:  93%|█████████████████████████████████████████▉   | 283/304 [03:56<00:14,  1.48it/s, recall_0.3=(1113, 1116) / 1469]eval:  93%|██████████████████████████████████████████   | 284/304 [03:56<00:10,  1.87it/s, recall_0.3=(1113, 1116) / 1469]eval:  93%|██████████████████████████████████████████   | 284/304 [03:56<00:10,  1.87it/s, recall_0.3=(1121, 1123) / 1482]eval:  94%|██████████████████████████████████████████▏  | 285/304 [03:56<00:08,  2.33it/s, recall_0.3=(1121, 1123) / 1482]eval:  94%|██████████████████████████████████████████▏  | 285/304 [03:58<00:08,  2.33it/s, recall_0.3=(1131, 1133) / 1496]eval:  94%|██████████████████████████████████████████▎  | 286/304 [03:58<00:12,  1.45it/s, recall_0.3=(1131, 1133) / 1496]eval:  94%|██████████████████████████████████████████▎  | 286/304 [04:00<00:12,  1.45it/s, recall_0.3=(1139, 1141) / 1509]eval:  94%|██████████████████████████████████████████▍  | 287/304 [04:00<00:20,  1.20s/it, recall_0.3=(1139, 1141) / 1509]eval:  94%|██████████████████████████████████████████▍  | 287/304 [04:00<00:20,  1.20s/it, recall_0.3=(1147, 1149) / 1522]eval:  95%|██████████████████████████████████████████▋  | 288/304 [04:00<00:14,  1.09it/s, recall_0.3=(1147, 1149) / 1522]eval:  95%|██████████████████████████████████████████▋  | 288/304 [04:01<00:14,  1.09it/s, recall_0.3=(1154, 1156) / 1529]eval:  95%|██████████████████████████████████████████▊  | 289/304 [04:01<00:10,  1.36it/s, recall_0.3=(1154, 1156) / 1529]eval:  95%|██████████████████████████████████████████▊  | 289/304 [04:01<00:10,  1.36it/s, recall_0.3=(1162, 1164) / 1543]eval:  95%|██████████████████████████████████████████▉  | 290/304 [04:01<00:09,  1.45it/s, recall_0.3=(1162, 1164) / 1543]eval:  95%|██████████████████████████████████████████▉  | 290/304 [04:03<00:09,  1.45it/s, recall_0.3=(1170, 1172) / 1559]eval:  96%|███████████████████████████████████████████  | 291/304 [04:03<00:13,  1.03s/it, recall_0.3=(1170, 1172) / 1559]eval:  96%|███████████████████████████████████████████  | 291/304 [04:03<00:13,  1.03s/it, recall_0.3=(1170, 1172) / 1559]eval:  96%|███████████████████████████████████████████▏ | 292/304 [04:03<00:09,  1.26it/s, recall_0.3=(1170, 1172) / 1559]eval:  96%|███████████████████████████████████████████▏ | 292/304 [04:03<00:09,  1.26it/s, recall_0.3=(1170, 1172) / 1559]eval:  96%|███████████████████████████████████████████▎ | 293/304 [04:03<00:06,  1.61it/s, recall_0.3=(1170, 1172) / 1559]eval:  96%|███████████████████████████████████████████▎ | 293/304 [04:04<00:06,  1.61it/s, recall_0.3=(1171, 1173) / 1561]eval:  97%|███████████████████████████████████████████▌ | 294/304 [04:04<00:05,  1.99it/s, recall_0.3=(1171, 1173) / 1561]eval:  97%|███████████████████████████████████████████▌ | 294/304 [04:04<00:05,  1.99it/s, recall_0.3=(1173, 1175) / 1563]eval:  97%|███████████████████████████████████████████▋ | 295/304 [04:04<00:04,  2.02it/s, recall_0.3=(1173, 1175) / 1563]eval:  97%|███████████████████████████████████████████▋ | 295/304 [04:04<00:04,  2.02it/s, recall_0.3=(1174, 1176) / 1565]eval:  97%|███████████████████████████████████████████▊ | 296/304 [04:04<00:03,  2.51it/s, recall_0.3=(1174, 1176) / 1565]eval:  97%|███████████████████████████████████████████▊ | 296/304 [04:05<00:03,  2.51it/s, recall_0.3=(1174, 1176) / 1565]eval:  98%|███████████████████████████████████████████▉ | 297/304 [04:05<00:02,  2.73it/s, recall_0.3=(1174, 1176) / 1565]eval:  98%|███████████████████████████████████████████▉ | 297/304 [04:05<00:02,  2.73it/s, recall_0.3=(1174, 1176) / 1565]eval:  98%|████████████████████████████████████████████ | 298/304 [04:05<00:01,  3.02it/s, recall_0.3=(1174, 1176) / 1565]eval:  98%|████████████████████████████████████████████ | 298/304 [04:06<00:01,  3.02it/s, recall_0.3=(1174, 1176) / 1565]eval:  98%|████████████████████████████████████████████▎| 299/304 [04:06<00:02,  1.86it/s, recall_0.3=(1174, 1176) / 1565]eval:  98%|████████████████████████████████████████████▎| 299/304 [04:06<00:02,  1.86it/s, recall_0.3=(1174, 1176) / 1565]eval:  99%|████████████████████████████████████████████▍| 300/304 [04:06<00:01,  2.35it/s, recall_0.3=(1174, 1176) / 1565]eval:  99%|████████████████████████████████████████████▍| 300/304 [04:06<00:01,  2.35it/s, recall_0.3=(1174, 1176) / 1565]eval:  99%|████████████████████████████████████████████▌| 301/304 [04:06<00:01,  2.82it/s, recall_0.3=(1174, 1176) / 1565]eval:  99%|████████████████████████████████████████████▌| 301/304 [04:06<00:01,  2.82it/s, recall_0.3=(1174, 1176) / 1565]eval:  99%|████████████████████████████████████████████▋| 302/304 [04:06<00:00,  3.35it/s, recall_0.3=(1174, 1176) / 1565]eval:  99%|████████████████████████████████████████████▋| 302/304 [04:07<00:00,  3.35it/s, recall_0.3=(1177, 1179) / 1570]eval: 100%|████████████████████████████████████████████▊| 303/304 [04:07<00:00,  2.19it/s, recall_0.3=(1177, 1179) / 1570]eval: 100%|████████████████████████████████████████████▊| 303/304 [04:07<00:00,  2.19it/s, recall_0.3=(1181, 1183) / 1574]eval: 100%|█████████████████████████████████████████████| 304/304 [04:07<00:00,  2.64it/s, recall_0.3=(1181, 1183) / 1574]eval: 100%|█████████████████████████████████████████████| 304/304 [04:08<00:00,  1.22it/s, recall_0.3=(1181, 1183) / 1574]
2023-03-01 02:04:09,737   INFO  *************** Performance of EPOCH 40 *****************
2023-03-01 02:04:09,738   INFO  Generate label finished(sec_per_example: 0.1021 second).
2023-03-01 02:04:09,738   INFO  recall_roi_0.3: 0.758798
2023-03-01 02:04:09,738   INFO  recall_rcnn_0.3: 0.759441
2023-03-01 02:04:09,738   INFO  recall_roi_0.5: 0.688735
2023-03-01 02:04:09,738   INFO  recall_rcnn_0.5: 0.711072
2023-03-01 02:04:09,738   INFO  recall_roi_0.7: 0.366222
2023-03-01 02:04:09,738   INFO  recall_rcnn_0.7: 0.505383
2023-03-01 02:04:09,740   INFO  Average predicted number of objects(2432 samples): 5.025
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
2023-03-01 02:04:49,548   INFO  Car IoU 0.7:
RANGE 00-30   30-50   50-80   00-80 
BEV:  68.114, 62.084, 35.648, 58.740
3D :  49.193, 34.774, 11.868, 35.962
Car IoU 0.5:
RANGE 00-30   30-50   50-80   00-80 
BEV:  79.108, 71.019, 55.244, 71.964
3D :  78.986, 68.743, 49.624, 69.285
Car IoU 0.7:
68.1 / 49.2, 62.1 / 34.8, 35.6 / 11.9, 58.7 / 36.0
Car IoU 0.5:
79.1 / 79.0, 71.0 / 68.7, 55.2 / 49.6, 72.0 / 69.3

Pedestrian IoU 0.7:
RANGE 00-30   30-50   50-80   00-80 
BEV:  18.536, 24.523, 13.697, 18.465
3D :  14.511, 20.316, 11.356, 14.900
Pedestrian IoU 0.5:
RANGE 00-30   30-50   50-80   00-80 
BEV:  27.864, 30.492, 20.672, 26.001
3D :  27.885, 30.492, 20.672, 26.000
Pedestrian IoU 0.7:
18.5 / 14.5, 24.5 / 20.3, 13.7 / 11.4, 18.5 / 14.9
Pedestrian IoU 0.5:
27.9 / 27.9, 30.5 / 30.5, 20.7 / 20.7, 26.0 / 26.0


2023-03-01 02:04:49,550   INFO  Result is save to /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5/default/eval/eval_with_train/epoch_40/val
2023-03-01 02:04:49,551   INFO  ****************Evaluation done.*****************
2023-03-01 02:04:49,567   INFO  Epoch 40 has been evaluated
2023-03-01 02:04:49,569   INFO  ==> Loading parameters from checkpoint /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5/default/ckpt/checkpoint_epoch_50.pth to CPU
2023-03-01 02:04:50,061   INFO  ==> Checkpoint trained from version: pcdet+0.3.0+0000000
2023-03-01 02:04:51,547   INFO  ==> Done (loaded 502/502)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
2023-03-01 02:04:51,559   INFO  *************** EPOCH 50 EVALUATION *****************
eval:   0%|                                                                                       | 0/304 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
eval:   0%|                                                                | 0/304 [00:03<?, ?it/s, recall_0.3=(2, 2) / 2]eval:   0%|▏                                                       | 1/304 [00:03<16:23,  3.25s/it, recall_0.3=(2, 2) / 2]eval:   0%|▏                                                       | 1/304 [00:04<16:23,  3.25s/it, recall_0.3=(4, 4) / 4]eval:   1%|▎                                                       | 2/304 [00:04<09:28,  1.88s/it, recall_0.3=(4, 4) / 4]eval:   1%|▎                                                       | 2/304 [00:04<09:28,  1.88s/it, recall_0.3=(6, 6) / 6]eval:   1%|▌                                                       | 3/304 [00:04<06:53,  1.37s/it, recall_0.3=(6, 6) / 6]eval:   1%|▌                                                       | 3/304 [00:05<06:53,  1.37s/it, recall_0.3=(8, 8) / 8]eval:   1%|▋                                                       | 4/304 [00:05<05:44,  1.15s/it, recall_0.3=(8, 8) / 8]eval:   1%|▋                                                      | 4/304 [00:06<05:44,  1.15s/it, recall_0.3=(9, 9) / 10]eval:   2%|▉                                                      | 5/304 [00:06<04:59,  1.00s/it, recall_0.3=(9, 9) / 10]eval:   2%|▊                                                    | 5/304 [00:07<04:59,  1.00s/it, recall_0.3=(21, 21) / 23]eval:   2%|█                                                    | 6/304 [00:07<04:50,  1.03it/s, recall_0.3=(21, 21) / 23]eval:   2%|█                                                    | 6/304 [00:08<04:50,  1.03it/s, recall_0.3=(31, 31) / 33]eval:   2%|█▏                                                   | 7/304 [00:08<04:20,  1.14it/s, recall_0.3=(31, 31) / 33]eval:   2%|█▏                                                   | 7/304 [00:08<04:20,  1.14it/s, recall_0.3=(41, 41) / 43]eval:   3%|█▍                                                   | 8/304 [00:08<03:48,  1.30it/s, recall_0.3=(41, 41) / 43]eval:   3%|█▍                                                   | 8/304 [00:09<03:48,  1.30it/s, recall_0.3=(51, 51) / 53]eval:   3%|█▌                                                   | 9/304 [00:09<03:39,  1.35it/s, recall_0.3=(51, 51) / 53]eval:   3%|█▌                                                   | 9/304 [00:10<03:39,  1.35it/s, recall_0.3=(58, 58) / 60]eval:   3%|█▋                                                  | 10/304 [00:10<03:54,  1.26it/s, recall_0.3=(58, 58) / 60]eval:   3%|█▋                                                  | 10/304 [00:10<03:54,  1.26it/s, recall_0.3=(65, 65) / 67]eval:   4%|█▉                                                  | 11/304 [00:10<03:43,  1.31it/s, recall_0.3=(65, 65) / 67]eval:   4%|█▉                                                  | 11/304 [00:11<03:43,  1.31it/s, recall_0.3=(71, 71) / 73]eval:   4%|██                                                  | 12/304 [00:11<03:32,  1.37it/s, recall_0.3=(71, 71) / 73]eval:   4%|██                                                  | 12/304 [00:12<03:32,  1.37it/s, recall_0.3=(75, 75) / 79]eval:   4%|██▏                                                 | 13/304 [00:12<03:44,  1.29it/s, recall_0.3=(75, 75) / 79]eval:   4%|██▏                                                 | 13/304 [00:13<03:44,  1.29it/s, recall_0.3=(79, 79) / 83]eval:   5%|██▍                                                 | 14/304 [00:13<03:42,  1.30it/s, recall_0.3=(79, 79) / 83]eval:   5%|██▍                                                 | 14/304 [00:13<03:42,  1.30it/s, recall_0.3=(86, 86) / 91]eval:   5%|██▌                                                 | 15/304 [00:13<03:28,  1.38it/s, recall_0.3=(86, 86) / 91]eval:   5%|██▌                                                | 15/304 [00:14<03:28,  1.38it/s, recall_0.3=(95, 95) / 102]eval:   5%|██▋                                                | 16/304 [00:14<03:24,  1.41it/s, recall_0.3=(95, 95) / 102]eval:   5%|██▌                                              | 16/304 [00:15<03:24,  1.41it/s, recall_0.3=(106, 106) / 114]eval:   6%|██▋                                              | 17/304 [00:15<03:16,  1.46it/s, recall_0.3=(106, 106) / 114]eval:   6%|██▋                                              | 17/304 [00:15<03:16,  1.46it/s, recall_0.3=(116, 116) / 124]eval:   6%|██▉                                              | 18/304 [00:15<03:17,  1.45it/s, recall_0.3=(116, 116) / 124]eval:   6%|██▉                                              | 18/304 [00:16<03:17,  1.45it/s, recall_0.3=(125, 125) / 134]eval:   6%|███                                              | 19/304 [00:16<03:12,  1.48it/s, recall_0.3=(125, 125) / 134]eval:   6%|███                                              | 19/304 [00:17<03:12,  1.48it/s, recall_0.3=(135, 135) / 144]eval:   7%|███▏                                             | 20/304 [00:17<03:22,  1.40it/s, recall_0.3=(135, 135) / 144]eval:   7%|███▏                                             | 20/304 [00:18<03:22,  1.40it/s, recall_0.3=(143, 143) / 153]eval:   7%|███▍                                             | 21/304 [00:18<03:24,  1.39it/s, recall_0.3=(143, 143) / 153]eval:   7%|███▍                                             | 21/304 [00:18<03:24,  1.39it/s, recall_0.3=(151, 151) / 161]eval:   7%|███▌                                             | 22/304 [00:18<03:31,  1.33it/s, recall_0.3=(151, 151) / 161]eval:   7%|███▌                                             | 22/304 [00:19<03:31,  1.33it/s, recall_0.3=(155, 155) / 165]eval:   8%|███▋                                             | 23/304 [00:19<03:30,  1.34it/s, recall_0.3=(155, 155) / 165]eval:   8%|███▋                                             | 23/304 [00:20<03:30,  1.34it/s, recall_0.3=(159, 159) / 169]eval:   8%|███▊                                             | 24/304 [00:20<03:15,  1.43it/s, recall_0.3=(159, 159) / 169]eval:   8%|███▊                                             | 24/304 [00:20<03:15,  1.43it/s, recall_0.3=(163, 163) / 173]eval:   8%|████                                             | 25/304 [00:20<03:03,  1.52it/s, recall_0.3=(163, 163) / 173]eval:   8%|████                                             | 25/304 [00:21<03:03,  1.52it/s, recall_0.3=(165, 165) / 176]eval:   9%|████▏                                            | 26/304 [00:21<03:00,  1.54it/s, recall_0.3=(165, 165) / 176]eval:   9%|████▏                                            | 26/304 [00:22<03:00,  1.54it/s, recall_0.3=(166, 166) / 179]eval:   9%|████▎                                            | 27/304 [00:22<03:10,  1.46it/s, recall_0.3=(166, 166) / 179]eval:   9%|████▎                                            | 27/304 [00:22<03:10,  1.46it/s, recall_0.3=(170, 170) / 184]eval:   9%|████▌                                            | 28/304 [00:22<03:06,  1.48it/s, recall_0.3=(170, 170) / 184]eval:   9%|████▌                                            | 28/304 [00:23<03:06,  1.48it/s, recall_0.3=(175, 175) / 190]eval:  10%|████▋                                            | 29/304 [00:23<03:04,  1.49it/s, recall_0.3=(175, 175) / 190]eval:  10%|████▋                                            | 29/304 [00:24<03:04,  1.49it/s, recall_0.3=(179, 179) / 194]eval:  10%|████▊                                            | 30/304 [00:24<03:04,  1.48it/s, recall_0.3=(179, 179) / 194]eval:  10%|████▊                                            | 30/304 [00:24<03:04,  1.48it/s, recall_0.3=(187, 187) / 203]eval:  10%|████▉                                            | 31/304 [00:24<02:59,  1.52it/s, recall_0.3=(187, 187) / 203]eval:  10%|████▉                                            | 31/304 [00:25<02:59,  1.52it/s, recall_0.3=(198, 198) / 219]eval:  11%|█████▏                                           | 32/304 [00:25<03:06,  1.46it/s, recall_0.3=(198, 198) / 219]eval:  11%|█████▏                                           | 32/304 [00:26<03:06,  1.46it/s, recall_0.3=(213, 213) / 238]eval:  11%|█████▎                                           | 33/304 [00:26<03:08,  1.43it/s, recall_0.3=(213, 213) / 238]eval:  11%|█████▎                                           | 33/304 [00:26<03:08,  1.43it/s, recall_0.3=(225, 225) / 252]eval:  11%|█████▍                                           | 34/304 [00:26<03:00,  1.49it/s, recall_0.3=(225, 225) / 252]eval:  11%|█████▍                                           | 34/304 [00:27<03:00,  1.49it/s, recall_0.3=(231, 231) / 262]eval:  12%|█████▋                                           | 35/304 [00:27<02:58,  1.51it/s, recall_0.3=(231, 231) / 262]eval:  12%|█████▋                                           | 35/304 [00:27<02:58,  1.51it/s, recall_0.3=(237, 237) / 268]eval:  12%|█████▊                                           | 36/304 [00:27<02:39,  1.68it/s, recall_0.3=(237, 237) / 268]eval:  12%|█████▊                                           | 36/304 [00:28<02:39,  1.68it/s, recall_0.3=(241, 241) / 273]eval:  12%|█████▉                                           | 37/304 [00:28<02:46,  1.61it/s, recall_0.3=(241, 241) / 273]eval:  12%|█████▉                                           | 37/304 [00:29<02:46,  1.61it/s, recall_0.3=(245, 245) / 277]eval:  12%|██████▏                                          | 38/304 [00:29<02:34,  1.73it/s, recall_0.3=(245, 245) / 277]eval:  12%|██████▏                                          | 38/304 [00:29<02:34,  1.73it/s, recall_0.3=(246, 246) / 279]eval:  13%|██████▎                                          | 39/304 [00:29<02:28,  1.78it/s, recall_0.3=(246, 246) / 279]eval:  13%|██████▎                                          | 39/304 [00:30<02:28,  1.78it/s, recall_0.3=(248, 248) / 281]eval:  13%|██████▍                                          | 40/304 [00:30<02:26,  1.81it/s, recall_0.3=(248, 248) / 281]eval:  13%|██████▍                                          | 40/304 [00:30<02:26,  1.81it/s, recall_0.3=(250, 250) / 283]eval:  13%|██████▌                                          | 41/304 [00:30<02:28,  1.77it/s, recall_0.3=(250, 250) / 283]eval:  13%|██████▌                                          | 41/304 [00:31<02:28,  1.77it/s, recall_0.3=(252, 252) / 286]eval:  14%|██████▊                                          | 42/304 [00:31<02:32,  1.72it/s, recall_0.3=(252, 252) / 286]eval:  14%|██████▊                                          | 42/304 [00:31<02:32,  1.72it/s, recall_0.3=(254, 254) / 290]eval:  14%|██████▉                                          | 43/304 [00:31<02:30,  1.74it/s, recall_0.3=(254, 254) / 290]eval:  14%|██████▉                                          | 43/304 [00:32<02:30,  1.74it/s, recall_0.3=(256, 256) / 293]eval:  14%|███████                                          | 44/304 [00:32<02:25,  1.79it/s, recall_0.3=(256, 256) / 293]eval:  14%|███████                                          | 44/304 [00:32<02:25,  1.79it/s, recall_0.3=(258, 258) / 295]eval:  15%|███████▎                                         | 45/304 [00:32<02:23,  1.81it/s, recall_0.3=(258, 258) / 295]eval:  15%|███████▎                                         | 45/304 [00:33<02:23,  1.81it/s, recall_0.3=(261, 261) / 299]eval:  15%|███████▍                                         | 46/304 [00:33<02:27,  1.75it/s, recall_0.3=(261, 261) / 299]eval:  15%|███████▍                                         | 46/304 [00:34<02:27,  1.75it/s, recall_0.3=(265, 265) / 303]eval:  15%|███████▌                                         | 47/304 [00:34<02:23,  1.79it/s, recall_0.3=(265, 265) / 303]eval:  15%|███████▌                                         | 47/304 [00:34<02:23,  1.79it/s, recall_0.3=(268, 268) / 307]eval:  16%|███████▋                                         | 48/304 [00:34<02:30,  1.70it/s, recall_0.3=(268, 268) / 307]eval:  16%|███████▋                                         | 48/304 [00:35<02:30,  1.70it/s, recall_0.3=(270, 270) / 311]eval:  16%|███████▉                                         | 49/304 [00:35<02:30,  1.69it/s, recall_0.3=(270, 270) / 311]eval:  16%|███████▉                                         | 49/304 [00:35<02:30,  1.69it/s, recall_0.3=(271, 271) / 315]eval:  16%|████████                                         | 50/304 [00:35<02:32,  1.67it/s, recall_0.3=(271, 271) / 315]eval:  16%|████████                                         | 50/304 [00:36<02:32,  1.67it/s, recall_0.3=(273, 273) / 320]eval:  17%|████████▏                                        | 51/304 [00:36<02:47,  1.51it/s, recall_0.3=(273, 273) / 320]eval:  17%|████████▏                                        | 51/304 [00:37<02:47,  1.51it/s, recall_0.3=(278, 278) / 328]eval:  17%|████████▍                                        | 52/304 [00:37<02:58,  1.41it/s, recall_0.3=(278, 278) / 328]eval:  17%|████████▍                                        | 52/304 [00:38<02:58,  1.41it/s, recall_0.3=(281, 281) / 333]eval:  17%|████████▌                                        | 53/304 [00:38<02:59,  1.40it/s, recall_0.3=(281, 281) / 333]eval:  17%|████████▌                                        | 53/304 [00:38<02:59,  1.40it/s, recall_0.3=(281, 282) / 336]eval:  18%|████████▋                                        | 54/304 [00:38<02:51,  1.46it/s, recall_0.3=(281, 282) / 336]eval:  18%|████████▋                                        | 54/304 [00:39<02:51,  1.46it/s, recall_0.3=(281, 282) / 338]eval:  18%|████████▊                                        | 55/304 [00:39<02:47,  1.49it/s, recall_0.3=(281, 282) / 338]eval:  18%|████████▊                                        | 55/304 [00:40<02:47,  1.49it/s, recall_0.3=(281, 282) / 340]eval:  18%|█████████                                        | 56/304 [00:40<02:43,  1.51it/s, recall_0.3=(281, 282) / 340]eval:  18%|█████████                                        | 56/304 [00:40<02:43,  1.51it/s, recall_0.3=(285, 286) / 346]eval:  19%|█████████▏                                       | 57/304 [00:40<02:31,  1.63it/s, recall_0.3=(285, 286) / 346]eval:  19%|█████████▏                                       | 57/304 [00:41<02:31,  1.63it/s, recall_0.3=(293, 294) / 355]eval:  19%|█████████▎                                       | 58/304 [00:41<02:14,  1.83it/s, recall_0.3=(293, 294) / 355]eval:  19%|█████████▎                                       | 58/304 [00:41<02:14,  1.83it/s, recall_0.3=(305, 306) / 367]eval:  19%|█████████▌                                       | 59/304 [00:41<02:03,  1.99it/s, recall_0.3=(305, 306) / 367]eval:  19%|█████████▌                                       | 59/304 [00:42<02:03,  1.99it/s, recall_0.3=(315, 316) / 381]eval:  20%|█████████▋                                       | 60/304 [00:42<02:16,  1.79it/s, recall_0.3=(315, 316) / 381]eval:  20%|█████████▋                                       | 60/304 [00:42<02:16,  1.79it/s, recall_0.3=(322, 323) / 394]eval:  20%|█████████▊                                       | 61/304 [00:42<02:15,  1.80it/s, recall_0.3=(322, 323) / 394]eval:  20%|█████████▊                                       | 61/304 [00:43<02:15,  1.80it/s, recall_0.3=(331, 332) / 406]eval:  20%|█████████▉                                       | 62/304 [00:43<02:20,  1.72it/s, recall_0.3=(331, 332) / 406]eval:  20%|█████████▉                                       | 62/304 [00:44<02:20,  1.72it/s, recall_0.3=(337, 338) / 412]eval:  21%|██████████▏                                      | 63/304 [00:44<02:29,  1.61it/s, recall_0.3=(337, 338) / 412]eval:  21%|██████████▏                                      | 63/304 [00:44<02:29,  1.61it/s, recall_0.3=(341, 342) / 416]eval:  21%|██████████▎                                      | 64/304 [00:44<02:23,  1.68it/s, recall_0.3=(341, 342) / 416]eval:  21%|██████████▎                                      | 64/304 [00:45<02:23,  1.68it/s, recall_0.3=(348, 349) / 424]eval:  21%|██████████▍                                      | 65/304 [00:45<02:24,  1.65it/s, recall_0.3=(348, 349) / 424]eval:  21%|██████████▍                                      | 65/304 [00:45<02:24,  1.65it/s, recall_0.3=(363, 364) / 443]eval:  22%|██████████▋                                      | 66/304 [00:45<02:32,  1.56it/s, recall_0.3=(363, 364) / 443]eval:  22%|██████████▋                                      | 66/304 [00:46<02:32,  1.56it/s, recall_0.3=(380, 381) / 463]eval:  22%|██████████▊                                      | 67/304 [00:46<02:36,  1.52it/s, recall_0.3=(380, 381) / 463]eval:  22%|██████████▊                                      | 67/304 [00:47<02:36,  1.52it/s, recall_0.3=(392, 393) / 478]eval:  22%|██████████▉                                      | 68/304 [00:47<02:28,  1.59it/s, recall_0.3=(392, 393) / 478]eval:  22%|██████████▉                                      | 68/304 [00:47<02:28,  1.59it/s, recall_0.3=(404, 405) / 494]eval:  23%|███████████                                      | 69/304 [00:47<02:31,  1.55it/s, recall_0.3=(404, 405) / 494]eval:  23%|███████████                                      | 69/304 [00:48<02:31,  1.55it/s, recall_0.3=(412, 413) / 504]eval:  23%|███████████▎                                     | 70/304 [00:48<02:36,  1.49it/s, recall_0.3=(412, 413) / 504]eval:  23%|███████████▎                                     | 70/304 [00:49<02:36,  1.49it/s, recall_0.3=(416, 417) / 509]eval:  23%|███████████▍                                     | 71/304 [00:49<02:31,  1.54it/s, recall_0.3=(416, 417) / 509]eval:  23%|███████████▍                                     | 71/304 [00:49<02:31,  1.54it/s, recall_0.3=(420, 421) / 513]eval:  24%|███████████▌                                     | 72/304 [00:49<02:27,  1.57it/s, recall_0.3=(420, 421) / 513]eval:  24%|███████████▌                                     | 72/304 [00:50<02:27,  1.57it/s, recall_0.3=(426, 427) / 519]eval:  24%|███████████▊                                     | 73/304 [00:50<02:26,  1.57it/s, recall_0.3=(426, 427) / 519]eval:  24%|███████████▊                                     | 73/304 [00:51<02:26,  1.57it/s, recall_0.3=(432, 433) / 525]eval:  24%|███████████▉                                     | 74/304 [00:51<02:30,  1.53it/s, recall_0.3=(432, 433) / 525]eval:  24%|███████████▉                                     | 74/304 [00:51<02:30,  1.53it/s, recall_0.3=(434, 435) / 527]eval:  25%|████████████                                     | 75/304 [00:51<02:28,  1.55it/s, recall_0.3=(434, 435) / 527]eval:  25%|████████████                                     | 75/304 [00:52<02:28,  1.55it/s, recall_0.3=(437, 438) / 531]eval:  25%|████████████▎                                    | 76/304 [00:52<02:25,  1.57it/s, recall_0.3=(437, 438) / 531]eval:  25%|████████████▎                                    | 76/304 [00:53<02:25,  1.57it/s, recall_0.3=(442, 443) / 537]eval:  25%|████████████▍                                    | 77/304 [00:53<02:32,  1.48it/s, recall_0.3=(442, 443) / 537]eval:  25%|████████████▍                                    | 77/304 [00:53<02:32,  1.48it/s, recall_0.3=(448, 449) / 543]eval:  26%|████████████▌                                    | 78/304 [00:53<02:27,  1.53it/s, recall_0.3=(448, 449) / 543]eval:  26%|████████████▌                                    | 78/304 [00:54<02:27,  1.53it/s, recall_0.3=(452, 453) / 549]eval:  26%|████████████▋                                    | 79/304 [00:54<02:25,  1.54it/s, recall_0.3=(452, 453) / 549]eval:  26%|████████████▋                                    | 79/304 [00:54<02:25,  1.54it/s, recall_0.3=(456, 457) / 554]eval:  26%|████████████▉                                    | 80/304 [00:54<02:19,  1.61it/s, recall_0.3=(456, 457) / 554]eval:  26%|████████████▉                                    | 80/304 [00:55<02:19,  1.61it/s, recall_0.3=(459, 460) / 557]eval:  27%|█████████████                                    | 81/304 [00:55<02:27,  1.51it/s, recall_0.3=(459, 460) / 557]eval:  27%|█████████████                                    | 81/304 [00:56<02:27,  1.51it/s, recall_0.3=(461, 462) / 559]eval:  27%|█████████████▏                                   | 82/304 [00:56<02:20,  1.58it/s, recall_0.3=(461, 462) / 559]eval:  27%|█████████████▏                                   | 82/304 [00:56<02:20,  1.58it/s, recall_0.3=(467, 468) / 566]eval:  27%|█████████████▍                                   | 83/304 [00:56<02:21,  1.56it/s, recall_0.3=(467, 468) / 566]eval:  27%|█████████████▍                                   | 83/304 [00:57<02:21,  1.56it/s, recall_0.3=(477, 478) / 576]eval:  28%|█████████████▌                                   | 84/304 [00:57<02:22,  1.54it/s, recall_0.3=(477, 478) / 576]eval:  28%|█████████████▌                                   | 84/304 [00:58<02:22,  1.54it/s, recall_0.3=(487, 488) / 586]eval:  28%|█████████████▋                                   | 85/304 [00:58<02:13,  1.64it/s, recall_0.3=(487, 488) / 586]eval:  28%|█████████████▋                                   | 85/304 [00:58<02:13,  1.64it/s, recall_0.3=(494, 495) / 593]eval:  28%|█████████████▊                                   | 86/304 [00:58<02:16,  1.60it/s, recall_0.3=(494, 495) / 593]eval:  28%|█████████████▊                                   | 86/304 [00:59<02:16,  1.60it/s, recall_0.3=(500, 501) / 600]eval:  29%|██████████████                                   | 87/304 [00:59<02:11,  1.65it/s, recall_0.3=(500, 501) / 600]eval:  29%|██████████████                                   | 87/304 [01:00<02:11,  1.65it/s, recall_0.3=(507, 508) / 608]eval:  29%|██████████████▏                                  | 88/304 [01:00<02:13,  1.62it/s, recall_0.3=(507, 508) / 608]eval:  29%|██████████████▏                                  | 88/304 [01:00<02:13,  1.62it/s, recall_0.3=(513, 514) / 614]eval:  29%|██████████████▎                                  | 89/304 [01:00<02:09,  1.66it/s, recall_0.3=(513, 514) / 614]eval:  29%|██████████████▎                                  | 89/304 [01:01<02:09,  1.66it/s, recall_0.3=(516, 517) / 617]eval:  30%|██████████████▌                                  | 90/304 [01:01<02:13,  1.61it/s, recall_0.3=(516, 517) / 617]eval:  30%|██████████████▌                                  | 90/304 [01:01<02:13,  1.61it/s, recall_0.3=(518, 519) / 619]eval:  30%|██████████████▋                                  | 91/304 [01:01<02:02,  1.74it/s, recall_0.3=(518, 519) / 619]eval:  30%|██████████████▋                                  | 91/304 [01:02<02:02,  1.74it/s, recall_0.3=(519, 520) / 621]eval:  30%|██████████████▊                                  | 92/304 [01:02<02:02,  1.73it/s, recall_0.3=(519, 520) / 621]eval:  30%|██████████████▊                                  | 92/304 [01:02<02:02,  1.73it/s, recall_0.3=(519, 520) / 623]eval:  31%|██████████████▉                                  | 93/304 [01:02<01:55,  1.83it/s, recall_0.3=(519, 520) / 623]eval:  31%|██████████████▉                                  | 93/304 [01:03<01:55,  1.83it/s, recall_0.3=(519, 520) / 623]eval:  31%|███████████████▏                                 | 94/304 [01:03<01:46,  1.97it/s, recall_0.3=(519, 520) / 623]eval:  31%|███████████████▏                                 | 94/304 [01:03<01:46,  1.97it/s, recall_0.3=(521, 522) / 625]eval:  31%|███████████████▎                                 | 95/304 [01:03<01:48,  1.92it/s, recall_0.3=(521, 522) / 625]eval:  31%|███████████████▎                                 | 95/304 [01:04<01:48,  1.92it/s, recall_0.3=(524, 525) / 628]eval:  32%|███████████████▍                                 | 96/304 [01:04<01:43,  2.00it/s, recall_0.3=(524, 525) / 628]eval:  32%|███████████████▍                                 | 96/304 [01:04<01:43,  2.00it/s, recall_0.3=(526, 527) / 631]eval:  32%|███████████████▋                                 | 97/304 [01:04<01:29,  2.32it/s, recall_0.3=(526, 527) / 631]eval:  32%|███████████████▋                                 | 97/304 [01:04<01:29,  2.32it/s, recall_0.3=(530, 531) / 635]eval:  32%|███████████████▊                                 | 98/304 [01:04<01:15,  2.74it/s, recall_0.3=(530, 531) / 635]eval:  32%|███████████████▊                                 | 98/304 [01:05<01:15,  2.74it/s, recall_0.3=(532, 533) / 637]eval:  33%|███████████████▉                                 | 99/304 [01:05<01:14,  2.77it/s, recall_0.3=(532, 533) / 637]eval:  33%|███████████████▉                                 | 99/304 [01:05<01:14,  2.77it/s, recall_0.3=(534, 535) / 639]eval:  33%|███████████████▊                                | 100/304 [01:05<01:23,  2.45it/s, recall_0.3=(534, 535) / 639]eval:  33%|███████████████▊                                | 100/304 [01:05<01:23,  2.45it/s, recall_0.3=(536, 537) / 641]eval:  33%|███████████████▉                                | 101/304 [01:05<01:16,  2.67it/s, recall_0.3=(536, 537) / 641]eval:  33%|███████████████▉                                | 101/304 [01:06<01:16,  2.67it/s, recall_0.3=(538, 539) / 643]eval:  34%|████████████████                                | 102/304 [01:06<01:13,  2.74it/s, recall_0.3=(538, 539) / 643]eval:  34%|████████████████                                | 102/304 [01:06<01:13,  2.74it/s, recall_0.3=(541, 542) / 647]eval:  34%|████████████████▎                               | 103/304 [01:06<01:12,  2.79it/s, recall_0.3=(541, 542) / 647]eval:  34%|████████████████▎                               | 103/304 [01:06<01:12,  2.79it/s, recall_0.3=(550, 550) / 660]eval:  34%|████████████████▍                               | 104/304 [01:06<01:09,  2.88it/s, recall_0.3=(550, 550) / 660]eval:  34%|████████████████▍                               | 104/304 [01:07<01:09,  2.88it/s, recall_0.3=(567, 567) / 686]eval:  35%|████████████████▌                               | 105/304 [01:07<01:02,  3.18it/s, recall_0.3=(567, 567) / 686]eval:  35%|████████████████▌                               | 105/304 [01:07<01:02,  3.18it/s, recall_0.3=(582, 582) / 710]eval:  35%|████████████████▋                               | 106/304 [01:07<01:10,  2.80it/s, recall_0.3=(582, 582) / 710]eval:  35%|████████████████▋                               | 106/304 [01:07<01:10,  2.80it/s, recall_0.3=(599, 599) / 734]eval:  35%|████████████████▉                               | 107/304 [01:07<01:10,  2.81it/s, recall_0.3=(599, 599) / 734]eval:  35%|████████████████▉                               | 107/304 [01:08<01:10,  2.81it/s, recall_0.3=(619, 619) / 759]eval:  36%|█████████████████                               | 108/304 [01:08<01:05,  2.98it/s, recall_0.3=(619, 619) / 759]eval:  36%|█████████████████                               | 108/304 [01:08<01:05,  2.98it/s, recall_0.3=(636, 637) / 782]eval:  36%|█████████████████▏                              | 109/304 [01:08<01:09,  2.79it/s, recall_0.3=(636, 637) / 782]eval:  36%|█████████████████▏                              | 109/304 [01:09<01:09,  2.79it/s, recall_0.3=(653, 654) / 808]eval:  36%|█████████████████▎                              | 110/304 [01:09<01:13,  2.63it/s, recall_0.3=(653, 654) / 808]eval:  36%|█████████████████▎                              | 110/304 [01:09<01:13,  2.63it/s, recall_0.3=(653, 654) / 808]eval:  37%|█████████████████▌                              | 111/304 [01:09<01:18,  2.45it/s, recall_0.3=(653, 654) / 808]eval:  37%|█████████████████▌                              | 111/304 [01:09<01:18,  2.45it/s, recall_0.3=(653, 654) / 808]eval:  37%|█████████████████▋                              | 112/304 [01:09<01:13,  2.62it/s, recall_0.3=(653, 654) / 808]eval:  37%|█████████████████▋                              | 112/304 [01:10<01:13,  2.62it/s, recall_0.3=(654, 655) / 810]eval:  37%|█████████████████▊                              | 113/304 [01:10<01:12,  2.64it/s, recall_0.3=(654, 655) / 810]eval:  37%|█████████████████▊                              | 113/304 [01:10<01:12,  2.64it/s, recall_0.3=(656, 657) / 812]eval:  38%|██████████████████                              | 114/304 [01:10<01:12,  2.62it/s, recall_0.3=(656, 657) / 812]eval:  38%|██████████████████                              | 114/304 [01:10<01:12,  2.62it/s, recall_0.3=(662, 663) / 818]eval:  38%|██████████████████▏                             | 115/304 [01:10<01:09,  2.72it/s, recall_0.3=(662, 663) / 818]eval:  38%|██████████████████▏                             | 115/304 [01:11<01:09,  2.72it/s, recall_0.3=(668, 669) / 825]eval:  38%|██████████████████▎                             | 116/304 [01:11<01:07,  2.78it/s, recall_0.3=(668, 669) / 825]eval:  38%|██████████████████▎                             | 116/304 [01:11<01:07,  2.78it/s, recall_0.3=(672, 673) / 829]eval:  38%|██████████████████▍                             | 117/304 [01:11<01:08,  2.71it/s, recall_0.3=(672, 673) / 829]eval:  38%|██████████████████▍                             | 117/304 [01:11<01:08,  2.71it/s, recall_0.3=(675, 676) / 833]eval:  39%|██████████████████▋                             | 118/304 [01:11<01:02,  2.98it/s, recall_0.3=(675, 676) / 833]eval:  39%|██████████████████▋                             | 118/304 [01:12<01:02,  2.98it/s, recall_0.3=(676, 677) / 835]eval:  39%|██████████████████▊                             | 119/304 [01:12<00:58,  3.19it/s, recall_0.3=(676, 677) / 835]eval:  39%|██████████████████▊                             | 119/304 [01:12<00:58,  3.19it/s, recall_0.3=(676, 677) / 835]eval:  39%|██████████████████▉                             | 120/304 [01:12<00:55,  3.33it/s, recall_0.3=(676, 677) / 835]eval:  39%|██████████████████▉                             | 120/304 [01:12<00:55,  3.33it/s, recall_0.3=(676, 677) / 835]eval:  40%|███████████████████                             | 121/304 [01:12<01:02,  2.91it/s, recall_0.3=(676, 677) / 835]eval:  40%|███████████████████                             | 121/304 [01:13<01:02,  2.91it/s, recall_0.3=(677, 678) / 837]eval:  40%|███████████████████▎                            | 122/304 [01:13<01:05,  2.79it/s, recall_0.3=(677, 678) / 837]eval:  40%|███████████████████▎                            | 122/304 [01:13<01:05,  2.79it/s, recall_0.3=(681, 682) / 842]eval:  40%|███████████████████▍                            | 123/304 [01:13<01:10,  2.56it/s, recall_0.3=(681, 682) / 842]eval:  40%|███████████████████▍                            | 123/304 [01:14<01:10,  2.56it/s, recall_0.3=(688, 689) / 849]eval:  41%|███████████████████▌                            | 124/304 [01:14<01:15,  2.39it/s, recall_0.3=(688, 689) / 849]eval:  41%|███████████████████▌                            | 124/304 [01:14<01:15,  2.39it/s, recall_0.3=(692, 693) / 854]eval:  41%|███████████████████▋                            | 125/304 [01:14<01:18,  2.29it/s, recall_0.3=(692, 693) / 854]eval:  41%|███████████████████▋                            | 125/304 [01:15<01:18,  2.29it/s, recall_0.3=(698, 699) / 860]eval:  41%|███████████████████▉                            | 126/304 [01:15<01:27,  2.04it/s, recall_0.3=(698, 699) / 860]eval:  41%|███████████████████▉                            | 126/304 [01:15<01:27,  2.04it/s, recall_0.3=(702, 703) / 864]eval:  42%|████████████████████                            | 127/304 [01:15<01:27,  2.01it/s, recall_0.3=(702, 703) / 864]eval:  42%|████████████████████                            | 127/304 [01:16<01:27,  2.01it/s, recall_0.3=(704, 705) / 868]eval:  42%|████████████████████▏                           | 128/304 [01:16<01:37,  1.81it/s, recall_0.3=(704, 705) / 868]eval:  42%|████████████████████▏                           | 128/304 [01:17<01:37,  1.81it/s, recall_0.3=(711, 712) / 875]eval:  42%|████████████████████▎                           | 129/304 [01:17<01:40,  1.74it/s, recall_0.3=(711, 712) / 875]eval:  42%|████████████████████▎                           | 129/304 [01:17<01:40,  1.74it/s, recall_0.3=(717, 718) / 881]eval:  43%|████████████████████▌                           | 130/304 [01:17<01:36,  1.81it/s, recall_0.3=(717, 718) / 881]eval:  43%|████████████████████▌                           | 130/304 [01:18<01:36,  1.81it/s, recall_0.3=(722, 723) / 886]eval:  43%|████████████████████▋                           | 131/304 [01:18<01:31,  1.90it/s, recall_0.3=(722, 723) / 886]eval:  43%|████████████████████▋                           | 131/304 [01:18<01:31,  1.90it/s, recall_0.3=(730, 731) / 894]eval:  43%|████████████████████▊                           | 132/304 [01:18<01:38,  1.74it/s, recall_0.3=(730, 731) / 894]eval:  43%|████████████████████▊                           | 132/304 [01:19<01:38,  1.74it/s, recall_0.3=(735, 736) / 900]eval:  44%|█████████████████████                           | 133/304 [01:19<01:37,  1.75it/s, recall_0.3=(735, 736) / 900]eval:  44%|█████████████████████                           | 133/304 [01:20<01:37,  1.75it/s, recall_0.3=(738, 739) / 903]eval:  44%|█████████████████████▏                          | 134/304 [01:20<01:42,  1.66it/s, recall_0.3=(738, 739) / 903]eval:  44%|█████████████████████▏                          | 134/304 [01:20<01:42,  1.66it/s, recall_0.3=(739, 740) / 905]eval:  44%|█████████████████████▎                          | 135/304 [01:20<01:39,  1.69it/s, recall_0.3=(739, 740) / 905]eval:  44%|█████████████████████▎                          | 135/304 [01:21<01:39,  1.69it/s, recall_0.3=(739, 740) / 905]eval:  45%|█████████████████████▍                          | 136/304 [01:21<01:43,  1.62it/s, recall_0.3=(739, 740) / 905]eval:  45%|█████████████████████▍                          | 136/304 [01:21<01:43,  1.62it/s, recall_0.3=(740, 741) / 908]eval:  45%|█████████████████████▋                          | 137/304 [01:21<01:32,  1.80it/s, recall_0.3=(740, 741) / 908]eval:  45%|█████████████████████▋                          | 137/304 [01:22<01:32,  1.80it/s, recall_0.3=(743, 744) / 912]eval:  45%|█████████████████████▊                          | 138/304 [01:22<01:22,  2.00it/s, recall_0.3=(743, 744) / 912]eval:  45%|█████████████████████▊                          | 138/304 [01:22<01:22,  2.00it/s, recall_0.3=(749, 750) / 918]eval:  46%|█████████████████████▉                          | 139/304 [01:22<01:18,  2.11it/s, recall_0.3=(749, 750) / 918]eval:  46%|█████████████████████▉                          | 139/304 [01:23<01:18,  2.11it/s, recall_0.3=(755, 756) / 924]eval:  46%|██████████████████████                          | 140/304 [01:23<01:24,  1.93it/s, recall_0.3=(755, 756) / 924]eval:  46%|██████████████████████                          | 140/304 [01:23<01:24,  1.93it/s, recall_0.3=(759, 760) / 930]eval:  46%|██████████████████████▎                         | 141/304 [01:23<01:24,  1.92it/s, recall_0.3=(759, 760) / 930]eval:  46%|██████████████████████▎                         | 141/304 [01:24<01:24,  1.92it/s, recall_0.3=(759, 760) / 930]eval:  47%|██████████████████████▍                         | 142/304 [01:24<01:27,  1.85it/s, recall_0.3=(759, 760) / 930]eval:  47%|██████████████████████▍                         | 142/304 [01:24<01:27,  1.85it/s, recall_0.3=(759, 760) / 930]eval:  47%|██████████████████████▌                         | 143/304 [01:24<01:20,  2.00it/s, recall_0.3=(759, 760) / 930]eval:  47%|██████████████████████▌                         | 143/304 [01:25<01:20,  2.00it/s, recall_0.3=(759, 760) / 930]eval:  47%|██████████████████████▋                         | 144/304 [01:25<01:23,  1.92it/s, recall_0.3=(759, 760) / 930]eval:  47%|██████████████████████▋                         | 144/304 [01:25<01:23,  1.92it/s, recall_0.3=(759, 760) / 930]eval:  48%|██████████████████████▉                         | 145/304 [01:25<01:19,  2.01it/s, recall_0.3=(759, 760) / 930]eval:  48%|██████████████████████▉                         | 145/304 [01:25<01:19,  2.01it/s, recall_0.3=(759, 760) / 930]eval:  48%|███████████████████████                         | 146/304 [01:25<01:10,  2.23it/s, recall_0.3=(759, 760) / 930]eval:  48%|███████████████████████                         | 146/304 [01:26<01:10,  2.23it/s, recall_0.3=(763, 764) / 936]eval:  48%|███████████████████████▏                        | 147/304 [01:26<00:59,  2.65it/s, recall_0.3=(763, 764) / 936]eval:  48%|███████████████████████▏                        | 147/304 [01:26<00:59,  2.65it/s, recall_0.3=(768, 769) / 947]eval:  49%|███████████████████████▎                        | 148/304 [01:26<00:53,  2.92it/s, recall_0.3=(768, 769) / 947]eval:  49%|███████████████████████▎                        | 148/304 [01:26<00:53,  2.92it/s, recall_0.3=(776, 777) / 960]eval:  49%|███████████████████████▌                        | 149/304 [01:26<00:50,  3.06it/s, recall_0.3=(776, 777) / 960]eval:  49%|███████████████████████▌                        | 149/304 [01:27<00:50,  3.06it/s, recall_0.3=(783, 784) / 970]eval:  49%|███████████████████████▋                        | 150/304 [01:27<01:14,  2.07it/s, recall_0.3=(783, 784) / 970]eval:  49%|███████████████████████▋                        | 150/304 [01:28<01:14,  2.07it/s, recall_0.3=(791, 791) / 981]eval:  50%|███████████████████████▊                        | 151/304 [01:28<01:16,  2.00it/s, recall_0.3=(791, 791) / 981]eval:  50%|███████████████████████▊                        | 151/304 [01:28<01:16,  2.00it/s, recall_0.3=(798, 798) / 992]eval:  50%|████████████████████████                        | 152/304 [01:28<01:09,  2.17it/s, recall_0.3=(798, 798) / 992]eval:  50%|███████████████████████▌                       | 152/304 [01:29<01:09,  2.17it/s, recall_0.3=(805, 805) / 1001]eval:  50%|███████████████████████▋                       | 153/304 [01:29<01:15,  2.00it/s, recall_0.3=(805, 805) / 1001]eval:  50%|███████████████████████▋                       | 153/304 [01:29<01:15,  2.00it/s, recall_0.3=(812, 812) / 1011]eval:  51%|███████████████████████▊                       | 154/304 [01:29<01:28,  1.69it/s, recall_0.3=(812, 812) / 1011]eval:  51%|███████████████████████▊                       | 154/304 [01:30<01:28,  1.69it/s, recall_0.3=(821, 820) / 1022]eval:  51%|███████████████████████▉                       | 155/304 [01:30<01:41,  1.47it/s, recall_0.3=(821, 820) / 1022]eval:  51%|███████████████████████▉                       | 155/304 [01:31<01:41,  1.47it/s, recall_0.3=(829, 828) / 1030]eval:  51%|████████████████████████                       | 156/304 [01:31<01:44,  1.42it/s, recall_0.3=(829, 828) / 1030]eval:  51%|████████████████████████                       | 156/304 [01:32<01:44,  1.42it/s, recall_0.3=(837, 836) / 1038]eval:  52%|████████████████████████▎                      | 157/304 [01:32<01:43,  1.42it/s, recall_0.3=(837, 836) / 1038]eval:  52%|████████████████████████▎                      | 157/304 [01:32<01:43,  1.42it/s, recall_0.3=(844, 843) / 1046]eval:  52%|████████████████████████▍                      | 158/304 [01:32<01:42,  1.43it/s, recall_0.3=(844, 843) / 1046]eval:  52%|████████████████████████▍                      | 158/304 [01:33<01:42,  1.43it/s, recall_0.3=(847, 846) / 1050]eval:  52%|████████████████████████▌                      | 159/304 [01:33<01:47,  1.35it/s, recall_0.3=(847, 846) / 1050]eval:  52%|████████████████████████▌                      | 159/304 [01:34<01:47,  1.35it/s, recall_0.3=(850, 849) / 1053]eval:  53%|████████████████████████▋                      | 160/304 [01:34<01:40,  1.43it/s, recall_0.3=(850, 849) / 1053]eval:  53%|████████████████████████▋                      | 160/304 [01:34<01:40,  1.43it/s, recall_0.3=(850, 849) / 1053]eval:  53%|████████████████████████▉                      | 161/304 [01:34<01:28,  1.62it/s, recall_0.3=(850, 849) / 1053]eval:  53%|████████████████████████▉                      | 161/304 [01:35<01:28,  1.62it/s, recall_0.3=(850, 849) / 1053]eval:  53%|█████████████████████████                      | 162/304 [01:35<01:21,  1.74it/s, recall_0.3=(850, 849) / 1053]eval:  53%|█████████████████████████                      | 162/304 [01:35<01:21,  1.74it/s, recall_0.3=(851, 850) / 1055]eval:  54%|█████████████████████████▏                     | 163/304 [01:35<01:11,  1.97it/s, recall_0.3=(851, 850) / 1055]eval:  54%|█████████████████████████▏                     | 163/304 [01:35<01:11,  1.97it/s, recall_0.3=(855, 854) / 1059]eval:  54%|█████████████████████████▎                     | 164/304 [01:35<01:02,  2.25it/s, recall_0.3=(855, 854) / 1059]eval:  54%|█████████████████████████▎                     | 164/304 [01:36<01:02,  2.25it/s, recall_0.3=(862, 861) / 1067]eval:  54%|█████████████████████████▌                     | 165/304 [01:36<00:57,  2.43it/s, recall_0.3=(862, 861) / 1067]eval:  54%|█████████████████████████▌                     | 165/304 [01:36<00:57,  2.43it/s, recall_0.3=(870, 869) / 1075]eval:  55%|█████████████████████████▋                     | 166/304 [01:36<00:53,  2.57it/s, recall_0.3=(870, 869) / 1075]eval:  55%|█████████████████████████▋                     | 166/304 [01:36<00:53,  2.57it/s, recall_0.3=(878, 877) / 1083]eval:  55%|█████████████████████████▊                     | 167/304 [01:36<00:53,  2.54it/s, recall_0.3=(878, 877) / 1083]eval:  55%|█████████████████████████▊                     | 167/304 [01:37<00:53,  2.54it/s, recall_0.3=(884, 883) / 1091]eval:  55%|█████████████████████████▉                     | 168/304 [01:37<00:50,  2.68it/s, recall_0.3=(884, 883) / 1091]eval:  55%|█████████████████████████▉                     | 168/304 [01:37<00:50,  2.68it/s, recall_0.3=(891, 890) / 1099]eval:  56%|██████████████████████████▏                    | 169/304 [01:37<00:51,  2.60it/s, recall_0.3=(891, 890) / 1099]eval:  56%|██████████████████████████▏                    | 169/304 [01:38<00:51,  2.60it/s, recall_0.3=(896, 895) / 1105]eval:  56%|██████████████████████████▎                    | 170/304 [01:38<00:54,  2.47it/s, recall_0.3=(896, 895) / 1105]eval:  56%|██████████████████████████▎                    | 170/304 [01:38<00:54,  2.47it/s, recall_0.3=(898, 897) / 1107]eval:  56%|██████████████████████████▍                    | 171/304 [01:38<00:56,  2.34it/s, recall_0.3=(898, 897) / 1107]eval:  56%|██████████████████████████▍                    | 171/304 [01:39<00:56,  2.34it/s, recall_0.3=(902, 901) / 1112]eval:  57%|██████████████████████████▌                    | 172/304 [01:39<01:00,  2.17it/s, recall_0.3=(902, 901) / 1112]eval:  57%|██████████████████████████▌                    | 172/304 [01:39<01:00,  2.17it/s, recall_0.3=(909, 908) / 1120]eval:  57%|██████████████████████████▋                    | 173/304 [01:39<01:00,  2.18it/s, recall_0.3=(909, 908) / 1120]eval:  57%|██████████████████████████▋                    | 173/304 [01:40<01:00,  2.18it/s, recall_0.3=(914, 913) / 1128]eval:  57%|██████████████████████████▉                    | 174/304 [01:40<01:01,  2.12it/s, recall_0.3=(914, 913) / 1128]eval:  57%|██████████████████████████▉                    | 174/304 [01:40<01:01,  2.12it/s, recall_0.3=(919, 918) / 1134]eval:  58%|███████████████████████████                    | 175/304 [01:40<00:59,  2.15it/s, recall_0.3=(919, 918) / 1134]eval:  58%|███████████████████████████                    | 175/304 [01:40<00:59,  2.15it/s, recall_0.3=(923, 922) / 1138]eval:  58%|███████████████████████████▏                   | 176/304 [01:40<00:55,  2.32it/s, recall_0.3=(923, 922) / 1138]eval:  58%|███████████████████████████▏                   | 176/304 [01:41<00:55,  2.32it/s, recall_0.3=(927, 926) / 1142]eval:  58%|███████████████████████████▎                   | 177/304 [01:41<01:00,  2.12it/s, recall_0.3=(927, 926) / 1142]eval:  58%|███████████████████████████▎                   | 177/304 [01:41<01:00,  2.12it/s, recall_0.3=(927, 926) / 1142]eval:  59%|███████████████████████████▌                   | 178/304 [01:41<00:55,  2.29it/s, recall_0.3=(927, 926) / 1142]eval:  59%|███████████████████████████▌                   | 178/304 [01:42<00:55,  2.29it/s, recall_0.3=(927, 926) / 1142]eval:  59%|███████████████████████████▋                   | 179/304 [01:42<00:52,  2.37it/s, recall_0.3=(927, 926) / 1142]eval:  59%|███████████████████████████▋                   | 179/304 [01:42<00:52,  2.37it/s, recall_0.3=(929, 928) / 1145]eval:  59%|███████████████████████████▊                   | 180/304 [01:42<00:51,  2.41it/s, recall_0.3=(929, 928) / 1145]eval:  59%|███████████████████████████▊                   | 180/304 [01:43<00:51,  2.41it/s, recall_0.3=(931, 930) / 1147]eval:  60%|███████████████████████████▉                   | 181/304 [01:43<00:49,  2.51it/s, recall_0.3=(931, 930) / 1147]eval:  60%|███████████████████████████▉                   | 181/304 [01:43<00:49,  2.51it/s, recall_0.3=(933, 932) / 1149]eval:  60%|████████████████████████████▏                  | 182/304 [01:43<00:52,  2.32it/s, recall_0.3=(933, 932) / 1149]eval:  60%|████████████████████████████▏                  | 182/304 [01:43<00:52,  2.32it/s, recall_0.3=(933, 932) / 1149]eval:  60%|████████████████████████████▎                  | 183/304 [01:43<00:50,  2.41it/s, recall_0.3=(933, 932) / 1149]eval:  60%|████████████████████████████▎                  | 183/304 [01:44<00:50,  2.41it/s, recall_0.3=(933, 932) / 1149]eval:  61%|████████████████████████████▍                  | 184/304 [01:44<00:54,  2.19it/s, recall_0.3=(933, 932) / 1149]eval:  61%|████████████████████████████▍                  | 184/304 [01:44<00:54,  2.19it/s, recall_0.3=(933, 932) / 1149]eval:  61%|████████████████████████████▌                  | 185/304 [01:44<00:57,  2.08it/s, recall_0.3=(933, 932) / 1149]eval:  61%|████████████████████████████▌                  | 185/304 [01:45<00:57,  2.08it/s, recall_0.3=(933, 932) / 1149]eval:  61%|████████████████████████████▊                  | 186/304 [01:45<00:58,  2.02it/s, recall_0.3=(933, 932) / 1149]eval:  61%|████████████████████████████▊                  | 186/304 [01:46<00:58,  2.02it/s, recall_0.3=(933, 932) / 1149]eval:  62%|████████████████████████████▉                  | 187/304 [01:46<00:58,  2.01it/s, recall_0.3=(933, 932) / 1149]eval:  62%|████████████████████████████▉                  | 187/304 [01:46<00:58,  2.01it/s, recall_0.3=(933, 932) / 1149]eval:  62%|█████████████████████████████                  | 188/304 [01:46<00:55,  2.08it/s, recall_0.3=(933, 932) / 1149]eval:  62%|█████████████████████████████                  | 188/304 [01:47<00:55,  2.08it/s, recall_0.3=(933, 932) / 1149]eval:  62%|█████████████████████████████▏                 | 189/304 [01:47<00:57,  2.01it/s, recall_0.3=(933, 932) / 1149]eval:  62%|█████████████████████████████▏                 | 189/304 [01:47<00:57,  2.01it/s, recall_0.3=(933, 932) / 1149]eval:  62%|█████████████████████████████▍                 | 190/304 [01:47<00:58,  1.96it/s, recall_0.3=(933, 932) / 1149]eval:  62%|█████████████████████████████▍                 | 190/304 [01:48<00:58,  1.96it/s, recall_0.3=(933, 932) / 1149]eval:  63%|█████████████████████████████▌                 | 191/304 [01:48<00:59,  1.89it/s, recall_0.3=(933, 932) / 1149]eval:  63%|█████████████████████████████▌                 | 191/304 [01:48<00:59,  1.89it/s, recall_0.3=(937, 936) / 1153]eval:  63%|█████████████████████████████▋                 | 192/304 [01:48<00:57,  1.95it/s, recall_0.3=(937, 936) / 1153]eval:  63%|█████████████████████████████▋                 | 192/304 [01:49<00:57,  1.95it/s, recall_0.3=(941, 940) / 1157]eval:  63%|█████████████████████████████▊                 | 193/304 [01:49<00:53,  2.07it/s, recall_0.3=(941, 940) / 1157]eval:  63%|█████████████████████████████▊                 | 193/304 [01:49<00:53,  2.07it/s, recall_0.3=(944, 943) / 1161]eval:  64%|█████████████████████████████▉                 | 194/304 [01:49<00:50,  2.16it/s, recall_0.3=(944, 943) / 1161]eval:  64%|█████████████████████████████▉                 | 194/304 [01:49<00:50,  2.16it/s, recall_0.3=(948, 947) / 1165]eval:  64%|██████████████████████████████▏                | 195/304 [01:49<00:50,  2.18it/s, recall_0.3=(948, 947) / 1165]eval:  64%|██████████████████████████████▏                | 195/304 [01:50<00:50,  2.18it/s, recall_0.3=(951, 950) / 1169]eval:  64%|██████████████████████████████▎                | 196/304 [01:50<00:49,  2.17it/s, recall_0.3=(951, 950) / 1169]eval:  64%|██████████████████████████████▎                | 196/304 [01:50<00:49,  2.17it/s, recall_0.3=(953, 952) / 1171]eval:  65%|██████████████████████████████▍                | 197/304 [01:50<00:50,  2.12it/s, recall_0.3=(953, 952) / 1171]eval:  65%|██████████████████████████████▍                | 197/304 [01:51<00:50,  2.12it/s, recall_0.3=(954, 953) / 1173]eval:  65%|██████████████████████████████▌                | 198/304 [01:51<00:52,  2.03it/s, recall_0.3=(954, 953) / 1173]eval:  65%|██████████████████████████████▌                | 198/304 [01:51<00:52,  2.03it/s, recall_0.3=(954, 953) / 1173]eval:  65%|██████████████████████████████▊                | 199/304 [01:51<00:50,  2.08it/s, recall_0.3=(954, 953) / 1173]eval:  65%|██████████████████████████████▊                | 199/304 [01:52<00:50,  2.08it/s, recall_0.3=(955, 954) / 1175]eval:  66%|██████████████████████████████▉                | 200/304 [01:52<00:49,  2.10it/s, recall_0.3=(955, 954) / 1175]eval:  66%|██████████████████████████████▉                | 200/304 [01:52<00:49,  2.10it/s, recall_0.3=(957, 956) / 1177]eval:  66%|███████████████████████████████                | 201/304 [01:52<00:44,  2.30it/s, recall_0.3=(957, 956) / 1177]eval:  66%|███████████████████████████████                | 201/304 [01:53<00:44,  2.30it/s, recall_0.3=(959, 958) / 1179]eval:  66%|███████████████████████████████▏               | 202/304 [01:53<00:43,  2.33it/s, recall_0.3=(959, 958) / 1179]eval:  66%|███████████████████████████████▏               | 202/304 [01:53<00:43,  2.33it/s, recall_0.3=(961, 960) / 1181]eval:  67%|███████████████████████████████▍               | 203/304 [01:53<00:44,  2.28it/s, recall_0.3=(961, 960) / 1181]eval:  67%|███████████████████████████████▍               | 203/304 [01:54<00:44,  2.28it/s, recall_0.3=(963, 962) / 1183]eval:  67%|███████████████████████████████▌               | 204/304 [01:54<00:49,  2.04it/s, recall_0.3=(963, 962) / 1183]eval:  67%|███████████████████████████████▌               | 204/304 [01:54<00:49,  2.04it/s, recall_0.3=(963, 962) / 1183]eval:  67%|███████████████████████████████▋               | 205/304 [01:54<00:49,  2.00it/s, recall_0.3=(963, 962) / 1183]eval:  67%|███████████████████████████████▋               | 205/304 [01:55<00:49,  2.00it/s, recall_0.3=(963, 962) / 1183]eval:  68%|███████████████████████████████▊               | 206/304 [01:55<00:46,  2.09it/s, recall_0.3=(963, 962) / 1183]eval:  68%|███████████████████████████████▊               | 206/304 [01:55<00:46,  2.09it/s, recall_0.3=(963, 962) / 1183]eval:  68%|████████████████████████████████               | 207/304 [01:55<00:43,  2.25it/s, recall_0.3=(963, 962) / 1183]eval:  68%|████████████████████████████████               | 207/304 [01:55<00:43,  2.25it/s, recall_0.3=(963, 962) / 1183]eval:  68%|████████████████████████████████▏              | 208/304 [01:55<00:43,  2.21it/s, recall_0.3=(963, 962) / 1183]eval:  68%|████████████████████████████████▏              | 208/304 [01:56<00:43,  2.21it/s, recall_0.3=(966, 965) / 1198]eval:  69%|████████████████████████████████▎              | 209/304 [01:56<00:42,  2.24it/s, recall_0.3=(966, 965) / 1198]eval:  69%|████████████████████████████████▎              | 209/304 [01:56<00:42,  2.24it/s, recall_0.3=(975, 974) / 1216]eval:  69%|████████████████████████████████▍              | 210/304 [01:56<00:42,  2.19it/s, recall_0.3=(975, 974) / 1216]eval:  69%|████████████████████████████████▍              | 210/304 [01:57<00:42,  2.19it/s, recall_0.3=(982, 981) / 1229]eval:  69%|████████████████████████████████▌              | 211/304 [01:57<00:41,  2.23it/s, recall_0.3=(982, 981) / 1229]eval:  69%|████████████████████████████████▌              | 211/304 [01:57<00:41,  2.23it/s, recall_0.3=(991, 990) / 1242]eval:  70%|████████████████████████████████▊              | 212/304 [01:57<00:43,  2.09it/s, recall_0.3=(991, 990) / 1242]eval:  70%|████████████████████████████████              | 212/304 [01:58<00:43,  2.09it/s, recall_0.3=(1000, 999) / 1251]eval:  70%|████████████████████████████████▏             | 213/304 [01:58<00:47,  1.93it/s, recall_0.3=(1000, 999) / 1251]eval:  70%|███████████████████████████████▌             | 213/304 [01:58<00:47,  1.93it/s, recall_0.3=(1010, 1009) / 1262]eval:  70%|███████████████████████████████▋             | 214/304 [01:58<00:45,  1.96it/s, recall_0.3=(1010, 1009) / 1262]eval:  70%|███████████████████████████████▋             | 214/304 [01:59<00:45,  1.96it/s, recall_0.3=(1017, 1016) / 1271]eval:  71%|███████████████████████████████▊             | 215/304 [01:59<00:42,  2.07it/s, recall_0.3=(1017, 1016) / 1271]eval:  71%|███████████████████████████████▊             | 215/304 [01:59<00:42,  2.07it/s, recall_0.3=(1026, 1025) / 1282]eval:  71%|███████████████████████████████▉             | 216/304 [01:59<00:38,  2.28it/s, recall_0.3=(1026, 1025) / 1282]eval:  71%|███████████████████████████████▉             | 216/304 [02:00<00:38,  2.28it/s, recall_0.3=(1038, 1037) / 1294]eval:  71%|████████████████████████████████             | 217/304 [02:00<00:37,  2.33it/s, recall_0.3=(1038, 1037) / 1294]eval:  71%|████████████████████████████████             | 217/304 [02:00<00:37,  2.33it/s, recall_0.3=(1048, 1047) / 1304]eval:  72%|████████████████████████████████▎            | 218/304 [02:00<00:34,  2.46it/s, recall_0.3=(1048, 1047) / 1304]eval:  72%|████████████████████████████████▎            | 218/304 [02:00<00:34,  2.46it/s, recall_0.3=(1052, 1051) / 1309]eval:  72%|████████████████████████████████▍            | 219/304 [02:00<00:34,  2.47it/s, recall_0.3=(1052, 1051) / 1309]eval:  72%|████████████████████████████████▍            | 219/304 [02:01<00:34,  2.47it/s, recall_0.3=(1052, 1051) / 1309]eval:  72%|████████████████████████████████▌            | 220/304 [02:01<00:34,  2.42it/s, recall_0.3=(1052, 1051) / 1309]eval:  72%|████████████████████████████████▌            | 220/304 [02:01<00:34,  2.42it/s, recall_0.3=(1052, 1051) / 1309]eval:  73%|████████████████████████████████▋            | 221/304 [02:01<00:36,  2.26it/s, recall_0.3=(1052, 1051) / 1309]eval:  73%|████████████████████████████████▋            | 221/304 [02:02<00:36,  2.26it/s, recall_0.3=(1052, 1051) / 1309]eval:  73%|████████████████████████████████▊            | 222/304 [02:02<00:37,  2.18it/s, recall_0.3=(1052, 1051) / 1309]eval:  73%|████████████████████████████████▊            | 222/304 [02:02<00:37,  2.18it/s, recall_0.3=(1054, 1053) / 1311]eval:  73%|█████████████████████████████████            | 223/304 [02:02<00:39,  2.07it/s, recall_0.3=(1054, 1053) / 1311]eval:  73%|█████████████████████████████████            | 223/304 [02:03<00:39,  2.07it/s, recall_0.3=(1056, 1055) / 1313]eval:  74%|█████████████████████████████████▏           | 224/304 [02:03<00:38,  2.09it/s, recall_0.3=(1056, 1055) / 1313]eval:  74%|█████████████████████████████████▏           | 224/304 [02:03<00:38,  2.09it/s, recall_0.3=(1057, 1056) / 1315]eval:  74%|█████████████████████████████████▎           | 225/304 [02:03<00:36,  2.17it/s, recall_0.3=(1057, 1056) / 1315]eval:  74%|█████████████████████████████████▎           | 225/304 [02:04<00:36,  2.17it/s, recall_0.3=(1058, 1057) / 1319]eval:  74%|█████████████████████████████████▍           | 226/304 [02:04<00:35,  2.20it/s, recall_0.3=(1058, 1057) / 1319]eval:  74%|█████████████████████████████████▍           | 226/304 [02:04<00:35,  2.20it/s, recall_0.3=(1073, 1072) / 1336]eval:  75%|█████████████████████████████████▌           | 227/304 [02:04<00:34,  2.23it/s, recall_0.3=(1073, 1072) / 1336]eval:  75%|█████████████████████████████████▌           | 227/304 [02:05<00:34,  2.23it/s, recall_0.3=(1083, 1082) / 1348]eval:  75%|█████████████████████████████████▊           | 228/304 [02:05<00:34,  2.23it/s, recall_0.3=(1083, 1082) / 1348]eval:  75%|█████████████████████████████████▊           | 228/304 [02:05<00:34,  2.23it/s, recall_0.3=(1089, 1088) / 1355]eval:  75%|█████████████████████████████████▉           | 229/304 [02:05<00:35,  2.13it/s, recall_0.3=(1089, 1088) / 1355]eval:  75%|█████████████████████████████████▉           | 229/304 [02:06<00:35,  2.13it/s, recall_0.3=(1095, 1094) / 1361]eval:  76%|██████████████████████████████████           | 230/304 [02:06<00:35,  2.08it/s, recall_0.3=(1095, 1094) / 1361]eval:  76%|██████████████████████████████████           | 230/304 [02:06<00:35,  2.08it/s, recall_0.3=(1100, 1099) / 1367]eval:  76%|██████████████████████████████████▏          | 231/304 [02:06<00:36,  1.99it/s, recall_0.3=(1100, 1099) / 1367]eval:  76%|██████████████████████████████████▏          | 231/304 [02:07<00:36,  1.99it/s, recall_0.3=(1102, 1101) / 1370]eval:  76%|██████████████████████████████████▎          | 232/304 [02:07<00:36,  1.97it/s, recall_0.3=(1102, 1101) / 1370]eval:  76%|██████████████████████████████████▎          | 232/304 [02:07<00:36,  1.97it/s, recall_0.3=(1102, 1101) / 1370]eval:  77%|██████████████████████████████████▍          | 233/304 [02:07<00:34,  2.09it/s, recall_0.3=(1102, 1101) / 1370]eval:  77%|██████████████████████████████████▍          | 233/304 [02:07<00:34,  2.09it/s, recall_0.3=(1102, 1101) / 1370]eval:  77%|██████████████████████████████████▋          | 234/304 [02:07<00:32,  2.17it/s, recall_0.3=(1102, 1101) / 1370]eval:  77%|██████████████████████████████████▋          | 234/304 [02:08<00:32,  2.17it/s, recall_0.3=(1102, 1101) / 1370]eval:  77%|██████████████████████████████████▊          | 235/304 [02:08<00:32,  2.11it/s, recall_0.3=(1102, 1101) / 1370]eval:  77%|██████████████████████████████████▊          | 235/304 [02:08<00:32,  2.11it/s, recall_0.3=(1102, 1101) / 1370]eval:  78%|██████████████████████████████████▉          | 236/304 [02:08<00:32,  2.09it/s, recall_0.3=(1102, 1101) / 1370]eval:  78%|██████████████████████████████████▉          | 236/304 [02:09<00:32,  2.09it/s, recall_0.3=(1102, 1101) / 1370]eval:  78%|███████████████████████████████████          | 237/304 [02:09<00:31,  2.11it/s, recall_0.3=(1102, 1101) / 1370]eval:  78%|███████████████████████████████████          | 237/304 [02:10<00:31,  2.11it/s, recall_0.3=(1102, 1101) / 1370]eval:  78%|███████████████████████████████████▏         | 238/304 [02:10<00:34,  1.90it/s, recall_0.3=(1102, 1101) / 1370]eval:  78%|███████████████████████████████████▏         | 238/304 [02:10<00:34,  1.90it/s, recall_0.3=(1102, 1101) / 1370]eval:  79%|███████████████████████████████████▍         | 239/304 [02:10<00:32,  1.98it/s, recall_0.3=(1102, 1101) / 1370]eval:  79%|███████████████████████████████████▍         | 239/304 [02:11<00:32,  1.98it/s, recall_0.3=(1102, 1101) / 1370]eval:  79%|███████████████████████████████████▌         | 240/304 [02:11<00:34,  1.86it/s, recall_0.3=(1102, 1101) / 1370]eval:  79%|███████████████████████████████████▌         | 240/304 [02:11<00:34,  1.86it/s, recall_0.3=(1103, 1102) / 1372]eval:  79%|███████████████████████████████████▋         | 241/304 [02:11<00:36,  1.74it/s, recall_0.3=(1103, 1102) / 1372]eval:  79%|███████████████████████████████████▋         | 241/304 [02:12<00:36,  1.74it/s, recall_0.3=(1105, 1104) / 1374]eval:  80%|███████████████████████████████████▊         | 242/304 [02:12<00:36,  1.70it/s, recall_0.3=(1105, 1104) / 1374]eval:  80%|███████████████████████████████████▊         | 242/304 [02:13<00:36,  1.70it/s, recall_0.3=(1107, 1106) / 1376]eval:  80%|███████████████████████████████████▉         | 243/304 [02:13<00:37,  1.63it/s, recall_0.3=(1107, 1106) / 1376]eval:  80%|███████████████████████████████████▉         | 243/304 [02:13<00:37,  1.63it/s, recall_0.3=(1108, 1107) / 1378]eval:  80%|████████████████████████████████████         | 244/304 [02:13<00:34,  1.74it/s, recall_0.3=(1108, 1107) / 1378]eval:  80%|████████████████████████████████████         | 244/304 [02:14<00:34,  1.74it/s, recall_0.3=(1110, 1109) / 1382]eval:  81%|████████████████████████████████████▎        | 245/304 [02:14<00:34,  1.73it/s, recall_0.3=(1110, 1109) / 1382]eval:  81%|████████████████████████████████████▎        | 245/304 [02:14<00:34,  1.73it/s, recall_0.3=(1115, 1114) / 1387]eval:  81%|████████████████████████████████████▍        | 246/304 [02:14<00:35,  1.65it/s, recall_0.3=(1115, 1114) / 1387]eval:  81%|████████████████████████████████████▍        | 246/304 [02:15<00:35,  1.65it/s, recall_0.3=(1121, 1120) / 1393]eval:  81%|████████████████████████████████████▌        | 247/304 [02:15<00:33,  1.69it/s, recall_0.3=(1121, 1120) / 1393]eval:  81%|████████████████████████████████████▌        | 247/304 [02:15<00:33,  1.69it/s, recall_0.3=(1126, 1125) / 1401]eval:  82%|████████████████████████████████████▋        | 248/304 [02:15<00:33,  1.67it/s, recall_0.3=(1126, 1125) / 1401]eval:  82%|████████████████████████████████████▋        | 248/304 [02:16<00:33,  1.67it/s, recall_0.3=(1132, 1131) / 1408]eval:  82%|████████████████████████████████████▊        | 249/304 [02:16<00:32,  1.67it/s, recall_0.3=(1132, 1131) / 1408]eval:  82%|████████████████████████████████████▊        | 249/304 [02:17<00:32,  1.67it/s, recall_0.3=(1137, 1136) / 1413]eval:  82%|█████████████████████████████████████        | 250/304 [02:17<00:32,  1.65it/s, recall_0.3=(1137, 1136) / 1413]eval:  82%|█████████████████████████████████████        | 250/304 [02:17<00:32,  1.65it/s, recall_0.3=(1140, 1139) / 1416]eval:  83%|█████████████████████████████████████▏       | 251/304 [02:17<00:31,  1.69it/s, recall_0.3=(1140, 1139) / 1416]eval:  83%|█████████████████████████████████████▏       | 251/304 [02:18<00:31,  1.69it/s, recall_0.3=(1141, 1140) / 1418]eval:  83%|█████████████████████████████████████▎       | 252/304 [02:18<00:30,  1.72it/s, recall_0.3=(1141, 1140) / 1418]eval:  83%|█████████████████████████████████████▎       | 252/304 [02:18<00:30,  1.72it/s, recall_0.3=(1143, 1142) / 1420]eval:  83%|█████████████████████████████████████▍       | 253/304 [02:18<00:28,  1.82it/s, recall_0.3=(1143, 1142) / 1420]eval:  83%|█████████████████████████████████████▍       | 253/304 [02:19<00:28,  1.82it/s, recall_0.3=(1143, 1142) / 1420]eval:  84%|█████████████████████████████████████▌       | 254/304 [02:19<00:26,  1.92it/s, recall_0.3=(1143, 1142) / 1420]eval:  84%|█████████████████████████████████████▌       | 254/304 [02:19<00:26,  1.92it/s, recall_0.3=(1145, 1144) / 1422]eval:  84%|█████████████████████████████████████▋       | 255/304 [02:19<00:25,  1.93it/s, recall_0.3=(1145, 1144) / 1422]eval:  84%|█████████████████████████████████████▋       | 255/304 [02:20<00:25,  1.93it/s, recall_0.3=(1146, 1146) / 1424]eval:  84%|█████████████████████████████████████▉       | 256/304 [02:20<00:27,  1.77it/s, recall_0.3=(1146, 1146) / 1424]eval:  84%|█████████████████████████████████████▉       | 256/304 [02:20<00:27,  1.77it/s, recall_0.3=(1146, 1146) / 1424]eval:  85%|██████████████████████████████████████       | 257/304 [02:20<00:26,  1.79it/s, recall_0.3=(1146, 1146) / 1424]eval:  85%|██████████████████████████████████████       | 257/304 [02:21<00:26,  1.79it/s, recall_0.3=(1146, 1146) / 1424]eval:  85%|██████████████████████████████████████▏      | 258/304 [02:21<00:25,  1.82it/s, recall_0.3=(1146, 1146) / 1424]eval:  85%|██████████████████████████████████████▏      | 258/304 [02:21<00:25,  1.82it/s, recall_0.3=(1146, 1146) / 1424]eval:  85%|██████████████████████████████████████▎      | 259/304 [02:21<00:23,  1.89it/s, recall_0.3=(1146, 1146) / 1424]eval:  85%|██████████████████████████████████████▎      | 259/304 [02:22<00:23,  1.89it/s, recall_0.3=(1146, 1146) / 1426]eval:  86%|██████████████████████████████████████▍      | 260/304 [02:22<00:21,  2.06it/s, recall_0.3=(1146, 1146) / 1426]eval:  86%|██████████████████████████████████████▍      | 260/304 [02:22<00:21,  2.06it/s, recall_0.3=(1150, 1150) / 1430]eval:  86%|██████████████████████████████████████▋      | 261/304 [02:22<00:20,  2.05it/s, recall_0.3=(1150, 1150) / 1430]eval:  86%|██████████████████████████████████████▋      | 261/304 [02:23<00:20,  2.05it/s, recall_0.3=(1151, 1151) / 1432]eval:  86%|██████████████████████████████████████▊      | 262/304 [02:23<00:20,  2.04it/s, recall_0.3=(1151, 1151) / 1432]eval:  86%|██████████████████████████████████████▊      | 262/304 [02:23<00:20,  2.04it/s, recall_0.3=(1151, 1151) / 1432]eval:  87%|██████████████████████████████████████▉      | 263/304 [02:23<00:19,  2.09it/s, recall_0.3=(1151, 1151) / 1432]eval:  87%|██████████████████████████████████████▉      | 263/304 [02:24<00:19,  2.09it/s, recall_0.3=(1151, 1151) / 1432]eval:  87%|███████████████████████████████████████      | 264/304 [02:24<00:18,  2.19it/s, recall_0.3=(1151, 1151) / 1432]eval:  87%|███████████████████████████████████████      | 264/304 [02:24<00:18,  2.19it/s, recall_0.3=(1151, 1151) / 1432]eval:  87%|███████████████████████████████████████▏     | 265/304 [02:24<00:17,  2.18it/s, recall_0.3=(1151, 1151) / 1432]eval:  87%|███████████████████████████████████████▏     | 265/304 [02:25<00:17,  2.18it/s, recall_0.3=(1151, 1151) / 1432]eval:  88%|███████████████████████████████████████▍     | 266/304 [02:25<00:18,  2.09it/s, recall_0.3=(1151, 1151) / 1432]eval:  88%|███████████████████████████████████████▍     | 266/304 [02:25<00:18,  2.09it/s, recall_0.3=(1151, 1151) / 1432]eval:  88%|███████████████████████████████████████▌     | 267/304 [02:25<00:19,  1.93it/s, recall_0.3=(1151, 1151) / 1432]eval:  88%|███████████████████████████████████████▌     | 267/304 [02:26<00:19,  1.93it/s, recall_0.3=(1154, 1154) / 1435]eval:  88%|███████████████████████████████████████▋     | 268/304 [02:26<00:17,  2.07it/s, recall_0.3=(1154, 1154) / 1435]eval:  88%|███████████████████████████████████████▋     | 268/304 [02:26<00:17,  2.07it/s, recall_0.3=(1158, 1158) / 1439]eval:  88%|███████████████████████████████████████▊     | 269/304 [02:26<00:16,  2.09it/s, recall_0.3=(1158, 1158) / 1439]eval:  88%|███████████████████████████████████████▊     | 269/304 [02:27<00:16,  2.09it/s, recall_0.3=(1162, 1162) / 1443]eval:  89%|███████████████████████████████████████▉     | 270/304 [02:27<00:15,  2.21it/s, recall_0.3=(1162, 1162) / 1443]eval:  89%|███████████████████████████████████████▉     | 270/304 [02:27<00:15,  2.21it/s, recall_0.3=(1163, 1163) / 1445]eval:  89%|████████████████████████████████████████     | 271/304 [02:27<00:14,  2.27it/s, recall_0.3=(1163, 1163) / 1445]eval:  89%|████████████████████████████████████████     | 271/304 [02:27<00:14,  2.27it/s, recall_0.3=(1164, 1163) / 1449]eval:  89%|████████████████████████████████████████▎    | 272/304 [02:27<00:14,  2.18it/s, recall_0.3=(1164, 1163) / 1449]eval:  89%|████████████████████████████████████████▎    | 272/304 [02:28<00:14,  2.18it/s, recall_0.3=(1167, 1166) / 1453]eval:  90%|████████████████████████████████████████▍    | 273/304 [02:28<00:15,  1.99it/s, recall_0.3=(1167, 1166) / 1453]eval:  90%|████████████████████████████████████████▍    | 273/304 [02:29<00:15,  1.99it/s, recall_0.3=(1171, 1170) / 1457]eval:  90%|████████████████████████████████████████▌    | 274/304 [02:29<00:15,  1.93it/s, recall_0.3=(1171, 1170) / 1457]eval:  90%|████████████████████████████████████████▌    | 274/304 [02:29<00:15,  1.93it/s, recall_0.3=(1174, 1173) / 1460]eval:  90%|████████████████████████████████████████▋    | 275/304 [02:29<00:14,  2.02it/s, recall_0.3=(1174, 1173) / 1460]eval:  90%|████████████████████████████████████████▋    | 275/304 [02:30<00:14,  2.02it/s, recall_0.3=(1176, 1175) / 1462]eval:  91%|████████████████████████████████████████▊    | 276/304 [02:30<00:13,  2.08it/s, recall_0.3=(1176, 1175) / 1462]eval:  91%|████████████████████████████████████████▊    | 276/304 [02:30<00:13,  2.08it/s, recall_0.3=(1178, 1177) / 1464]eval:  91%|█████████████████████████████████████████    | 277/304 [02:30<00:12,  2.12it/s, recall_0.3=(1178, 1177) / 1464]eval:  91%|█████████████████████████████████████████    | 277/304 [02:30<00:12,  2.12it/s, recall_0.3=(1178, 1177) / 1464]eval:  91%|█████████████████████████████████████████▏   | 278/304 [02:30<00:10,  2.43it/s, recall_0.3=(1178, 1177) / 1464]eval:  91%|█████████████████████████████████████████▏   | 278/304 [02:31<00:10,  2.43it/s, recall_0.3=(1178, 1177) / 1464]eval:  92%|█████████████████████████████████████████▎   | 279/304 [02:31<00:10,  2.42it/s, recall_0.3=(1178, 1177) / 1464]eval:  92%|█████████████████████████████████████████▎   | 279/304 [02:31<00:10,  2.42it/s, recall_0.3=(1178, 1177) / 1464]eval:  92%|█████████████████████████████████████████▍   | 280/304 [02:31<00:10,  2.25it/s, recall_0.3=(1178, 1177) / 1464]eval:  92%|█████████████████████████████████████████▍   | 280/304 [02:32<00:10,  2.25it/s, recall_0.3=(1178, 1177) / 1464]eval:  92%|█████████████████████████████████████████▌   | 281/304 [02:32<00:10,  2.14it/s, recall_0.3=(1178, 1177) / 1464]eval:  92%|█████████████████████████████████████████▌   | 281/304 [02:32<00:10,  2.14it/s, recall_0.3=(1178, 1177) / 1464]eval:  93%|█████████████████████████████████████████▋   | 282/304 [02:32<00:10,  2.00it/s, recall_0.3=(1178, 1177) / 1464]eval:  93%|█████████████████████████████████████████▋   | 282/304 [02:33<00:10,  2.00it/s, recall_0.3=(1178, 1177) / 1464]eval:  93%|█████████████████████████████████████████▉   | 283/304 [02:33<00:10,  1.95it/s, recall_0.3=(1178, 1177) / 1464]eval:  93%|█████████████████████████████████████████▉   | 283/304 [02:33<00:10,  1.95it/s, recall_0.3=(1179, 1178) / 1469]eval:  93%|██████████████████████████████████████████   | 284/304 [02:33<00:09,  2.02it/s, recall_0.3=(1179, 1178) / 1469]eval:  93%|██████████████████████████████████████████   | 284/304 [02:34<00:09,  2.02it/s, recall_0.3=(1189, 1188) / 1482]eval:  94%|██████████████████████████████████████████▏  | 285/304 [02:34<00:09,  2.00it/s, recall_0.3=(1189, 1188) / 1482]eval:  94%|██████████████████████████████████████████▏  | 285/304 [02:34<00:09,  2.00it/s, recall_0.3=(1202, 1201) / 1496]eval:  94%|██████████████████████████████████████████▎  | 286/304 [02:34<00:08,  2.14it/s, recall_0.3=(1202, 1201) / 1496]eval:  94%|██████████████████████████████████████████▎  | 286/304 [02:35<00:08,  2.14it/s, recall_0.3=(1211, 1210) / 1509]eval:  94%|██████████████████████████████████████████▍  | 287/304 [02:35<00:07,  2.19it/s, recall_0.3=(1211, 1210) / 1509]eval:  94%|██████████████████████████████████████████▍  | 287/304 [02:35<00:07,  2.19it/s, recall_0.3=(1222, 1221) / 1522]eval:  95%|██████████████████████████████████████████▋  | 288/304 [02:35<00:07,  2.13it/s, recall_0.3=(1222, 1221) / 1522]eval:  95%|██████████████████████████████████████████▋  | 288/304 [02:36<00:07,  2.13it/s, recall_0.3=(1229, 1228) / 1529]eval:  95%|██████████████████████████████████████████▊  | 289/304 [02:36<00:07,  2.13it/s, recall_0.3=(1229, 1228) / 1529]eval:  95%|██████████████████████████████████████████▊  | 289/304 [02:36<00:07,  2.13it/s, recall_0.3=(1240, 1239) / 1543]eval:  95%|██████████████████████████████████████████▉  | 290/304 [02:36<00:06,  2.18it/s, recall_0.3=(1240, 1239) / 1543]eval:  95%|██████████████████████████████████████████▉  | 290/304 [02:37<00:06,  2.18it/s, recall_0.3=(1249, 1248) / 1559]eval:  96%|███████████████████████████████████████████  | 291/304 [02:37<00:06,  2.11it/s, recall_0.3=(1249, 1248) / 1559]eval:  96%|███████████████████████████████████████████  | 291/304 [02:37<00:06,  2.11it/s, recall_0.3=(1249, 1248) / 1559]eval:  96%|███████████████████████████████████████████▏ | 292/304 [02:37<00:04,  2.43it/s, recall_0.3=(1249, 1248) / 1559]eval:  96%|███████████████████████████████████████████▏ | 292/304 [02:37<00:04,  2.43it/s, recall_0.3=(1249, 1248) / 1559]eval:  96%|███████████████████████████████████████████▎ | 293/304 [02:37<00:04,  2.61it/s, recall_0.3=(1249, 1248) / 1559]eval:  96%|███████████████████████████████████████████▎ | 293/304 [02:37<00:04,  2.61it/s, recall_0.3=(1250, 1249) / 1561]eval:  97%|███████████████████████████████████████████▌ | 294/304 [02:37<00:03,  2.62it/s, recall_0.3=(1250, 1249) / 1561]eval:  97%|███████████████████████████████████████████▌ | 294/304 [02:38<00:03,  2.62it/s, recall_0.3=(1252, 1251) / 1563]eval:  97%|███████████████████████████████████████████▋ | 295/304 [02:38<00:03,  2.98it/s, recall_0.3=(1252, 1251) / 1563]eval:  97%|███████████████████████████████████████████▋ | 295/304 [02:38<00:03,  2.98it/s, recall_0.3=(1253, 1252) / 1565]eval:  97%|███████████████████████████████████████████▊ | 296/304 [02:38<00:02,  2.77it/s, recall_0.3=(1253, 1252) / 1565]eval:  97%|███████████████████████████████████████████▊ | 296/304 [02:38<00:02,  2.77it/s, recall_0.3=(1253, 1252) / 1565]eval:  98%|███████████████████████████████████████████▉ | 297/304 [02:38<00:02,  2.95it/s, recall_0.3=(1253, 1252) / 1565]eval:  98%|███████████████████████████████████████████▉ | 297/304 [02:39<00:02,  2.95it/s, recall_0.3=(1253, 1252) / 1565]eval:  98%|████████████████████████████████████████████ | 298/304 [02:39<00:01,  3.27it/s, recall_0.3=(1253, 1252) / 1565]eval:  98%|████████████████████████████████████████████ | 298/304 [02:39<00:01,  3.27it/s, recall_0.3=(1253, 1252) / 1565]eval:  98%|████████████████████████████████████████████▎| 299/304 [02:39<00:01,  3.67it/s, recall_0.3=(1253, 1252) / 1565]eval:  98%|████████████████████████████████████████████▎| 299/304 [02:39<00:01,  3.67it/s, recall_0.3=(1253, 1252) / 1565]eval:  99%|████████████████████████████████████████████▍| 300/304 [02:39<00:00,  4.17it/s, recall_0.3=(1253, 1252) / 1565]eval:  99%|████████████████████████████████████████████▍| 300/304 [02:39<00:00,  4.17it/s, recall_0.3=(1253, 1252) / 1565]eval:  99%|████████████████████████████████████████████▌| 301/304 [02:39<00:00,  4.59it/s, recall_0.3=(1253, 1252) / 1565]eval:  99%|████████████████████████████████████████████▌| 301/304 [02:39<00:00,  4.59it/s, recall_0.3=(1253, 1252) / 1565]eval:  99%|████████████████████████████████████████████▋| 302/304 [02:39<00:00,  4.93it/s, recall_0.3=(1253, 1252) / 1565]eval:  99%|████████████████████████████████████████████▋| 302/304 [02:40<00:00,  4.93it/s, recall_0.3=(1256, 1255) / 1570]eval: 100%|████████████████████████████████████████████▊| 303/304 [02:40<00:00,  5.06it/s, recall_0.3=(1256, 1255) / 1570]eval: 100%|████████████████████████████████████████████▊| 303/304 [02:40<00:00,  5.06it/s, recall_0.3=(1260, 1259) / 1574]eval: 100%|█████████████████████████████████████████████| 304/304 [02:40<00:00,  5.09it/s, recall_0.3=(1260, 1259) / 1574]eval: 100%|█████████████████████████████████████████████| 304/304 [02:40<00:00,  1.89it/s, recall_0.3=(1260, 1259) / 1574]
2023-03-01 02:07:32,867   INFO  *************** Performance of EPOCH 50 *****************
2023-03-01 02:07:32,867   INFO  Generate label finished(sec_per_example: 0.0663 second).
2023-03-01 02:07:32,868   INFO  recall_roi_0.3: 0.798972
2023-03-01 02:07:32,868   INFO  recall_rcnn_0.3: 0.800257
2023-03-01 02:07:32,868   INFO  recall_roi_0.5: 0.707697
2023-03-01 02:07:32,868   INFO  recall_rcnn_0.5: 0.741604
2023-03-01 02:07:32,868   INFO  recall_roi_0.7: 0.383256
2023-03-01 02:07:32,868   INFO  recall_rcnn_0.7: 0.505544
2023-03-01 02:07:32,870   INFO  Average predicted number of objects(2432 samples): 3.989
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
2023-03-01 02:07:38,415   INFO  Car IoU 0.7:
RANGE 00-30   30-50   50-80   00-80 
BEV:  73.075, 66.058, 28.473, 60.135
3D :  62.063, 38.387,  7.241, 41.477
Car IoU 0.5:
RANGE 00-30   30-50   50-80   00-80 
BEV:  84.361, 77.237, 55.213, 75.509
3D :  81.977, 74.586, 45.409, 72.655
Car IoU 0.7:
73.1 / 62.1, 66.1 / 38.4, 28.5 / 7.2, 60.1 / 41.5
Car IoU 0.5:
84.4 / 82.0, 77.2 / 74.6, 55.2 / 45.4, 75.5 / 72.7

Pedestrian IoU 0.7:
RANGE 00-30   30-50   50-80   00-80 
BEV:  27.671, 30.057, 19.044, 23.326
3D :  23.792, 24.362, 12.855, 18.905
Pedestrian IoU 0.5:
RANGE 00-30   30-50   50-80   00-80 
BEV:  36.167, 38.320, 25.214, 30.754
3D :  36.167, 38.320, 25.214, 30.754
Pedestrian IoU 0.7:
27.7 / 23.8, 30.1 / 24.4, 19.0 / 12.9, 23.3 / 18.9
Pedestrian IoU 0.5:
36.2 / 36.2, 38.3 / 38.3, 25.2 / 25.2, 30.8 / 30.8


2023-03-01 02:07:38,417   INFO  Result is save to /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5/default/eval/eval_with_train/epoch_50/val
2023-03-01 02:07:38,417   INFO  ****************Evaluation done.*****************
2023-03-01 02:07:38,432   INFO  Epoch 50 has been evaluated
2023-03-01 02:07:38,434   INFO  ==> Loading parameters from checkpoint /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5/default/ckpt/checkpoint_epoch_60.pth to CPU
2023-03-01 02:07:38,555   INFO  ==> Checkpoint trained from version: pcdet+0.3.0+0000000
2023-03-01 02:07:40,025   INFO  ==> Done (loaded 502/502)
PointRCNN(
  (history_query): SparseResUQueryNet(
    (history_backbone): Res16UNet14E(
      (conv0p1s1): MinkowskiConvolution(in=1, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (conv1p1s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block1): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (conv2p2s2): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block2): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv3p4s2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn3): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block3): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=64, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (conv4p8s2): MinkowskiConvolution(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bn4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block4): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
        )
      )
      (convtr4p16s2): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr4): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block5): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=256, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=128, out=128, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=256, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr5p8s2): MinkowskiConvolutionTranspose(in=128, out=96, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr5): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block6): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=160, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=96, out=96, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=160, out=96, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(96, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr6p4s2): MinkowskiConvolutionTranspose(in=96, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr6): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block7): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (convtr7p2s2): MinkowskiConvolutionTranspose(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])
      (bntr7): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (block8): Sequential(
        (0): BasicBlock(
          (conv1): MinkowskiConvolution(in=96, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
          (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): MinkowskiReLU()
          (downsample): Sequential(
            (0): MinkowskiConvolution(in=96, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
            (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): MinkowskiReLU()
      (final): MinkowskiConvolution(in=64, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
    )
    (pool): MinkowskiMaxPooling(kernel_size=[1000, 1, 1, 1], stride=[1000, 1, 1, 1], dilation=[1, 1, 1, 1])
    (p2_backbone): Sequential(
      (0): Linear(in_features=68, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
    (current_conv): MinkowskiConvolution(in=64, out=64, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  )
  (vfe): None
  (backbone_3d): PointNet2MSG(
    (SA_modules): ModuleList(
      (0): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(67, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(67, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (3): PointnetSAModuleMSG(
        (groupers): ModuleList(
          (0): QueryAndGroup()
          (1): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (FP_modules): ModuleList(
      (0): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (1): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (2): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
      (3): PointnetFPModule(
        (mlp): Sequential(
          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
        )
      )
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): None
  (point_head): PointHeadBox(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (cls_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=2, bias=True)
    )
    (box_layers): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=False)
      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=8, bias=True)
    )
  )
  (roi_head): PointRCNNHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (SA_modules): ModuleList(
      (0): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (1): PointnetSAModule(
        (groupers): ModuleList(
          (0): QueryAndGroup()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
      (2): PointnetSAModule(
        (groupers): ModuleList(
          (0): GroupAll()
        )
        (mlps): ModuleList(
          (0): Sequential(
            (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU()
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (8): ReLU()
          )
        )
      )
    )
    (xyz_up_layer): Sequential(
      (0): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU()
    )
    (merge_down_layer): Sequential(
      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
    )
    (cls_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (reg_layers): Sequential(
      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv1d(256, 7, kernel_size=(1,), stride=(1,))
    )
    (roipoint_pool3d_layer): RoIPointPool3d()
  )
)
2023-03-01 02:07:40,037   INFO  *************** EPOCH 60 EVALUATION *****************
eval:   0%|                                                                                       | 0/304 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
eval:   0%|                                                                | 0/304 [00:03<?, ?it/s, recall_0.3=(2, 2) / 2]eval:   0%|▏                                                       | 1/304 [00:03<17:20,  3.43s/it, recall_0.3=(2, 2) / 2]eval:   0%|▏                                                       | 1/304 [00:04<17:20,  3.43s/it, recall_0.3=(4, 4) / 4]eval:   1%|▎                                                       | 2/304 [00:04<09:39,  1.92s/it, recall_0.3=(4, 4) / 4]eval:   1%|▎                                                       | 2/304 [00:04<09:39,  1.92s/it, recall_0.3=(6, 6) / 6]eval:   1%|▌                                                       | 3/304 [00:04<06:48,  1.36s/it, recall_0.3=(6, 6) / 6]eval:   1%|▌                                                       | 3/304 [00:05<06:48,  1.36s/it, recall_0.3=(7, 7) / 8]eval:   1%|▋                                                       | 4/304 [00:05<05:35,  1.12s/it, recall_0.3=(7, 7) / 8]eval:   1%|▋                                                      | 4/304 [00:06<05:35,  1.12s/it, recall_0.3=(7, 7) / 10]eval:   2%|▉                                                      | 5/304 [00:06<04:42,  1.06it/s, recall_0.3=(7, 7) / 10]eval:   2%|▊                                                    | 5/304 [00:07<04:42,  1.06it/s, recall_0.3=(19, 19) / 23]eval:   2%|█                                                    | 6/304 [00:07<04:24,  1.13it/s, recall_0.3=(19, 19) / 23]eval:   2%|█                                                    | 6/304 [00:07<04:24,  1.13it/s, recall_0.3=(29, 29) / 33]eval:   2%|█▏                                                   | 7/304 [00:07<03:56,  1.26it/s, recall_0.3=(29, 29) / 33]eval:   2%|█▏                                                   | 7/304 [00:08<03:56,  1.26it/s, recall_0.3=(39, 39) / 43]eval:   3%|█▍                                                   | 8/304 [00:08<04:07,  1.20it/s, recall_0.3=(39, 39) / 43]eval:   3%|█▍                                                   | 8/304 [00:09<04:07,  1.20it/s, recall_0.3=(49, 49) / 53]eval:   3%|█▌                                                   | 9/304 [00:09<04:08,  1.19it/s, recall_0.3=(49, 49) / 53]eval:   3%|█▌                                                   | 9/304 [00:10<04:08,  1.19it/s, recall_0.3=(56, 56) / 60]eval:   3%|█▋                                                  | 10/304 [00:10<03:57,  1.24it/s, recall_0.3=(56, 56) / 60]eval:   3%|█▋                                                  | 10/304 [00:10<03:57,  1.24it/s, recall_0.3=(62, 62) / 67]eval:   4%|█▉                                                  | 11/304 [00:10<03:45,  1.30it/s, recall_0.3=(62, 62) / 67]eval:   4%|█▉                                                  | 11/304 [00:11<03:45,  1.30it/s, recall_0.3=(68, 68) / 73]eval:   4%|██                                                  | 12/304 [00:11<03:29,  1.40it/s, recall_0.3=(68, 68) / 73]eval:   4%|██                                                  | 12/304 [00:12<03:29,  1.40it/s, recall_0.3=(72, 72) / 79]eval:   4%|██▏                                                 | 13/304 [00:12<03:14,  1.50it/s, recall_0.3=(72, 72) / 79]eval:   4%|██▏                                                 | 13/304 [00:12<03:14,  1.50it/s, recall_0.3=(76, 76) / 83]eval:   5%|██▍                                                 | 14/304 [00:12<02:57,  1.64it/s, recall_0.3=(76, 76) / 83]eval:   5%|██▍                                                 | 14/304 [00:13<02:57,  1.64it/s, recall_0.3=(83, 83) / 91]eval:   5%|██▌                                                 | 15/304 [00:13<02:50,  1.70it/s, recall_0.3=(83, 83) / 91]eval:   5%|██▌                                                | 15/304 [00:13<02:50,  1.70it/s, recall_0.3=(92, 92) / 102]eval:   5%|██▋                                                | 16/304 [00:13<02:45,  1.74it/s, recall_0.3=(92, 92) / 102]eval:   5%|██▌                                              | 16/304 [00:14<02:45,  1.74it/s, recall_0.3=(102, 102) / 114]eval:   6%|██▋                                              | 17/304 [00:14<02:58,  1.61it/s, recall_0.3=(102, 102) / 114]eval:   6%|██▋                                              | 17/304 [00:15<02:58,  1.61it/s, recall_0.3=(112, 112) / 124]eval:   6%|██▉                                              | 18/304 [00:15<03:08,  1.52it/s, recall_0.3=(112, 112) / 124]eval:   6%|██▉                                              | 18/304 [00:15<03:08,  1.52it/s, recall_0.3=(121, 121) / 134]eval:   6%|███                                              | 19/304 [00:15<03:14,  1.47it/s, recall_0.3=(121, 121) / 134]eval:   6%|███                                              | 19/304 [00:16<03:14,  1.47it/s, recall_0.3=(131, 131) / 144]eval:   7%|███▏                                             | 20/304 [00:16<03:12,  1.48it/s, recall_0.3=(131, 131) / 144]eval:   7%|███▏                                             | 20/304 [00:17<03:12,  1.48it/s, recall_0.3=(139, 139) / 153]eval:   7%|███▍                                             | 21/304 [00:17<03:04,  1.53it/s, recall_0.3=(139, 139) / 153]eval:   7%|███▍                                             | 21/304 [00:17<03:04,  1.53it/s, recall_0.3=(147, 147) / 161]eval:   7%|███▌                                             | 22/304 [00:17<03:18,  1.42it/s, recall_0.3=(147, 147) / 161]eval:   7%|███▌                                             | 22/304 [00:18<03:18,  1.42it/s, recall_0.3=(151, 151) / 165]eval:   8%|███▋                                             | 23/304 [00:18<03:12,  1.46it/s, recall_0.3=(151, 151) / 165]eval:   8%|███▋                                             | 23/304 [00:19<03:12,  1.46it/s, recall_0.3=(155, 155) / 169]eval:   8%|███▊                                             | 24/304 [00:19<03:06,  1.50it/s, recall_0.3=(155, 155) / 169]eval:   8%|███▊                                             | 24/304 [00:19<03:06,  1.50it/s, recall_0.3=(158, 158) / 173]eval:   8%|████                                             | 25/304 [00:19<03:01,  1.53it/s, recall_0.3=(158, 158) / 173]eval:   8%|████                                             | 25/304 [00:20<03:01,  1.53it/s, recall_0.3=(160, 160) / 176]eval:   9%|████▏                                            | 26/304 [00:20<02:44,  1.69it/s, recall_0.3=(160, 160) / 176]eval:   9%|████▏                                            | 26/304 [00:20<02:44,  1.69it/s, recall_0.3=(161, 161) / 179]eval:   9%|████▎                                            | 27/304 [00:20<02:33,  1.80it/s, recall_0.3=(161, 161) / 179]eval:   9%|████▎                                            | 27/304 [00:21<02:33,  1.80it/s, recall_0.3=(165, 165) / 184]eval:   9%|████▌                                            | 28/304 [00:21<02:39,  1.73it/s, recall_0.3=(165, 165) / 184]eval:   9%|████▌                                            | 28/304 [00:22<02:39,  1.73it/s, recall_0.3=(170, 170) / 190]eval:  10%|████▋                                            | 29/304 [00:22<02:49,  1.62it/s, recall_0.3=(170, 170) / 190]eval:  10%|████▋                                            | 29/304 [00:22<02:49,  1.62it/s, recall_0.3=(174, 174) / 194]eval:  10%|████▊                                            | 30/304 [00:22<03:04,  1.48it/s, recall_0.3=(174, 174) / 194]eval:  10%|████▊                                            | 30/304 [00:23<03:04,  1.48it/s, recall_0.3=(181, 181) / 203]eval:  10%|████▉                                            | 31/304 [00:23<02:46,  1.64it/s, recall_0.3=(181, 181) / 203]eval:  10%|████▉                                            | 31/304 [00:24<02:46,  1.64it/s, recall_0.3=(192, 192) / 219]eval:  11%|█████▏                                           | 32/304 [00:24<03:01,  1.50it/s, recall_0.3=(192, 192) / 219]eval:  11%|█████▏                                           | 32/304 [00:24<03:01,  1.50it/s, recall_0.3=(208, 208) / 238]eval:  11%|█████▎                                           | 33/304 [00:24<03:02,  1.49it/s, recall_0.3=(208, 208) / 238]eval:  11%|█████▎                                           | 33/304 [00:25<03:02,  1.49it/s, recall_0.3=(218, 218) / 252]eval:  11%|█████▍                                           | 34/304 [00:25<02:44,  1.64it/s, recall_0.3=(218, 218) / 252]eval:  11%|█████▍                                           | 34/304 [00:25<02:44,  1.64it/s, recall_0.3=(225, 225) / 262]eval:  12%|█████▋                                           | 35/304 [00:25<02:42,  1.66it/s, recall_0.3=(225, 225) / 262]eval:  12%|█████▋                                           | 35/304 [00:26<02:42,  1.66it/s, recall_0.3=(231, 231) / 268]eval:  12%|█████▊                                           | 36/304 [00:26<02:45,  1.62it/s, recall_0.3=(231, 231) / 268]eval:  12%|█████▊                                           | 36/304 [00:27<02:45,  1.62it/s, recall_0.3=(235, 235) / 273]eval:  12%|█████▉                                           | 37/304 [00:27<02:45,  1.61it/s, recall_0.3=(235, 235) / 273]eval:  12%|█████▉                                           | 37/304 [00:27<02:45,  1.61it/s, recall_0.3=(239, 239) / 277]eval:  12%|██████▏                                          | 38/304 [00:27<02:43,  1.62it/s, recall_0.3=(239, 239) / 277]eval:  12%|██████▏                                          | 38/304 [00:28<02:43,  1.62it/s, recall_0.3=(241, 241) / 279]eval:  13%|██████▎                                          | 39/304 [00:28<02:27,  1.79it/s, recall_0.3=(241, 241) / 279]eval:  13%|██████▎                                          | 39/304 [00:28<02:27,  1.79it/s, recall_0.3=(243, 243) / 281]eval:  13%|██████▍                                          | 40/304 [00:28<02:25,  1.82it/s, recall_0.3=(243, 243) / 281]eval:  13%|██████▍                                          | 40/304 [00:29<02:25,  1.82it/s, recall_0.3=(245, 245) / 283]eval:  13%|██████▌                                          | 41/304 [00:29<02:20,  1.88it/s, recall_0.3=(245, 245) / 283]eval:  13%|██████▌                                          | 41/304 [00:29<02:20,  1.88it/s, recall_0.3=(246, 247) / 286]eval:  14%|██████▊                                          | 42/304 [00:29<02:16,  1.91it/s, recall_0.3=(246, 247) / 286]eval:  14%|██████▊                                          | 42/304 [00:30<02:16,  1.91it/s, recall_0.3=(248, 249) / 290]eval:  14%|██████▉                                          | 43/304 [00:30<02:20,  1.86it/s, recall_0.3=(248, 249) / 290]eval:  14%|██████▉                                          | 43/304 [00:30<02:20,  1.86it/s, recall_0.3=(250, 251) / 293]eval:  14%|███████                                          | 44/304 [00:30<02:30,  1.73it/s, recall_0.3=(250, 251) / 293]eval:  14%|███████                                          | 44/304 [00:31<02:30,  1.73it/s, recall_0.3=(252, 253) / 295]eval:  15%|███████▎                                         | 45/304 [00:31<02:13,  1.95it/s, recall_0.3=(252, 253) / 295]eval:  15%|███████▎                                         | 45/304 [00:31<02:13,  1.95it/s, recall_0.3=(256, 257) / 299]eval:  15%|███████▍                                         | 46/304 [00:31<02:09,  1.99it/s, recall_0.3=(256, 257) / 299]eval:  15%|███████▍                                         | 46/304 [00:32<02:09,  1.99it/s, recall_0.3=(260, 261) / 303]eval:  15%|███████▌                                         | 47/304 [00:32<02:13,  1.92it/s, recall_0.3=(260, 261) / 303]eval:  15%|███████▌                                         | 47/304 [00:32<02:13,  1.92it/s, recall_0.3=(263, 264) / 307]eval:  16%|███████▋                                         | 48/304 [00:32<02:18,  1.84it/s, recall_0.3=(263, 264) / 307]eval:  16%|███████▋                                         | 48/304 [00:33<02:18,  1.84it/s, recall_0.3=(265, 266) / 311]eval:  16%|███████▉                                         | 49/304 [00:33<02:25,  1.75it/s, recall_0.3=(265, 266) / 311]eval:  16%|███████▉                                         | 49/304 [00:34<02:25,  1.75it/s, recall_0.3=(267, 268) / 315]eval:  16%|████████                                         | 50/304 [00:34<02:22,  1.78it/s, recall_0.3=(267, 268) / 315]eval:  16%|████████                                         | 50/304 [00:34<02:22,  1.78it/s, recall_0.3=(270, 271) / 320]eval:  17%|████████▏                                        | 51/304 [00:34<02:36,  1.62it/s, recall_0.3=(270, 271) / 320]eval:  17%|████████▏                                        | 51/304 [00:35<02:36,  1.62it/s, recall_0.3=(276, 277) / 328]eval:  17%|████████▍                                        | 52/304 [00:35<02:42,  1.55it/s, recall_0.3=(276, 277) / 328]eval:  17%|████████▍                                        | 52/304 [00:36<02:42,  1.55it/s, recall_0.3=(279, 280) / 333]eval:  17%|████████▌                                        | 53/304 [00:36<02:43,  1.53it/s, recall_0.3=(279, 280) / 333]eval:  17%|████████▌                                        | 53/304 [00:36<02:43,  1.53it/s, recall_0.3=(280, 281) / 336]eval:  18%|████████▋                                        | 54/304 [00:36<02:45,  1.51it/s, recall_0.3=(280, 281) / 336]eval:  18%|████████▋                                        | 54/304 [00:37<02:45,  1.51it/s, recall_0.3=(280, 281) / 338]eval:  18%|████████▊                                        | 55/304 [00:37<02:46,  1.49it/s, recall_0.3=(280, 281) / 338]eval:  18%|████████▊                                        | 55/304 [00:38<02:46,  1.49it/s, recall_0.3=(281, 282) / 340]eval:  18%|█████████                                        | 56/304 [00:38<02:46,  1.49it/s, recall_0.3=(281, 282) / 340]eval:  18%|█████████                                        | 56/304 [00:38<02:46,  1.49it/s, recall_0.3=(287, 288) / 346]eval:  19%|█████████▏                                       | 57/304 [00:38<02:37,  1.57it/s, recall_0.3=(287, 288) / 346]eval:  19%|█████████▏                                       | 57/304 [00:39<02:37,  1.57it/s, recall_0.3=(295, 296) / 355]eval:  19%|█████████▎                                       | 58/304 [00:39<02:25,  1.69it/s, recall_0.3=(295, 296) / 355]eval:  19%|█████████▎                                       | 58/304 [00:39<02:25,  1.69it/s, recall_0.3=(307, 308) / 367]eval:  19%|█████████▌                                       | 59/304 [00:39<02:14,  1.82it/s, recall_0.3=(307, 308) / 367]eval:  19%|█████████▌                                       | 59/304 [00:40<02:14,  1.82it/s, recall_0.3=(319, 320) / 381]eval:  20%|█████████▋                                       | 60/304 [00:40<02:04,  1.96it/s, recall_0.3=(319, 320) / 381]eval:  20%|█████████▋                                       | 60/304 [00:40<02:04,  1.96it/s, recall_0.3=(329, 330) / 394]eval:  20%|█████████▊                                       | 61/304 [00:40<01:56,  2.09it/s, recall_0.3=(329, 330) / 394]eval:  20%|█████████▊                                       | 61/304 [00:41<01:56,  2.09it/s, recall_0.3=(337, 338) / 406]eval:  20%|█████████▉                                       | 62/304 [00:41<02:00,  2.01it/s, recall_0.3=(337, 338) / 406]eval:  20%|█████████▉                                       | 62/304 [00:41<02:00,  2.01it/s, recall_0.3=(343, 344) / 412]eval:  21%|██████████▏                                      | 63/304 [00:41<02:02,  1.97it/s, recall_0.3=(343, 344) / 412]eval:  21%|██████████▏                                      | 63/304 [00:42<02:02,  1.97it/s, recall_0.3=(347, 348) / 416]eval:  21%|██████████▎                                      | 64/304 [00:42<01:48,  2.21it/s, recall_0.3=(347, 348) / 416]eval:  21%|██████████▎                                      | 64/304 [00:42<01:48,  2.21it/s, recall_0.3=(354, 355) / 424]eval:  21%|██████████▍                                      | 65/304 [00:42<01:46,  2.24it/s, recall_0.3=(354, 355) / 424]eval:  21%|██████████▍                                      | 65/304 [00:43<01:46,  2.24it/s, recall_0.3=(371, 372) / 443]eval:  22%|██████████▋                                      | 66/304 [00:43<01:54,  2.07it/s, recall_0.3=(371, 372) / 443]eval:  22%|██████████▋                                      | 66/304 [00:43<01:54,  2.07it/s, recall_0.3=(387, 388) / 463]eval:  22%|██████████▊                                      | 67/304 [00:43<02:08,  1.85it/s, recall_0.3=(387, 388) / 463]eval:  22%|██████████▊                                      | 67/304 [00:44<02:08,  1.85it/s, recall_0.3=(400, 401) / 478]eval:  22%|██████████▉                                      | 68/304 [00:44<02:19,  1.70it/s, recall_0.3=(400, 401) / 478]eval:  22%|██████████▉                                      | 68/304 [00:45<02:19,  1.70it/s, recall_0.3=(412, 413) / 494]eval:  23%|███████████                                      | 69/304 [00:45<02:30,  1.56it/s, recall_0.3=(412, 413) / 494]eval:  23%|███████████                                      | 69/304 [00:45<02:30,  1.56it/s, recall_0.3=(421, 422) / 504]eval:  23%|███████████▎                                     | 70/304 [00:45<02:39,  1.46it/s, recall_0.3=(421, 422) / 504]eval:  23%|███████████▎                                     | 70/304 [00:46<02:39,  1.46it/s, recall_0.3=(425, 426) / 509]eval:  23%|███████████▍                                     | 71/304 [00:46<02:43,  1.42it/s, recall_0.3=(425, 426) / 509]eval:  23%|███████████▍                                     | 71/304 [00:47<02:43,  1.42it/s, recall_0.3=(429, 430) / 513]eval:  24%|███████████▌                                     | 72/304 [00:47<02:43,  1.42it/s, recall_0.3=(429, 430) / 513]eval:  24%|███████████▌                                     | 72/304 [00:48<02:43,  1.42it/s, recall_0.3=(434, 435) / 519]eval:  24%|███████████▊                                     | 73/304 [00:48<02:39,  1.45it/s, recall_0.3=(434, 435) / 519]eval:  24%|███████████▊                                     | 73/304 [00:48<02:39,  1.45it/s, recall_0.3=(440, 441) / 525]eval:  24%|███████████▉                                     | 74/304 [00:48<02:33,  1.50it/s, recall_0.3=(440, 441) / 525]eval:  24%|███████████▉                                     | 74/304 [00:49<02:33,  1.50it/s, recall_0.3=(442, 443) / 527]eval:  25%|████████████                                     | 75/304 [00:49<02:39,  1.44it/s, recall_0.3=(442, 443) / 527]eval:  25%|████████████                                     | 75/304 [00:50<02:39,  1.44it/s, recall_0.3=(445, 446) / 531]eval:  25%|████████████▎                                    | 76/304 [00:50<02:35,  1.46it/s, recall_0.3=(445, 446) / 531]eval:  25%|████████████▎                                    | 76/304 [00:50<02:35,  1.46it/s, recall_0.3=(451, 452) / 537]eval:  25%|████████████▍                                    | 77/304 [00:50<02:33,  1.48it/s, recall_0.3=(451, 452) / 537]eval:  25%|████████████▍                                    | 77/304 [00:51<02:33,  1.48it/s, recall_0.3=(457, 458) / 543]eval:  26%|████████████▌                                    | 78/304 [00:51<02:29,  1.51it/s, recall_0.3=(457, 458) / 543]eval:  26%|████████████▌                                    | 78/304 [00:52<02:29,  1.51it/s, recall_0.3=(462, 463) / 549]eval:  26%|████████████▋                                    | 79/304 [00:52<02:31,  1.48it/s, recall_0.3=(462, 463) / 549]eval:  26%|████████████▋                                    | 79/304 [00:52<02:31,  1.48it/s, recall_0.3=(466, 467) / 554]eval:  26%|████████████▉                                    | 80/304 [00:52<02:28,  1.51it/s, recall_0.3=(466, 467) / 554]eval:  26%|████████████▉                                    | 80/304 [00:53<02:28,  1.51it/s, recall_0.3=(469, 470) / 557]eval:  27%|█████████████                                    | 81/304 [00:53<02:18,  1.61it/s, recall_0.3=(469, 470) / 557]eval:  27%|█████████████                                    | 81/304 [00:53<02:18,  1.61it/s, recall_0.3=(471, 472) / 559]eval:  27%|█████████████▏                                   | 82/304 [00:53<02:18,  1.61it/s, recall_0.3=(471, 472) / 559]eval:  27%|█████████████▏                                   | 82/304 [00:54<02:18,  1.61it/s, recall_0.3=(478, 479) / 566]eval:  27%|█████████████▍                                   | 83/304 [00:54<02:26,  1.51it/s, recall_0.3=(478, 479) / 566]eval:  27%|█████████████▍                                   | 83/304 [00:55<02:26,  1.51it/s, recall_0.3=(485, 486) / 576]eval:  28%|█████████████▌                                   | 84/304 [00:55<02:32,  1.45it/s, recall_0.3=(485, 486) / 576]eval:  28%|█████████████▌                                   | 84/304 [00:56<02:32,  1.45it/s, recall_0.3=(493, 494) / 586]eval:  28%|█████████████▋                                   | 85/304 [00:56<02:26,  1.50it/s, recall_0.3=(493, 494) / 586]eval:  28%|█████████████▋                                   | 85/304 [00:56<02:26,  1.50it/s, recall_0.3=(500, 501) / 593]eval:  28%|█████████████▊                                   | 86/304 [00:56<02:14,  1.62it/s, recall_0.3=(500, 501) / 593]eval:  28%|█████████████▊                                   | 86/304 [00:57<02:14,  1.62it/s, recall_0.3=(506, 507) / 600]eval:  29%|██████████████                                   | 87/304 [00:57<02:10,  1.66it/s, recall_0.3=(506, 507) / 600]eval:  29%|██████████████                                   | 87/304 [00:57<02:10,  1.66it/s, recall_0.3=(513, 514) / 608]eval:  29%|██████████████▏                                  | 88/304 [00:57<02:15,  1.59it/s, recall_0.3=(513, 514) / 608]eval:  29%|██████████████▏                                  | 88/304 [00:58<02:15,  1.59it/s, recall_0.3=(519, 520) / 614]eval:  29%|██████████████▎                                  | 89/304 [00:58<02:16,  1.57it/s, recall_0.3=(519, 520) / 614]eval:  29%|██████████████▎                                  | 89/304 [00:58<02:16,  1.57it/s, recall_0.3=(522, 523) / 617]eval:  30%|██████████████▌                                  | 90/304 [00:58<02:11,  1.63it/s, recall_0.3=(522, 523) / 617]eval:  30%|██████████████▌                                  | 90/304 [00:59<02:11,  1.63it/s, recall_0.3=(524, 525) / 619]eval:  30%|██████████████▋                                  | 91/304 [00:59<02:06,  1.69it/s, recall_0.3=(524, 525) / 619]eval:  30%|██████████████▋                                  | 91/304 [01:00<02:06,  1.69it/s, recall_0.3=(525, 526) / 621]eval:  30%|██████████████▊                                  | 92/304 [01:00<02:00,  1.76it/s, recall_0.3=(525, 526) / 621]eval:  30%|██████████████▊                                  | 92/304 [01:00<02:00,  1.76it/s, recall_0.3=(525, 526) / 623]eval:  31%|██████████████▉                                  | 93/304 [01:00<01:58,  1.78it/s, recall_0.3=(525, 526) / 623]eval:  31%|██████████████▉                                  | 93/304 [01:01<01:58,  1.78it/s, recall_0.3=(525, 526) / 623]eval:  31%|███████████████▏                                 | 94/304 [01:01<02:00,  1.74it/s, recall_0.3=(525, 526) / 623]eval:  31%|███████████████▏                                 | 94/304 [01:01<02:00,  1.74it/s, recall_0.3=(526, 527) / 625]eval:  31%|███████████████▎                                 | 95/304 [01:01<01:48,  1.93it/s, recall_0.3=(526, 527) / 625]eval:  31%|███████████████▎                                 | 95/304 [01:02<01:48,  1.93it/s, recall_0.3=(529, 530) / 628]eval:  32%|███████████████▍                                 | 96/304 [01:02<01:45,  1.98it/s, recall_0.3=(529, 530) / 628]eval:  32%|███████████████▍                                 | 96/304 [01:02<01:45,  1.98it/s, recall_0.3=(531, 532) / 631]eval:  32%|███████████████▋                                 | 97/304 [01:02<01:40,  2.06it/s, recall_0.3=(531, 532) / 631]eval:  32%|███████████████▋                                 | 97/304 [01:02<01:40,  2.06it/s, recall_0.3=(534, 535) / 635]eval:  32%|███████████████▊                                 | 98/304 [01:02<01:32,  2.24it/s, recall_0.3=(534, 535) / 635]eval:  32%|███████████████▊                                 | 98/304 [01:03<01:32,  2.24it/s, recall_0.3=(536, 537) / 637]eval:  33%|███████████████▉                                 | 99/304 [01:03<01:33,  2.19it/s, recall_0.3=(536, 537) / 637]eval:  33%|███████████████▉                                 | 99/304 [01:03<01:33,  2.19it/s, recall_0.3=(538, 539) / 639]eval:  33%|███████████████▊                                | 100/304 [01:03<01:28,  2.32it/s, recall_0.3=(538, 539) / 639]eval:  33%|███████████████▊                                | 100/304 [01:04<01:28,  2.32it/s, recall_0.3=(540, 541) / 641]eval:  33%|███████████████▉                                | 101/304 [01:04<01:29,  2.27it/s, recall_0.3=(540, 541) / 641]eval:  33%|███████████████▉                                | 101/304 [01:04<01:29,  2.27it/s, recall_0.3=(542, 543) / 643]eval:  34%|████████████████                                | 102/304 [01:04<01:24,  2.39it/s, recall_0.3=(542, 543) / 643]eval:  34%|████████████████                                | 102/304 [01:04<01:24,  2.39it/s, recall_0.3=(545, 546) / 647]eval:  34%|████████████████▎                               | 103/304 [01:04<01:17,  2.59it/s, recall_0.3=(545, 546) / 647]eval:  34%|████████████████▎                               | 103/304 [01:05<01:17,  2.59it/s, recall_0.3=(554, 555) / 660]eval:  34%|████████████████▍                               | 104/304 [01:05<01:12,  2.75it/s, recall_0.3=(554, 555) / 660]eval:  34%|████████████████▍                               | 104/304 [01:05<01:12,  2.75it/s, recall_0.3=(570, 571) / 686]eval:  35%|████████████████▌                               | 105/304 [01:05<01:11,  2.79it/s, recall_0.3=(570, 571) / 686]eval:  35%|████████████████▌                               | 105/304 [01:05<01:11,  2.79it/s, recall_0.3=(586, 587) / 710]eval:  35%|████████████████▋                               | 106/304 [01:05<01:12,  2.72it/s, recall_0.3=(586, 587) / 710]eval:  35%|████████████████▋                               | 106/304 [01:06<01:12,  2.72it/s, recall_0.3=(607, 608) / 734]eval:  35%|████████████████▉                               | 107/304 [01:06<01:11,  2.76it/s, recall_0.3=(607, 608) / 734]eval:  35%|████████████████▉                               | 107/304 [01:06<01:11,  2.76it/s, recall_0.3=(627, 628) / 759]eval:  36%|█████████████████                               | 108/304 [01:06<01:04,  3.06it/s, recall_0.3=(627, 628) / 759]eval:  36%|█████████████████                               | 108/304 [01:06<01:04,  3.06it/s, recall_0.3=(644, 645) / 782]eval:  36%|█████████████████▏                              | 109/304 [01:06<01:04,  3.03it/s, recall_0.3=(644, 645) / 782]eval:  36%|█████████████████▏                              | 109/304 [01:07<01:04,  3.03it/s, recall_0.3=(664, 665) / 808]eval:  36%|█████████████████▎                              | 110/304 [01:07<01:04,  2.99it/s, recall_0.3=(664, 665) / 808]eval:  36%|█████████████████▎                              | 110/304 [01:07<01:04,  2.99it/s, recall_0.3=(664, 665) / 808]eval:  37%|█████████████████▌                              | 111/304 [01:07<01:05,  2.96it/s, recall_0.3=(664, 665) / 808]eval:  37%|█████████████████▌                              | 111/304 [01:07<01:05,  2.96it/s, recall_0.3=(664, 665) / 808]eval:  37%|█████████████████▋                              | 112/304 [01:07<01:05,  2.93it/s, recall_0.3=(664, 665) / 808]eval:  37%|█████████████████▋                              | 112/304 [01:08<01:05,  2.93it/s, recall_0.3=(665, 666) / 810]eval:  37%|█████████████████▊                              | 113/304 [01:08<01:06,  2.88it/s, recall_0.3=(665, 666) / 810]eval:  37%|█████████████████▊                              | 113/304 [01:08<01:06,  2.88it/s, recall_0.3=(667, 668) / 812]eval:  38%|██████████████████                              | 114/304 [01:08<01:07,  2.80it/s, recall_0.3=(667, 668) / 812]eval:  38%|██████████████████                              | 114/304 [01:08<01:07,  2.80it/s, recall_0.3=(672, 673) / 818]eval:  38%|██████████████████▏                             | 115/304 [01:08<01:08,  2.74it/s, recall_0.3=(672, 673) / 818]eval:  38%|██████████████████▏                             | 115/304 [01:09<01:08,  2.74it/s, recall_0.3=(679, 680) / 825]eval:  38%|██████████████████▎                             | 116/304 [01:09<01:13,  2.55it/s, recall_0.3=(679, 680) / 825]eval:  38%|██████████████████▎                             | 116/304 [01:09<01:13,  2.55it/s, recall_0.3=(683, 684) / 829]eval:  38%|██████████████████▍                             | 117/304 [01:09<01:13,  2.54it/s, recall_0.3=(683, 684) / 829]eval:  38%|██████████████████▍                             | 117/304 [01:10<01:13,  2.54it/s, recall_0.3=(686, 687) / 833]eval:  39%|██████████████████▋                             | 118/304 [01:10<01:12,  2.55it/s, recall_0.3=(686, 687) / 833]eval:  39%|██████████████████▋                             | 118/304 [01:10<01:12,  2.55it/s, recall_0.3=(687, 688) / 835]eval:  39%|██████████████████▊                             | 119/304 [01:10<01:11,  2.60it/s, recall_0.3=(687, 688) / 835]eval:  39%|██████████████████▊                             | 119/304 [01:10<01:11,  2.60it/s, recall_0.3=(687, 688) / 835]eval:  39%|██████████████████▉                             | 120/304 [01:10<01:10,  2.63it/s, recall_0.3=(687, 688) / 835]eval:  39%|██████████████████▉                             | 120/304 [01:11<01:10,  2.63it/s, recall_0.3=(687, 688) / 835]eval:  40%|███████████████████                             | 121/304 [01:11<01:06,  2.76it/s, recall_0.3=(687, 688) / 835]eval:  40%|███████████████████                             | 121/304 [01:11<01:06,  2.76it/s, recall_0.3=(688, 689) / 837]eval:  40%|███████████████████▎                            | 122/304 [01:11<01:06,  2.74it/s, recall_0.3=(688, 689) / 837]eval:  40%|███████████████████▎                            | 122/304 [01:12<01:06,  2.74it/s, recall_0.3=(692, 693) / 842]eval:  40%|███████████████████▍                            | 123/304 [01:12<01:10,  2.55it/s, recall_0.3=(692, 693) / 842]eval:  40%|███████████████████▍                            | 123/304 [01:12<01:10,  2.55it/s, recall_0.3=(699, 700) / 849]eval:  41%|███████████████████▌                            | 124/304 [01:12<01:16,  2.36it/s, recall_0.3=(699, 700) / 849]eval:  41%|███████████████████▌                            | 124/304 [01:13<01:16,  2.36it/s, recall_0.3=(703, 704) / 854]eval:  41%|███████████████████▋                            | 125/304 [01:13<01:19,  2.26it/s, recall_0.3=(703, 704) / 854]eval:  41%|███████████████████▋                            | 125/304 [01:13<01:19,  2.26it/s, recall_0.3=(709, 710) / 860]eval:  41%|███████████████████▉                            | 126/304 [01:13<01:19,  2.24it/s, recall_0.3=(709, 710) / 860]eval:  41%|███████████████████▉                            | 126/304 [01:14<01:19,  2.24it/s, recall_0.3=(713, 714) / 864]eval:  42%|████████████████████                            | 127/304 [01:14<01:25,  2.06it/s, recall_0.3=(713, 714) / 864]eval:  42%|████████████████████                            | 127/304 [01:14<01:25,  2.06it/s, recall_0.3=(715, 716) / 868]eval:  42%|████████████████████▏                           | 128/304 [01:14<01:25,  2.06it/s, recall_0.3=(715, 716) / 868]eval:  42%|████████████████████▏                           | 128/304 [01:15<01:25,  2.06it/s, recall_0.3=(722, 723) / 875]eval:  42%|████████████████████▎                           | 129/304 [01:15<01:28,  1.98it/s, recall_0.3=(722, 723) / 875]eval:  42%|████████████████████▎                           | 129/304 [01:15<01:28,  1.98it/s, recall_0.3=(728, 729) / 881]eval:  43%|████████████████████▌                           | 130/304 [01:15<01:30,  1.93it/s, recall_0.3=(728, 729) / 881]eval:  43%|████████████████████▌                           | 130/304 [01:16<01:30,  1.93it/s, recall_0.3=(733, 734) / 886]eval:  43%|████████████████████▋                           | 131/304 [01:16<01:37,  1.77it/s, recall_0.3=(733, 734) / 886]eval:  43%|████████████████████▋                           | 131/304 [01:17<01:37,  1.77it/s, recall_0.3=(741, 742) / 894]eval:  43%|████████████████████▊                           | 132/304 [01:17<01:45,  1.63it/s, recall_0.3=(741, 742) / 894]eval:  43%|████████████████████▊                           | 132/304 [01:17<01:45,  1.63it/s, recall_0.3=(747, 748) / 900]eval:  44%|█████████████████████                           | 133/304 [01:17<01:51,  1.54it/s, recall_0.3=(747, 748) / 900]eval:  44%|█████████████████████                           | 133/304 [01:18<01:51,  1.54it/s, recall_0.3=(750, 751) / 903]eval:  44%|█████████████████████▏                          | 134/304 [01:18<01:56,  1.46it/s, recall_0.3=(750, 751) / 903]eval:  44%|█████████████████████▏                          | 134/304 [01:19<01:56,  1.46it/s, recall_0.3=(751, 752) / 905]eval:  44%|█████████████████████▎                          | 135/304 [01:19<01:54,  1.47it/s, recall_0.3=(751, 752) / 905]eval:  44%|█████████████████████▎                          | 135/304 [01:19<01:54,  1.47it/s, recall_0.3=(751, 752) / 905]eval:  45%|█████████████████████▍                          | 136/304 [01:19<01:51,  1.51it/s, recall_0.3=(751, 752) / 905]eval:  45%|█████████████████████▍                          | 136/304 [01:20<01:51,  1.51it/s, recall_0.3=(751, 752) / 908]eval:  45%|█████████████████████▋                          | 137/304 [01:20<01:45,  1.58it/s, recall_0.3=(751, 752) / 908]eval:  45%|█████████████████████▋                          | 137/304 [01:20<01:45,  1.58it/s, recall_0.3=(755, 756) / 912]eval:  45%|█████████████████████▊                          | 138/304 [01:20<01:36,  1.72it/s, recall_0.3=(755, 756) / 912]eval:  45%|█████████████████████▊                          | 138/304 [01:21<01:36,  1.72it/s, recall_0.3=(761, 762) / 918]eval:  46%|█████████████████████▉                          | 139/304 [01:21<01:33,  1.76it/s, recall_0.3=(761, 762) / 918]eval:  46%|█████████████████████▉                          | 139/304 [01:21<01:33,  1.76it/s, recall_0.3=(767, 768) / 924]eval:  46%|██████████████████████                          | 140/304 [01:21<01:30,  1.82it/s, recall_0.3=(767, 768) / 924]eval:  46%|██████████████████████                          | 140/304 [01:22<01:30,  1.82it/s, recall_0.3=(771, 772) / 930]eval:  46%|██████████████████████▎                         | 141/304 [01:22<01:26,  1.89it/s, recall_0.3=(771, 772) / 930]eval:  46%|██████████████████████▎                         | 141/304 [01:23<01:26,  1.89it/s, recall_0.3=(771, 772) / 930]eval:  47%|██████████████████████▍                         | 142/304 [01:23<01:26,  1.86it/s, recall_0.3=(771, 772) / 930]eval:  47%|██████████████████████▍                         | 142/304 [01:23<01:26,  1.86it/s, recall_0.3=(771, 772) / 930]eval:  47%|██████████████████████▌                         | 143/304 [01:23<01:22,  1.96it/s, recall_0.3=(771, 772) / 930]eval:  47%|██████████████████████▌                         | 143/304 [01:23<01:22,  1.96it/s, recall_0.3=(771, 772) / 930]eval:  47%|██████████████████████▋                         | 144/304 [01:24<01:24,  1.90it/s, recall_0.3=(771, 772) / 930]eval:  47%|██████████████████████▋                         | 144/304 [01:24<01:24,  1.90it/s, recall_0.3=(771, 772) / 930]eval:  48%|██████████████████████▉                         | 145/304 [01:24<01:20,  1.97it/s, recall_0.3=(771, 772) / 930]eval:  48%|██████████████████████▉                         | 145/304 [01:24<01:20,  1.97it/s, recall_0.3=(771, 772) / 930]eval:  48%|███████████████████████                         | 146/304 [01:24<01:18,  2.01it/s, recall_0.3=(771, 772) / 930]eval:  48%|███████████████████████                         | 146/304 [01:25<01:18,  2.01it/s, recall_0.3=(775, 776) / 936]eval:  48%|███████████████████████▏                        | 147/304 [01:25<01:27,  1.79it/s, recall_0.3=(775, 776) / 936]eval:  48%|███████████████████████▏                        | 147/304 [01:26<01:27,  1.79it/s, recall_0.3=(782, 784) / 947]eval:  49%|███████████████████████▎                        | 148/304 [01:26<01:36,  1.62it/s, recall_0.3=(782, 784) / 947]eval:  49%|███████████████████████▎                        | 148/304 [01:27<01:36,  1.62it/s, recall_0.3=(791, 793) / 960]eval:  49%|███████████████████████▌                        | 149/304 [01:27<01:36,  1.61it/s, recall_0.3=(791, 793) / 960]eval:  49%|███████████████████████▌                        | 149/304 [01:27<01:36,  1.61it/s, recall_0.3=(798, 800) / 970]eval:  49%|███████████████████████▋                        | 150/304 [01:27<01:42,  1.50it/s, recall_0.3=(798, 800) / 970]eval:  49%|███████████████████████▋                        | 150/304 [01:28<01:42,  1.50it/s, recall_0.3=(805, 807) / 981]eval:  50%|███████████████████████▊                        | 151/304 [01:28<01:40,  1.52it/s, recall_0.3=(805, 807) / 981]eval:  50%|███████████████████████▊                        | 151/304 [01:29<01:40,  1.52it/s, recall_0.3=(813, 816) / 992]eval:  50%|████████████████████████                        | 152/304 [01:29<01:42,  1.48it/s, recall_0.3=(813, 816) / 992]eval:  50%|███████████████████████▌                       | 152/304 [01:29<01:42,  1.48it/s, recall_0.3=(820, 823) / 1001]eval:  50%|███████████████████████▋                       | 153/304 [01:29<01:44,  1.45it/s, recall_0.3=(820, 823) / 1001]eval:  50%|███████████████████████▋                       | 153/304 [01:30<01:44,  1.45it/s, recall_0.3=(827, 830) / 1011]eval:  51%|███████████████████████▊                       | 154/304 [01:30<01:41,  1.47it/s, recall_0.3=(827, 830) / 1011]eval:  51%|███████████████████████▊                       | 154/304 [01:31<01:41,  1.47it/s, recall_0.3=(836, 839) / 1022]eval:  51%|███████████████████████▉                       | 155/304 [01:31<01:38,  1.52it/s, recall_0.3=(836, 839) / 1022]eval:  51%|███████████████████████▉                       | 155/304 [01:31<01:38,  1.52it/s, recall_0.3=(843, 846) / 1030]eval:  51%|████████████████████████                       | 156/304 [01:31<01:28,  1.68it/s, recall_0.3=(843, 846) / 1030]eval:  51%|████████████████████████                       | 156/304 [01:32<01:28,  1.68it/s, recall_0.3=(851, 854) / 1038]eval:  52%|████████████████████████▎                      | 157/304 [01:32<01:23,  1.76it/s, recall_0.3=(851, 854) / 1038]eval:  52%|████████████████████████▎                      | 157/304 [01:32<01:23,  1.76it/s, recall_0.3=(859, 862) / 1046]eval:  52%|████████████████████████▍                      | 158/304 [01:32<01:15,  1.94it/s, recall_0.3=(859, 862) / 1046]eval:  52%|████████████████████████▍                      | 158/304 [01:32<01:15,  1.94it/s, recall_0.3=(863, 866) / 1050]eval:  52%|████████████████████████▌                      | 159/304 [01:32<01:09,  2.10it/s, recall_0.3=(863, 866) / 1050]eval:  52%|████████████████████████▌                      | 159/304 [01:33<01:09,  2.10it/s, recall_0.3=(866, 869) / 1053]eval:  53%|████████████████████████▋                      | 160/304 [01:33<01:04,  2.22it/s, recall_0.3=(866, 869) / 1053]eval:  53%|████████████████████████▋                      | 160/304 [01:33<01:04,  2.22it/s, recall_0.3=(866, 869) / 1053]eval:  53%|████████████████████████▉                      | 161/304 [01:33<00:59,  2.42it/s, recall_0.3=(866, 869) / 1053]eval:  53%|████████████████████████▉                      | 161/304 [01:34<00:59,  2.42it/s, recall_0.3=(866, 869) / 1053]eval:  53%|█████████████████████████                      | 162/304 [01:34<00:58,  2.42it/s, recall_0.3=(866, 869) / 1053]eval:  53%|█████████████████████████                      | 162/304 [01:34<00:58,  2.42it/s, recall_0.3=(867, 870) / 1055]eval:  54%|█████████████████████████▏                     | 163/304 [01:34<00:58,  2.40it/s, recall_0.3=(867, 870) / 1055]eval:  54%|█████████████████████████▏                     | 163/304 [01:34<00:58,  2.40it/s, recall_0.3=(870, 873) / 1059]eval:  54%|█████████████████████████▎                     | 164/304 [01:34<00:57,  2.44it/s, recall_0.3=(870, 873) / 1059]eval:  54%|█████████████████████████▎                     | 164/304 [01:35<00:57,  2.44it/s, recall_0.3=(876, 879) / 1067]eval:  54%|█████████████████████████▌                     | 165/304 [01:35<00:55,  2.51it/s, recall_0.3=(876, 879) / 1067]eval:  54%|█████████████████████████▌                     | 165/304 [01:35<00:55,  2.51it/s, recall_0.3=(884, 887) / 1075]eval:  55%|█████████████████████████▋                     | 166/304 [01:35<00:57,  2.42it/s, recall_0.3=(884, 887) / 1075]eval:  55%|█████████████████████████▋                     | 166/304 [01:36<00:57,  2.42it/s, recall_0.3=(891, 894) / 1083]eval:  55%|█████████████████████████▊                     | 167/304 [01:36<00:56,  2.41it/s, recall_0.3=(891, 894) / 1083]eval:  55%|█████████████████████████▊                     | 167/304 [01:36<00:56,  2.41it/s, recall_0.3=(898, 901) / 1091]eval:  55%|█████████████████████████▉                     | 168/304 [01:36<00:55,  2.47it/s, recall_0.3=(898, 901) / 1091]eval:  55%|█████████████████████████▉                     | 168/304 [01:36<00:55,  2.47it/s, recall_0.3=(905, 908) / 1099]eval:  56%|██████████████████████████▏                    | 169/304 [01:36<00:57,  2.35it/s, recall_0.3=(905, 908) / 1099]eval:  56%|██████████████████████████▏                    | 169/304 [01:37<00:57,  2.35it/s, recall_0.3=(910, 913) / 1105]eval:  56%|██████████████████████████▎                    | 170/304 [01:37<01:00,  2.22it/s, recall_0.3=(910, 913) / 1105]eval:  56%|██████████████████████████▎                    | 170/304 [01:37<01:00,  2.22it/s, recall_0.3=(912, 915) / 1107]eval:  56%|██████████████████████████▍                    | 171/304 [01:37<01:01,  2.16it/s, recall_0.3=(912, 915) / 1107]eval:  56%|██████████████████████████▍                    | 171/304 [01:38<01:01,  2.16it/s, recall_0.3=(917, 920) / 1112]eval:  57%|██████████████████████████▌                    | 172/304 [01:38<00:59,  2.21it/s, recall_0.3=(917, 920) / 1112]eval:  57%|██████████████████████████▌                    | 172/304 [01:38<00:59,  2.21it/s, recall_0.3=(925, 928) / 1120]eval:  57%|██████████████████████████▋                    | 173/304 [01:38<01:00,  2.15it/s, recall_0.3=(925, 928) / 1120]eval:  57%|██████████████████████████▋                    | 173/304 [01:39<01:00,  2.15it/s, recall_0.3=(931, 934) / 1128]eval:  57%|██████████████████████████▉                    | 174/304 [01:39<00:56,  2.29it/s, recall_0.3=(931, 934) / 1128]eval:  57%|██████████████████████████▉                    | 174/304 [01:39<00:56,  2.29it/s, recall_0.3=(935, 938) / 1134]eval:  58%|███████████████████████████                    | 175/304 [01:39<00:54,  2.38it/s, recall_0.3=(935, 938) / 1134]eval:  58%|███████████████████████████                    | 175/304 [01:39<00:54,  2.38it/s, recall_0.3=(939, 942) / 1138]eval:  58%|███████████████████████████▏                   | 176/304 [01:39<00:52,  2.44it/s, recall_0.3=(939, 942) / 1138]eval:  58%|███████████████████████████▏                   | 176/304 [01:40<00:52,  2.44it/s, recall_0.3=(943, 946) / 1142]eval:  58%|███████████████████████████▎                   | 177/304 [01:40<00:53,  2.36it/s, recall_0.3=(943, 946) / 1142]eval:  58%|███████████████████████████▎                   | 177/304 [01:40<00:53,  2.36it/s, recall_0.3=(943, 946) / 1142]eval:  59%|███████████████████████████▌                   | 178/304 [01:40<00:52,  2.38it/s, recall_0.3=(943, 946) / 1142]eval:  59%|███████████████████████████▌                   | 178/304 [01:41<00:52,  2.38it/s, recall_0.3=(943, 946) / 1142]eval:  59%|███████████████████████████▋                   | 179/304 [01:41<00:52,  2.38it/s, recall_0.3=(943, 946) / 1142]eval:  59%|███████████████████████████▋                   | 179/304 [01:41<00:52,  2.38it/s, recall_0.3=(945, 948) / 1145]eval:  59%|███████████████████████████▊                   | 180/304 [01:41<00:54,  2.28it/s, recall_0.3=(945, 948) / 1145]eval:  59%|███████████████████████████▊                   | 180/304 [01:42<00:54,  2.28it/s, recall_0.3=(947, 950) / 1147]eval:  60%|███████████████████████████▉                   | 181/304 [01:42<00:51,  2.37it/s, recall_0.3=(947, 950) / 1147]eval:  60%|███████████████████████████▉                   | 181/304 [01:42<00:51,  2.37it/s, recall_0.3=(949, 952) / 1149]eval:  60%|████████████████████████████▏                  | 182/304 [01:42<00:52,  2.31it/s, recall_0.3=(949, 952) / 1149]eval:  60%|████████████████████████████▏                  | 182/304 [01:43<00:52,  2.31it/s, recall_0.3=(949, 952) / 1149]eval:  60%|████████████████████████████▎                  | 183/304 [01:43<00:51,  2.33it/s, recall_0.3=(949, 952) / 1149]eval:  60%|████████████████████████████▎                  | 183/304 [01:43<00:51,  2.33it/s, recall_0.3=(949, 952) / 1149]eval:  61%|████████████████████████████▍                  | 184/304 [01:43<00:56,  2.13it/s, recall_0.3=(949, 952) / 1149]eval:  61%|████████████████████████████▍                  | 184/304 [01:44<00:56,  2.13it/s, recall_0.3=(949, 952) / 1149]eval:  61%|████████████████████████████▌                  | 185/304 [01:44<00:59,  1.99it/s, recall_0.3=(949, 952) / 1149]eval:  61%|████████████████████████████▌                  | 185/304 [01:44<00:59,  1.99it/s, recall_0.3=(949, 952) / 1149]eval:  61%|████████████████████████████▊                  | 186/304 [01:44<00:57,  2.07it/s, recall_0.3=(949, 952) / 1149]eval:  61%|████████████████████████████▊                  | 186/304 [01:44<00:57,  2.07it/s, recall_0.3=(949, 952) / 1149]eval:  62%|████████████████████████████▉                  | 187/304 [01:44<00:53,  2.18it/s, recall_0.3=(949, 952) / 1149]eval:  62%|████████████████████████████▉                  | 187/304 [01:45<00:53,  2.18it/s, recall_0.3=(949, 952) / 1149]eval:  62%|█████████████████████████████                  | 188/304 [01:45<00:53,  2.16it/s, recall_0.3=(949, 952) / 1149]eval:  62%|█████████████████████████████                  | 188/304 [01:45<00:53,  2.16it/s, recall_0.3=(949, 952) / 1149]eval:  62%|█████████████████████████████▏                 | 189/304 [01:45<00:54,  2.11it/s, recall_0.3=(949, 952) / 1149]eval:  62%|█████████████████████████████▏                 | 189/304 [01:46<00:54,  2.11it/s, recall_0.3=(949, 952) / 1149]eval:  62%|█████████████████████████████▍                 | 190/304 [01:46<00:51,  2.20it/s, recall_0.3=(949, 952) / 1149]eval:  62%|█████████████████████████████▍                 | 190/304 [01:46<00:51,  2.20it/s, recall_0.3=(949, 952) / 1149]eval:  63%|█████████████████████████████▌                 | 191/304 [01:46<00:55,  2.03it/s, recall_0.3=(949, 952) / 1149]eval:  63%|█████████████████████████████▌                 | 191/304 [01:47<00:55,  2.03it/s, recall_0.3=(953, 956) / 1153]eval:  63%|█████████████████████████████▋                 | 192/304 [01:47<00:55,  2.03it/s, recall_0.3=(953, 956) / 1153]eval:  63%|█████████████████████████████▋                 | 192/304 [01:47<00:55,  2.03it/s, recall_0.3=(957, 960) / 1157]eval:  63%|█████████████████████████████▊                 | 193/304 [01:47<00:56,  1.97it/s, recall_0.3=(957, 960) / 1157]eval:  63%|█████████████████████████████▊                 | 193/304 [01:48<00:56,  1.97it/s, recall_0.3=(961, 964) / 1161]eval:  64%|█████████████████████████████▉                 | 194/304 [01:48<00:56,  1.95it/s, recall_0.3=(961, 964) / 1161]eval:  64%|█████████████████████████████▉                 | 194/304 [01:49<00:56,  1.95it/s, recall_0.3=(965, 968) / 1165]eval:  64%|██████████████████████████████▏                | 195/304 [01:49<00:55,  1.97it/s, recall_0.3=(965, 968) / 1165]eval:  64%|██████████████████████████████▏                | 195/304 [01:49<00:55,  1.97it/s, recall_0.3=(968, 971) / 1169]eval:  64%|██████████████████████████████▎                | 196/304 [01:49<00:54,  1.99it/s, recall_0.3=(968, 971) / 1169]eval:  64%|██████████████████████████████▎                | 196/304 [01:49<00:54,  1.99it/s, recall_0.3=(970, 973) / 1171]eval:  65%|██████████████████████████████▍                | 197/304 [01:49<00:52,  2.04it/s, recall_0.3=(970, 973) / 1171]eval:  65%|██████████████████████████████▍                | 197/304 [01:50<00:52,  2.04it/s, recall_0.3=(971, 974) / 1173]eval:  65%|██████████████████████████████▌                | 198/304 [01:50<00:50,  2.08it/s, recall_0.3=(971, 974) / 1173]eval:  65%|██████████████████████████████▌                | 198/304 [01:50<00:50,  2.08it/s, recall_0.3=(971, 974) / 1173]eval:  65%|██████████████████████████████▊                | 199/304 [01:50<00:49,  2.11it/s, recall_0.3=(971, 974) / 1173]eval:  65%|██████████████████████████████▊                | 199/304 [01:51<00:49,  2.11it/s, recall_0.3=(973, 976) / 1175]eval:  66%|██████████████████████████████▉                | 200/304 [01:51<00:49,  2.12it/s, recall_0.3=(973, 976) / 1175]eval:  66%|██████████████████████████████▉                | 200/304 [01:51<00:49,  2.12it/s, recall_0.3=(975, 978) / 1177]eval:  66%|███████████████████████████████                | 201/304 [01:51<00:44,  2.32it/s, recall_0.3=(975, 978) / 1177]eval:  66%|███████████████████████████████                | 201/304 [01:52<00:44,  2.32it/s, recall_0.3=(977, 980) / 1179]eval:  66%|███████████████████████████████▏               | 202/304 [01:52<00:42,  2.38it/s, recall_0.3=(977, 980) / 1179]eval:  66%|███████████████████████████████▏               | 202/304 [01:52<00:42,  2.38it/s, recall_0.3=(979, 982) / 1181]eval:  67%|███████████████████████████████▍               | 203/304 [01:52<00:43,  2.34it/s, recall_0.3=(979, 982) / 1181]eval:  67%|███████████████████████████████▍               | 203/304 [01:53<00:43,  2.34it/s, recall_0.3=(981, 984) / 1183]eval:  67%|███████████████████████████████▌               | 204/304 [01:53<00:44,  2.23it/s, recall_0.3=(981, 984) / 1183]eval:  67%|███████████████████████████████▌               | 204/304 [01:53<00:44,  2.23it/s, recall_0.3=(981, 984) / 1183]eval:  67%|███████████████████████████████▋               | 205/304 [01:53<00:44,  2.22it/s, recall_0.3=(981, 984) / 1183]eval:  67%|███████████████████████████████▋               | 205/304 [01:54<00:44,  2.22it/s, recall_0.3=(981, 984) / 1183]eval:  68%|███████████████████████████████▊               | 206/304 [01:54<00:46,  2.11it/s, recall_0.3=(981, 984) / 1183]eval:  68%|███████████████████████████████▊               | 206/304 [01:54<00:46,  2.11it/s, recall_0.3=(981, 984) / 1183]eval:  68%|████████████████████████████████               | 207/304 [01:54<00:45,  2.11it/s, recall_0.3=(981, 984) / 1183]eval:  68%|████████████████████████████████               | 207/304 [01:54<00:45,  2.11it/s, recall_0.3=(981, 984) / 1183]eval:  68%|████████████████████████████████▏              | 208/304 [01:54<00:43,  2.22it/s, recall_0.3=(981, 984) / 1183]eval:  68%|████████████████████████████████▏              | 208/304 [01:55<00:43,  2.22it/s, recall_0.3=(988, 991) / 1198]eval:  69%|████████████████████████████████▎              | 209/304 [01:55<00:42,  2.22it/s, recall_0.3=(988, 991) / 1198]eval:  69%|███████████████████████████████▋              | 209/304 [01:55<00:42,  2.22it/s, recall_0.3=(997, 1000) / 1216]eval:  69%|███████████████████████████████▊              | 210/304 [01:55<00:41,  2.29it/s, recall_0.3=(997, 1000) / 1216]eval:  69%|███████████████████████████████              | 210/304 [01:56<00:41,  2.29it/s, recall_0.3=(1006, 1009) / 1229]eval:  69%|███████████████████████████████▏             | 211/304 [01:56<00:43,  2.14it/s, recall_0.3=(1006, 1009) / 1229]eval:  69%|███████████████████████████████▏             | 211/304 [01:56<00:43,  2.14it/s, recall_0.3=(1018, 1021) / 1242]eval:  70%|███████████████████████████████▍             | 212/304 [01:56<00:42,  2.19it/s, recall_0.3=(1018, 1021) / 1242]eval:  70%|███████████████████████████████▍             | 212/304 [01:57<00:42,  2.19it/s, recall_0.3=(1027, 1030) / 1251]eval:  70%|███████████████████████████████▌             | 213/304 [01:57<00:44,  2.03it/s, recall_0.3=(1027, 1030) / 1251]eval:  70%|███████████████████████████████▌             | 213/304 [01:57<00:44,  2.03it/s, recall_0.3=(1037, 1040) / 1262]eval:  70%|███████████████████████████████▋             | 214/304 [01:57<00:45,  1.99it/s, recall_0.3=(1037, 1040) / 1262]eval:  70%|███████████████████████████████▋             | 214/304 [01:58<00:45,  1.99it/s, recall_0.3=(1045, 1048) / 1271]eval:  71%|███████████████████████████████▊             | 215/304 [01:58<00:43,  2.03it/s, recall_0.3=(1045, 1048) / 1271]eval:  71%|███████████████████████████████▊             | 215/304 [01:58<00:43,  2.03it/s, recall_0.3=(1054, 1057) / 1282]eval:  71%|███████████████████████████████▉             | 216/304 [01:58<00:40,  2.18it/s, recall_0.3=(1054, 1057) / 1282]eval:  71%|███████████████████████████████▉             | 216/304 [01:59<00:40,  2.18it/s, recall_0.3=(1066, 1069) / 1294]eval:  71%|████████████████████████████████             | 217/304 [01:59<00:38,  2.26it/s, recall_0.3=(1066, 1069) / 1294]eval:  71%|████████████████████████████████             | 217/304 [01:59<00:38,  2.26it/s, recall_0.3=(1076, 1078) / 1304]eval:  72%|████████████████████████████████▎            | 218/304 [01:59<00:36,  2.38it/s, recall_0.3=(1076, 1078) / 1304]eval:  72%|████████████████████████████████▎            | 218/304 [01:59<00:36,  2.38it/s, recall_0.3=(1080, 1082) / 1309]eval:  72%|████████████████████████████████▍            | 219/304 [01:59<00:36,  2.31it/s, recall_0.3=(1080, 1082) / 1309]eval:  72%|████████████████████████████████▍            | 219/304 [02:00<00:36,  2.31it/s, recall_0.3=(1080, 1082) / 1309]eval:  72%|████████████████████████████████▌            | 220/304 [02:00<00:35,  2.39it/s, recall_0.3=(1080, 1082) / 1309]eval:  72%|████████████████████████████████▌            | 220/304 [02:00<00:35,  2.39it/s, recall_0.3=(1080, 1082) / 1309]eval:  73%|████████████████████████████████▋            | 221/304 [02:00<00:35,  2.31it/s, recall_0.3=(1080, 1082) / 1309]eval:  73%|████████████████████████████████▋            | 221/304 [02:01<00:35,  2.31it/s, recall_0.3=(1080, 1082) / 1309]eval:  73%|████████████████████████████████▊            | 222/304 [02:01<00:37,  2.20it/s, recall_0.3=(1080, 1082) / 1309]eval:  73%|████████████████████████████████▊            | 222/304 [02:01<00:37,  2.20it/s, recall_0.3=(1082, 1084) / 1311]eval:  73%|█████████████████████████████████            | 223/304 [02:01<00:36,  2.21it/s, recall_0.3=(1082, 1084) / 1311]eval:  73%|█████████████████████████████████            | 223/304 [02:02<00:36,  2.21it/s, recall_0.3=(1084, 1086) / 1313]eval:  74%|█████████████████████████████████▏           | 224/304 [02:02<00:36,  2.18it/s, recall_0.3=(1084, 1086) / 1313]eval:  74%|█████████████████████████████████▏           | 224/304 [02:02<00:36,  2.18it/s, recall_0.3=(1085, 1087) / 1315]eval:  74%|█████████████████████████████████▎           | 225/304 [02:02<00:38,  2.07it/s, recall_0.3=(1085, 1087) / 1315]eval:  74%|█████████████████████████████████▎           | 225/304 [02:03<00:38,  2.07it/s, recall_0.3=(1085, 1087) / 1319]eval:  74%|█████████████████████████████████▍           | 226/304 [02:03<00:36,  2.11it/s, recall_0.3=(1085, 1087) / 1319]eval:  74%|█████████████████████████████████▍           | 226/304 [02:03<00:36,  2.11it/s, recall_0.3=(1099, 1101) / 1336]eval:  75%|█████████████████████████████████▌           | 227/304 [02:03<00:35,  2.18it/s, recall_0.3=(1099, 1101) / 1336]eval:  75%|█████████████████████████████████▌           | 227/304 [02:03<00:35,  2.18it/s, recall_0.3=(1109, 1111) / 1348]eval:  75%|█████████████████████████████████▊           | 228/304 [02:03<00:33,  2.24it/s, recall_0.3=(1109, 1111) / 1348]eval:  75%|█████████████████████████████████▊           | 228/304 [02:04<00:33,  2.24it/s, recall_0.3=(1115, 1117) / 1355]eval:  75%|█████████████████████████████████▉           | 229/304 [02:04<00:35,  2.11it/s, recall_0.3=(1115, 1117) / 1355]eval:  75%|█████████████████████████████████▉           | 229/304 [02:05<00:35,  2.11it/s, recall_0.3=(1121, 1123) / 1361]eval:  76%|██████████████████████████████████           | 230/304 [02:05<00:36,  2.02it/s, recall_0.3=(1121, 1123) / 1361]eval:  76%|██████████████████████████████████           | 230/304 [02:05<00:36,  2.02it/s, recall_0.3=(1126, 1128) / 1367]eval:  76%|██████████████████████████████████▏          | 231/304 [02:05<00:36,  2.02it/s, recall_0.3=(1126, 1128) / 1367]eval:  76%|██████████████████████████████████▏          | 231/304 [02:06<00:36,  2.02it/s, recall_0.3=(1128, 1130) / 1370]eval:  76%|██████████████████████████████████▎          | 232/304 [02:06<00:35,  2.05it/s, recall_0.3=(1128, 1130) / 1370]eval:  76%|██████████████████████████████████▎          | 232/304 [02:06<00:35,  2.05it/s, recall_0.3=(1128, 1130) / 1370]eval:  77%|██████████████████████████████████▍          | 233/304 [02:06<00:33,  2.14it/s, recall_0.3=(1128, 1130) / 1370]eval:  77%|██████████████████████████████████▍          | 233/304 [02:06<00:33,  2.14it/s, recall_0.3=(1128, 1130) / 1370]eval:  77%|██████████████████████████████████▋          | 234/304 [02:06<00:32,  2.13it/s, recall_0.3=(1128, 1130) / 1370]eval:  77%|██████████████████████████████████▋          | 234/304 [02:07<00:32,  2.13it/s, recall_0.3=(1128, 1130) / 1370]eval:  77%|██████████████████████████████████▊          | 235/304 [02:07<00:34,  1.99it/s, recall_0.3=(1128, 1130) / 1370]eval:  77%|██████████████████████████████████▊          | 235/304 [02:08<00:34,  1.99it/s, recall_0.3=(1128, 1130) / 1370]eval:  78%|██████████████████████████████████▉          | 236/304 [02:08<00:34,  1.99it/s, recall_0.3=(1128, 1130) / 1370]eval:  78%|██████████████████████████████████▉          | 236/304 [02:08<00:34,  1.99it/s, recall_0.3=(1128, 1130) / 1370]eval:  78%|███████████████████████████████████          | 237/304 [02:08<00:33,  1.97it/s, recall_0.3=(1128, 1130) / 1370]eval:  78%|███████████████████████████████████          | 237/304 [02:09<00:33,  1.97it/s, recall_0.3=(1128, 1130) / 1370]eval:  78%|███████████████████████████████████▏         | 238/304 [02:09<00:33,  1.96it/s, recall_0.3=(1128, 1130) / 1370]eval:  78%|███████████████████████████████████▏         | 238/304 [02:09<00:33,  1.96it/s, recall_0.3=(1128, 1130) / 1370]eval:  79%|███████████████████████████████████▍         | 239/304 [02:09<00:34,  1.86it/s, recall_0.3=(1128, 1130) / 1370]eval:  79%|███████████████████████████████████▍         | 239/304 [02:10<00:34,  1.86it/s, recall_0.3=(1128, 1130) / 1370]eval:  79%|███████████████████████████████████▌         | 240/304 [02:10<00:35,  1.81it/s, recall_0.3=(1128, 1130) / 1370]eval:  79%|███████████████████████████████████▌         | 240/304 [02:10<00:35,  1.81it/s, recall_0.3=(1129, 1131) / 1372]eval:  79%|███████████████████████████████████▋         | 241/304 [02:10<00:36,  1.74it/s, recall_0.3=(1129, 1131) / 1372]eval:  79%|███████████████████████████████████▋         | 241/304 [02:11<00:36,  1.74it/s, recall_0.3=(1131, 1133) / 1374]eval:  80%|███████████████████████████████████▊         | 242/304 [02:11<00:37,  1.66it/s, recall_0.3=(1131, 1133) / 1374]eval:  80%|███████████████████████████████████▊         | 242/304 [02:12<00:37,  1.66it/s, recall_0.3=(1133, 1135) / 1376]eval:  80%|███████████████████████████████████▉         | 243/304 [02:12<00:37,  1.61it/s, recall_0.3=(1133, 1135) / 1376]eval:  80%|███████████████████████████████████▉         | 243/304 [02:12<00:37,  1.61it/s, recall_0.3=(1134, 1136) / 1378]eval:  80%|████████████████████████████████████         | 244/304 [02:12<00:36,  1.64it/s, recall_0.3=(1134, 1136) / 1378]eval:  80%|████████████████████████████████████         | 244/304 [02:13<00:36,  1.64it/s, recall_0.3=(1136, 1138) / 1382]eval:  81%|████████████████████████████████████▎        | 245/304 [02:13<00:36,  1.62it/s, recall_0.3=(1136, 1138) / 1382]eval:  81%|████████████████████████████████████▎        | 245/304 [02:14<00:36,  1.62it/s, recall_0.3=(1141, 1143) / 1387]eval:  81%|████████████████████████████████████▍        | 246/304 [02:14<00:37,  1.53it/s, recall_0.3=(1141, 1143) / 1387]eval:  81%|████████████████████████████████████▍        | 246/304 [02:14<00:37,  1.53it/s, recall_0.3=(1147, 1149) / 1393]eval:  81%|████████████████████████████████████▌        | 247/304 [02:14<00:37,  1.53it/s, recall_0.3=(1147, 1149) / 1393]eval:  81%|████████████████████████████████████▌        | 247/304 [02:15<00:37,  1.53it/s, recall_0.3=(1152, 1154) / 1401]eval:  82%|████████████████████████████████████▋        | 248/304 [02:15<00:37,  1.50it/s, recall_0.3=(1152, 1154) / 1401]eval:  82%|████████████████████████████████████▋        | 248/304 [02:16<00:37,  1.50it/s, recall_0.3=(1158, 1160) / 1408]eval:  82%|████████████████████████████████████▊        | 249/304 [02:16<00:37,  1.47it/s, recall_0.3=(1158, 1160) / 1408]eval:  82%|████████████████████████████████████▊        | 249/304 [02:16<00:37,  1.47it/s, recall_0.3=(1163, 1165) / 1413]eval:  82%|█████████████████████████████████████        | 250/304 [02:16<00:34,  1.55it/s, recall_0.3=(1163, 1165) / 1413]eval:  82%|█████████████████████████████████████        | 250/304 [02:17<00:34,  1.55it/s, recall_0.3=(1166, 1168) / 1416]eval:  83%|█████████████████████████████████████▏       | 251/304 [02:17<00:32,  1.65it/s, recall_0.3=(1166, 1168) / 1416]eval:  83%|█████████████████████████████████████▏       | 251/304 [02:17<00:32,  1.65it/s, recall_0.3=(1167, 1169) / 1418]eval:  83%|█████████████████████████████████████▎       | 252/304 [02:17<00:28,  1.86it/s, recall_0.3=(1167, 1169) / 1418]eval:  83%|█████████████████████████████████████▎       | 252/304 [02:18<00:28,  1.86it/s, recall_0.3=(1169, 1171) / 1420]eval:  83%|█████████████████████████████████████▍       | 253/304 [02:18<00:26,  1.92it/s, recall_0.3=(1169, 1171) / 1420]eval:  83%|█████████████████████████████████████▍       | 253/304 [02:18<00:26,  1.92it/s, recall_0.3=(1169, 1171) / 1420]eval:  84%|█████████████████████████████████████▌       | 254/304 [02:18<00:25,  1.93it/s, recall_0.3=(1169, 1171) / 1420]eval:  84%|█████████████████████████████████████▌       | 254/304 [02:19<00:25,  1.93it/s, recall_0.3=(1171, 1173) / 1422]eval:  84%|█████████████████████████████████████▋       | 255/304 [02:19<00:24,  1.98it/s, recall_0.3=(1171, 1173) / 1422]eval:  84%|█████████████████████████████████████▋       | 255/304 [02:19<00:24,  1.98it/s, recall_0.3=(1173, 1175) / 1424]eval:  84%|█████████████████████████████████████▉       | 256/304 [02:19<00:24,  1.99it/s, recall_0.3=(1173, 1175) / 1424]eval:  84%|█████████████████████████████████████▉       | 256/304 [02:20<00:24,  1.99it/s, recall_0.3=(1173, 1175) / 1424]eval:  85%|██████████████████████████████████████       | 257/304 [02:20<00:23,  1.99it/s, recall_0.3=(1173, 1175) / 1424]eval:  85%|██████████████████████████████████████       | 257/304 [02:20<00:23,  1.99it/s, recall_0.3=(1173, 1175) / 1424]eval:  85%|██████████████████████████████████████▏      | 258/304 [02:20<00:23,  1.94it/s, recall_0.3=(1173, 1175) / 1424]eval:  85%|██████████████████████████████████████▏      | 258/304 [02:21<00:23,  1.94it/s, recall_0.3=(1173, 1175) / 1424]eval:  85%|██████████████████████████████████████▎      | 259/304 [02:21<00:22,  1.99it/s, recall_0.3=(1173, 1175) / 1424]eval:  85%|██████████████████████████████████████▎      | 259/304 [02:21<00:22,  1.99it/s, recall_0.3=(1174, 1176) / 1426]eval:  86%|██████████████████████████████████████▍      | 260/304 [02:21<00:21,  2.04it/s, recall_0.3=(1174, 1176) / 1426]eval:  86%|██████████████████████████████████████▍      | 260/304 [02:22<00:21,  2.04it/s, recall_0.3=(1178, 1180) / 1430]eval:  86%|██████████████████████████████████████▋      | 261/304 [02:22<00:20,  2.10it/s, recall_0.3=(1178, 1180) / 1430]eval:  86%|██████████████████████████████████████▋      | 261/304 [02:22<00:20,  2.10it/s, recall_0.3=(1179, 1181) / 1432]eval:  86%|██████████████████████████████████████▊      | 262/304 [02:22<00:19,  2.18it/s, recall_0.3=(1179, 1181) / 1432]eval:  86%|██████████████████████████████████████▊      | 262/304 [02:22<00:19,  2.18it/s, recall_0.3=(1179, 1181) / 1432]eval:  87%|██████████████████████████████████████▉      | 263/304 [02:22<00:17,  2.28it/s, recall_0.3=(1179, 1181) / 1432]eval:  87%|██████████████████████████████████████▉      | 263/304 [02:23<00:17,  2.28it/s, recall_0.3=(1179, 1181) / 1432]eval:  87%|███████████████████████████████████████      | 264/304 [02:23<00:18,  2.13it/s, recall_0.3=(1179, 1181) / 1432]eval:  87%|███████████████████████████████████████      | 264/304 [02:23<00:18,  2.13it/s, recall_0.3=(1179, 1181) / 1432]eval:  87%|███████████████████████████████████████▏     | 265/304 [02:23<00:18,  2.11it/s, recall_0.3=(1179, 1181) / 1432]eval:  87%|███████████████████████████████████████▏     | 265/304 [02:24<00:18,  2.11it/s, recall_0.3=(1179, 1181) / 1432]eval:  88%|███████████████████████████████████████▍     | 266/304 [02:24<00:17,  2.12it/s, recall_0.3=(1179, 1181) / 1432]eval:  88%|███████████████████████████████████████▍     | 266/304 [02:24<00:17,  2.12it/s, recall_0.3=(1179, 1181) / 1432]eval:  88%|███████████████████████████████████████▌     | 267/304 [02:24<00:18,  1.97it/s, recall_0.3=(1179, 1181) / 1432]eval:  88%|███████████████████████████████████████▌     | 267/304 [02:25<00:18,  1.97it/s, recall_0.3=(1182, 1184) / 1435]eval:  88%|███████████████████████████████████████▋     | 268/304 [02:25<00:17,  2.02it/s, recall_0.3=(1182, 1184) / 1435]eval:  88%|███████████████████████████████████████▋     | 268/304 [02:26<00:17,  2.02it/s, recall_0.3=(1186, 1188) / 1439]eval:  88%|███████████████████████████████████████▊     | 269/304 [02:26<00:18,  1.90it/s, recall_0.3=(1186, 1188) / 1439]eval:  88%|███████████████████████████████████████▊     | 269/304 [02:26<00:18,  1.90it/s, recall_0.3=(1190, 1192) / 1443]eval:  89%|███████████████████████████████████████▉     | 270/304 [02:26<00:17,  1.93it/s, recall_0.3=(1190, 1192) / 1443]eval:  89%|███████████████████████████████████████▉     | 270/304 [02:26<00:17,  1.93it/s, recall_0.3=(1191, 1193) / 1445]eval:  89%|████████████████████████████████████████     | 271/304 [02:26<00:16,  2.01it/s, recall_0.3=(1191, 1193) / 1445]eval:  89%|████████████████████████████████████████     | 271/304 [02:27<00:16,  2.01it/s, recall_0.3=(1193, 1195) / 1449]eval:  89%|████████████████████████████████████████▎    | 272/304 [02:27<00:16,  1.95it/s, recall_0.3=(1193, 1195) / 1449]eval:  89%|████████████████████████████████████████▎    | 272/304 [02:28<00:16,  1.95it/s, recall_0.3=(1196, 1198) / 1453]eval:  90%|████████████████████████████████████████▍    | 273/304 [02:28<00:16,  1.88it/s, recall_0.3=(1196, 1198) / 1453]eval:  90%|████████████████████████████████████████▍    | 273/304 [02:28<00:16,  1.88it/s, recall_0.3=(1200, 1202) / 1457]eval:  90%|████████████████████████████████████████▌    | 274/304 [02:28<00:15,  1.89it/s, recall_0.3=(1200, 1202) / 1457]eval:  90%|████████████████████████████████████████▌    | 274/304 [02:29<00:15,  1.89it/s, recall_0.3=(1203, 1205) / 1460]eval:  90%|████████████████████████████████████████▋    | 275/304 [02:29<00:15,  1.82it/s, recall_0.3=(1203, 1205) / 1460]eval:  90%|████████████████████████████████████████▋    | 275/304 [02:29<00:15,  1.82it/s, recall_0.3=(1205, 1207) / 1462]eval:  91%|████████████████████████████████████████▊    | 276/304 [02:29<00:14,  1.87it/s, recall_0.3=(1205, 1207) / 1462]eval:  91%|████████████████████████████████████████▊    | 276/304 [02:30<00:14,  1.87it/s, recall_0.3=(1207, 1209) / 1464]eval:  91%|█████████████████████████████████████████    | 277/304 [02:30<00:14,  1.87it/s, recall_0.3=(1207, 1209) / 1464]eval:  91%|█████████████████████████████████████████    | 277/304 [02:30<00:14,  1.87it/s, recall_0.3=(1207, 1209) / 1464]eval:  91%|█████████████████████████████████████████▏   | 278/304 [02:30<00:13,  1.97it/s, recall_0.3=(1207, 1209) / 1464]eval:  91%|█████████████████████████████████████████▏   | 278/304 [02:31<00:13,  1.97it/s, recall_0.3=(1207, 1209) / 1464]eval:  92%|█████████████████████████████████████████▎   | 279/304 [02:31<00:12,  1.94it/s, recall_0.3=(1207, 1209) / 1464]eval:  92%|█████████████████████████████████████████▎   | 279/304 [02:31<00:12,  1.94it/s, recall_0.3=(1207, 1209) / 1464]eval:  92%|█████████████████████████████████████████▍   | 280/304 [02:31<00:13,  1.83it/s, recall_0.3=(1207, 1209) / 1464]eval:  92%|█████████████████████████████████████████▍   | 280/304 [02:32<00:13,  1.83it/s, recall_0.3=(1207, 1209) / 1464]eval:  92%|█████████████████████████████████████████▌   | 281/304 [02:32<00:11,  1.92it/s, recall_0.3=(1207, 1209) / 1464]eval:  92%|█████████████████████████████████████████▌   | 281/304 [02:32<00:11,  1.92it/s, recall_0.3=(1207, 1209) / 1464]eval:  93%|█████████████████████████████████████████▋   | 282/304 [02:32<00:11,  1.94it/s, recall_0.3=(1207, 1209) / 1464]eval:  93%|█████████████████████████████████████████▋   | 282/304 [02:33<00:11,  1.94it/s, recall_0.3=(1207, 1209) / 1464]eval:  93%|█████████████████████████████████████████▉   | 283/304 [02:33<00:10,  2.10it/s, recall_0.3=(1207, 1209) / 1464]eval:  93%|█████████████████████████████████████████▉   | 283/304 [02:33<00:10,  2.10it/s, recall_0.3=(1209, 1211) / 1469]eval:  93%|██████████████████████████████████████████   | 284/304 [02:33<00:08,  2.25it/s, recall_0.3=(1209, 1211) / 1469]eval:  93%|██████████████████████████████████████████   | 284/304 [02:34<00:08,  2.25it/s, recall_0.3=(1219, 1221) / 1482]eval:  94%|██████████████████████████████████████████▏  | 285/304 [02:34<00:08,  2.25it/s, recall_0.3=(1219, 1221) / 1482]eval:  94%|██████████████████████████████████████████▏  | 285/304 [02:34<00:08,  2.25it/s, recall_0.3=(1232, 1234) / 1496]eval:  94%|██████████████████████████████████████████▎  | 286/304 [02:34<00:07,  2.44it/s, recall_0.3=(1232, 1234) / 1496]eval:  94%|██████████████████████████████████████████▎  | 286/304 [02:34<00:07,  2.44it/s, recall_0.3=(1242, 1244) / 1509]eval:  94%|██████████████████████████████████████████▍  | 287/304 [02:34<00:06,  2.46it/s, recall_0.3=(1242, 1244) / 1509]eval:  94%|██████████████████████████████████████████▍  | 287/304 [02:35<00:06,  2.46it/s, recall_0.3=(1252, 1254) / 1522]eval:  95%|██████████████████████████████████████████▋  | 288/304 [02:35<00:06,  2.36it/s, recall_0.3=(1252, 1254) / 1522]eval:  95%|██████████████████████████████████████████▋  | 288/304 [02:35<00:06,  2.36it/s, recall_0.3=(1259, 1261) / 1529]eval:  95%|██████████████████████████████████████████▊  | 289/304 [02:35<00:06,  2.15it/s, recall_0.3=(1259, 1261) / 1529]eval:  95%|██████████████████████████████████████████▊  | 289/304 [02:36<00:06,  2.15it/s, recall_0.3=(1269, 1271) / 1543]eval:  95%|██████████████████████████████████████████▉  | 290/304 [02:36<00:06,  2.05it/s, recall_0.3=(1269, 1271) / 1543]eval:  95%|██████████████████████████████████████████▉  | 290/304 [02:36<00:06,  2.05it/s, recall_0.3=(1280, 1282) / 1559]eval:  96%|███████████████████████████████████████████  | 291/304 [02:36<00:06,  2.06it/s, recall_0.3=(1280, 1282) / 1559]eval:  96%|███████████████████████████████████████████  | 291/304 [02:37<00:06,  2.06it/s, recall_0.3=(1280, 1282) / 1559]eval:  96%|███████████████████████████████████████████▏ | 292/304 [02:37<00:05,  2.28it/s, recall_0.3=(1280, 1282) / 1559]eval:  96%|███████████████████████████████████████████▏ | 292/304 [02:37<00:05,  2.28it/s, recall_0.3=(1280, 1282) / 1559]eval:  96%|███████████████████████████████████████████▎ | 293/304 [02:37<00:04,  2.56it/s, recall_0.3=(1280, 1282) / 1559]eval:  96%|███████████████████████████████████████████▎ | 293/304 [02:37<00:04,  2.56it/s, recall_0.3=(1281, 1283) / 1561]eval:  97%|███████████████████████████████████████████▌ | 294/304 [02:37<00:03,  2.87it/s, recall_0.3=(1281, 1283) / 1561]eval:  97%|███████████████████████████████████████████▌ | 294/304 [02:37<00:03,  2.87it/s, recall_0.3=(1283, 1285) / 1563]eval:  97%|███████████████████████████████████████████▋ | 295/304 [02:37<00:02,  3.14it/s, recall_0.3=(1283, 1285) / 1563]eval:  97%|███████████████████████████████████████████▋ | 295/304 [02:38<00:02,  3.14it/s, recall_0.3=(1284, 1286) / 1565]eval:  97%|███████████████████████████████████████████▊ | 296/304 [02:38<00:02,  3.63it/s, recall_0.3=(1284, 1286) / 1565]eval:  97%|███████████████████████████████████████████▊ | 296/304 [02:38<00:02,  3.63it/s, recall_0.3=(1284, 1286) / 1565]eval:  98%|███████████████████████████████████████████▉ | 297/304 [02:38<00:01,  3.76it/s, recall_0.3=(1284, 1286) / 1565]eval:  98%|███████████████████████████████████████████▉ | 297/304 [02:38<00:01,  3.76it/s, recall_0.3=(1284, 1286) / 1565]eval:  98%|████████████████████████████████████████████ | 298/304 [02:38<00:01,  4.16it/s, recall_0.3=(1284, 1286) / 1565]eval:  98%|████████████████████████████████████████████ | 298/304 [02:38<00:01,  4.16it/s, recall_0.3=(1284, 1286) / 1565]eval:  98%|████████████████████████████████████████████▎| 299/304 [02:38<00:01,  4.34it/s, recall_0.3=(1284, 1286) / 1565]eval:  98%|████████████████████████████████████████████▎| 299/304 [02:38<00:01,  4.34it/s, recall_0.3=(1284, 1286) / 1565]eval:  99%|████████████████████████████████████████████▍| 300/304 [02:38<00:00,  4.74it/s, recall_0.3=(1284, 1286) / 1565]eval:  99%|████████████████████████████████████████████▍| 300/304 [02:39<00:00,  4.74it/s, recall_0.3=(1284, 1286) / 1565]eval:  99%|████████████████████████████████████████████▌| 301/304 [02:39<00:00,  4.30it/s, recall_0.3=(1284, 1286) / 1565]eval:  99%|████████████████████████████████████████████▌| 301/304 [02:39<00:00,  4.30it/s, recall_0.3=(1284, 1286) / 1565]eval:  99%|████████████████████████████████████████████▋| 302/304 [02:39<00:00,  4.69it/s, recall_0.3=(1284, 1286) / 1565]eval:  99%|████████████████████████████████████████████▋| 302/304 [02:39<00:00,  4.69it/s, recall_0.3=(1288, 1290) / 1570]eval: 100%|████████████████████████████████████████████▊| 303/304 [02:39<00:00,  4.87it/s, recall_0.3=(1288, 1290) / 1570]eval: 100%|████████████████████████████████████████████▊| 303/304 [02:39<00:00,  4.87it/s, recall_0.3=(1291, 1294) / 1574]eval: 100%|█████████████████████████████████████████████| 304/304 [02:39<00:00,  4.93it/s, recall_0.3=(1291, 1294) / 1574]eval: 100%|█████████████████████████████████████████████| 304/304 [02:39<00:00,  1.90it/s, recall_0.3=(1291, 1294) / 1574]
2023-03-01 02:10:20,187   INFO  *************** Performance of EPOCH 60 *****************
2023-03-01 02:10:20,188   INFO  Generate label finished(sec_per_example: 0.0658 second).
2023-03-01 02:10:20,188   INFO  recall_roi_0.3: 0.819219
2023-03-01 02:10:20,189   INFO  recall_rcnn_0.3: 0.819862
2023-03-01 02:10:20,189   INFO  recall_roi_0.5: 0.743050
2023-03-01 02:10:20,190   INFO  recall_rcnn_0.5: 0.769404
2023-03-01 02:10:20,190   INFO  recall_roi_0.7: 0.389844
2023-03-01 02:10:20,191   INFO  recall_rcnn_0.7: 0.533665
2023-03-01 02:10:20,194   INFO  Average predicted number of objects(2432 samples): 4.727
2023-03-01 02:10:25,997   INFO  Car IoU 0.7:
RANGE 00-30   30-50   50-80   00-80 
BEV:  69.089, 70.114, 30.961, 60.832
3D :  57.459, 40.219, 10.744, 41.513
Car IoU 0.5:
RANGE 00-30   30-50   50-80   00-80 
BEV:  84.457, 79.272, 61.915, 79.734
3D :  84.347, 76.708, 51.168, 75.026
Car IoU 0.7:
69.1 / 57.5, 70.1 / 40.2, 31.0 / 10.7, 60.8 / 41.5
Car IoU 0.5:
84.5 / 84.3, 79.3 / 76.7, 61.9 / 51.2, 79.7 / 75.0

Pedestrian IoU 0.7:
RANGE 00-30   30-50   50-80   00-80 
BEV:  32.185, 27.274, 19.043, 24.071
3D :  28.651, 21.973, 15.507, 19.852
Pedestrian IoU 0.5:
RANGE 00-30   30-50   50-80   00-80 
BEV:  41.574, 32.064, 28.955, 30.791
3D :  41.141, 31.952, 28.946, 30.345
Pedestrian IoU 0.7:
32.2 / 28.7, 27.3 / 22.0, 19.0 / 15.5, 24.1 / 19.9
Pedestrian IoU 0.5:
41.6 / 41.1, 32.1 / 32.0, 29.0 / 28.9, 30.8 / 30.3


2023-03-01 02:10:26,000   INFO  Result is save to /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5/default/eval/eval_with_train/epoch_60/val
2023-03-01 02:10:26,000   INFO  ****************Evaluation done.*****************
2023-03-01 02:10:26,038   INFO  Epoch 60 has been evaluated
Wait 30 seconds for next check (progress: 0.0 / 0 minutes): /home/tz98/projects/continual-DA/downstream/OpenPCDet/output/lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5/default/ckpt 2023-03-01 02:10:56,072   INFO  **********************End evaluation lyft_models/pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5(default)**********************
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:         eval/eval_with_train/tensorboard_val/Car_3d_iou0.5/00-30_R40 ▁▅█
wandb:         eval/eval_with_train/tensorboard_val/Car_3d_iou0.5/00-80_R40 ▁▅█
wandb:         eval/eval_with_train/tensorboard_val/Car_3d_iou0.5/30-50_R40 ▁▆█
wandb:         eval/eval_with_train/tensorboard_val/Car_3d_iou0.5/50-80_R40 ▆▁█
wandb:         eval/eval_with_train/tensorboard_val/Car_3d_iou0.7/00-30_R40 ▁█▅
wandb:         eval/eval_with_train/tensorboard_val/Car_3d_iou0.7/00-80_R40 ▁██
wandb:         eval/eval_with_train/tensorboard_val/Car_3d_iou0.7/30-50_R40 ▁▆█
wandb:         eval/eval_with_train/tensorboard_val/Car_3d_iou0.7/50-80_R40 █▁▆
wandb:        eval/eval_with_train/tensorboard_val/Car_bev_iou0.5/00-30_R40 ▁██
wandb:        eval/eval_with_train/tensorboard_val/Car_bev_iou0.5/00-80_R40 ▁▄█
wandb:        eval/eval_with_train/tensorboard_val/Car_bev_iou0.5/30-50_R40 ▁▆█
wandb:        eval/eval_with_train/tensorboard_val/Car_bev_iou0.5/50-80_R40 ▁▁█
wandb:        eval/eval_with_train/tensorboard_val/Car_bev_iou0.7/00-30_R40 ▁█▂
wandb:        eval/eval_with_train/tensorboard_val/Car_bev_iou0.7/00-80_R40 ▁▆█
wandb:        eval/eval_with_train/tensorboard_val/Car_bev_iou0.7/30-50_R40 ▁▄█
wandb:        eval/eval_with_train/tensorboard_val/Car_bev_iou0.7/50-80_R40 █▁▃
wandb:  eval/eval_with_train/tensorboard_val/Pedestrian_3d_iou0.5/00-30_R40 ▁▅█
wandb:  eval/eval_with_train/tensorboard_val/Pedestrian_3d_iou0.5/00-80_R40 ▁█▇
wandb:  eval/eval_with_train/tensorboard_val/Pedestrian_3d_iou0.5/30-50_R40 ▁█▂
wandb:  eval/eval_with_train/tensorboard_val/Pedestrian_3d_iou0.5/50-80_R40 ▁▅█
wandb:  eval/eval_with_train/tensorboard_val/Pedestrian_3d_iou0.7/00-30_R40 ▁▆█
wandb:  eval/eval_with_train/tensorboard_val/Pedestrian_3d_iou0.7/00-80_R40 ▁▇█
wandb:  eval/eval_with_train/tensorboard_val/Pedestrian_3d_iou0.7/30-50_R40 ▁█▄
wandb:  eval/eval_with_train/tensorboard_val/Pedestrian_3d_iou0.7/50-80_R40 ▁▄█
wandb: eval/eval_with_train/tensorboard_val/Pedestrian_bev_iou0.5/00-30_R40 ▁▅█
wandb: eval/eval_with_train/tensorboard_val/Pedestrian_bev_iou0.5/00-80_R40 ▁██
wandb: eval/eval_with_train/tensorboard_val/Pedestrian_bev_iou0.5/30-50_R40 ▁█▂
wandb: eval/eval_with_train/tensorboard_val/Pedestrian_bev_iou0.5/50-80_R40 ▁▅█
wandb: eval/eval_with_train/tensorboard_val/Pedestrian_bev_iou0.7/00-30_R40 ▁▆█
wandb: eval/eval_with_train/tensorboard_val/Pedestrian_bev_iou0.7/00-80_R40 ▁▇█
wandb: eval/eval_with_train/tensorboard_val/Pedestrian_bev_iou0.7/30-50_R40 ▁█▄
wandb: eval/eval_with_train/tensorboard_val/Pedestrian_bev_iou0.7/50-80_R40 ▁██
wandb:                     eval/eval_with_train/tensorboard_val/global_step ▁▅█
wandb:                 eval/eval_with_train/tensorboard_val/recall/rcnn_0.3 ▁▆█
wandb:                 eval/eval_with_train/tensorboard_val/recall/rcnn_0.5 ▁▅█
wandb:                 eval/eval_with_train/tensorboard_val/recall/rcnn_0.7 ▁▁█
wandb:                  eval/eval_with_train/tensorboard_val/recall/roi_0.3 ▁▆█
wandb:                  eval/eval_with_train/tensorboard_val/recall/roi_0.5 ▁▃█
wandb:                  eval/eval_with_train/tensorboard_val/recall/roi_0.7 ▁▆█
wandb:                                                          global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:                                              meta_data/learning_rate ███▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:                                               train/higher_part_loss ▄▂▃▃▂▁▅▆▄▇▃▂▄▃▂█▁▃▂▂▂▂▃▃▃▂▃▂▂▁▂▅▂▆▄▂▃▂▂▂
wandb:                                                train/imbalanced_loss ▄▂▃▃▆▁▅▅▄█▃▂▃▂▃▆▁▂▂▁▂▂▂▂▃▃▃▄▂▁▃▅▂▅▃▂▃▂▄▂
wandb:                                                           train/loss ▇▇▅▃█▅▄▃▅▅▄▂▄▁▃▃▅▂▂▂▄▆▁▁▂▃▃▄▃▂▃▂▂▂▂▁▃▁▄▃
wandb:                                                train/lower_part_loss ▅▄▄▃█▃▃▄▃█▅▁▄▃▅▃▂▃▃▂▃▃▂▁▂▆▃▆▄▁▃▅▂▃▃▃▃▂▆▂
wandb:                                                        train/p2_loss ▅▃▄▃▇▃▄▄▃█▅▁▄▃▅▄▂▃▂▂▃▃▂▁▂▆▃▅▄▁▃▅▂▃▃▃▃▂▅▂
wandb:                                                 train/point_loss_box ▅█▂▄▅▅▃▂▆▃▂▂▄▂▃▂▆▂▁▃▄▄▂▂▃▃▂▃▃▄▂▁▃▂▂▂▄▂▂▄
wandb:                                                 train/point_loss_cls ▄▃▂▂▄▆▃▃▄▃▂▁▃▁▃▂▂▅▁▃█▃▁▂▂▃▁█▂▆▁▂▆▁▃▂▄▂▂▄
wandb:                                       train/point_loss_cls_margin_p2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                                  train/point_pos_num ▃▁▂▆▂▁▆▃▆▃▂█▃▃▂▆▁▂▄▂▁▁▅▂▃▂▅▅▃▂▃█▄▆▆▃▂▂▃▃
wandb:                                               train/point_total_loss ▄▃▂▂▄▆▃▃▄▃▂▁▃▁▃▂▂▅▁▃█▃▁▂▂▃▁█▂▆▁▂▆▁▃▂▄▂▂▄
wandb:                                                      train/rcnn_loss ▇▄█▃▇▅▃▄▄▃▃▅▃▂▂▃▅▃▃▃▃▇▃▃▄▂▃▃▃▃▅▁▃▂▂▁▂▂▄▄
wandb:                                                  train/rcnn_loss_cls ▅▄▆▂▇▆▅▅▆▅▄▆▃▁▃▆▅▅▅▃▅█▃▃▄▄▆▄▄▄▅▁▃▁▃▂▃▃▆▅
wandb:                                               train/rcnn_loss_corner ▇▆▇▆▇▅▆▅▅▄▂▆▆▃▂▂█▃▅▄▅▄▂▆▆▃▆▄▂▃▃▄▄▅▅▁▅▄▃▄
wandb:                                                  train/rcnn_loss_reg █▄█▄▆▄▂▃▂▂▃▃▃▃▂▁▄▂▂▃▂▆▃▃▃▁▁▃▃▃▆▂▃▃▁▂▂▁▂▄
wandb: 
wandb: Run summary:
wandb:         eval/eval_with_train/tensorboard_val/Car_3d_iou0.5/00-30_R40 84.34651
wandb:         eval/eval_with_train/tensorboard_val/Car_3d_iou0.5/00-80_R40 75.02553
wandb:         eval/eval_with_train/tensorboard_val/Car_3d_iou0.5/30-50_R40 76.70817
wandb:         eval/eval_with_train/tensorboard_val/Car_3d_iou0.5/50-80_R40 51.16806
wandb:         eval/eval_with_train/tensorboard_val/Car_3d_iou0.7/00-30_R40 57.45891
wandb:         eval/eval_with_train/tensorboard_val/Car_3d_iou0.7/00-80_R40 41.51343
wandb:         eval/eval_with_train/tensorboard_val/Car_3d_iou0.7/30-50_R40 40.21889
wandb:         eval/eval_with_train/tensorboard_val/Car_3d_iou0.7/50-80_R40 10.74381
wandb:        eval/eval_with_train/tensorboard_val/Car_bev_iou0.5/00-30_R40 84.45662
wandb:        eval/eval_with_train/tensorboard_val/Car_bev_iou0.5/00-80_R40 79.73357
wandb:        eval/eval_with_train/tensorboard_val/Car_bev_iou0.5/30-50_R40 79.27161
wandb:        eval/eval_with_train/tensorboard_val/Car_bev_iou0.5/50-80_R40 61.9155
wandb:        eval/eval_with_train/tensorboard_val/Car_bev_iou0.7/00-30_R40 69.08875
wandb:        eval/eval_with_train/tensorboard_val/Car_bev_iou0.7/00-80_R40 60.83179
wandb:        eval/eval_with_train/tensorboard_val/Car_bev_iou0.7/30-50_R40 70.11386
wandb:        eval/eval_with_train/tensorboard_val/Car_bev_iou0.7/50-80_R40 30.96081
wandb:  eval/eval_with_train/tensorboard_val/Pedestrian_3d_iou0.5/00-30_R40 41.1408
wandb:  eval/eval_with_train/tensorboard_val/Pedestrian_3d_iou0.5/00-80_R40 30.34513
wandb:  eval/eval_with_train/tensorboard_val/Pedestrian_3d_iou0.5/30-50_R40 31.95175
wandb:  eval/eval_with_train/tensorboard_val/Pedestrian_3d_iou0.5/50-80_R40 28.94637
wandb:  eval/eval_with_train/tensorboard_val/Pedestrian_3d_iou0.7/00-30_R40 28.65077
wandb:  eval/eval_with_train/tensorboard_val/Pedestrian_3d_iou0.7/00-80_R40 19.85229
wandb:  eval/eval_with_train/tensorboard_val/Pedestrian_3d_iou0.7/30-50_R40 21.97318
wandb:  eval/eval_with_train/tensorboard_val/Pedestrian_3d_iou0.7/50-80_R40 15.50692
wandb: eval/eval_with_train/tensorboard_val/Pedestrian_bev_iou0.5/00-30_R40 41.57416
wandb: eval/eval_with_train/tensorboard_val/Pedestrian_bev_iou0.5/00-80_R40 30.79074
wandb: eval/eval_with_train/tensorboard_val/Pedestrian_bev_iou0.5/30-50_R40 32.06393
wandb: eval/eval_with_train/tensorboard_val/Pedestrian_bev_iou0.5/50-80_R40 28.95543
wandb: eval/eval_with_train/tensorboard_val/Pedestrian_bev_iou0.7/00-30_R40 32.18469
wandb: eval/eval_with_train/tensorboard_val/Pedestrian_bev_iou0.7/00-80_R40 24.07109
wandb: eval/eval_with_train/tensorboard_val/Pedestrian_bev_iou0.7/30-50_R40 27.27358
wandb: eval/eval_with_train/tensorboard_val/Pedestrian_bev_iou0.7/50-80_R40 19.04321
wandb:                     eval/eval_with_train/tensorboard_val/global_step 60
wandb:                 eval/eval_with_train/tensorboard_val/recall/rcnn_0.3 0.81986
wandb:                 eval/eval_with_train/tensorboard_val/recall/rcnn_0.5 0.7694
wandb:                 eval/eval_with_train/tensorboard_val/recall/rcnn_0.7 0.53367
wandb:                  eval/eval_with_train/tensorboard_val/recall/roi_0.3 0.81922
wandb:                  eval/eval_with_train/tensorboard_val/recall/roi_0.5 0.74305
wandb:                  eval/eval_with_train/tensorboard_val/recall/roi_0.7 0.38984
wandb:                                                          global_step 89100
wandb:                                              meta_data/learning_rate 0.0
wandb:                                               train/higher_part_loss 0.01746
wandb:                                                train/imbalanced_loss 0.19467
wandb:                                                           train/loss 0.72652
wandb:                                                train/lower_part_loss 0.40973
wandb:                                                        train/p2_loss 0.4272
wandb:                                                 train/point_loss_box 0.08396
wandb:                                                 train/point_loss_cls 0.00689
wandb:                                       train/point_loss_cls_margin_p2 0.0
wandb:                                                  train/point_pos_num 3081.0
wandb:                                               train/point_total_loss 0.00689
wandb:                                                      train/rcnn_loss 0.20846
wandb:                                                  train/rcnn_loss_cls 0.0938
wandb:                                               train/rcnn_loss_corner 0.01684
wandb:                                                  train/rcnn_loss_reg 0.09783
wandb: 
wandb: Synced lyft_models_pointrcnn_hindsight_p2_squashlevel_balancethresh_0.5_default: https://wandb.ai/travis10/pointrcnn_hindsight_p2_balancethresh_0.5_2/runs/bmk5jchx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)
wandb: Find logs at: ./wandb/run-20230228_161448-bmk5jchx/logs
INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.
INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish
/home/tz98/anaconda3/envs/continual-da/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:70: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.009096860885620117 seconds
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 0, "group_rank": 0, "worker_id": "2269739", "role": "default", "hostname": "nikola-compute-16.cs.cornell.edu", "state": "SUCCEEDED", "total_run_time": 35849, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [0], \"role_rank\": [0], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 1, "group_rank": 0, "worker_id": "2269740", "role": "default", "hostname": "nikola-compute-16.cs.cornell.edu", "state": "SUCCEEDED", "total_run_time": 35849, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [1], \"role_rank\": [1], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 2, "group_rank": 0, "worker_id": "2269741", "role": "default", "hostname": "nikola-compute-16.cs.cornell.edu", "state": "SUCCEEDED", "total_run_time": 35849, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [2], \"role_rank\": [2], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 3, "group_rank": 0, "worker_id": "2269742", "role": "default", "hostname": "nikola-compute-16.cs.cornell.edu", "state": "SUCCEEDED", "total_run_time": 35849, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [3], \"role_rank\": [3], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "AGENT", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": null, "group_rank": 0, "worker_id": null, "role": "default", "hostname": "nikola-compute-16.cs.cornell.edu", "state": "SUCCEEDED", "total_run_time": 35849, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\"}", "agent_restarts": 0}}
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
